{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VLSP_RE_model_GPU_dropout_clipgrad.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HsVFPOEqKivl",
        "YmLDKiKvqMvj",
        "rbbwIE69LJGt",
        "3HoxrF8WKupX",
        "fD22vnF7K4Ta",
        "InJpM7aDEtHB",
        "eCOWz9EfFPzn",
        "CmeM-JyXcOKO",
        "WPuSYwKCBYRu",
        "MZFgdq1PBbLl",
        "JcwMQApng86X",
        "IADdZhElb4D4",
        "Fc2MsmAt4zDF",
        "9pQSd9DT2nAR",
        "EAeHqITIgWdI",
        "7nFiNJVV5DTf",
        "-0Pwkh5W6wZ4",
        "yoKdd-zY66Jc",
        "5xfu-7oPFyIA",
        "SuL9lddpF3eS",
        "OBh9YcvMeghQ",
        "WRaOZpRFeghS",
        "J1fwk7ckeghS",
        "WM60o1G9eghS",
        "-2w44XoqKy_P",
        "k7SbTS2ol2bC"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d7f00da78bf4a35b98eb42551454ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c6e00c25d184732984eb4f161467538",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_821e311883d942e0b2180b69ee1b552b",
              "IPY_MODEL_15bdaf4a33d440fd88ab0488822edf99"
            ]
          }
        },
        "0c6e00c25d184732984eb4f161467538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "821e311883d942e0b2180b69ee1b552b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4db21fd4c0674c71962f5442ac94d281",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fc417b825d64da68ac40858a782deef"
          }
        },
        "15bdaf4a33d440fd88ab0488822edf99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_263df059f87a4150a8fca099ad6067e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/557 [00:00&lt;00:00, 1.89kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afd2538138724373900eaeb1688efc36"
          }
        },
        "4db21fd4c0674c71962f5442ac94d281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fc417b825d64da68ac40858a782deef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "263df059f87a4150a8fca099ad6067e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afd2538138724373900eaeb1688efc36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d004fe82ffb54950842e3683f45a309b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a73fbf27691f4f5289c44827473d39ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_433a8c5175904673921361eeb8bfd1ba",
              "IPY_MODEL_dec43ca8bb29462e91bb43d0e9ffa978"
            ]
          }
        },
        "a73fbf27691f4f5289c44827473d39ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "433a8c5175904673921361eeb8bfd1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1305cccaccf6479d96e09db5c005129c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542923308,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542923308,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb6b1d045aef47e99f9b418def4d0169"
          }
        },
        "dec43ca8bb29462e91bb43d0e9ffa978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_346844a9be4f4ad188fe618f881f97f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 543M/543M [00:19&lt;00:00, 27.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b628fc67f254f2681523e7c5487c501"
          }
        },
        "1305cccaccf6479d96e09db5c005129c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb6b1d045aef47e99f9b418def4d0169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "346844a9be4f4ad188fe618f881f97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b628fc67f254f2681523e7c5487c501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d4a5d444df64f63ac64fe7584abf918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5032d3c7e2304bb1bac5cf7e8dd10c72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ad7137a1031403092e96267fae4d24b",
              "IPY_MODEL_2b0c545137bc40089039d5d1015d8b69"
            ]
          }
        },
        "5032d3c7e2304bb1bac5cf7e8dd10c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ad7137a1031403092e96267fae4d24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4114fe8078014918ae5708dd85c796b9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62c0689e8e504d0faf0b01eab120ce55"
          }
        },
        "2b0c545137bc40089039d5d1015d8b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43aa4d7c474144b1a57173cfd8d1e693",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 895k/895k [00:01&lt;00:00, 544kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce72904d84c04769b5137f66e79c7f73"
          }
        },
        "4114fe8078014918ae5708dd85c796b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62c0689e8e504d0faf0b01eab120ce55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43aa4d7c474144b1a57173cfd8d1e693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce72904d84c04769b5137f66e79c7f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bddeeb58fc7a4b628a1d8d8e4606fb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8f8002c48cd4d3b926ed85db70ebb78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb8a88fab00d40c8b07451fb61042e03",
              "IPY_MODEL_7eb0ab1f07c34319a3b57213c52b1332"
            ]
          }
        },
        "d8f8002c48cd4d3b926ed85db70ebb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb8a88fab00d40c8b07451fb61042e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6958d23cc3ae48849c07b67ecba633f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8488973986942d8952a61359447d156"
          }
        },
        "7eb0ab1f07c34319a3b57213c52b1332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf95b4b7083b46939f8cd24b3ff9a434",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 1.92MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae4f8237097f4350bbeab107c0da65e6"
          }
        },
        "6958d23cc3ae48849c07b67ecba633f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8488973986942d8952a61359447d156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf95b4b7083b46939f8cd24b3ff9a434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae4f8237097f4350bbeab107c0da65e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7a1671d0c0942be898144f641a3ed2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_296423fb5efa40cf85745233ab577aee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_878eae72d87f44c5a6ab1780ec8c9269",
              "IPY_MODEL_ce6743197a0a4079be034d281145fb8f"
            ]
          }
        },
        "296423fb5efa40cf85745233ab577aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "878eae72d87f44c5a6ab1780ec8c9269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9216513b21e47bfbda01a5c3719f435",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0b964f51f24542ac84c52f7c4af45b"
          }
        },
        "ce6743197a0a4079be034d281145fb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3749cca31f1946caadb28688e9a4ca01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:35&lt;00:00, 14.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37ad6e4238244db5a9d3afda80aeab92"
          }
        },
        "d9216513b21e47bfbda01a5c3719f435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0b964f51f24542ac84c52f7c4af45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3749cca31f1946caadb28688e9a4ca01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37ad6e4238244db5a9d3afda80aeab92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41dc90e15bcd4b97a2cb4f5bdf465fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d257cba9d5c4a108647cb05cd904cf7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e179b041303643739798dfda57722b64",
              "IPY_MODEL_d70aaeda98444f55b1b497a62a633d21"
            ]
          }
        },
        "2d257cba9d5c4a108647cb05cd904cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e179b041303643739798dfda57722b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a2a5c7ab676c42e29bd8af517c7fb4e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2244861551,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2244861551,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19b49917d2b74af9a82023ba82d769d7"
          }
        },
        "d70aaeda98444f55b1b497a62a633d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b8e40e3349d4648932f2253025891bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24G/2.24G [00:27&lt;00:00, 80.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3de39172d5fc4362965ea32ff6450466"
          }
        },
        "a2a5c7ab676c42e29bd8af517c7fb4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19b49917d2b74af9a82023ba82d769d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b8e40e3349d4648932f2253025891bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3de39172d5fc4362965ea32ff6450466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7012c91beb9548e78be43a7960c27eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e60446ae7734a2cbeeea429b65ff3d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_907ecc2709e24f7d829dec1f581b2467",
              "IPY_MODEL_edae3026e7414ab28a6439feba02d4ff"
            ]
          }
        },
        "1e60446ae7734a2cbeeea429b65ff3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "907ecc2709e24f7d829dec1f581b2467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16196fbd2c1e4f289788caf18374a3f5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f09a5358d8a4651b6b0d069ea914ec9"
          }
        },
        "edae3026e7414ab28a6439feba02d4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dc477952e814770aac51ae024ec07fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:03&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23a138725d914d3fad90b14c74be7979"
          }
        },
        "16196fbd2c1e4f289788caf18374a3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f09a5358d8a4651b6b0d069ea914ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dc477952e814770aac51ae024ec07fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23a138725d914d3fad90b14c74be7979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbOntuVkYZ7"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBXHW6YDkJGo",
        "outputId": "5389ce9f-1047-44f8-ae9f-b660e7d6fdb1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utwsxFqrEZ32"
      },
      "source": [
        "Output from VLSP2020_RE_extract_[training, dev].ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i008g3mMQjV",
        "outputId": "ce8a8963-a9c7-4083-8d8f-02c3fc0ef119"
      },
      "source": [
        "!ls \"/gdrive/MyDrive/VLSP2020_RE/json_data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev_data.json  train_data.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-e5X6WSNPUk"
      },
      "source": [
        "!cp -i \"/gdrive/MyDrive/VLSP2020_RE/json_data/train_data.json\" train_data.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mln1Z7CQNHk9"
      },
      "source": [
        "!cp -i \"/gdrive/MyDrive/VLSP2020_RE/json_data/dev_data.json\" dev_data.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2MrBvz3A0wk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVFPOEqKivl"
      },
      "source": [
        "# Install Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmLDKiKvqMvj"
      },
      "source": [
        "## Intsall Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpLCC4CRqP2A"
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbbwIE69LJGt"
      },
      "source": [
        "## Install Huggingface Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wOcO4VKUgl",
        "outputId": "1e9df2af-64e5-48d1-f4a6-291f68a79d39"
      },
      "source": [
        "# new command in huggingface v4.x has some anoy change. so better use old version for now\n",
        "# https://github.com/huggingface/transformers/releases\n",
        "\n",
        "!pip install transformers==3.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 30.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 27.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 19.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 13.6MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 15.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 14.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 14.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 14.2MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 14.2MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.8)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (4.41.1)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 63.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (50.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=63d6660f483c6a4348376f479f34e9fcc25201184d8cdd71338b687f21472983\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HoxrF8WKupX"
      },
      "source": [
        "## Install VNCoreNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYXTRsYRKoJn",
        "outputId": "b64674c3-5ac5-4aaf-f36d-69becdfeb709"
      },
      "source": [
        "# Install the vncorenlp python wrapper\n",
        "!pip install vncorenlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.11.8)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=d1b077fd2cb6b371e11e38da834efe6bd823a1b2d4732e40db1c98385c11423d\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G95nbje5KxnD",
        "outputId": "f9cb45e0-8ff8-4b9d-802c-816e51f0c0bb"
      },
      "source": [
        "# Download VnCoreNLP-1.1.1.jar & all of its  component (i.e. RDRSegmenter, pos, ner, deprel) \n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!mkdir -p vncorenlp/models/dep\n",
        "!mkdir -p vncorenlp/models/ner\n",
        "!mkdir -p vncorenlp/models/postagger\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/dep/vi-dep.xz\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n",
        "\n",
        "\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "\n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "\n",
        "!mv vi-dep.xz vncorenlp/models/dep/\n",
        "\n",
        "!mv vi-500brownclusters.xz vncorenlp/models/ner/\n",
        "!mv vi-ner.xz vncorenlp/models/ner/\n",
        "!mv vi-pretrainedembeddings.xz vncorenlp/models/ner/\n",
        "\n",
        "!mv vi-tagger vncorenlp/models/postagger/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 18:17:39--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412575 (26M) [application/octet-stream]\n",
            "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
            "\n",
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   100MB/s    in 0.3s    \n",
            "\n",
            "2020-12-06 18:17:40 (100 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
            "\n",
            "--2020-12-06 18:17:40--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 526544 (514K) [application/octet-stream]\n",
            "Saving to: ‘vi-vocab’\n",
            "\n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-12-06 18:17:40 (17.4 MB/s) - ‘vi-vocab’ saved [526544/526544]\n",
            "\n",
            "--2020-12-06 18:17:40--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128508 (125K) [text/plain]\n",
            "Saving to: ‘wordsegmenter.rdr’\n",
            "\n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2020-12-06 18:17:41 (16.9 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
            "\n",
            "--2020-12-06 18:17:41--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/dep/vi-dep.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16048864 (15M) [application/octet-stream]\n",
            "Saving to: ‘vi-dep.xz’\n",
            "\n",
            "vi-dep.xz           100%[===================>]  15.30M  73.0MB/s    in 0.2s    \n",
            "\n",
            "2020-12-06 18:17:41 (73.0 MB/s) - ‘vi-dep.xz’ saved [16048864/16048864]\n",
            "\n",
            "--2020-12-06 18:17:41--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5599844 (5.3M) [application/octet-stream]\n",
            "Saving to: ‘vi-500brownclusters.xz’\n",
            "\n",
            "vi-500brownclusters 100%[===================>]   5.34M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-06 18:17:41 (37.1 MB/s) - ‘vi-500brownclusters.xz’ saved [5599844/5599844]\n",
            "\n",
            "--2020-12-06 18:17:41--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9956876 (9.5M) [application/octet-stream]\n",
            "Saving to: ‘vi-ner.xz’\n",
            "\n",
            "vi-ner.xz           100%[===================>]   9.50M  57.1MB/s    in 0.2s    \n",
            "\n",
            "2020-12-06 18:17:42 (57.1 MB/s) - ‘vi-ner.xz’ saved [9956876/9956876]\n",
            "\n",
            "--2020-12-06 18:17:42--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57313672 (55M) [application/octet-stream]\n",
            "Saving to: ‘vi-pretrainedembeddings.xz’\n",
            "\n",
            "vi-pretrainedembedd 100%[===================>]  54.66M   166MB/s    in 0.3s    \n",
            "\n",
            "2020-12-06 18:17:43 (166 MB/s) - ‘vi-pretrainedembeddings.xz’ saved [57313672/57313672]\n",
            "\n",
            "--2020-12-06 18:17:43--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29709468 (28M) [application/octet-stream]\n",
            "Saving to: ‘vi-tagger’\n",
            "\n",
            "vi-tagger           100%[===================>]  28.33M  90.2MB/s    in 0.3s    \n",
            "\n",
            "2020-12-06 18:17:43 (90.2 MB/s) - ‘vi-tagger’ saved [29709468/29709468]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD22vnF7K4Ta"
      },
      "source": [
        "## Install UndertheSea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZnrrGI2LB_D",
        "outputId": "8e578b36-9b88-492e-cec4-a99ae92d6674"
      },
      "source": [
        "!pip install underthesea"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting underthesea\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/46/1acb7e83092bbcbc9082afe3901ec51e98a303a19c8152655c43bd51583f/underthesea-1.2.3-py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from underthesea) (4.41.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.2.5)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.13)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 68.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.2)\n",
            "Collecting scikit-learn<0.22,>=0.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 59.1MB/s \n",
            "\u001b[?25hCollecting python-crfsuite>=0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval->underthesea) (1.18.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2020.11.8)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.20->underthesea) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=ccf941dfe95e89a9acc82714bcc288f54ddee268b1d33be95ab9b1789a8ffbbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: scikit-learn, seqeval, unidecode, python-crfsuite, underthesea\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed python-crfsuite-0.9.7 scikit-learn-0.21.3 seqeval-1.2.2 underthesea-1.2.3 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InJpM7aDEtHB"
      },
      "source": [
        "# Read and Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcW3ncfLE_sB"
      },
      "source": [
        "import unicodedata\n",
        "import os, time\n",
        "import copy, json\n",
        "\n",
        "from underthesea import sent_tokenize, word_tokenize\n",
        "from vncorenlp import VnCoreNLP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCOWz9EfFPzn"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OukJU79aE1pl",
        "outputId": "0c9f7cc1-bac9-47c5-d15d-09f6cf035c08"
      },
      "source": [
        "with open('train_data.json') as train_data_json:\n",
        "  jtrain_data = json.load(train_data_json)\n",
        "\n",
        "print(type(jtrain_data))\n",
        "print(*jtrain_data[0:6], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "{'doc_id': '23351113', 'sent_id': 1, 'sentence': 'Ảnh minh họa Thứ trưởng Bộ GD&ĐT Nguyễn Thị Nghĩa đã có ý kiến về vấn đề này.', 'spos': [311, 388], 'entity_1': {'text': 'Bộ GD&ĐT', 'pos': [24, 32]}, 'entity_2': {'text': 'Nguyễn Thị Nghĩa', 'pos': [33, 49]}, 'label': 'AFFILIATION_TO'}\n",
            "{'doc_id': '23351113', 'sent_id': 2, 'sentence': 'Ông Nguyễn Tùng Lâm Sắp tới, Bộ GD&ĐT sẽ tăng cường thanh, kiểm tra để có biện pháp chấn chỉnh việc thực hiện quy định Điều lệ của Ban đại diện cha mẹ học sinh.', 'spos': [894, 1054], 'entity_1': {'text': 'Nguyễn Tùng Lâm', 'pos': [4, 19]}, 'entity_2': {'text': 'Bộ GD&ĐT', 'pos': [29, 37]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 3, 'sentence': 'Cũng theo Thứ trưởng Nguyễn Thị Nghĩa , trước những biến tướng như hiện tại, Bộ GD&ĐT nghiên cứu có thể bỏ quy định này để tránh hiện tượng lách luật.', 'spos': [1220, 1370], 'entity_1': {'text': 'Nguyễn Thị Nghĩa', 'pos': [21, 37]}, 'entity_2': {'text': 'Bộ GD&ĐT', 'pos': [77, 85]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 4, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Nguyễn Văn Định', 'pos': [60, 75]}, 'entity_2': {'text': 'Trường THPT Phú Điền', 'pos': [90, 110]}, 'label': 'AFFILIATION'}\n",
            "{'doc_id': '23351113', 'sent_id': 5, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Nguyễn Văn Định', 'pos': [60, 75]}, 'entity_2': {'text': 'Đồng Tháp', 'pos': [113, 122]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351113', 'sent_id': 6, 'sentence': 'Liên quan đến vấn đề lãnh đạo ngành Giáo dục trao đổi, thầy Nguyễn Văn Định – Hiệu trưởng Trường THPT Phú Điền , Đồng Tháp – chia sẻ:', 'spos': [1371, 1504], 'entity_1': {'text': 'Trường THPT Phú Điền', 'pos': [90, 110]}, 'entity_2': {'text': 'Đồng Tháp', 'pos': [113, 122]}, 'label': 'LOCATED'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ujZcUPlBGzD",
        "outputId": "14351926-8a21-4ca5-ce9e-7813b1ef9f6f"
      },
      "source": [
        "with open('dev_data.json') as dev_data_json:\n",
        "  jdev_data = json.load(dev_data_json)\n",
        "\n",
        "print(type(jdev_data))\n",
        "print(*jdev_data[0:6], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 2, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 3, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 4, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 5, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n",
            "{'doc_id': '23351996', 'sent_id': 6, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [69, 81]}, 'entity_2': {'text': 'U16 Mông Cổ', 'pos': [114, 125]}, 'label': 'OTHERS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jyBD2u1NP3r"
      },
      "source": [
        "## Clean func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgaMrjV05d1k"
      },
      "source": [
        "### Normalize text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy2V2T-h5orS"
      },
      "source": [
        "Bên dưới, ta sẽ normalize lại các câu và normalize cả entity text. Tuy nhiên, ta sẽ tạo bản copy, vẫn giữ lại câu gốc và entity gốc để tiện sau này match cho tập test. Normalize sẽ giúp các mô hình BERT nhận diện, word peice câu tốt hơn.\n",
        "\n",
        "Và do nhiều câu bị lỗi unicode, chưa được normalize nên sau khi normalize thì pos entity bị thay đổi nên ta phải tìm pos mới của entity trong câu mới.\n",
        "\n",
        "\n",
        "Vấn đề: \n",
        "- do sau khi được normalize thì pos của entity sẽ thay đổi nên ta cần tìm lại pos của entity trong câu mới\n",
        "- trong câu có thể có nhiều cụm từ giống entity đang xét trong câu (nhiều entity giống nhau trong câu) nên cũng phải cẩn thận khi tìm pos của entity trong câu mới.\n",
        "\n",
        "Ý tưởng:\n",
        "- giả sử trong câu có 5 entity giống hệt nhau. và entity ta đang xét là entity thứ 3 trong số 5 entity kia.\n",
        "  + ... entity_1 ... entity_2 ... **entity_3** ... entity_4 ... entity_5 ...  (dù tên khác nhưng text sau khi được normlize sẽ là một.)\n",
        "- Từ **câu gốc** ta tạo thành 3 câu: \n",
        "  + ... entity_1 ... entity_2 ... **entity_3** ... entity_4 ... entity_5 ... (vẫn là câu gốc)\n",
        "  + ... entity_1 ... entity_2 ... (phần trước entity trong câu gốc - dùng **pos cũ** của entity trong câu cũ)\n",
        "  + ... entity_4 ... entity_5 ... (phần sau entity trong câu gốc - dùng **pos cũ** của entity trong câu cũ)\n",
        "- đầu tiên ta normalize cả 3 câu trên và normalize entity_text đang xét\n",
        "- sau đó tìm pos indice của 'normalized entity_text' trong cả 3 câu đã được nomalize trên, sẽ thu được kết quả như dưới:\n",
        "  + ``` [[ent_1_pos], [ent_2_pos], [ent_3_pos], [ent_4_pos], [ent_5_pos]] ```\n",
        "  + ``` [[ent_1_pos], [ent_2_pos]] ```\n",
        "  + ``` [[ent_4_pos], [ent_5_pos]] ```\n",
        "- cuối cùng chỉ cần lấy list đầu trừ đi tổng 2 list dưới là sẽ thu được: ```[ent_3_pos]```\n",
        "\n",
        "- Hiểu một cách đơn giản là tìm pos pos trong cả câu, rồi tìm trong phần trước xem có những cái nào, tìm trong phần sau xem có những cái nào. rồi cái còn lại chưa xuất hiện thì chính là pos entity của cái cần tìm\n",
        "\n",
        "Sau khi so một vài kết quả của cách này với cách cũ (có bug nên chỉ in ra được vài kết quả) thì thấy đều ổn, giống nhau.\n",
        "\n",
        "**Lưu ý:** cần xem entity có bị overlap không, không thì mới dùng được. do code bên dưới là dùng cho tìm pos non overlap. (ví dụ overlap: tìm ACA trong ACACA thì code bên dưới chỉ tìm được 1 pos đầu dù có 2 cái). Dùng code không overlap vì muốn xem data kĩ hơn. xem có bị xấu như kia không.\n",
        "https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLR5EJB1uq9l",
        "outputId": "86ff23e0-cb35-4833-badc-819ec997da47"
      },
      "source": [
        "import re\n",
        "\n",
        "txt = \"Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\"\n",
        "\n",
        "print([i for i in range(len(txt)) if txt.startswith('Hoàng Sa', i)])\n",
        "\n",
        "print([[a.start(), a.end()] for a in list(re.finditer('Hoàng Sa', txt))])\n",
        "\n",
        "print([[m.start(), m.end()] for m in re.finditer('Hoàng Sa', txt)])  # <--- dùng code này\n",
        "                                                                     # không dùng được cho overlap (find 'ACA' in 'ACACA' sẽ chỉ cho 1 kết quả)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[109, 200, 232]\n",
            "[[109, 117], [200, 208], [232, 240]]\n",
            "[[109, 117], [200, 208], [232, 240]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1B6xMCyZ62y",
        "outputId": "512b3388-c3d4-46f6-a1b2-6b9459f969b0"
      },
      "source": [
        "a = [[1,2], [6,8]]\n",
        "b = [[1,2], [3,5], [6,8], [11,22]]\n",
        "print(all(i in b for i in a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyhi7xJi5hpl"
      },
      "source": [
        "def normalize_sentif(jdata):\n",
        "\n",
        "    new_jdata = []\n",
        "\n",
        "    count_changed_sent = 0\n",
        "\n",
        "    for sentif in jdata:\n",
        "\n",
        "        new_sentence = copy.deepcopy(sentif['sentence'])\n",
        "        new_entity_1_text, new_entity_1_pos = copy.deepcopy(sentif['entity_1']['text']), copy.deepcopy(sentif['entity_1']['pos'])\n",
        "        new_entity_2_text, new_entity_2_pos = copy.deepcopy(sentif['entity_2']['text']), copy.deepcopy(sentif['entity_2']['pos'])\n",
        "\n",
        "        if sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence']):\n",
        "\n",
        "            new_sentence = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['sentence']))\n",
        "            new_entity_1_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['entity_1']['text']))\n",
        "            new_entity_2_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['entity_2']['text']))\n",
        "\n",
        "            # tìm trong cả câu đã được normalized:  A B C entity D E F\n",
        "            entity_1_all_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), new_sentence)]\n",
        "            entity_2_all_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), new_sentence)]\n",
        "\n",
        "            # tìm trong phần đằng trước entity: A B C\n",
        "            sent_before_entity_1 = sentif['sentence'][:sentif['entity_1']['pos'][0]]\n",
        "            sent_before_entity_1 = unicodedata.normalize(\"NFC\", sent_before_entity_1)\n",
        "\n",
        "            sent_before_entity_2 = sentif['sentence'][:sentif['entity_2']['pos'][0]]\n",
        "            sent_before_entity_2 = unicodedata.normalize(\"NFC\", sent_before_entity_2)\n",
        "\n",
        "            entity_1_before_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), sent_before_entity_1)]\n",
        "            entity_2_before_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), sent_before_entity_2)]\n",
        "\n",
        "            assert (all(i in entity_1_all_pos for i in entity_1_before_pos)), str('\\nPROBLEM WITH POS BEFORE ENTITY 1')\n",
        "            assert (all(i in entity_2_all_pos for i in entity_2_before_pos)), str('\\nPROBLEM WITH POS BEFORE ENTITY 2')\n",
        "\n",
        "            # tìm trong phần đằng sau entity: D E F\n",
        "            sent_after_entity_1 = sentif['sentence'][sentif['entity_1']['pos'][1]:]\n",
        "            sent_after_entity_1 = unicodedata.normalize(\"NFC\", sent_after_entity_1)\n",
        "\n",
        "            sent_after_entity_2 = sentif['sentence'][sentif['entity_2']['pos'][1]:]\n",
        "            sent_after_entity_2 = unicodedata.normalize(\"NFC\", sent_after_entity_2)\n",
        "\n",
        "            entity_1_after_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_1_text), sent_after_entity_1)]\n",
        "            entity_2_after_pos = [[m.start(), m.end()] for m in re.finditer(re.escape(new_entity_2_text), sent_after_entity_2)]\n",
        "\n",
        "            change_index_after_1 = len(unicodedata.normalize(\"NFC\", sentif['sentence'][:sentif['entity_1']['pos'][1]]))\n",
        "            change_index_after_2 = len(unicodedata.normalize(\"NFC\", sentif['sentence'][:sentif['entity_2']['pos'][1]]))\n",
        "\n",
        "            entity_1_after_pos = [[(tmp[0]+change_index_after_1), (tmp[1]+change_index_after_1)] for tmp in entity_1_after_pos]\n",
        "            entity_2_after_pos = [[(tmp[0]+change_index_after_2), (tmp[1]+change_index_after_2)] for tmp in entity_2_after_pos]\n",
        "\n",
        "            assert (all(i in entity_1_all_pos for i in entity_1_after_pos)), str('\\nPROBLEM WITH POS AFTER ENTITY 1')\n",
        "            assert (all(i in entity_2_all_pos for i in entity_2_after_pos)), str('\\nPROBLEM WITH POS AFTER ENTITY 2')\n",
        "\n",
        "\n",
        "            new_entity_1_pos = [itm for itm in entity_1_all_pos if itm not in (entity_1_before_pos + entity_1_after_pos)]\n",
        "            new_entity_2_pos = [itm for itm in entity_2_all_pos if itm not in (entity_2_before_pos + entity_2_after_pos)]\n",
        "            \n",
        "            \n",
        "            assert (len(new_entity_1_pos) == 1), str('BELLELEELL 1')\n",
        "            assert (len(new_entity_2_pos) == 1), str('BELLELEELL 2')\n",
        "            \n",
        "            '''\n",
        "            if (len(new_entity_1_pos) != 1):\n",
        "                print(sentif)\n",
        "                print(entity_1_all_pos)\n",
        "                print(entity_1_before_pos)\n",
        "                print(entity_1_after_pos)\n",
        "\n",
        "            if (len(new_entity_2_pos) != 1):\n",
        "                print(sentif)\n",
        "                print(entity_2_all_pos)\n",
        "                print(entity_2_before_pos)\n",
        "                print(entity_2_after_pos)\n",
        "            '''\n",
        "\n",
        "            new_entity_1_pos = copy.deepcopy(new_entity_1_pos[0])\n",
        "            new_entity_2_pos = copy.deepcopy(new_entity_2_pos[0])\n",
        "            \n",
        "\n",
        "            assert (new_sentence[new_entity_1_pos[0]:new_entity_1_pos[1]] == new_entity_1_text), \\\n",
        "            str('\\nAFTER NORMALIZE, ENTITY 1 TEXT NOT MATCH ENTITY 1 POS. sent_id: ' + str(sent_id))\n",
        "\n",
        "            assert (new_sentence[new_entity_2_pos[0]:new_entity_2_pos[1]] == new_entity_2_text), \\\n",
        "            str('\\nAFTER NORMALIZE, ENTITY 2 TEXT NOT MATCH ENTITY 2 POS. sent_id: ' + str(sent_id))\n",
        "\n",
        "\n",
        "        # thêm vào new_jdata\n",
        "        new_sentif = copy.deepcopy(sentif)\n",
        "\n",
        "        new_sentif['new_sentence'] = copy.deepcopy(new_sentence)\n",
        "\n",
        "        new_entity_1 = copy.deepcopy({'text': copy.deepcopy(new_entity_1_text), 'pos': copy.deepcopy(new_entity_1_pos)})\n",
        "        new_entity_2 = copy.deepcopy({'text': copy.deepcopy(new_entity_2_text), 'pos': copy.deepcopy(new_entity_2_pos)})\n",
        "\n",
        "        new_sentif['new_entity_1'] = copy.deepcopy(new_entity_1)\n",
        "        new_sentif['new_entity_2'] = copy.deepcopy(new_entity_2)\n",
        "\n",
        "        new_jdata.append(copy.deepcopy(new_sentif))\n",
        "\n",
        "\n",
        "        \n",
        "        # in để check xem code chạy đúng không\n",
        "        if new_jdata[-1]['new_sentence'] != sentif['sentence']:\n",
        "            count_changed_sent += 1\n",
        "\n",
        "            print('\\n\\n----- ', count_changed_sent,  ' - sent_id: ', sentif['sent_id'])\n",
        "            print('Original sent:   ', sentif['sentence'])\n",
        "            print('Normalized sent: ', new_jdata[-1]['new_sentence'])\n",
        "\n",
        "            print('Previous entity 1:   ', sentif['entity_1'])\n",
        "            print('Normalized entity 1: ', new_jdata[-1]['new_entity_1'])\n",
        "\n",
        "            print('Previous entity 2:   ', sentif['entity_2'])\n",
        "            print('Normalized entity 2: ', new_jdata[-1]['new_entity_2'])\n",
        "        \n",
        "        # phần cũ vẫn phải y nguyên. bên trên chỉ thêm 'new_sentence', 'new_entity_1' và 'new_entity_2'\n",
        "        assert (new_jdata[-1]['sent_id'] == sentif['sent_id']), str('FAILED TO COPY sent_id. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['doc_id'] == sentif['doc_id']), str('FAILED TO COPY doc_id. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['sentence'] == sentif['sentence']), str('FAILED TO COPY sentence. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['entity_1'] == sentif['entity_1']), str('FAILED TO COPY entity_1. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['entity_2'] == sentif['entity_2']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['label'] == sentif['label']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['spos'] == sentif['spos']), str('FAILED TO COPY spos. sent_id: ' + sentif['sent_id'])\n",
        "    \n",
        "    \n",
        "    return copy.deepcopy(new_jdata)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNfcso5IDPPK"
      },
      "source": [
        "### Remove non alnum character at start and end of entity_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjsrq58pDZVj"
      },
      "source": [
        "Trong data nhiều entity ở đầu hoặc cuối (kí tự đầu hoặc cuối) bị lẫn dấu câu như (, ',... hay khoảng trắng. Điều này làm ảnh hướng tới mô hình nếu sau này ta pooling vectors của các word piece trong entity để được vector đại diện cho entity thì sẽ bị lẫn các kí tự không cần kia.\n",
        "\n",
        "Ngoài ra, cách tìm index các wordpiece của entity (để sau pooling được) bên dưới ta dùng không cho phép có khoảng trắng lẫn vào ở đầu hoặc cuối entity nên cần loại bỏ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ly6uxrDOmI"
      },
      "source": [
        "def remove_entity_non_alnum_start_end(sent_id, sentence, entity_if):\n",
        "    '''\n",
        "    Bên trên ở phần \"check\", thấy rằng nhiều entity bị lẫn những kí tự \"thừa\" ở đầu hoặc ở cuối entity\n",
        "    ví dụ: (Thái Nguyên    <----- bị lẫn kí tự (\n",
        "\n",
        "    Sau khi xem dữ liệu, ta thấy những kí tự \"thừa\" là những kí tự không phải là chữ cái hay chữ số. (not .isalnum())\n",
        "    (trừ dấu \".\" và trường hợp entity là \"6+\")\n",
        "\n",
        "    Ngoài ra, bên trên trong phần check, thấy rằng nếu trong (giữa) entity có kí tự không phải chữ số hay chữ cái thì cũng đều hợp lý \n",
        "    chứ không phải lỗi.\n",
        "\n",
        "    Trong hàm này, ta sẽ tạo ra một sửa, loại bỏ các kí tự kia khỏi entity lỗi.\n",
        "\n",
        "    Tuy nhiên, để tránh việc sau này trên tập test khó match được entity thì ta sẽ chỉ tạo bản copy và sửa trên bản copy thôi.\n",
        "    '''\n",
        "\n",
        "    # just double check\n",
        "    assert ((not entity_if['text'][0].isalnum()) or (not entity_if['text'][-1].isalnum())), \\\n",
        "    str('Both First and last character of entity are  alnum.')\n",
        "\n",
        "    # count non alnum character at start\n",
        "    count_at_start = 0\n",
        "    for c in entity_if['text']:\n",
        "        if (not c.isalnum()):\n",
        "            count_at_start += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # count non alnum character at end\n",
        "    count_at_end = 0\n",
        "    for c in entity_if['text'][::-1]:\n",
        "        if (not c.isalnum()) and (c != '+') and (c != '.'):   # trong tập train, dev, thì + và . chỉ xuất hiện ở cuối entity nên phần count start k có\n",
        "            count_at_end += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    entity_text = entity_if['text']\n",
        "    entity_pos = entity_if['pos']   # pos trong câu\n",
        "\n",
        "    new_entity_text = entity_text[(count_at_start):(len(entity_text) - count_at_end)]   # slice trong entity không phải slice trong sentence\n",
        "    new_entity_pos = [(entity_pos[0] + count_at_start), (entity_pos[1] - count_at_end)]   # pos trong câu\n",
        "\n",
        "    assert (sentence[new_entity_pos[0]:new_entity_pos[1]] == new_entity_text), \\\n",
        "    str('\\nNew entity text not match new entity pos.')\n",
        "\n",
        "\n",
        "    return new_entity_text, new_entity_pos\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH5RjECE32S"
      },
      "source": [
        "def fix_start_end_of_entity(jdata):\n",
        "\n",
        "    new_jdata = copy.deepcopy([])\n",
        "\n",
        "    tmpppent = []\n",
        "\n",
        "    for sentif in jdata:\n",
        "\n",
        "        # nếu bên dưới không bị thay đổi tức là không chứa \"kí tự thừa\" thì vẫn giống entity cũ\n",
        "        # ngoài ra ta sẽ truyền vào hàm này j(train/dev)_data_v1 và thay đổi trên new_entity_1\n",
        "        new_entity_1_text = copy.deepcopy(sentif['new_entity_1']['text'])\n",
        "        new_entity_1_pos = copy.deepcopy(sentif['new_entity_1']['pos'])\n",
        "\n",
        "        if (not sentif['new_entity_1']['text'][0].isalnum()) or (not sentif['new_entity_1']['text'][-1].isalnum()):\n",
        "            new_entity_1_text, new_entity_1_pos = remove_entity_non_alnum_start_end(sentif['sent_id'], sentif['new_sentence'], sentif['new_entity_1'])\n",
        "\n",
        "        # nếu bên dưới không bị thay đổi tức là không chứa \"kí tự thừa\" thì vẫn giống entity cũ\n",
        "        # ngoài ra ta sẽ truyền vào hàm này j(train/dev)_data_v1 và thay đổi trên new_entity_2\n",
        "        new_entity_2_text = copy.deepcopy(sentif['new_entity_2']['text'])\n",
        "        new_entity_2_pos = copy.deepcopy(sentif['new_entity_2']['pos'])\n",
        "\n",
        "        if (not sentif['new_entity_2']['text'][0].isalnum()) or (not sentif['new_entity_2']['text'][-1].isalnum()):\n",
        "            new_entity_2_text, new_entity_2_pos = remove_entity_non_alnum_start_end(sentif['sent_id'], sentif['new_sentence'], sentif['new_entity_2'])\n",
        "\n",
        "        \n",
        "\n",
        "        new_sentif = copy.deepcopy(sentif)\n",
        "\n",
        "        new_entity_1 = {'text': copy.deepcopy(new_entity_1_text), 'pos': copy.deepcopy(new_entity_1_pos)}\n",
        "        new_entity_2 = {'text': copy.deepcopy(new_entity_2_text), 'pos': copy.deepcopy(new_entity_2_pos)}\n",
        "\n",
        "        '''\n",
        "        del new_sentif['new_entity_1']\n",
        "        del new_sentif['new_entity_2']\n",
        "        '''\n",
        "\n",
        "        new_sentif['new_entity_1'] = copy.deepcopy(new_entity_1)\n",
        "        new_sentif['new_entity_2'] = copy.deepcopy(new_entity_2)\n",
        "\n",
        "\n",
        "        new_jdata.append(copy.deepcopy(new_sentif))\n",
        "\n",
        "\n",
        "\n",
        "        # in kết quả\n",
        "        if (new_jdata[-1]['new_entity_1'] != sentif['new_entity_1']) and (sentif['new_entity_1']['text'] not in tmpppent):\n",
        "\n",
        "            print('\\noriginal:      ', sentif['new_entity_1'])\n",
        "            print('new_entity:    ', new_jdata[-1]['new_entity_1'])\n",
        "\n",
        "            tmpppent.append(sentif['new_entity_1']['text'])\n",
        "\n",
        "        if (new_jdata[-1]['new_entity_2'] != sentif['new_entity_2']) and (sentif['new_entity_2']['text'] not in tmpppent):\n",
        "\n",
        "            print('\\noriginal:      ', sentif['new_entity_2'])\n",
        "            print('new_entity:    ', new_jdata[-1]['new_entity_2'])\n",
        "\n",
        "            tmpppent.append(sentif['new_entity_2']['text'])\n",
        "\n",
        "    return new_jdata\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQiZyJLEDJWQ"
      },
      "source": [
        "## Clean train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCR3Ur5xSFuv"
      },
      "source": [
        "### Normalize train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmeM-JyXcOKO"
      },
      "source": [
        "#### check overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_906CLzcdja"
      },
      "source": [
        "CHÚ Ý: Cần review data để xem có xảy ra overlap entity không vì code find_nth bên dưới dùng là cho không overlap.\n",
        "\n",
        "Ví dụ: overlap: ACACA\n",
        "\n",
        "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string\n",
        "\n",
        "https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9vSd_IscTD3",
        "outputId": "780a4f5c-c4e5-4973-a5b4-6a40a9f3d560"
      },
      "source": [
        "tmpppsent = []\n",
        "counttt = 0\n",
        "\n",
        "for sentif in jtrain_data:\n",
        "\n",
        "    if (sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence'])):\n",
        "        counttt += 1\n",
        "\n",
        "        if (sentif['sentence'] not in tmpppsent):\n",
        "            print(sentif['sent_id'])\n",
        "            print(sentif['sentence'])\n",
        "            tmpppsent.append(sentif['sentence'])\n",
        "\n",
        "print(counttt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2662\n",
            "Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "2668\n",
            "Đặc biệt, sự nguy hiểm của đội chủ nhà sẽ càng có điều kiện để phát huy khi Chelsea mất trung vệ David Luiz do án treo giò.\n",
            "2684\n",
            "Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "12008\n",
            "﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "12044\n",
            "Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "12050\n",
            "Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "12060\n",
            "Đặc biệt là các châu bản triều Nguyễn (từ triều Gia Long đến triều Bảo Đại ) ban hành liên quan trực tiếp đến vấn đề khai thác, quản lý, xác lập và thực thi chủ quyền đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "12061\n",
            "Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "12071\n",
            "Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "12077\n",
            "Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "12083\n",
            "Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "12098\n",
            "Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "12101\n",
            "Triển lãm diễn ra đến ngày 24-9, sau đó Bộ Thông tin và Truyền thông sẽ bàn giao toàn bộ hiện vật tại cuộc Triển lãm cho Bộ Tư lệnh Vùng 3 Hải quân để trưng bày cho các đơn vị trực thuộc xem.\n",
            "12586\n",
            "Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "12601\n",
            "Phó Thủ tướng Vũ Đức Đam yêu cầu Bộ GD&ĐT rà soát các văn bản của Bộ đảm bảo chặt chẽ, minh bạch trong thực hiện xã hội hóa theo đúng quy định của pháp luật đồng thời chỉ đạo tuyệt đối không để lợi dụng danh nghĩa xã hội hóa để tổ chức thu các khoản đóng góp mang tính cào bằng, áp đặt.\n",
            "13227\n",
            "Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "13242\n",
            "Nói về ý tưởng ra đời của đề án, nhóm trưởng Hải Đăng cho biết, Thủ tướng Chính phủ đã ra quyết định Việt Nam sẽ phát triển nền nông nghiệp theo hướng công nghệ cao.\n",
            "13243\n",
            "Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "15171\n",
            "“Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "15174\n",
            "Thầy Nguyễn Duy Quy , Hiệu trưởng Trường Chuyên biệt Tương Lai nhận xét:\n",
            "146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3LQXcEcP5A"
      },
      "source": [
        "#### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B0aTFjOQ0jV",
        "outputId": "ca0a7267-38fb-442f-8e90-3563a19eda6d"
      },
      "source": [
        "jtrain_data_v1 = copy.deepcopy(normalize_sentif(jtrain_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----  1  - sent_id:  2662\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Newcastle', 'pos': [115, 124]}\n",
            "Normalized entity 1:  {'text': 'Newcastle', 'pos': [113, 122]}\n",
            "Previous entity 2:    {'text': 'Anh', 'pos': [142, 145]}\n",
            "Normalized entity 2:  {'text': 'Anh', 'pos': [140, 143]}\n",
            "\n",
            "\n",
            "-----  2  - sent_id:  2663\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Newcastle', 'pos': [115, 124]}\n",
            "Normalized entity 1:  {'text': 'Newcastle', 'pos': [113, 122]}\n",
            "Previous entity 2:    {'text': 'Bristol City', 'pos': [151, 163]}\n",
            "Normalized entity 2:  {'text': 'Bristol City', 'pos': [149, 161]}\n",
            "\n",
            "\n",
            "-----  3  - sent_id:  2664\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Newcastle', 'pos': [115, 124]}\n",
            "Normalized entity 1:  {'text': 'Newcastle', 'pos': [113, 122]}\n",
            "Previous entity 2:    {'text': 'Liên đoàn Anh', 'pos': [174, 187]}\n",
            "Normalized entity 2:  {'text': 'Liên đoàn Anh', 'pos': [172, 185]}\n",
            "\n",
            "\n",
            "-----  4  - sent_id:  2665\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Anh', 'pos': [142, 145]}\n",
            "Normalized entity 1:  {'text': 'Anh', 'pos': [140, 143]}\n",
            "Previous entity 2:    {'text': 'Bristol City', 'pos': [151, 163]}\n",
            "Normalized entity 2:  {'text': 'Bristol City', 'pos': [149, 161]}\n",
            "\n",
            "\n",
            "-----  5  - sent_id:  2666\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Anh', 'pos': [142, 145]}\n",
            "Normalized entity 1:  {'text': 'Anh', 'pos': [140, 143]}\n",
            "Previous entity 2:    {'text': 'Liên đoàn Anh', 'pos': [174, 187]}\n",
            "Normalized entity 2:  {'text': 'Liên đoàn Anh', 'pos': [172, 185]}\n",
            "\n",
            "\n",
            "-----  6  - sent_id:  2667\n",
            "Original sent:    Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Normalized sent:  Mặc dù phong độ đang theo chiều hướng đi xuống qua việc để thua 2 trận liên tiếp trước những đội bóng yếu hơn là Newcastle (1-2, Ngoại hạng Anh ) và Bristol City (0-2, cúp Liên đoàn Anh ), song đó đều là những trận họ phải thi đấu sân khách.\n",
            "Previous entity 1:    {'text': 'Bristol City', 'pos': [151, 163]}\n",
            "Normalized entity 1:  {'text': 'Bristol City', 'pos': [149, 161]}\n",
            "Previous entity 2:    {'text': 'Liên đoàn Anh', 'pos': [174, 187]}\n",
            "Normalized entity 2:  {'text': 'Liên đoàn Anh', 'pos': [172, 185]}\n",
            "\n",
            "\n",
            "-----  7  - sent_id:  2668\n",
            "Original sent:    Đặc biệt, sự nguy hiểm của đội chủ nhà sẽ càng có điều kiện để phát huy khi Chelsea mất trung vệ David Luiz do án treo giò.\n",
            "Normalized sent:  Đặc biệt, sự nguy hiểm của đội chủ nhà sẽ càng có điều kiện để phát huy khi Chelsea mất trung vệ David Luiz do án treo giò.\n",
            "Previous entity 1:    {'text': 'Chelsea', 'pos': [77, 84]}\n",
            "Normalized entity 1:  {'text': 'Chelsea', 'pos': [76, 83]}\n",
            "Previous entity 2:    {'text': 'David Luiz', 'pos': [99, 109]}\n",
            "Normalized entity 2:  {'text': 'David Luiz', 'pos': [97, 107]}\n",
            "\n",
            "\n",
            "-----  8  - sent_id:  2684\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Normalized entity 1:  {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Previous entity 2:    {'text': 'Stoke', 'pos': [80, 85]}\n",
            "Normalized entity 2:  {'text': 'Stoke', 'pos': [80, 85]}\n",
            "\n",
            "\n",
            "-----  9  - sent_id:  2685\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Normalized entity 1:  {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Previous entity 2:    {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "Normalized entity 2:  {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "\n",
            "\n",
            "-----  10  - sent_id:  2686\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Normalized entity 1:  {'text': 'Chelsea', 'pos': [21, 28]}\n",
            "Previous entity 2:    {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "Normalized entity 2:  {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "\n",
            "\n",
            "-----  11  - sent_id:  2687\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Stoke', 'pos': [80, 85]}\n",
            "Normalized entity 1:  {'text': 'Stoke', 'pos': [80, 85]}\n",
            "Previous entity 2:    {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "Normalized entity 2:  {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "\n",
            "\n",
            "-----  12  - sent_id:  2688\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Stoke', 'pos': [80, 85]}\n",
            "Normalized entity 1:  {'text': 'Stoke', 'pos': [80, 85]}\n",
            "Previous entity 2:    {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "Normalized entity 2:  {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "\n",
            "\n",
            "-----  13  - sent_id:  2689\n",
            "Original sent:    Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Normalized sent:  Bên cạnh đó, một mặt Chelsea phải quyết tâm giành trọn 3 điểm trong màn đụng độ Stoke , mặt khác, họ còn phải tính tới việc giữ chân các trụ cột để chuẩn bị hành quân đến Tây Ban Nha đá lượt trận thứ 2 vòng bảng Champions League gặp Atletico Madrid diễn ra vào giữa tuần tới.\n",
            "Previous entity 1:    {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "Normalized entity 1:  {'text': 'Tây Ban Nha', 'pos': [171, 182]}\n",
            "Previous entity 2:    {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "Normalized entity 2:  {'text': 'Atletico Madrid', 'pos': [233, 248]}\n",
            "\n",
            "\n",
            "-----  14  - sent_id:  12008\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "\n",
            "\n",
            "-----  15  - sent_id:  12009\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "\n",
            "\n",
            "-----  16  - sent_id:  12010\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 2:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "\n",
            "\n",
            "-----  17  - sent_id:  12011\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 2:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "\n",
            "\n",
            "-----  18  - sent_id:  12012\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 2:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "\n",
            "\n",
            "-----  19  - sent_id:  12013\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  20  - sent_id:  12014\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  21  - sent_id:  12015\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Normalized entity 1:  {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  22  - sent_id:  12016\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "\n",
            "\n",
            "-----  23  - sent_id:  12017\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 2:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "\n",
            "\n",
            "-----  24  - sent_id:  12018\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 2:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "\n",
            "\n",
            "-----  25  - sent_id:  12019\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 2:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "\n",
            "\n",
            "-----  26  - sent_id:  12020\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  27  - sent_id:  12021\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  28  - sent_id:  12022\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [51, 60]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  29  - sent_id:  12023\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 2:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "\n",
            "\n",
            "-----  30  - sent_id:  12024\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 2:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "\n",
            "\n",
            "-----  31  - sent_id:  12025\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 2:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "\n",
            "\n",
            "-----  32  - sent_id:  12026\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  33  - sent_id:  12027\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  34  - sent_id:  12028\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  35  - sent_id:  12029\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 1:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "Previous entity 2:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 2:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "\n",
            "\n",
            "-----  36  - sent_id:  12030\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 1:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "Previous entity 2:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 2:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "\n",
            "\n",
            "-----  37  - sent_id:  12031\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 1:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  38  - sent_id:  12032\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 1:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  39  - sent_id:  12033\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "Normalized entity 1:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [129, 155]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  40  - sent_id:  12034\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 1:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "Previous entity 2:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 2:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "\n",
            "\n",
            "-----  41  - sent_id:  12035\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 1:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  42  - sent_id:  12036\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 1:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  43  - sent_id:  12037\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'TP Đà Nẵng', 'pos': [169, 179]}\n",
            "Normalized entity 1:  {'text': 'TP Đà Nẵng', 'pos': [166, 176]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  44  - sent_id:  12038\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 1:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "Previous entity 2:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 2:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "\n",
            "\n",
            "-----  45  - sent_id:  12039\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 1:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  46  - sent_id:  12040\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "Normalized entity 1:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [180, 208]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  47  - sent_id:  12041\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 1:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "\n",
            "\n",
            "-----  48  - sent_id:  12042\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': '“Hoàng Sa', 'pos': [273, 282]}\n",
            "Normalized entity 1:  {'text': '“Hoàng Sa', 'pos': [264, 273]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  49  - sent_id:  12043\n",
            "Original sent:    ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Normalized sent:  ﻿Triển lãm bản đồ và trưng bày tư liệu 'Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý' Chiều 22-9, tại Bộ Tư lệnh Vùng 3 Hải quân (đóng tại TP Đà Nẵng ), Bộ Thông tin và Truyền thông tổ chức khai mạc Triển lãm bản đồ và trưng bày tư liệu “Hoàng Sa , Trường Sa của Việt Nam – Những bằng chứng lịch sử và pháp lý”.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [285, 294]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [276, 285]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [290, 298]}\n",
            "\n",
            "\n",
            "-----  50  - sent_id:  12044\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [110, 119]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [106, 114]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [143, 151]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [136, 144]}\n",
            "\n",
            "\n",
            "-----  51  - sent_id:  12045\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [110, 119]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [106, 114]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [155, 164]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [148, 157]}\n",
            "\n",
            "\n",
            "-----  52  - sent_id:  12046\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [110, 119]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [106, 114]}\n",
            "Previous entity 2:    {'text': 'Biển Đông', 'pos': [170, 180]}\n",
            "Normalized entity 2:  {'text': 'Biển Đông', 'pos': [163, 172]}\n",
            "\n",
            "\n",
            "-----  53  - sent_id:  12047\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [143, 151]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [136, 144]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [155, 164]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [148, 157]}\n",
            "\n",
            "\n",
            "-----  54  - sent_id:  12048\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [143, 151]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [136, 144]}\n",
            "Previous entity 2:    {'text': 'Biển Đông', 'pos': [170, 180]}\n",
            "Normalized entity 2:  {'text': 'Biển Đông', 'pos': [163, 172]}\n",
            "\n",
            "\n",
            "-----  55  - sent_id:  12049\n",
            "Original sent:    Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Normalized sent:  Bản đồ và tư liệu trưng bày tại Triển lãm là bằng chứng lịch sử và cơ sở pháp lý chứng minh chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa trên Biển Đông .\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [155, 164]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [148, 157]}\n",
            "Previous entity 2:    {'text': 'Biển Đông', 'pos': [170, 180]}\n",
            "Normalized entity 2:  {'text': 'Biển Đông', 'pos': [163, 172]}\n",
            "\n",
            "\n",
            "-----  56  - sent_id:  12050\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [348, 357]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [328, 336]}\n",
            "Previous entity 2:    {'text': 'Đông Dương', 'pos': [381, 391]}\n",
            "Normalized entity 2:  {'text': 'Đông Dương', 'pos': [359, 369]}\n",
            "\n",
            "\n",
            "-----  57  - sent_id:  12051\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [348, 357]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [328, 336]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [507, 516]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [478, 486]}\n",
            "\n",
            "\n",
            "-----  58  - sent_id:  12052\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [348, 357]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [328, 336]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [540, 548]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [508, 516]}\n",
            "\n",
            "\n",
            "-----  59  - sent_id:  12053\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [348, 357]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [328, 336]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [552, 561]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [520, 529]}\n",
            "\n",
            "\n",
            "-----  60  - sent_id:  12054\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Đông Dương', 'pos': [381, 391]}\n",
            "Normalized entity 1:  {'text': 'Đông Dương', 'pos': [359, 369]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [507, 516]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [478, 486]}\n",
            "\n",
            "\n",
            "-----  61  - sent_id:  12055\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Đông Dương', 'pos': [381, 391]}\n",
            "Normalized entity 1:  {'text': 'Đông Dương', 'pos': [359, 369]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [540, 548]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [508, 516]}\n",
            "\n",
            "\n",
            "-----  62  - sent_id:  12056\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Đông Dương', 'pos': [381, 391]}\n",
            "Normalized entity 1:  {'text': 'Đông Dương', 'pos': [359, 369]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [552, 561]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [520, 529]}\n",
            "\n",
            "\n",
            "-----  63  - sent_id:  12057\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [507, 516]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [478, 486]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [540, 548]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [508, 516]}\n",
            "\n",
            "\n",
            "-----  64  - sent_id:  12058\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [507, 516]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [478, 486]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [552, 561]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [520, 529]}\n",
            "\n",
            "\n",
            "-----  65  - sent_id:  12059\n",
            "Original sent:    Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Với nhiều tư liệu, văn bản, hiện vật, ấn phẩm và gần 100 bản đồ được trưng bày là tập hợp các nguồn tư liệu đã được công bố từ trước đến nay của các nhà nghiên cứu, học giả ở trong nước và quốc tế, Triển lãm gồm các nhóm tư liệu chính; Phiên bản của các văn bản Hán – Nôm , văn bản Việt ngữ và Pháp ngữ do triều đình phong kiến Việt Nam và chính quyền Pháp ở Đông Dương , ban hành từ thế kỷ XVII đến đầu thế kỷ XX, khẳng định quá trình xác lập, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [540, 548]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [508, 516]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [552, 561]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [520, 529]}\n",
            "\n",
            "\n",
            "-----  66  - sent_id:  12060\n",
            "Original sent:    Đặc biệt là các châu bản triều Nguyễn (từ triều Gia Long đến triều Bảo Đại ) ban hành liên quan trực tiếp đến vấn đề khai thác, quản lý, xác lập và thực thi chủ quyền đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Đặc biệt là các châu bản triều Nguyễn (từ triều Gia Long đến triều Bảo Đại ) ban hành liên quan trực tiếp đến vấn đề khai thác, quản lý, xác lập và thực thi chủ quyền đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [202, 210]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [188, 196]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [214, 223]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [200, 209]}\n",
            "\n",
            "\n",
            "-----  67  - sent_id:  12061\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'miền Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'miền Nam', 'pos': [73, 81]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [86, 95]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [82, 90]}\n",
            "\n",
            "\n",
            "-----  68  - sent_id:  12062\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'miền Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'miền Nam', 'pos': [73, 81]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [217, 226]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "\n",
            "\n",
            "-----  69  - sent_id:  12063\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'miền Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'miền Nam', 'pos': [73, 81]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [250, 258]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [239, 247]}\n",
            "\n",
            "\n",
            "-----  70  - sent_id:  12064\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'miền Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'miền Nam', 'pos': [73, 81]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [251, 260]}\n",
            "\n",
            "\n",
            "-----  71  - sent_id:  12065\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [86, 95]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [82, 90]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [217, 226]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "\n",
            "\n",
            "-----  72  - sent_id:  12066\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [86, 95]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [82, 90]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [250, 258]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [239, 247]}\n",
            "\n",
            "\n",
            "-----  73  - sent_id:  12067\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [86, 95]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [82, 90]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [251, 260]}\n",
            "\n",
            "\n",
            "-----  74  - sent_id:  12068\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [217, 226]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [250, 258]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [239, 247]}\n",
            "\n",
            "\n",
            "-----  75  - sent_id:  12069\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [217, 226]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [251, 260]}\n",
            "\n",
            "\n",
            "-----  76  - sent_id:  12070\n",
            "Original sent:    Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của chính quyền Việt Nam Cộng hòa ở miền Nam Việt Nam ban hành trong thời kỳ 1954 – 1975 tiếp tục khẳng định quá trình quản lý hành chính, thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [250, 258]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [239, 247]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [251, 260]}\n",
            "\n",
            "\n",
            "-----  77  - sent_id:  12071\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [161, 170]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [155, 163]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [194, 202]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [185, 193]}\n",
            "\n",
            "\n",
            "-----  78  - sent_id:  12072\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [161, 170]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [155, 163]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [206, 215]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [197, 206]}\n",
            "\n",
            "\n",
            "-----  79  - sent_id:  12073\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [161, 170]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [155, 163]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [250, 258]}\n",
            "\n",
            "\n",
            "-----  80  - sent_id:  12074\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [194, 202]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [185, 193]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [206, 215]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [197, 206]}\n",
            "\n",
            "\n",
            "-----  81  - sent_id:  12075\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [194, 202]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [185, 193]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [250, 258]}\n",
            "\n",
            "\n",
            "-----  82  - sent_id:  12076\n",
            "Original sent:    Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Normalized sent:  Phiên bản của các văn bản hành chính của nhà nước Cộng hòa XHCH Việt Nam ban hành từ năm 1975 đến nay tiếp tục khẳng định thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa và những vùng biển đảo khác thuộc lãnh thổ Việt Nam .\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [206, 215]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [197, 206]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [262, 271]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [250, 258]}\n",
            "\n",
            "\n",
            "-----  83  - sent_id:  12077\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'phương Tây', 'pos': [66, 76]}\n",
            "Normalized entity 1:  {'text': 'phương Tây', 'pos': [60, 70]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [164, 173]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [152, 160]}\n",
            "\n",
            "\n",
            "-----  84  - sent_id:  12078\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'phương Tây', 'pos': [66, 76]}\n",
            "Normalized entity 1:  {'text': 'phương Tây', 'pos': [60, 70]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [197, 205]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [182, 190]}\n",
            "\n",
            "\n",
            "-----  85  - sent_id:  12079\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'phương Tây', 'pos': [66, 76]}\n",
            "Normalized entity 1:  {'text': 'phương Tây', 'pos': [60, 70]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [209, 218]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [194, 203]}\n",
            "\n",
            "\n",
            "-----  86  - sent_id:  12080\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [164, 173]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [152, 160]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [197, 205]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [182, 190]}\n",
            "\n",
            "\n",
            "-----  87  - sent_id:  12081\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [164, 173]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [152, 160]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [209, 218]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [194, 203]}\n",
            "\n",
            "\n",
            "-----  88  - sent_id:  12082\n",
            "Original sent:    Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Normalized sent:  Tại triển lãm trưng bày một số tư liệu, ấn phẩm do các nước phương Tây biên soạn và xuất bản từ thế kỷ XVIII đến thế kỷ XIX liên quan đến chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa .\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [197, 205]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [182, 190]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [209, 218]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [194, 203]}\n",
            "\n",
            "\n",
            "-----  89  - sent_id:  12083\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [70, 78]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [109, 117]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [100, 108]}\n",
            "\n",
            "\n",
            "-----  90  - sent_id:  12084\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [70, 78]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [121, 130]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [112, 121]}\n",
            "\n",
            "\n",
            "-----  91  - sent_id:  12085\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [70, 78]}\n",
            "Previous entity 2:    {'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "Normalized entity 2:  {'text': 'Trung Quốc', 'pos': [148, 158]}\n",
            "\n",
            "\n",
            "-----  92  - sent_id:  12086\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [70, 78]}\n",
            "Previous entity 2:    {'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "Normalized entity 2:  {'text': 'quần đảo Hoàng Sa', 'pos': [177, 194]}\n",
            "\n",
            "\n",
            "-----  93  - sent_id:  12087\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Việt Nam', 'pos': [76, 85]}\n",
            "Normalized entity 1:  {'text': 'Việt Nam', 'pos': [70, 78]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [232, 240]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [216, 224]}\n",
            "\n",
            "\n",
            "-----  94  - sent_id:  12088\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [109, 117]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [100, 108]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [121, 130]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [112, 121]}\n",
            "\n",
            "\n",
            "-----  95  - sent_id:  12089\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [109, 117]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [100, 108]}\n",
            "Previous entity 2:    {'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "Normalized entity 2:  {'text': 'Trung Quốc', 'pos': [148, 158]}\n",
            "\n",
            "\n",
            "-----  96  - sent_id:  12090\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [109, 117]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [100, 108]}\n",
            "Previous entity 2:    {'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "Normalized entity 2:  {'text': 'quần đảo Hoàng Sa', 'pos': [177, 194]}\n",
            "\n",
            "\n",
            "-----  97  - sent_id:  12091\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Hoàng Sa', 'pos': [109, 117]}\n",
            "Normalized entity 1:  {'text': 'Hoàng Sa', 'pos': [100, 108]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [232, 240]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [216, 224]}\n",
            "\n",
            "\n",
            "-----  98  - sent_id:  12092\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [121, 130]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [112, 121]}\n",
            "Previous entity 2:    {'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "Normalized entity 2:  {'text': 'Trung Quốc', 'pos': [148, 158]}\n",
            "\n",
            "\n",
            "-----  99  - sent_id:  12093\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [121, 130]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [112, 121]}\n",
            "Previous entity 2:    {'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "Normalized entity 2:  {'text': 'quần đảo Hoàng Sa', 'pos': [177, 194]}\n",
            "\n",
            "\n",
            "-----  100  - sent_id:  12094\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [121, 130]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [112, 121]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [232, 240]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [216, 224]}\n",
            "\n",
            "\n",
            "-----  101  - sent_id:  12095\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "Normalized entity 1:  {'text': 'Trung Quốc', 'pos': [148, 158]}\n",
            "Previous entity 2:    {'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "Normalized entity 2:  {'text': 'quần đảo Hoàng Sa', 'pos': [177, 194]}\n",
            "\n",
            "\n",
            "-----  102  - sent_id:  12096\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "Normalized entity 1:  {'text': 'Trung Quốc', 'pos': [148, 158]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [232, 240]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [216, 224]}\n",
            "\n",
            "\n",
            "-----  103  - sent_id:  12097\n",
            "Original sent:    Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Normalized sent:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19-1-1974.\n",
            "Previous entity 1:    {'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "Normalized entity 1:  {'text': 'quần đảo Hoàng Sa', 'pos': [177, 194]}\n",
            "Previous entity 2:    {'text': 'Hoàng Sa', 'pos': [232, 240]}\n",
            "Normalized entity 2:  {'text': 'Hoàng Sa', 'pos': [216, 224]}\n",
            "\n",
            "\n",
            "-----  104  - sent_id:  12098\n",
            "Original sent:    Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Normalized sent:  Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Previous entity 1:    {'text': '“Hoàng Sa', 'pos': [23, 32]}\n",
            "Normalized entity 1:  {'text': '“Hoàng Sa', 'pos': [21, 30]}\n",
            "Previous entity 2:    {'text': 'Trường Sa', 'pos': [35, 44]}\n",
            "Normalized entity 2:  {'text': 'Trường Sa', 'pos': [33, 42]}\n",
            "\n",
            "\n",
            "-----  105  - sent_id:  12099\n",
            "Original sent:    Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Normalized sent:  Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Previous entity 1:    {'text': '“Hoàng Sa', 'pos': [23, 32]}\n",
            "Normalized entity 1:  {'text': '“Hoàng Sa', 'pos': [21, 30]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [60, 69]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [58, 66]}\n",
            "\n",
            "\n",
            "-----  106  - sent_id:  12100\n",
            "Original sent:    Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Normalized sent:  Trưng bày tư liệu về “Hoàng Sa , Trường Sa trong trái tim Việt Nam ” được thể hiện rất sinh động thông qua những hình ảnh, tài liệu, hiện vật thể hiện sự quan tâm, tình cảm đặc biệt của Đảng, Nhà nước, quân đội, các tổ chức chính trị - xã hội, nhân dân với những hành động thiết thực, chung sức bảo vệ chủ quyền biển đảo quê hương.\n",
            "Previous entity 1:    {'text': 'Trường Sa', 'pos': [35, 44]}\n",
            "Normalized entity 1:  {'text': 'Trường Sa', 'pos': [33, 42]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [60, 69]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [58, 66]}\n",
            "\n",
            "\n",
            "-----  107  - sent_id:  12101\n",
            "Original sent:    Triển lãm diễn ra đến ngày 24-9, sau đó Bộ Thông tin và Truyền thông sẽ bàn giao toàn bộ hiện vật tại cuộc Triển lãm cho Bộ Tư lệnh Vùng 3 Hải quân để trưng bày cho các đơn vị trực thuộc xem.\n",
            "Normalized sent:  Triển lãm diễn ra đến ngày 24-9, sau đó Bộ Thông tin và Truyền thông sẽ bàn giao toàn bộ hiện vật tại cuộc Triển lãm cho Bộ Tư lệnh Vùng 3 Hải quân để trưng bày cho các đơn vị trực thuộc xem.\n",
            "Previous entity 1:    {'text': 'Bộ Thông tin và Truyền thông', 'pos': [43, 73]}\n",
            "Normalized entity 1:  {'text': 'Bộ Thông tin và Truyền thông', 'pos': [40, 68]}\n",
            "Previous entity 2:    {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [131, 159]}\n",
            "Normalized entity 2:  {'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [121, 147]}\n",
            "\n",
            "\n",
            "-----  108  - sent_id:  12586\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Cao Lãnh', 'pos': [87, 98]}\n",
            "Normalized entity 1:  {'text': 'TP Cao Lãnh', 'pos': [81, 92]}\n",
            "Previous entity 2:    {'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "Normalized entity 2:  {'text': 'tỉnh Đồng Tháp', 'pos': [95, 109]}\n",
            "\n",
            "\n",
            "-----  109  - sent_id:  12587\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Cao Lãnh', 'pos': [87, 98]}\n",
            "Normalized entity 1:  {'text': 'TP Cao Lãnh', 'pos': [81, 92]}\n",
            "Previous entity 2:    {'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "Normalized entity 2:  {'text': 'H.\\xa0 Hải Dương', 'pos': [244, 257]}\n",
            "\n",
            "\n",
            "-----  110  - sent_id:  12588\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Cao Lãnh', 'pos': [87, 98]}\n",
            "Normalized entity 1:  {'text': 'TP Cao Lãnh', 'pos': [81, 92]}\n",
            "Previous entity 2:    {'text': 'TP Hải Phòng', 'pos': [273, 285]}\n",
            "Normalized entity 2:  {'text': 'TP Hải Phòng', 'pos': [260, 272]}\n",
            "\n",
            "\n",
            "-----  111  - sent_id:  12589\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Cao Lãnh', 'pos': [87, 98]}\n",
            "Normalized entity 1:  {'text': 'TP Cao Lãnh', 'pos': [81, 92]}\n",
            "Previous entity 2:    {'text': 'H. Đông Anh', 'pos': [308, 319]}\n",
            "Normalized entity 2:  {'text': 'H. Đông Anh', 'pos': [295, 306]}\n",
            "\n",
            "\n",
            "-----  112  - sent_id:  12590\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Cao Lãnh', 'pos': [87, 98]}\n",
            "Normalized entity 1:  {'text': 'TP Cao Lãnh', 'pos': [81, 92]}\n",
            "Previous entity 2:    {'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "Normalized entity 2:  {'text': 'TP Hà Nội', 'pos': [309, 318]}\n",
            "\n",
            "\n",
            "-----  113  - sent_id:  12591\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "Normalized entity 1:  {'text': 'tỉnh Đồng Tháp', 'pos': [95, 109]}\n",
            "Previous entity 2:    {'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "Normalized entity 2:  {'text': 'H.\\xa0 Hải Dương', 'pos': [244, 257]}\n",
            "\n",
            "\n",
            "-----  114  - sent_id:  12592\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "Normalized entity 1:  {'text': 'tỉnh Đồng Tháp', 'pos': [95, 109]}\n",
            "Previous entity 2:    {'text': 'TP Hải Phòng', 'pos': [273, 285]}\n",
            "Normalized entity 2:  {'text': 'TP Hải Phòng', 'pos': [260, 272]}\n",
            "\n",
            "\n",
            "-----  115  - sent_id:  12593\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "Normalized entity 1:  {'text': 'tỉnh Đồng Tháp', 'pos': [95, 109]}\n",
            "Previous entity 2:    {'text': 'H. Đông Anh', 'pos': [308, 319]}\n",
            "Normalized entity 2:  {'text': 'H. Đông Anh', 'pos': [295, 306]}\n",
            "\n",
            "\n",
            "-----  116  - sent_id:  12594\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "Normalized entity 1:  {'text': 'tỉnh Đồng Tháp', 'pos': [95, 109]}\n",
            "Previous entity 2:    {'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "Normalized entity 2:  {'text': 'TP Hà Nội', 'pos': [309, 318]}\n",
            "\n",
            "\n",
            "-----  117  - sent_id:  12595\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "Normalized entity 1:  {'text': 'H.\\xa0 Hải Dương', 'pos': [244, 257]}\n",
            "Previous entity 2:    {'text': 'TP Hải Phòng', 'pos': [273, 285]}\n",
            "Normalized entity 2:  {'text': 'TP Hải Phòng', 'pos': [260, 272]}\n",
            "\n",
            "\n",
            "-----  118  - sent_id:  12596\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "Normalized entity 1:  {'text': 'H.\\xa0 Hải Dương', 'pos': [244, 257]}\n",
            "Previous entity 2:    {'text': 'H. Đông Anh', 'pos': [308, 319]}\n",
            "Normalized entity 2:  {'text': 'H. Đông Anh', 'pos': [295, 306]}\n",
            "\n",
            "\n",
            "-----  119  - sent_id:  12597\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "Normalized entity 1:  {'text': 'H.\\xa0 Hải Dương', 'pos': [244, 257]}\n",
            "Previous entity 2:    {'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "Normalized entity 2:  {'text': 'TP Hà Nội', 'pos': [309, 318]}\n",
            "\n",
            "\n",
            "-----  120  - sent_id:  12598\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Hải Phòng', 'pos': [273, 285]}\n",
            "Normalized entity 1:  {'text': 'TP Hải Phòng', 'pos': [260, 272]}\n",
            "Previous entity 2:    {'text': 'H. Đông Anh', 'pos': [308, 319]}\n",
            "Normalized entity 2:  {'text': 'H. Đông Anh', 'pos': [295, 306]}\n",
            "\n",
            "\n",
            "-----  121  - sent_id:  12599\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'TP Hải Phòng', 'pos': [273, 285]}\n",
            "Normalized entity 1:  {'text': 'TP Hải Phòng', 'pos': [260, 272]}\n",
            "Previous entity 2:    {'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "Normalized entity 2:  {'text': 'TP Hà Nội', 'pos': [309, 318]}\n",
            "\n",
            "\n",
            "-----  122  - sent_id:  12600\n",
            "Original sent:    Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Normalized sent:  Câu chuyện hơn 16 triệu đồng cho các khoản thu đầu năm ở một trường tiểu học tại TP Cao Lãnh , tỉnh Đồng Tháp đang còn nóng hầm hập thì liên tiếp những ngày qua thông tin phụ huynh chịu không thấu với 20 khoản thu tự nguyện ở một ngôi trường ở H.  Hải Dương , TP Hải Phòng , 17 khoản tương tự ở H. Đông Anh , TP Hà Nội cũng như câu chuyện “xã hội hóa” ở nhiều ngôi trường khác khiến dư luận không khỏi bức xúc.\n",
            "Previous entity 1:    {'text': 'H. Đông Anh', 'pos': [308, 319]}\n",
            "Normalized entity 1:  {'text': 'H. Đông Anh', 'pos': [295, 306]}\n",
            "Previous entity 2:    {'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "Normalized entity 2:  {'text': 'TP Hà Nội', 'pos': [309, 318]}\n",
            "\n",
            "\n",
            "-----  123  - sent_id:  12601\n",
            "Original sent:    Phó Thủ tướng Vũ Đức Đam yêu cầu Bộ GD&ĐT rà soát các văn bản của Bộ đảm bảo chặt chẽ, minh bạch trong thực hiện xã hội hóa theo đúng quy định của pháp luật đồng thời chỉ đạo tuyệt đối không để lợi dụng danh nghĩa xã hội hóa để tổ chức thu các khoản đóng góp mang tính cào bằng, áp đặt.\n",
            "Normalized sent:  Phó Thủ tướng Vũ Đức Đam yêu cầu Bộ GD&ĐT rà soát các văn bản của Bộ đảm bảo chặt chẽ, minh bạch trong thực hiện xã hội hóa theo đúng quy định của pháp luật đồng thời chỉ đạo tuyệt đối không để lợi dụng danh nghĩa xã hội hóa để tổ chức thu các khoản đóng góp mang tính cào bằng, áp đặt.\n",
            "Previous entity 1:    {'text': 'Vũ Đức Đam', 'pos': [14, 24]}\n",
            "Normalized entity 1:  {'text': 'Vũ Đức Đam', 'pos': [14, 24]}\n",
            "Previous entity 2:    {'text': 'Bộ GD&ĐT', 'pos': [34, 43]}\n",
            "Normalized entity 2:  {'text': 'Bộ GD&ĐT', 'pos': [33, 41]}\n",
            "\n",
            "\n",
            "-----  124  - sent_id:  13227\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Anh Nhiên', 'pos': [189, 205]}\n",
            "Previous entity 2:    {'text': 'Lê Hải Đăng', 'pos': [218, 229]}\n",
            "Normalized entity 2:  {'text': 'Lê Hải Đăng', 'pos': [208, 219]}\n",
            "\n",
            "\n",
            "-----  125  - sent_id:  13228\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Anh Nhiên', 'pos': [189, 205]}\n",
            "Previous entity 2:    {'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "Normalized entity 2:  {'text': 'Hồ Sơn Công', 'pos': [222, 233]}\n",
            "\n",
            "\n",
            "-----  126  - sent_id:  13229\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Anh Nhiên', 'pos': [189, 205]}\n",
            "Previous entity 2:    {'text': 'Đặng Trí Dũng', 'pos': [247, 260]}\n",
            "Normalized entity 2:  {'text': 'Đặng Trí Dũng', 'pos': [236, 249]}\n",
            "\n",
            "\n",
            "-----  127  - sent_id:  13230\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Anh Nhiên', 'pos': [189, 205]}\n",
            "Previous entity 2:    {'text': 'Trương Quang Sinh', 'pos': [263, 280]}\n",
            "Normalized entity 2:  {'text': 'Trương Quang Sinh', 'pos': [252, 269]}\n",
            "\n",
            "\n",
            "-----  128  - sent_id:  13231\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Anh Nhiên', 'pos': [189, 205]}\n",
            "Previous entity 2:    {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "Normalized entity 2:  {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "\n",
            "\n",
            "-----  129  - sent_id:  13232\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Lê Hải Đăng', 'pos': [218, 229]}\n",
            "Normalized entity 1:  {'text': 'Lê Hải Đăng', 'pos': [208, 219]}\n",
            "Previous entity 2:    {'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "Normalized entity 2:  {'text': 'Hồ Sơn Công', 'pos': [222, 233]}\n",
            "\n",
            "\n",
            "-----  130  - sent_id:  13233\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Lê Hải Đăng', 'pos': [218, 229]}\n",
            "Normalized entity 1:  {'text': 'Lê Hải Đăng', 'pos': [208, 219]}\n",
            "Previous entity 2:    {'text': 'Đặng Trí Dũng', 'pos': [247, 260]}\n",
            "Normalized entity 2:  {'text': 'Đặng Trí Dũng', 'pos': [236, 249]}\n",
            "\n",
            "\n",
            "-----  131  - sent_id:  13234\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Lê Hải Đăng', 'pos': [218, 229]}\n",
            "Normalized entity 1:  {'text': 'Lê Hải Đăng', 'pos': [208, 219]}\n",
            "Previous entity 2:    {'text': 'Trương Quang Sinh', 'pos': [263, 280]}\n",
            "Normalized entity 2:  {'text': 'Trương Quang Sinh', 'pos': [252, 269]}\n",
            "\n",
            "\n",
            "-----  132  - sent_id:  13235\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Lê Hải Đăng', 'pos': [218, 229]}\n",
            "Normalized entity 1:  {'text': 'Lê Hải Đăng', 'pos': [208, 219]}\n",
            "Previous entity 2:    {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "Normalized entity 2:  {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "\n",
            "\n",
            "-----  133  - sent_id:  13236\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "Normalized entity 1:  {'text': 'Hồ Sơn Công', 'pos': [222, 233]}\n",
            "Previous entity 2:    {'text': 'Đặng Trí Dũng', 'pos': [247, 260]}\n",
            "Normalized entity 2:  {'text': 'Đặng Trí Dũng', 'pos': [236, 249]}\n",
            "\n",
            "\n",
            "-----  134  - sent_id:  13237\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "Normalized entity 1:  {'text': 'Hồ Sơn Công', 'pos': [222, 233]}\n",
            "Previous entity 2:    {'text': 'Trương Quang Sinh', 'pos': [263, 280]}\n",
            "Normalized entity 2:  {'text': 'Trương Quang Sinh', 'pos': [252, 269]}\n",
            "\n",
            "\n",
            "-----  135  - sent_id:  13238\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "Normalized entity 1:  {'text': 'Hồ Sơn Công', 'pos': [222, 233]}\n",
            "Previous entity 2:    {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "Normalized entity 2:  {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "\n",
            "\n",
            "-----  136  - sent_id:  13239\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Đặng Trí Dũng', 'pos': [247, 260]}\n",
            "Normalized entity 1:  {'text': 'Đặng Trí Dũng', 'pos': [236, 249]}\n",
            "Previous entity 2:    {'text': 'Trương Quang Sinh', 'pos': [263, 280]}\n",
            "Normalized entity 2:  {'text': 'Trương Quang Sinh', 'pos': [252, 269]}\n",
            "\n",
            "\n",
            "-----  137  - sent_id:  13240\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Đặng Trí Dũng', 'pos': [247, 260]}\n",
            "Normalized entity 1:  {'text': 'Đặng Trí Dũng', 'pos': [236, 249]}\n",
            "Previous entity 2:    {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "Normalized entity 2:  {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "\n",
            "\n",
            "-----  138  - sent_id:  13241\n",
            "Original sent:    Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Normalized sent:  Sinh viên sản xuất bộ điều khiển nông nghiệp công nghệ cao Vượt qua hàng trăm đề tài  dự thi, đề án “Sản xuất, phân phối bộ điều khiển nông nghiệp công nghệ cao (NNCNC)” của nhóm sinh viên Nguyễn Anh Nhiên , Lê Hải Đăng , Hồ Sơn Công , Đặng Trí Dũng , Trương Quang Sinh (Trường Đại học Nông Lâm Huế ) đã xuất sắc đạt giải Nhất cuộc thi Khởi nghiệp từ nông nghiệp năm 2017 do trường tổ chức.\n",
            "Previous entity 1:    {'text': 'Trương Quang Sinh', 'pos': [263, 280]}\n",
            "Normalized entity 1:  {'text': 'Trương Quang Sinh', 'pos': [252, 269]}\n",
            "Previous entity 2:    {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "Normalized entity 2:  {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "\n",
            "\n",
            "-----  139  - sent_id:  13242\n",
            "Original sent:    Nói về ý tưởng ra đời của đề án, nhóm trưởng Hải Đăng cho biết, Thủ tướng Chính phủ đã ra quyết định Việt Nam sẽ phát triển nền nông nghiệp theo hướng công nghệ cao.\n",
            "Normalized sent:  Nói về ý tưởng ra đời của đề án, nhóm trưởng Hải Đăng cho biết, Thủ tướng Chính phủ đã ra quyết định Việt Nam sẽ phát triển nền nông nghiệp theo hướng công nghệ cao.\n",
            "Previous entity 1:    {'text': 'Hải Đăng', 'pos': [47, 55]}\n",
            "Normalized entity 1:  {'text': 'Hải Đăng', 'pos': [45, 53]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [105, 114]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [101, 109]}\n",
            "\n",
            "\n",
            "-----  140  - sent_id:  13243\n",
            "Original sent:    Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Normalized sent:  Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Previous entity 1:    {'text': 'Mỹ', 'pos': [128, 130]}\n",
            "Normalized entity 1:  {'text': 'Mỹ', 'pos': [118, 120]}\n",
            "Previous entity 2:    {'text': 'Israel', 'pos': [133, 139]}\n",
            "Normalized entity 2:  {'text': 'Israel', 'pos': [123, 129]}\n",
            "\n",
            "\n",
            "-----  141  - sent_id:  13244\n",
            "Original sent:    Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Normalized sent:  Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Previous entity 1:    {'text': 'Mỹ', 'pos': [128, 130]}\n",
            "Normalized entity 1:  {'text': 'Mỹ', 'pos': [118, 120]}\n",
            "Previous entity 2:    {'text': 'Châu Âu', 'pos': [143, 150]}\n",
            "Normalized entity 2:  {'text': 'Châu Âu', 'pos': [133, 140]}\n",
            "\n",
            "\n",
            "-----  142  - sent_id:  13245\n",
            "Original sent:    Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Normalized sent:  Cùng với xu thế phát triển NNCNC, hiện nhiều công ty trên cả nước đã nhập các hệ thống điều khiển tự động từ các nước Mỹ , Israel và Châu Âu về để phân phối trong nước.\n",
            "Previous entity 1:    {'text': 'Israel', 'pos': [133, 139]}\n",
            "Normalized entity 1:  {'text': 'Israel', 'pos': [123, 129]}\n",
            "Previous entity 2:    {'text': 'Châu Âu', 'pos': [143, 150]}\n",
            "Normalized entity 2:  {'text': 'Châu Âu', 'pos': [133, 140]}\n",
            "\n",
            "\n",
            "-----  143  - sent_id:  15171\n",
            "Original sent:    “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Normalized sent:  “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Previous entity 1:    {'text': 'Đà Nẵng', 'pos': [44, 51]}\n",
            "Normalized entity 1:  {'text': 'Đà Nẵng', 'pos': [44, 51]}\n",
            "Previous entity 2:    {'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [77, 107]}\n",
            "Normalized entity 2:  {'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [76, 104]}\n",
            "\n",
            "\n",
            "-----  144  - sent_id:  15172\n",
            "Original sent:    “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Normalized sent:  “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Previous entity 1:    {'text': 'Đà Nẵng', 'pos': [44, 51]}\n",
            "Normalized entity 1:  {'text': 'Đà Nẵng', 'pos': [44, 51]}\n",
            "Previous entity 2:    {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [120, 149]}\n",
            "Normalized entity 2:  {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [117, 145]}\n",
            "\n",
            "\n",
            "-----  145  - sent_id:  15173\n",
            "Original sent:    “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Normalized sent:  “Lúc đó, khi tôi vừa ra trường thì cùng lúc Đà Nẵng có chủ trương thành lập Trung tâm dạy trẻ khuyết tật (sau này là Trường Chuyên biệt Tương Lai ) và tôi về nhận nhiệm vụ.\n",
            "Previous entity 1:    {'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [77, 107]}\n",
            "Normalized entity 1:  {'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [76, 104]}\n",
            "Previous entity 2:    {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [120, 149]}\n",
            "Normalized entity 2:  {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [117, 145]}\n",
            "\n",
            "\n",
            "-----  146  - sent_id:  15174\n",
            "Original sent:    Thầy Nguyễn Duy Quy , Hiệu trưởng Trường Chuyên biệt Tương Lai nhận xét:\n",
            "Normalized sent:  Thầy Nguyễn Duy Quy , Hiệu trưởng Trường Chuyên biệt Tương Lai nhận xét:\n",
            "Previous entity 1:    {'text': 'Nguyễn Duy Quy', 'pos': [6, 21]}\n",
            "Normalized entity 1:  {'text': 'Nguyễn Duy Quy', 'pos': [5, 19]}\n",
            "Previous entity 2:    {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [37, 66]}\n",
            "Normalized entity 2:  {'text': 'Trường Chuyên biệt Tương Lai', 'pos': [34, 62]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ddsEEr5B56"
      },
      "source": [
        "#### OLD CODE HAS BUG. KEEP FOR EXPERIMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euyHUMCQ5PNA"
      },
      "source": [
        "Ý tưởng: mặc dù pos bị thay đổi nhưng thứ tự vẫn vậy.\n",
        "\n",
        "Ví dụ câu sau:  \"Dù cho Trung Quốc có muốn có \"*Hoàng Sa*\" như nào đi nữa, thì quần đảo \"***Hoàng Sa***\" và Trường Sa vẫn luôn thuộc về Việt Nam.\"\n",
        "\n",
        "Hoàng Sa ở đây là entity, thì dù cho có normalize thì từ \"Hoàng Sa\" **thứ 2** trong câu gốc vẫn sẽ tương ứng là từ Hoàng Sa **thứ 2** trong \n",
        "câu được normalize. \n",
        "\n",
        "Dựa vào đó để tìm pos trong câu được normalize.\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "Tức là nếu câu có n cụm từ (entity) giống nhau thì sau khi normalize, thứ tự các cụm này vẫn như vậy.\n",
        "\n",
        "Ví dụ: trong câu gốc, có **3** từ (entity) Thuật và 3 từ này có pos lần lượt là: [(5,10), (15,20), **(25,30)**]\n",
        "\n",
        "trong câu mới vẫn sẽ phải có đúng **3** từ Thuật được normalize và pos lần lượt là [(6,11), (16,22), (26,33)]\n",
        "\n",
        "Giả sử trong câu gốc đang xét, có entity Thuật có pos là **(25,30)** \n",
        "\n",
        "--> entity Thuật trong câu gốc là từ Thuật **thứ 3** trong câu gốc (từ trái sang) (do trùng pos)\n",
        "\n",
        "Do đó entity Thuật này khi sang câu mới sẽ tương ứng với từ Thuật **thứ 3** trong câu mới --> pos của entity trong câu mới là **(26,33)**\n",
        "\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54g8sUnZSMat",
        "outputId": "209fef2d-78c7-441e-d47f-cf267761676a"
      },
      "source": [
        "''' BUG QUÁ NẶNG KHÔNG FIX ĐƯỢC NHƯNG MAY NGHĨ RA CÁCH KHÁC DÙ CHƯA BIẾT CÁCH MỚI CHẠY ỔN KHÔNG\n",
        "jtrain_data_v2 = []\n",
        "\n",
        "for sentif in jtrain_data_v1:\n",
        "\n",
        "    new_sentence = copy.deepcopy(sentif['sentence'])\n",
        "    new_entity_1_text, new_entity_1_pos = copy.deepcopy(sentif['new_entity_1']['text']), copy.deepcopy(sentif['new_entity_1']['pos'])\n",
        "    new_entity_2_text, new_entity_2_pos = copy.deepcopy(sentif['new_entity_2']['text']), copy.deepcopy(sentif['new_entity_2']['pos'])\n",
        "\n",
        "    if sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence']):\n",
        "\n",
        "        # BUG:GGG sent_id: 12009\n",
        "        # entity_text trong 1 câu gốc có thể có cả 2 loại biến thể là unicode lỗi và unicode chuẩn (giống như đã được normalize rồi). \n",
        "        # Nên trong khi tìm pos của entity_text trong câu gốc cần tìm cho cả entity_text gốc và entity_text đã được normalize\n",
        "        # Điều này cũng có nghĩa là nếu có nhiều entity_text trong câu gốc và mỗi cái lại có một unicode riêng thì khó mà xử lý được\n",
        "        # và nếu entity là text chuẩn đã được normalize thì sẽ k xử lý được như bên dưới. do khi tìm trong câu gốc thì vì nó là text chuẩn\n",
        "        # nên có normalize hay k normalize thì vẫn vậy và do đó tìm trong câu gốc vẫn chỉ ra 1 pos.\n",
        "\n",
        "        \n",
        "        # tìm entity_text gốc trong câu gốc (bắt buộc phải thấy)\n",
        "        old_all_entity_1_pos_1 = [[m.start(), m.end()] for m in re.finditer(sentif['new_entity_1']['text'], sentif['sentence'])]\n",
        "        old_all_entity_2_pos_1 = [[m.start(), m.end()] for m in re.finditer(sentif['new_entity_2']['text'], sentif['sentence'])]\n",
        "\n",
        "        assert (len(old_all_entity_1_pos_1) > 0), str('\\nNOT FOUND ENTITY 1 IN ORIGINAL SENTENCE. sent_id: ' + str(sentif['sent_id']))\n",
        "        assert (len(old_all_entity_2_pos_1) > 0), str('\\nNOT FOUND ENTITY 2 IN ORIGINAL SENTENCE. sent_id: ' + str(sentif['sent_id']))\n",
        "\n",
        "        # tìm entity_text normalized trong câu gốc (có thể thấy có thể không)\n",
        "        old_all_entity_1_pos_2 = [[m.start(), m.end()] for m in re.finditer(unicodedata.normalize(\"NFC\", sentif['new_entity_1']['text']), sentif['sentence'])]\n",
        "        old_all_entity_2_pos_2 = [[m.start(), m.end()] for m in re.finditer(unicodedata.normalize(\"NFC\", sentif['new_entity_2']['text']), sentif['sentence'])]\n",
        "\n",
        "        # combine, remove duplicate and sort\n",
        "        old_all_entity_1_pos = []\n",
        "\n",
        "        for tmp1 in (old_all_entity_1_pos_1 + old_all_entity_1_pos_2):\n",
        "            if tmp1 not in old_all_entity_1_pos:\n",
        "                old_all_entity_1_pos.append(tmp1)\n",
        "        \n",
        "        old_all_entity_1_pos = sorted(old_all_entity_1_pos)\n",
        "\n",
        "        old_all_entity_2_pos = []\n",
        "\n",
        "        for tmp2 in (old_all_entity_2_pos_1 + old_all_entity_2_pos_2):\n",
        "            if tmp2 not in old_all_entity_2_pos:\n",
        "                old_all_entity_2_pos.append(tmp2)\n",
        "        \n",
        "        old_all_entity_2_pos = sorted(old_all_entity_2_pos)\n",
        "\n",
        "\n",
        "\n",
        "        # if not found element in list, list.index(element) will auto return error\n",
        "        entity_1_th = old_all_entity_1_pos.index(sentif['new_entity_1']['pos'])\n",
        "        entity_2_th = old_all_entity_2_pos.index(sentif['new_entity_2']['pos'])\n",
        "\n",
        "\n",
        "        new_sentence = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['sentence']))\n",
        "        new_entity_1_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['new_entity_1']['text']))\n",
        "        new_entity_2_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif['new_entity_2']['text']))\n",
        "\n",
        "        new_all_entity_1_pos = [[m.start(), m.end()] for m in re.finditer(new_entity_1_text, new_sentence)]\n",
        "        new_all_entity_2_pos = [[m.start(), m.end()] for m in re.finditer(new_entity_2_text, new_sentence)]\n",
        "\n",
        "\n",
        "        ###\n",
        "        if sentif['sent_id'] == 12009:\n",
        "            print(old_all_entity_2_pos)\n",
        "            print(old_all_entity_2_pos_1)\n",
        "            print(old_all_entity_2_pos_2)\n",
        "            print('\\n', new_all_entity_2_pos)\n",
        "\n",
        "\n",
        "        ###\n",
        "\n",
        "\n",
        "        \n",
        "        assert (len(new_all_entity_1_pos) == len(old_all_entity_1_pos)), \\\n",
        "        str('Num entity_text 1 in original sent not equal to num entity_text 1 in normalize sent. sent_id: ' + str(sentif['sent_id']))\n",
        "\n",
        "        assert (len(new_all_entity_2_pos) == len(old_all_entity_2_pos)), \\\n",
        "        str('Num entity_text 2 in original sent not equal to num entity_text 2 in normalize sent. sent_id: ' + str(sentif['sent_id']))\n",
        "\n",
        "\n",
        "        new_entity_1_pos = copy.deepcopy(new_all_entity_1_pos[entity_1_th])\n",
        "        new_entity_2_pos = copy.deepcopy(new_all_entity_2_pos[entity_2_th])\n",
        "\n",
        "        assert (new_sentence[new_entity_1_pos[0]:new_entity_1_pos[1]] == new_entity_1_text), \\\n",
        "        str('\\nAFTER NORMALIZE, ENTITY 1 TEXT NOT MATCH ENTITY 1 POS. sent_id: ' + str(sent_id))\n",
        "\n",
        "        assert (new_sentence[new_entity_2_pos[0]:new_entity_2_pos[1]] == new_entity_2_text), \\\n",
        "        str('\\nAFTER NORMALIZE, ENTITY 2 TEXT NOT MATCH ENTITY 2 POS. sent_id: ' + str(sent_id))\n",
        "\n",
        "\n",
        "    # thêm vào jtrain_data_v2\n",
        "    new_sentif_v2 = copy.deepcopy(sentif)\n",
        "\n",
        "    new_sentif_v2['new_sentence'] = copy.deepcopy(new_sentence)\n",
        "\n",
        "    new_entity_1 = copy.deepcopy({'text': copy.deepcopy(new_entity_1_text), 'pos': copy.deepcopy(new_entity_1_pos)})\n",
        "    new_entity_2 = copy.deepcopy({'text': copy.deepcopy(new_entity_2_text), 'pos': copy.deepcopy(new_entity_2_pos)})\n",
        "\n",
        "    new_sentif_v2['new_entity_1'] = copy.deepcopy(new_entity_1)\n",
        "    new_sentif_v2['new_entity_2'] = copy.deepcopy(new_entity_2)\n",
        "\n",
        "    jtrain_data_v2.append(copy.deepcopy(new_sentif_v2))\n",
        "\n",
        "\n",
        "    \n",
        "    # in để check xem code chạy đúng không\n",
        "    if jtrain_data_v2[-1]['new_sentence'] != sentif['sentence']:\n",
        "\n",
        "        print('\\n----- sent_id: ', sentif['sent_id'])\n",
        "        print('Original sent:   ', sentif['sentence'])\n",
        "        print('Normalized sent: ', jtrain_data_v2[-1]['new_sentence'])\n",
        "\n",
        "        print('Previous entity 1:   ', sentif['new_entity_1'])\n",
        "        print('Normalized entity 1: ', jtrain_data_v2[-1]['new_entity_1'])\n",
        "\n",
        "        print('Previous entity 2:   ', sentif['new_entity_2'])\n",
        "        print('Normalized entity 2: ', jtrain_data_v2[-1]['new_entity_2'])\n",
        "        \n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' BUG QUÁ NẶNG KHÔNG FIX ĐƯỢC NHƯNG MAY NGHĨ RA CÁCH KHÁC DÙ CHƯA BIẾT CÁCH MỚI CHẠY ỔN KHÔNG\\njtrain_data_v2 = []\\n\\nfor sentif in jtrain_data_v1:\\n\\n    new_sentence = copy.deepcopy(sentif[\\'sentence\\'])\\n    new_entity_1_text, new_entity_1_pos = copy.deepcopy(sentif[\\'new_entity_1\\'][\\'text\\']), copy.deepcopy(sentif[\\'new_entity_1\\'][\\'pos\\'])\\n    new_entity_2_text, new_entity_2_pos = copy.deepcopy(sentif[\\'new_entity_2\\'][\\'text\\']), copy.deepcopy(sentif[\\'new_entity_2\\'][\\'pos\\'])\\n\\n    if sentif[\\'sentence\\'] != unicodedata.normalize(\"NFC\", sentif[\\'sentence\\']):\\n\\n        # BUG:GGG sent_id: 12009\\n        # entity_text trong 1 câu gốc có thể có cả 2 loại biến thể là unicode lỗi và unicode chuẩn (giống như đã được normalize rồi). \\n        # Nên trong khi tìm pos của entity_text trong câu gốc cần tìm cho cả entity_text gốc và entity_text đã được normalize\\n        # Điều này cũng có nghĩa là nếu có nhiều entity_text trong câu gốc và mỗi cái lại có một unicode riêng thì khó mà xử lý được\\n        # và nếu entity là text chuẩn đã được normalize thì sẽ k xử lý được như bên dưới. do khi tìm trong câu gốc thì vì nó là text chuẩn\\n        # nên có normalize hay k normalize thì vẫn vậy và do đó tìm trong câu gốc vẫn chỉ ra 1 pos.\\n\\n        \\n        # tìm entity_text gốc trong câu gốc (bắt buộc phải thấy)\\n        old_all_entity_1_pos_1 = [[m.start(), m.end()] for m in re.finditer(sentif[\\'new_entity_1\\'][\\'text\\'], sentif[\\'sentence\\'])]\\n        old_all_entity_2_pos_1 = [[m.start(), m.end()] for m in re.finditer(sentif[\\'new_entity_2\\'][\\'text\\'], sentif[\\'sentence\\'])]\\n\\n        assert (len(old_all_entity_1_pos_1) > 0), str(\\'\\nNOT FOUND ENTITY 1 IN ORIGINAL SENTENCE. sent_id: \\' + str(sentif[\\'sent_id\\']))\\n        assert (len(old_all_entity_2_pos_1) > 0), str(\\'\\nNOT FOUND ENTITY 2 IN ORIGINAL SENTENCE. sent_id: \\' + str(sentif[\\'sent_id\\']))\\n\\n        # tìm entity_text normalized trong câu gốc (có thể thấy có thể không)\\n        old_all_entity_1_pos_2 = [[m.start(), m.end()] for m in re.finditer(unicodedata.normalize(\"NFC\", sentif[\\'new_entity_1\\'][\\'text\\']), sentif[\\'sentence\\'])]\\n        old_all_entity_2_pos_2 = [[m.start(), m.end()] for m in re.finditer(unicodedata.normalize(\"NFC\", sentif[\\'new_entity_2\\'][\\'text\\']), sentif[\\'sentence\\'])]\\n\\n        # combine, remove duplicate and sort\\n        old_all_entity_1_pos = []\\n\\n        for tmp1 in (old_all_entity_1_pos_1 + old_all_entity_1_pos_2):\\n            if tmp1 not in old_all_entity_1_pos:\\n                old_all_entity_1_pos.append(tmp1)\\n        \\n        old_all_entity_1_pos = sorted(old_all_entity_1_pos)\\n\\n        old_all_entity_2_pos = []\\n\\n        for tmp2 in (old_all_entity_2_pos_1 + old_all_entity_2_pos_2):\\n            if tmp2 not in old_all_entity_2_pos:\\n                old_all_entity_2_pos.append(tmp2)\\n        \\n        old_all_entity_2_pos = sorted(old_all_entity_2_pos)\\n\\n\\n\\n        # if not found element in list, list.index(element) will auto return error\\n        entity_1_th = old_all_entity_1_pos.index(sentif[\\'new_entity_1\\'][\\'pos\\'])\\n        entity_2_th = old_all_entity_2_pos.index(sentif[\\'new_entity_2\\'][\\'pos\\'])\\n\\n\\n        new_sentence = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif[\\'sentence\\']))\\n        new_entity_1_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif[\\'new_entity_1\\'][\\'text\\']))\\n        new_entity_2_text = copy.deepcopy(unicodedata.normalize(\"NFC\", sentif[\\'new_entity_2\\'][\\'text\\']))\\n\\n        new_all_entity_1_pos = [[m.start(), m.end()] for m in re.finditer(new_entity_1_text, new_sentence)]\\n        new_all_entity_2_pos = [[m.start(), m.end()] for m in re.finditer(new_entity_2_text, new_sentence)]\\n\\n\\n        ###\\n        if sentif[\\'sent_id\\'] == 12009:\\n            print(old_all_entity_2_pos)\\n            print(old_all_entity_2_pos_1)\\n            print(old_all_entity_2_pos_2)\\n            print(\\'\\n\\', new_all_entity_2_pos)\\n\\n\\n        ###\\n\\n\\n        \\n        assert (len(new_all_entity_1_pos) == len(old_all_entity_1_pos)),         str(\\'Num entity_text 1 in original sent not equal to num entity_text 1 in normalize sent. sent_id: \\' + str(sentif[\\'sent_id\\']))\\n\\n        assert (len(new_all_entity_2_pos) == len(old_all_entity_2_pos)),         str(\\'Num entity_text 2 in original sent not equal to num entity_text 2 in normalize sent. sent_id: \\' + str(sentif[\\'sent_id\\']))\\n\\n\\n        new_entity_1_pos = copy.deepcopy(new_all_entity_1_pos[entity_1_th])\\n        new_entity_2_pos = copy.deepcopy(new_all_entity_2_pos[entity_2_th])\\n\\n        assert (new_sentence[new_entity_1_pos[0]:new_entity_1_pos[1]] == new_entity_1_text),         str(\\'\\nAFTER NORMALIZE, ENTITY 1 TEXT NOT MATCH ENTITY 1 POS. sent_id: \\' + str(sent_id))\\n\\n        assert (new_sentence[new_entity_2_pos[0]:new_entity_2_pos[1]] == new_entity_2_text),         str(\\'\\nAFTER NORMALIZE, ENTITY 2 TEXT NOT MATCH ENTITY 2 POS. sent_id: \\' + str(sent_id))\\n\\n\\n    # thêm vào jtrain_data_v2\\n    new_sentif_v2 = copy.deepcopy(sentif)\\n\\n    new_sentif_v2[\\'new_sentence\\'] = copy.deepcopy(new_sentence)\\n\\n    new_entity_1 = copy.deepcopy({\\'text\\': copy.deepcopy(new_entity_1_text), \\'pos\\': copy.deepcopy(new_entity_1_pos)})\\n    new_entity_2 = copy.deepcopy({\\'text\\': copy.deepcopy(new_entity_2_text), \\'pos\\': copy.deepcopy(new_entity_2_pos)})\\n\\n    new_sentif_v2[\\'new_entity_1\\'] = copy.deepcopy(new_entity_1)\\n    new_sentif_v2[\\'new_entity_2\\'] = copy.deepcopy(new_entity_2)\\n\\n    jtrain_data_v2.append(copy.deepcopy(new_sentif_v2))\\n\\n\\n    \\n    # in để check xem code chạy đúng không\\n    if jtrain_data_v2[-1][\\'new_sentence\\'] != sentif[\\'sentence\\']:\\n\\n        print(\\'\\n----- sent_id: \\', sentif[\\'sent_id\\'])\\n        print(\\'Original sent:   \\', sentif[\\'sentence\\'])\\n        print(\\'Normalized sent: \\', jtrain_data_v2[-1][\\'new_sentence\\'])\\n\\n        print(\\'Previous entity 1:   \\', sentif[\\'new_entity_1\\'])\\n        print(\\'Normalized entity 1: \\', jtrain_data_v2[-1][\\'new_entity_1\\'])\\n\\n        print(\\'Previous entity 2:   \\', sentif[\\'new_entity_2\\'])\\n        print(\\'Normalized entity 2: \\', jtrain_data_v2[-1][\\'new_entity_2\\'])\\n        \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPuSYwKCBYRu"
      },
      "source": [
        "### fix start end of entity in train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-owmYTo3MwBo"
      },
      "source": [
        "jtrain_data_use = copy.deepcopy(jtrain_data_v1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZFgdq1PBbLl"
      },
      "source": [
        "#### Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ofb_f2_Bejx",
        "outputId": "1d85a80f-dd81-41f3-b7d9-92ddd24643a9"
      },
      "source": [
        "tmpppsent = []\n",
        "allchar_lst = []\n",
        "alnum_char_lst = []\n",
        "not_alnum_char_lst = []\n",
        "\n",
        "for sentif in jtrain_data_use:\n",
        "    if sentif['sentence'] not in tmpppsent:\n",
        "        for ch in sentif['sentence']:\n",
        "            if ch not in allchar_lst:\n",
        "                allchar_lst.append(ch)\n",
        "\n",
        "            if ch.isalnum() and (ch not in alnum_char_lst):\n",
        "                alnum_char_lst.append(ch)\n",
        "\n",
        "            if (not ch.isalnum()) and (ch not in not_alnum_char_lst):\n",
        "                not_alnum_char_lst.append(ch)\n",
        "              \n",
        "        tmpppsent.append(sentif['sentence'])\n",
        "\n",
        "\n",
        "print(len(allchar_lst))\n",
        "for i in range(0, len(allchar_lst), 30):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 30, len(allchar_lst) + 1)\n",
        "\n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(allchar_lst[i:end])))\n",
        "\n",
        "\n",
        "print('\\n', len(alnum_char_lst))\n",
        "for i in range(0, len(alnum_char_lst), 20):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 20, len(alnum_char_lst) + 1)\n",
        "\n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(alnum_char_lst[i:end])))\n",
        "\n",
        "\n",
        "print('\\n', len(not_alnum_char_lst))\n",
        "for i in range(0, len(not_alnum_char_lst), 20):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 20, len(not_alnum_char_lst) + 1)\n",
        "    \n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(not_alnum_char_lst[i:end])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195\n",
            "'Ả n h   m i ọ a T ứ t r ư ở g B ộ G D & Đ N u y ễ ị ĩ đ ã c'\n",
            "'ó ý k ế v ề ấ à . Ô ù L â S ắ p ớ , s ẽ ă ờ ể b ệ á ỉ ự q l'\n",
            "'ủ ạ d ẹ C ũ e o ữ ê ỏ ợ ậ ụ ổ ầ V – H P ú ồ ẻ : ( ) ằ ẫ ả ô'\n",
            "'Q ì ặ ò ? “ ” é í ừ ố x X 1 ơ 2 / 9 ử K … U - M ỹ R W w ỳ O'\n",
            "'I 0 6 5 8 4 f 7 ỷ % 3 A Á ỗ E õ ẩ z ẳ F Ý \" Â è \\ufeff J Z \\' \\xa0 ;'\n",
            "'Y Ủ ỡ ẵ Ư Ú Ấ j Ở ’ + Ơ Ạ Ứ ̣ ́ ̀ Í | Ê Ắ ỵ À Ế Ồ ‘ ! * ö <'\n",
            "'= > Ð ½ ² [ ] ñ ï Ẩ Ễ Ị Ề ̉ ̃'\n",
            "\n",
            " 159\n",
            "'Ả n h m i ọ a T ứ t r ư ở g B ộ G D Đ N'\n",
            "'u y ễ ị ĩ đ ã c ó ý k ế v ề ấ à Ô ù L â'\n",
            "'S ắ p ớ s ẽ ă ờ ể b ệ á ỉ ự q l ủ ạ d ẹ'\n",
            "'C ũ e o ữ ê ỏ ợ ậ ụ ổ ầ V H P ú ồ ẻ ằ ẫ'\n",
            "'ả ô Q ì ặ ò é í ừ ố x X 1 ơ 2 9 ử K U M'\n",
            "'ỹ R W w ỳ O I 0 6 5 8 4 f 7 ỷ 3 A Á ỗ E'\n",
            "'õ ẩ z ẳ F Ý Â è J Z Y Ủ ỡ ẵ Ư Ú Ấ j Ở Ơ'\n",
            "'Ạ Ứ Í Ê Ắ ỵ À Ế Ồ ö Ð ½ ² ñ ï Ẩ Ễ Ị Ề'\n",
            "\n",
            " 36\n",
            "'  & . , – : ( ) ? “ ” / … - % \" \\ufeff \\' \\xa0 ;'\n",
            "'’ + ̣ ́ ̀ | ‘ ! * < = > [ ] ̉ ̃'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLN0kQ-MDe71",
        "outputId": "010fdb76-0e81-4746-860a-6f8488176c2d"
      },
      "source": [
        "# review data\n",
        "# có vẻ là nếu trong entity có kí tự bắt đầu hoặc kết thúc là số thì k phải lỗi.\n",
        "\n",
        "for sentif in jtrain_data_use:\n",
        "    if (sentif['entity_1']['text'][0].isnumeric()) or (sentif['entity_1']['text'][-1].isnumeric()):\n",
        "        print(sentif['entity_1'])\n",
        "\n",
        "    if (sentif['entity_2']['text'][0].isnumeric()) or (sentif['entity_2']['text'][-1].isnumeric()):\n",
        "        print(sentif['entity_2'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'thôn Xuân Dục 1', 'pos': [155, 170]}\n",
            "{'text': 'thôn Xuân Dục 1', 'pos': [155, 170]}\n",
            "{'text': 'thôn Xuân Dục 1', 'pos': [155, 170]}\n",
            "{'text': 'thôn Xuân Dục 1', 'pos': [155, 170]}\n",
            "{'text': 'thôn Xuân Dục 1', 'pos': [155, 170]}\n",
            "{'text': 'thôn Xuân Dụ 1', 'pos': [96, 110]}\n",
            "{'text': 'thôn Xuân Dụ 1', 'pos': [96, 110]}\n",
            "{'text': 'thôn Xuân Dụ 1', 'pos': [96, 110]}\n",
            "{'text': 'thôn Xuân Dụ 1', 'pos': [96, 110]}\n",
            "{'text': 'QL1', 'pos': [75, 78]}\n",
            "{'text': 'QL1', 'pos': [75, 78]}\n",
            "{'text': 'QL1', 'pos': [75, 78]}\n",
            "{'text': 'Jelman21', 'pos': [62, 70]}\n",
            "{'text': 'Jelman21', 'pos': [62, 70]}\n",
            "{'text': 'Công an quận 3', 'pos': [12, 26]}\n",
            "{'text': 'Công an quận 3', 'pos': [12, 26]}\n",
            "{'text': 'Công an quận 3', 'pos': [12, 26]}\n",
            "{'text': 'Công an quận 3', 'pos': [12, 26]}\n",
            "{'text': '(quận 3', 'pos': [67, 74]}\n",
            "{'text': '(quận 3', 'pos': [67, 74]}\n",
            "{'text': 'Công ty Cổ phần DAP số 2', 'pos': [0, 24]}\n",
            "{'text': 'Công ty CP DAP số 2', 'pos': [115, 134]}\n",
            "{'text': 'Công ty CP DAP số 2', 'pos': [115, 134]}\n",
            "{'text': 'Công ty CP DAP số 2', 'pos': [115, 134]}\n",
            "{'text': 'Công ty CP DAP số 2', 'pos': [115, 134]}\n",
            "{'text': 'Tiểu khu 557', 'pos': [36, 48]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [181, 195]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [83, 97]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [83, 97]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [83, 97]}\n",
            "{'text': 'tổ 8', 'pos': [108, 112]}\n",
            "{'text': 'tổ 8', 'pos': [108, 112]}\n",
            "{'text': 'tổ 8', 'pos': [108, 112]}\n",
            "{'text': 'tổ 8', 'pos': [108, 112]}\n",
            "{'text': 'tổ 8', 'pos': [48, 52]}\n",
            "{'text': 'tổ 8', 'pos': [48, 52]}\n",
            "{'text': 'tổ 8', 'pos': [48, 52]}\n",
            "{'text': 'tổ 8', 'pos': [48, 52]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [36, 50]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [36, 50]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [36, 50]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [36, 50]}\n",
            "{'text': 'thôn Xuân Tự 1', 'pos': [36, 50]}\n",
            "{'text': 'phường 12', 'pos': [208, 217]}\n",
            "{'text': 'phường 12', 'pos': [208, 217]}\n",
            "{'text': 'phường 12', 'pos': [208, 217]}\n",
            "{'text': 'phường 12', 'pos': [208, 217]}\n",
            "{'text': 'Hội Nông dân phường 12', 'pos': [5, 27]}\n",
            "{'text': 'Hội Nông dân phường 12', 'pos': [5, 27]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': 'PC45', 'pos': [113, 117]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': '(PC 45', 'pos': [31, 37]}\n",
            "{'text': '(PC 45', 'pos': [31, 37]}\n",
            "{'text': '31/2016/TT-NHNN', 'pos': [125, 140]}\n",
            "{'text': '7295/NHNN', 'pos': [44, 53]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 12', 'pos': [131, 138]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 10', 'pos': [177, 184]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': 'quận 12', 'pos': [231, 238]}\n",
            "{'text': '(quận 12', 'pos': [87, 95]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': 'tổ 3', 'pos': [244, 248]}\n",
            "{'text': '(PC64', 'pos': [114, 119]}\n",
            "{'text': '(PC64', 'pos': [114, 119]}\n",
            "{'text': 'PC45', 'pos': [113, 117]}\n",
            "{'text': 'PC45', 'pos': [113, 117]}\n",
            "{'text': 'PC45', 'pos': [113, 117]}\n",
            "{'text': '(QL13', 'pos': [84, 89]}\n",
            "{'text': '(QL13', 'pos': [84, 89]}\n",
            "{'text': '(QL13', 'pos': [84, 89]}\n",
            "{'text': '(QL13', 'pos': [84, 89]}\n",
            "{'text': 'quận 1', 'pos': [80, 86]}\n",
            "{'text': 'quận 1', 'pos': [80, 86]}\n",
            "{'text': 'quận 1', 'pos': [80, 86]}\n",
            "{'text': 'quận 1', 'pos': [80, 86]}\n",
            "{'text': 'bet365', 'pos': [105, 111]}\n",
            "{'text': 'bet365', 'pos': [105, 111]}\n",
            "{'text': 'bet365', 'pos': [70, 76]}\n",
            "{'text': 'bet365', 'pos': [70, 76]}\n",
            "{'text': 'Bet365', 'pos': [50, 56]}\n",
            "{'text': 'Bet365', 'pos': [50, 56]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Công ty CP Quảng An 1', 'pos': [448, 469]}\n",
            "{'text': 'Thôn 6', 'pos': [114, 120]}\n",
            "{'text': 'Thôn 6', 'pos': [114, 120]}\n",
            "{'text': 'Thôn 6', 'pos': [114, 120]}\n",
            "{'text': 'Thôn 6', 'pos': [114, 120]}\n",
            "{'text': 'Thôn 6', 'pos': [114, 120]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ 13', 'pos': [61, 66]}\n",
            "{'text': 'tổ dân phố 8', 'pos': [68, 80]}\n",
            "{'text': 'tổ dân phố 8', 'pos': [68, 80]}\n",
            "{'text': 'Khu công nghiệp Biên Hòa 1', 'pos': [88, 114]}\n",
            "{'text': 'Khu công nghiệp Biên Hòa 1', 'pos': [88, 114]}\n",
            "{'text': 'Quốc lộ 51', 'pos': [143, 153]}\n",
            "{'text': 'Quốc lộ 51', 'pos': [143, 153]}\n",
            "{'text': '(Q.1', 'pos': [153, 157]}\n",
            "{'text': '(Q.1', 'pos': [153, 157]}\n",
            "{'text': '(Q.1', 'pos': [153, 157]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'khóm 1', 'pos': [203, 209]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'ấp Trung 2', 'pos': [315, 325]}\n",
            "{'text': 'Quốc lộ 18', 'pos': [24, 34]}\n",
            "{'text': 'Quốc lộ 18', 'pos': [24, 34]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [216, 235]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [216, 235]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [216, 235]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [216, 235]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [91, 110]}\n",
            "{'text': 'Ban quản lý dự án 2', 'pos': [91, 110]}\n",
            "{'text': 'khối 8', 'pos': [52, 58]}\n",
            "{'text': 'khối 8', 'pos': [52, 58]}\n",
            "{'text': 'khối 8', 'pos': [52, 58]}\n",
            "{'text': 'khối 8', 'pos': [52, 58]}\n",
            "{'text': 'khối 8', 'pos': [52, 58]}\n",
            "{'text': 'Công an quận 3', 'pos': [11, 25]}\n",
            "{'text': 'Công an quận 3', 'pos': [11, 25]}\n",
            "{'text': 'Công an quận 3', 'pos': [11, 25]}\n",
            "{'text': '(phường 3', 'pos': [67, 76]}\n",
            "{'text': 'quận 3', 'pos': [79, 85]}\n",
            "{'text': '(phường 3', 'pos': [67, 76]}\n",
            "{'text': 'quận 3', 'pos': [79, 85]}\n",
            "{'text': 'quận 3', 'pos': [29, 35]}\n",
            "{'text': 'thôn 6', 'pos': [174, 180]}\n",
            "{'text': 'thôn 6', 'pos': [174, 180]}\n",
            "{'text': 'thôn 6', 'pos': [174, 180]}\n",
            "{'text': 'thôn 6', 'pos': [174, 180]}\n",
            "{'text': 'thôn 6', 'pos': [174, 180]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [70, 83]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [45, 58]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [6, 19]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [6, 19]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [6, 19]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [6, 19]}\n",
            "{'text': 'Ủy ban Quốc gia APEC 2017', 'pos': [36, 61]}\n",
            "{'text': 'Ủy ban Quốc gia APEC 2017', 'pos': [36, 61]}\n",
            "{'text': '(PC67', 'pos': [44, 49]}\n",
            "{'text': '(PC67', 'pos': [44, 49]}\n",
            "{'text': 'PC67', 'pos': [179, 183]}\n",
            "{'text': 'PC67', 'pos': [179, 183]}\n",
            "{'text': 'PC67', 'pos': [179, 183]}\n",
            "{'text': 'PC67', 'pos': [44, 48]}\n",
            "{'text': 'Tiểu học Kỳ Thịnh 2', 'pos': [31, 50]}\n",
            "{'text': 'Tiểu học Kỳ Thịnh 2', 'pos': [31, 50]}\n",
            "{'text': 'Trường Tiểu học Kỳ Thịnh 2', 'pos': [10, 36]}\n",
            "{'text': 'Khu công nghiệp Biên Hòa 1', 'pos': [90, 116]}\n",
            "{'text': 'quốc lộ 51', 'pos': [120, 130]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [123, 154]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [123, 154]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [123, 154]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [123, 154]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [123, 154]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [139, 170]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 1', 'pos': [181, 212]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [90, 121]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [90, 121]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [90, 121]}\n",
            "{'text': 'Nhà máy sản xuất phân bón DAP 2', 'pos': [90, 121]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [214, 248]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'DAP số 2', 'pos': [264, 272]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [190, 224]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [243, 277]}\n",
            "{'text': 'DAP số 2', 'pos': [110, 118]}\n",
            "{'text': 'DAP số 2', 'pos': [110, 118]}\n",
            "{'text': 'DAP số 2', 'pos': [110, 118]}\n",
            "{'text': 'DAP số 2', 'pos': [110, 118]}\n",
            "{'text': 'DAP số 2', 'pos': [110, 118]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 2', 'pos': [314, 348]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'nhà máy sản xuất phân bón DAP số 1', 'pos': [367, 401]}\n",
            "{'text': 'Đoàn thanh niên Ban QLDA 5', 'pos': [36, 62]}\n",
            "{'text': 'Đoàn thanh niên Ban QLDA 5', 'pos': [36, 62]}\n",
            "{'text': 'xóm 5', 'pos': [57, 62]}\n",
            "{'text': 'xóm 5', 'pos': [57, 62]}\n",
            "{'text': 'xóm 5', 'pos': [57, 62]}\n",
            "{'text': 'xóm 5', 'pos': [57, 62]}\n",
            "{'text': 'xóm 5', 'pos': [57, 62]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': 'xóm 7', 'pos': [26, 31]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [147, 163]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [147, 163]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [256, 277]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [256, 277]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [256, 277]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [256, 277]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [256, 277]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [43, 64]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [43, 64]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [43, 64]}\n",
            "{'text': 'lớp Kỹ thuật y học K5', 'pos': [43, 64]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [67, 82]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [67, 82]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [67, 82]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [67, 82]}\n",
            "{'text': 'Bệnh viện Nhân dân 115', 'pos': [95, 117]}\n",
            "{'text': 'Bệnh viện Nhân dân 115', 'pos': [95, 117]}\n",
            "{'text': 'Bệnh viện Nhân dân 115', 'pos': [95, 117]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [82, 97]}\n",
            "{'text': '(Quận 10', 'pos': [55, 63]}\n",
            "{'text': '(Quận 10', 'pos': [55, 63]}\n",
            "{'text': '(Quận 10', 'pos': [55, 63]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [89, 104]}\n",
            "{'text': 'BV Nhân dân 115', 'pos': [89, 104]}\n",
            "{'text': 'bến K15', 'pos': [215, 222]}\n",
            "{'text': 'bến K15', 'pos': [215, 222]}\n",
            "{'text': 'bến K15', 'pos': [215, 222]}\n",
            "{'text': 'bến K15', 'pos': [215, 222]}\n",
            "{'text': 'bến K15', 'pos': [215, 222]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'nhóm P5+1', 'pos': [41, 50]}\n",
            "{'text': 'nhóm P5+1', 'pos': [41, 50]}\n",
            "{'text': 'nhóm P5+1', 'pos': [41, 50]}\n",
            "{'text': '87 Mã Mây', 'pos': [7, 16]}\n",
            "{'text': '87 Mã Mây', 'pos': [7, 16]}\n",
            "{'text': '42-44 Hàng Bạc', 'pos': [33, 47]}\n",
            "{'text': '87 Mã Mây', 'pos': [7, 16]}\n",
            "{'text': '87 Mã Mây', 'pos': [7, 16]}\n",
            "{'text': '50 Đào Duy Từ', 'pos': [91, 104]}\n",
            "{'text': '42-44 Hàng Bạc', 'pos': [33, 47]}\n",
            "{'text': '50 Đào Duy Từ', 'pos': [91, 104]}\n",
            "{'text': '42-44 Hàng Bạc', 'pos': [33, 47]}\n",
            "{'text': '42-44 Hàng Bạc', 'pos': [33, 47]}\n",
            "{'text': '50 Đào Duy Từ', 'pos': [91, 104]}\n",
            "{'text': '50 Đào Duy Từ', 'pos': [91, 104]}\n",
            "{'text': 'Tòa nhà trung tâm liên bang 1202', 'pos': [0, 32]}\n",
            "{'text': 'Tòa nhà trung tâm liên bang 1202', 'pos': [0, 32]}\n",
            "{'text': 'ngách 35/15', 'pos': [38, 49]}\n",
            "{'text': 'ngách 35/15', 'pos': [38, 49]}\n",
            "{'text': 'ngách 35/15', 'pos': [38, 49]}\n",
            "{'text': 'ngách 35/15', 'pos': [38, 49]}\n",
            "{'text': 'Đại đội 2', 'pos': [31, 40]}\n",
            "{'text': 'Đại đội 2', 'pos': [31, 40]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': 'Đại đội 2', 'pos': [162, 171]}\n",
            "{'text': '36 Lý Thái Tổ', 'pos': [86, 99]}\n",
            "{'text': 'Quận 1', 'pos': [80, 86]}\n",
            "{'text': 'Quận 1', 'pos': [80, 86]}\n",
            "{'text': 'QL1', 'pos': [61, 64]}\n",
            "{'text': 'QL1', 'pos': [13, 16]}\n",
            "{'text': 'quận 9', 'pos': [172, 178]}\n",
            "{'text': 'quận 9', 'pos': [172, 178]}\n",
            "{'text': 'quận 9', 'pos': [172, 178]}\n",
            "{'text': 'quận 9', 'pos': [172, 178]}\n",
            "{'text': 'quận 9', 'pos': [172, 178]}\n",
            "{'text': '(quận 9', 'pos': [90, 97]}\n",
            "{'text': '(quận 9', 'pos': [90, 97]}\n",
            "{'text': 'phòng GD&ĐT quận 9', 'pos': [32, 50]}\n",
            "{'text': '87 Mã Mây', 'pos': [32, 41]}\n",
            "{'text': '44 Hàng Bạc', 'pos': [44, 55]}\n",
            "{'text': '87 Mã Mây', 'pos': [32, 41]}\n",
            "{'text': '28 Hàng Buồm', 'pos': [58, 70]}\n",
            "{'text': '87 Mã Mây', 'pos': [32, 41]}\n",
            "{'text': '44 Hàng Bạc', 'pos': [44, 55]}\n",
            "{'text': '28 Hàng Buồm', 'pos': [58, 70]}\n",
            "{'text': '44 Hàng Bạc', 'pos': [44, 55]}\n",
            "{'text': '28 Hàng Buồm', 'pos': [58, 70]}\n",
            "{'text': 'ấp 7', 'pos': [137, 141]}\n",
            "{'text': 'ấp 7', 'pos': [137, 141]}\n",
            "{'text': 'ấp 7', 'pos': [137, 141]}\n",
            "{'text': 'ấp 7', 'pos': [137, 141]}\n",
            "{'text': 'ấp 7', 'pos': [137, 141]}\n",
            "{'text': 'Trường Hoàng Diệu 1', 'pos': [14, 33]}\n",
            "{'text': 'Q.1', 'pos': [43, 46]}\n",
            "{'text': 'Q.1', 'pos': [43, 46]}\n",
            "{'text': 'Q.1', 'pos': [43, 46]}\n",
            "{'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "{'text': 'KP.2', 'pos': [39, 43]}\n",
            "{'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "{'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "{'text': 'Q.7', 'pos': [60, 63]}\n",
            "{'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "{'text': 'KP.2', 'pos': [39, 43]}\n",
            "{'text': 'KP.2', 'pos': [39, 43]}\n",
            "{'text': 'Q.7', 'pos': [60, 63]}\n",
            "{'text': 'KP.2', 'pos': [39, 43]}\n",
            "{'text': 'Q.7', 'pos': [60, 63]}\n",
            "{'text': 'Q.7', 'pos': [60, 63]}\n",
            "{'text': '(P.4', 'pos': [22, 26]}\n",
            "{'text': 'Q.3', 'pos': [29, 32]}\n",
            "{'text': '(P.4', 'pos': [22, 26]}\n",
            "{'text': 'Q.3', 'pos': [29, 32]}\n",
            "{'text': '(Q.3', 'pos': [22, 26]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': 'P.3', 'pos': [54, 57]}\n",
            "{'text': 'Q.3', 'pos': [60, 63]}\n",
            "{'text': 'P.3', 'pos': [54, 57]}\n",
            "{'text': 'Q.3', 'pos': [60, 63]}\n",
            "{'text': 'P.3', 'pos': [54, 57]}\n",
            "{'text': 'Q.3', 'pos': [60, 63]}\n",
            "{'text': 'P.3', 'pos': [54, 57]}\n",
            "{'text': 'Q.3', 'pos': [60, 63]}\n",
            "{'text': 'Q.10', 'pos': [54, 58]}\n",
            "{'text': 'Q.10', 'pos': [54, 58]}\n",
            "{'text': 'Q.10', 'pos': [54, 58]}\n",
            "{'text': '(Q.1', 'pos': [30, 34]}\n",
            "{'text': '(Q.1', 'pos': [30, 34]}\n",
            "{'text': '(Q.4', 'pos': [32, 36]}\n",
            "{'text': '(Q.4', 'pos': [32, 36]}\n",
            "{'text': '(Q.8', 'pos': [36, 40]}\n",
            "{'text': '(Q.8', 'pos': [36, 40]}\n",
            "{'text': 'Q.1', 'pos': [40, 43]}\n",
            "{'text': 'Q.1', 'pos': [40, 43]}\n",
            "{'text': 'Q.1', 'pos': [40, 43]}\n",
            "{'text': '(Q.12', 'pos': [22, 27]}\n",
            "{'text': 'P.1', 'pos': [51, 54]}\n",
            "{'text': 'P.1', 'pos': [51, 54]}\n",
            "{'text': 'P.1', 'pos': [51, 54]}\n",
            "{'text': 'P.12', 'pos': [44, 48]}\n",
            "{'text': 'Q.3', 'pos': [51, 54]}\n",
            "{'text': 'P.12', 'pos': [44, 48]}\n",
            "{'text': 'Q.3', 'pos': [51, 54]}\n",
            "{'text': 'P.12', 'pos': [44, 48]}\n",
            "{'text': 'Q.3', 'pos': [51, 54]}\n",
            "{'text': 'P.1', 'pos': [47, 50]}\n",
            "{'text': 'P.1', 'pos': [47, 50]}\n",
            "{'text': 'P.1', 'pos': [47, 50]}\n",
            "{'text': 'Q.1', 'pos': [59, 62]}\n",
            "{'text': 'Q.1', 'pos': [59, 62]}\n",
            "{'text': 'Q.1', 'pos': [59, 62]}\n",
            "{'text': 'P.14', 'pos': [48, 52]}\n",
            "{'text': 'Q.3', 'pos': [55, 58]}\n",
            "{'text': 'P.14', 'pos': [48, 52]}\n",
            "{'text': 'Q.3', 'pos': [55, 58]}\n",
            "{'text': 'P.14', 'pos': [48, 52]}\n",
            "{'text': 'Q.3', 'pos': [55, 58]}\n",
            "{'text': 'P.14', 'pos': [48, 52]}\n",
            "{'text': 'Q.3', 'pos': [55, 58]}\n",
            "{'text': 'P.13', 'pos': [44, 48]}\n",
            "{'text': 'Q.6', 'pos': [51, 54]}\n",
            "{'text': 'P.13', 'pos': [44, 48]}\n",
            "{'text': 'Q.6', 'pos': [51, 54]}\n",
            "{'text': 'P.13', 'pos': [44, 48]}\n",
            "{'text': 'Q.6', 'pos': [51, 54]}\n",
            "{'text': 'P.13', 'pos': [44, 48]}\n",
            "{'text': 'Q.6', 'pos': [51, 54]}\n",
            "{'text': '(Q.3', 'pos': [32, 36]}\n",
            "{'text': '(Q.3', 'pos': [32, 36]}\n",
            "{'text': '(Q.3', 'pos': [22, 26]}\n",
            "{'text': 'P.3', 'pos': [53, 56]}\n",
            "{'text': 'P.3', 'pos': [53, 56]}\n",
            "{'text': 'P.3', 'pos': [53, 56]}\n",
            "{'text': 'P.3', 'pos': [53, 56]}\n",
            "{'text': 'P.13', 'pos': [62, 66]}\n",
            "{'text': 'P.13', 'pos': [62, 66]}\n",
            "{'text': 'P.13', 'pos': [62, 66]}\n",
            "{'text': 'P.13', 'pos': [62, 66]}\n",
            "{'text': 'Q.1', 'pos': [46, 49]}\n",
            "{'text': 'Q.1', 'pos': [46, 49]}\n",
            "{'text': 'Q.1', 'pos': [46, 49]}\n",
            "{'text': 'Q.7', 'pos': [50, 53]}\n",
            "{'text': 'Q.7', 'pos': [50, 53]}\n",
            "{'text': 'P.6', 'pos': [53, 56]}\n",
            "{'text': 'Q.3', 'pos': [59, 62]}\n",
            "{'text': 'P.6', 'pos': [53, 56]}\n",
            "{'text': 'Q.3', 'pos': [59, 62]}\n",
            "{'text': 'P.6', 'pos': [53, 56]}\n",
            "{'text': 'Q.3', 'pos': [59, 62]}\n",
            "{'text': 'P.6', 'pos': [53, 56]}\n",
            "{'text': 'Q.3', 'pos': [59, 62]}\n",
            "{'text': '(P.7', 'pos': [26, 30]}\n",
            "{'text': 'Q.3', 'pos': [33, 36]}\n",
            "{'text': '(P.7', 'pos': [26, 30]}\n",
            "{'text': 'Q.3', 'pos': [33, 36]}\n",
            "{'text': '(P.7', 'pos': [26, 30]}\n",
            "{'text': 'Q.3', 'pos': [33, 36]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': 'Q.1', 'pos': [50, 53]}\n",
            "{'text': '(Q.4', 'pos': [48, 52]}\n",
            "{'text': '(Q.4', 'pos': [48, 52]}\n",
            "{'text': '(Q.4', 'pos': [48, 52]}\n",
            "{'text': 'Q.3', 'pos': [44, 47]}\n",
            "{'text': 'Q.3', 'pos': [44, 47]}\n",
            "{'text': '(P.1', 'pos': [24, 28]}\n",
            "{'text': 'Q.3', 'pos': [31, 34]}\n",
            "{'text': '(P.1', 'pos': [24, 28]}\n",
            "{'text': 'Q.3', 'pos': [31, 34]}\n",
            "{'text': '(P.1', 'pos': [24, 28]}\n",
            "{'text': 'Q.3', 'pos': [31, 34]}\n",
            "{'text': 'P.24', 'pos': [48, 52]}\n",
            "{'text': 'P.24', 'pos': [48, 52]}\n",
            "{'text': 'P.24', 'pos': [48, 52]}\n",
            "{'text': 'P.24', 'pos': [48, 52]}\n",
            "{'text': 'Q.1', 'pos': [45, 48]}\n",
            "{'text': 'Q.1', 'pos': [45, 48]}\n",
            "{'text': 'Q.1', 'pos': [45, 48]}\n",
            "{'text': '(Q.3', 'pos': [23, 27]}\n",
            "{'text': '(Q.3', 'pos': [23, 27]}\n",
            "{'text': '(Q.10', 'pos': [30, 35]}\n",
            "{'text': '(Q.10', 'pos': [30, 35]}\n",
            "{'text': '(P.7', 'pos': [29, 33]}\n",
            "{'text': 'Q.3', 'pos': [36, 39]}\n",
            "{'text': '(P.7', 'pos': [29, 33]}\n",
            "{'text': 'Q.3', 'pos': [36, 39]}\n",
            "{'text': '(P.7', 'pos': [29, 33]}\n",
            "{'text': 'Q.3', 'pos': [36, 39]}\n",
            "{'text': 'Q.7', 'pos': [57, 60]}\n",
            "{'text': 'Q.7', 'pos': [57, 60]}\n",
            "{'text': 'Q.7', 'pos': [57, 60]}\n",
            "{'text': 'P.2', 'pos': [63, 66]}\n",
            "{'text': 'P.2', 'pos': [63, 66]}\n",
            "{'text': 'P.2', 'pos': [63, 66]}\n",
            "{'text': 'P.2', 'pos': [63, 66]}\n",
            "{'text': '(Cafe 90', 'pos': [33, 41]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [95, 111]}\n",
            "{'text': '(PC67', 'pos': [161, 166]}\n",
            "{'text': '(PC67', 'pos': [161, 166]}\n",
            "{'text': '(PC67', 'pos': [161, 166]}\n",
            "{'text': '(PC67', 'pos': [161, 166]}\n",
            "{'text': 'PC67', 'pos': [68, 72]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'trường Tiểu học Kỳ Thịnh 2', 'pos': [271, 297]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': 'A Đăng 1', 'pos': [140, 148]}\n",
            "{'text': '(Q.1', 'pos': [176, 180]}\n",
            "{'text': '(Q.1', 'pos': [176, 180]}\n",
            "{'text': '(Q.1', 'pos': [176, 180]}\n",
            "{'text': '(Q.1', 'pos': [176, 180]}\n",
            "{'text': '(Q.1', 'pos': [176, 180]}\n",
            "{'text': '(Q.1', 'pos': [106, 110]}\n",
            "{'text': '(Q.1', 'pos': [106, 110]}\n",
            "{'text': '(Q.1', 'pos': [106, 110]}\n",
            "{'text': '(quận 1', 'pos': [114, 121]}\n",
            "{'text': '(quận 1', 'pos': [114, 121]}\n",
            "{'text': '(quận 1', 'pos': [114, 121]}\n",
            "{'text': 'phường 8', 'pos': [151, 159]}\n",
            "{'text': 'phường 8', 'pos': [151, 159]}\n",
            "{'text': 'phường 8', 'pos': [151, 159]}\n",
            "{'text': 'phường 8', 'pos': [151, 159]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': 'tổ dân phố 9', 'pos': [258, 270]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [48, 62]}\n",
            "{'text': 'TDP 9', 'pos': [65, 70]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [48, 62]}\n",
            "{'text': 'TDP 9', 'pos': [65, 70]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [48, 62]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [48, 62]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [48, 62]}\n",
            "{'text': 'TDP 9', 'pos': [65, 70]}\n",
            "{'text': 'TDP 9', 'pos': [65, 70]}\n",
            "{'text': 'TDP 9', 'pos': [65, 70]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'Văn phòng kiến trúc 1+1>2', 'pos': [95, 120]}\n",
            "{'text': 'Văn phòng kiến trúc 1+1>2', 'pos': [95, 120]}\n",
            "{'text': 'Văn phòng kiến trúc 1+1>2', 'pos': [95, 120]}\n",
            "{'text': 'tàu CSB 4006', 'pos': [135, 147]}\n",
            "{'text': 'Hải đội 101', 'pos': [149, 160]}\n",
            "{'text': 'tàu CSB 4006', 'pos': [135, 147]}\n",
            "{'text': 'Vùng Cảnh sát biển 1', 'pos': [163, 183]}\n",
            "{'text': 'Hải đội 101', 'pos': [149, 160]}\n",
            "{'text': 'Vùng Cảnh sát biển 1', 'pos': [163, 183]}\n",
            "{'text': 'quận 9', 'pos': [125, 131]}\n",
            "{'text': 'quận 9', 'pos': [125, 131]}\n",
            "{'text': '(quận 9', 'pos': [90, 97]}\n",
            "{'text': '(quận 9', 'pos': [90, 97]}\n",
            "{'text': '(quận 9', 'pos': [103, 110]}\n",
            "{'text': '(quận 9', 'pos': [103, 110]}\n",
            "{'text': '(quận 9', 'pos': [103, 110]}\n",
            "{'text': '(quận 9', 'pos': [103, 110]}\n",
            "{'text': '(quận 9', 'pos': [103, 110]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [92, 106]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [92, 106]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [92, 106]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n",
            "{'text': 'THCS Mỹ Đình 1', 'pos': [38, 52]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7id7lFXpDmfk",
        "outputId": "6d6d11c7-32bc-42d5-b151-4c98bc37416d"
      },
      "source": [
        "for sentif in jtrain_data_use:\n",
        "    if ('½' in sentif['entity_1']['text']) or ('²' in sentif['entity_1']['text']) or ('ï' in sentif['entity_1']['text']):\n",
        "        print(sentif['entity_1'])\n",
        "\n",
        "    if ('½' in sentif['entity_2']['text']) or ('²' in sentif['entity_2']['text']) or ('ï' in sentif['entity_2']['text']):\n",
        "        print(sentif['entity_2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "{'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "{'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "{'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "{'text': 'Leïla Slimani', 'pos': [107, 120]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec1xD8cEFsm2",
        "outputId": "41ba3df6-8335-485f-dcd5-6e79f3419550"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "tmpppent = []\n",
        "for sentif in jtrain_data_use:\n",
        "    if (not sentif['entity_1']['text'][0].isalnum()) or (not sentif['entity_1']['text'][-1].isalnum()):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (not sentif['entity_2']['text'][0].isalnum()) or (not sentif['entity_2']['text'][-1].isalnum()):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '(Hà Nội', 'pos': [177, 184]}\n",
            "{'text': '(Thái Nguyên', 'pos': [212, 224]}\n",
            "{'text': '(Techcombank', 'pos': [170, 182]}\n",
            "{'text': '“Việt Nam', 'pos': [0, 9]}\n",
            "{'text': '(Thụy Sĩ', 'pos': [106, 114]}\n",
            "{'text': '(IEA', 'pos': [141, 145]}\n",
            "{'text': '(BNEF', 'pos': [175, 180]}\n",
            "{'text': '\\ufeffTrung Quốc', 'pos': [0, 11]}\n",
            "{'text': '(CCTV', 'pos': [56, 61]}\n",
            "{'text': \"'Đông Phương Bất Bại\", 'pos': [13, 33]}\n",
            "{'text': '\"Đông Phương Bất Bại', 'pos': [51, 71]}\n",
            "{'text': '\"Trần Kiều Ân', 'pos': [0, 13]}\n",
            "{'text': '(Trung Quốc', 'pos': [34, 45]}\n",
            "{'text': '(TP.HCM', 'pos': [27, 34]}\n",
            "{'text': '(quận 3', 'pos': [67, 74]}\n",
            "{'text': 'H.T.H.', 'pos': [46, 52]}\n",
            "{'text': 'H.', 'pos': [16, 18]}\n",
            "{'text': '(TITC', 'pos': [56, 61]}\n",
            "{'text': '-TP.Hồ Chí Minh', 'pos': [144, 159]}\n",
            "{'text': '(Vinachem', 'pos': [219, 228]}\n",
            "{'text': '(Vietinbank', 'pos': [191, 202]}\n",
            "{'text': '(Ban Tuyên giáo LĐLĐ TP Đà Nẵng', 'pos': [9, 40]}\n",
            "{'text': '\\xa0Shin Jin Ju', 'pos': [18, 30]}\n",
            "{'text': '(tỉnh Quảng Nam', 'pos': [170, 185]}\n",
            "{'text': '(Lệ Thủy', 'pos': [117, 125]}\n",
            "{'text': '(AFF', 'pos': [16, 20]}\n",
            "{'text': 'N.T.T.', 'pos': [68, 74]}\n",
            "{'text': 'N.C.', 'pos': [40, 44]}\n",
            "{'text': 'C.', 'pos': [112, 114]}\n",
            "{'text': 'T.', 'pos': [156, 158]}\n",
            "{'text': '(ILO', 'pos': [26, 30]}\n",
            "{'text': '(OECD', 'pos': [120, 125]}\n",
            "{'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n",
            "{'text': 'Cáp Trọng Th.', 'pos': [25, 38]}\n",
            "{'text': 'Cáp Trọng T.', 'pos': [39, 51]}\n",
            "{'text': 'Th.', 'pos': [76, 79]}\n",
            "{'text': 'Nguyễn Thị H.', 'pos': [46, 59]}\n",
            "{'text': '(PC45', 'pos': [230, 235]}\n",
            "{'text': '(PC 45', 'pos': [31, 37]}\n",
            "{'text': '(NHNN', 'pos': [35, 40]}\n",
            "{'text': '(MBB', 'pos': [88, 92]}\n",
            "{'text': '(OCB', 'pos': [106, 110]}\n",
            "{'text': '(VIB', 'pos': [61, 65]}\n",
            "{'text': '(NCB', 'pos': [50, 54]}\n",
            "{'text': '(OceanBank', 'pos': [134, 144]}\n",
            "{'text': '(Singapore', 'pos': [19, 29]}\n",
            "{'text': '(quận 12', 'pos': [87, 95]}\n",
            "{'text': '(PC64', 'pos': [114, 119]}\n",
            "{'text': '(QL13', 'pos': [84, 89]}\n",
            "{'text': '(Quảng Trị', 'pos': [250, 260]}\n",
            "{'text': \"'Cavani\", 'pos': [0, 7]}\n",
            "{'text': '(Pháp', 'pos': [12, 17]}\n",
            "{'text': 'Việt “đỏ”', 'pos': [105, 114]}\n",
            "{'text': '(Mỹ Đức', 'pos': [33, 40]}\n",
            "{'text': '(Mường La', 'pos': [38, 47]}\n",
            "{'text': ';\\xa0Tập đoàn xăng dầu Việt Nam', 'pos': [38, 66]}\n",
            "{'text': ';\\xa0Công ty TNHH xuất nhập khẩu 3A Việt Nam', 'pos': [207, 248]}\n",
            "{'text': 'Công ty CP du lịch văn hóa An Nguyên;', 'pos': [310, 347]}\n",
            "{'text': '\\xa0Công ty Điện lực Sơn La', 'pos': [421, 445]}\n",
            "{'text': '(Gia Lai', 'pos': [87, 95]}\n",
            "{'text': '(MTTQVN', 'pos': [152, 159]}\n",
            "{'text': '(WHO', 'pos': [65, 69]}\n",
            "{'text': 'Nguyễn Danh Vĩnh\\xa0', 'pos': [196, 213]}\n",
            "{'text': 'N.', 'pos': [25, 27]}\n",
            "{'text': '(USAID', 'pos': [268, 274]}\n",
            "{'text': '(Q.1', 'pos': [153, 157]}\n",
            "{'text': '(Đồng Tháp', 'pos': [68, 78]}\n",
            "{'text': '-Uông Bí', 'pos': [19, 27]}\n",
            "{'text': '/Vietnam+', 'pos': [9, 18]}\n",
            "{'text': '(phường 3', 'pos': [67, 76]}\n",
            "{'text': '(TAC', 'pos': [74, 78]}\n",
            "{'text': '(quận Tây Hồ', 'pos': [154, 166]}\n",
            "{'text': '(quận Hoàng Mai', 'pos': [41, 56]}\n",
            "{'text': '-HIẾU MINH', 'pos': [12, 22]}\n",
            "{'text': '(Cộng hòa Czech', 'pos': [51, 66]}\n",
            "{'text': '(Anh', 'pos': [123, 127]}\n",
            "{'text': '(TP Cần Thơ', 'pos': [60, 71]}\n",
            "{'text': '“Câu lạc bộ điểm vườn du lịch Phong Điền', 'pos': [120, 160]}\n",
            "{'text': '(Phòng CSGT Thanh Hóa', 'pos': [84, 105]}\n",
            "{'text': \"'Real Madrid\", 'pos': [0, 12]}\n",
            "{'text': '“Bộ GD&ĐT', 'pos': [0, 9]}\n",
            "{'text': '(IMF', 'pos': [51, 55]}\n",
            "{'text': '(PBOC', 'pos': [105, 110]}\n",
            "{'text': '(Long An', 'pos': [153, 161]}\n",
            "{'text': '(WTO', 'pos': [209, 213]}\n",
            "{'text': '(Bỉ', 'pos': [113, 116]}\n",
            "{'text': '(Hàn Quốc', 'pos': [148, 157]}\n",
            "{'text': '(ASEAN', 'pos': [85, 91]}\n",
            "{'text': '(EU', 'pos': [115, 118]}\n",
            "{'text': '(S&P', 'pos': [16, 20]}\n",
            "{'text': '(Pháp luật TPHCM', 'pos': [15, 31]}\n",
            "{'text': '(Bộ NN&PTNT', 'pos': [228, 239]}\n",
            "{'text': '\"UNICEF', 'pos': [0, 7]}\n",
            "{'text': '-Thái Bình Dương', 'pos': [396, 412]}\n",
            "{'text': '(Dân Việt', 'pos': [14, 23]}\n",
            "{'text': '(Quảng Bình', 'pos': [276, 287]}\n",
            "{'text': '(MSN', 'pos': [31, 35]}\n",
            "{'text': '(HNX', 'pos': [34, 38]}\n",
            "{'text': '(Kido Foods', 'pos': [126, 137]}\n",
            "{'text': '(UBCKNN', 'pos': [28, 35]}\n",
            "{'text': '(VISecurities', 'pos': [99, 112]}\n",
            "{'text': '(HAGL Agrico', 'pos': [54, 66]}\n",
            "{'text': '(Vinh Râu', 'pos': [71, 80]}\n",
            "{'text': '(Diệu Nhi', 'pos': [105, 114]}\n",
            "{'text': '(PC67', 'pos': [44, 49]}\n",
            "{'text': '(Báo Tuổi Trẻ', 'pos': [44, 57]}\n",
            "{'text': '/TTXVN', 'pos': [14, 20]}\n",
            "{'text': '(Thăng Long', 'pos': [80, 91]}\n",
            "{'text': '(Thái Bình', 'pos': [72, 82]}\n",
            "{'text': '(DQS', 'pos': [59, 63]}\n",
            "{'text': '(TISCO', 'pos': [73, 79]}\n",
            "{'text': '‘thánh Andres’', 'pos': [160, 174]}\n",
            "{'text': '‘Neymar', 'pos': [60, 67]}\n",
            "{'text': '/VOV', 'pos': [10, 14]}\n",
            "{'text': '-Miền Trung', 'pos': [15, 26]}\n",
            "{'text': '“Real Madrid', 'pos': [40, 52]}\n",
            "{'text': '(Các tiểu vương quốc Ả Rập thống nhất', 'pos': [128, 165]}\n",
            "{'text': '(CH Séc', 'pos': [12, 19]}\n",
            "{'text': '(Bulgaria', 'pos': [53, 62]}\n",
            "{'text': '(Phạm Thị Hương', 'pos': [114, 129]}\n",
            "{'text': '(Trần Thị Bích Thủy', 'pos': [175, 194]}\n",
            "{'text': '(HTS', 'pos': [195, 199]}\n",
            "{'text': '“Zvezda', 'pos': [22, 29]}\n",
            "{'text': '(SDF', 'pos': [137, 141]}\n",
            "{'text': '(IS', 'pos': [299, 302]}\n",
            "{'text': '-Iraq', 'pos': [414, 419]}\n",
            "{'text': '(SAA', 'pos': [34, 38]}\n",
            "{'text': \"'Ronaldo xứ Nghệ'\", 'pos': [10, 27]}\n",
            "{'text': '\"Ronaldo xứ Nghệ\"', 'pos': [108, 125]}\n",
            "{'text': '(VFF', 'pos': [140, 144]}\n",
            "{'text': '(Indonesia', 'pos': [113, 123]}\n",
            "{'text': '(FAT', 'pos': [97, 101]}\n",
            "{'text': '(Thành', 'pos': [79, 85]}\n",
            "{'text': '(Phương', 'pos': [100, 107]}\n",
            "{'text': '(Sơn', 'pos': [124, 128]}\n",
            "{'text': '(Mai', 'pos': [166, 170]}\n",
            "{'text': '(Trang', 'pos': [13, 19]}\n",
            "{'text': '(Lực', 'pos': [31, 35]}\n",
            "{'text': '(Hiệp', 'pos': [48, 53]}\n",
            "{'text': '(Châu', 'pos': [70, 75]}\n",
            "{'text': '(Liêm', 'pos': [88, 93]}\n",
            "{'text': '(AfD', 'pos': [108, 112]}\n",
            "{'text': '(Ban Tuyên giáo Trung ương', 'pos': [86, 112]}\n",
            "{'text': '(Hà Tĩnh', 'pos': [253, 261]}\n",
            "{'text': '(huyện Kỳ Anh', 'pos': [283, 296]}\n",
            "{'text': '(TP.Biên Hoà', 'pos': [115, 127]}\n",
            "{'text': '(Việt Nam', 'pos': [140, 149]}\n",
            "{'text': '(Tisco', 'pos': [114, 120]}\n",
            "{'text': '(PVN', 'pos': [83, 87]}\n",
            "{'text': '(LĐBĐ Đông Nam Á', 'pos': [63, 79]}\n",
            "{'text': '(PVTex', 'pos': [59, 65]}\n",
            "{'text': '\\ufeffJang Dong Gun', 'pos': [0, 14]}\n",
            "{'text': '(Công ty Tín Thành', 'pos': [135, 153]}\n",
            "{'text': '(BSR', 'pos': [29, 33]}\n",
            "{'text': '(PVFCCo', 'pos': [53, 60]}\n",
            "{'text': '(SCIC', 'pos': [134, 139]}\n",
            "{'text': '(VTM', 'pos': [107, 111]}\n",
            "{'text': '(UAE', 'pos': [92, 96]}\n",
            "{'text': '(Vivaso', 'pos': [199, 206]}\n",
            "{'text': '(TTF', 'pos': [49, 53]}\n",
            "{'text': '(TTI', 'pos': [182, 186]}\n",
            "{'text': '(HOSE', 'pos': [36, 41]}\n",
            "{'text': '(Sabeco', 'pos': [71, 78]}\n",
            "{'text': '(Teen Top', 'pos': [15, 24]}\n",
            "{'text': '(Đà Nẵng', 'pos': [53, 61]}\n",
            "{'text': '/Thế Phong', 'pos': [4, 14]}\n",
            "{'text': '(Mỹ', 'pos': [79, 82]}\n",
            "{'text': '-Ấn Độ', 'pos': [32, 38]}\n",
            "{'text': '(TfL', 'pos': [32, 36]}\n",
            "{'text': '(SOHR', 'pos': [38, 43]}\n",
            "{'text': '(xã Phước Hòa', 'pos': [115, 128]}\n",
            "{'text': '(thôn Kim Tây', 'pos': [119, 132]}\n",
            "{'text': '-Mỹ', 'pos': [31, 34]}\n",
            "{'text': '/GĐVN', 'pos': [15, 20]}\n",
            "{'text': '/Phương Liên', 'pos': [4, 16]}\n",
            "{'text': '(Quảng Ninh', 'pos': [112, 123]}\n",
            "{'text': '(Thái Thụy', 'pos': [97, 107]}\n",
            "{'text': '(Tổng cục Chính trị', 'pos': [71, 90]}\n",
            "{'text': '\"miền Nam', 'pos': [153, 162]}\n",
            "{'text': '(Thanh Thủy', 'pos': [120, 131]}\n",
            "{'text': '/Dân Việt', 'pos': [15, 24]}\n",
            "{'text': '/Người Lao Động', 'pos': [15, 30]}\n",
            "{'text': '(Đắk Lắk', 'pos': [90, 98]}\n",
            "{'text': '\"Royal Zone', 'pos': [102, 113]}\n",
            "{'text': '\"Private Zone', 'pos': [167, 180]}\n",
            "{'text': '(MSF', 'pos': [97, 101]}\n",
            "{'text': '(Bộ Công thương', 'pos': [64, 79]}\n",
            "{'text': '(Bộ KH&ĐT', 'pos': [61, 70]}\n",
            "{'text': '(Trung tâm Đào tạo Quản lý tiên tiến', 'pos': [18, 54]}\n",
            "{'text': '(Nhật Bản', 'pos': [101, 110]}\n",
            "{'text': '(Mạnh Trường', 'pos': [67, 79]}\n",
            "{'text': '(Hà Việt Dũng', 'pos': [38, 51]}\n",
            "{'text': '(Phương Oanh', 'pos': [88, 100]}\n",
            "{'text': '(Trang Cherry', 'pos': [97, 110]}\n",
            "{'text': 'Đ.', 'pos': [98, 100]}\n",
            "{'text': 'Trần Thị Đ.', 'pos': [164, 175]}\n",
            "{'text': '(Quận 10', 'pos': [55, 63]}\n",
            "{'text': '(ICAO', 'pos': [119, 124]}\n",
            "{'text': '(Italia', 'pos': [42, 49]}\n",
            "{'text': '“Ông già cao nguyên đá”', 'pos': [0, 23]}\n",
            "{'text': '“Bác Dùng đại đoàn kết”', 'pos': [26, 49]}\n",
            "{'text': '“Ông già Dùng có tài”', 'pos': [52, 73]}\n",
            "{'text': '“Ông già Dùng Mặt trận”', 'pos': [76, 99]}\n",
            "{'text': '“Dùng Mặt trận”', 'pos': [68, 83]}\n",
            "{'text': '(Mauritius', 'pos': [96, 106]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '(huyện Con Cuông', 'pos': [130, 146]}\n",
            "{'text': '(JICA', 'pos': [172, 177]}\n",
            "{'text': '\"Mỹ', 'pos': [0, 3]}\n",
            "{'text': '(Global Taiwan Institute', 'pos': [204, 228]}\n",
            "{'text': '\"Trung Quốc', 'pos': [0, 11]}\n",
            "{'text': '(NATO', 'pos': [79, 84]}\n",
            "{'text': '(TQ', 'pos': [88, 91]}\n",
            "{'text': ',\\xa0ABC News', 'pos': [73, 83]}\n",
            "{'text': '(Lebanon', 'pos': [131, 139]}\n",
            "{'text': '\\xa0(Thái Bình', 'pos': [9, 20]}\n",
            "{'text': '(AAP', 'pos': [25, 29]}\n",
            "{'text': '-Thành Hữu', 'pos': [13, 23]}\n",
            "{'text': '/Tokyo', 'pos': [60, 66]}\n",
            "{'text': '(Vietnam+', 'pos': [67, 76]}\n",
            "{'text': '-Chợ Lớn', 'pos': [33, 41]}\n",
            "{'text': '(thành phố Hồ Chí Minh', 'pos': [155, 177]}\n",
            "{'text': '(Cambridgeshire', 'pos': [105, 120]}\n",
            "{'text': '(Melbourne', 'pos': [29, 39]}\n",
            "{'text': '(Cambridge', 'pos': [80, 90]}\n",
            "{'text': '(xã Núa Ngam', 'pos': [41, 53]}\n",
            "{'text': '(xã Sa Lông', 'pos': [71, 82]}\n",
            "{'text': '(xã An Đồng', 'pos': [25, 36]}\n",
            "{'text': '(xã An Khê', 'pos': [20, 30]}\n",
            "{'text': '(xã Ngư Lộc', 'pos': [15, 26]}\n",
            "{'text': '(xã Đông Anh', 'pos': [36, 48]}\n",
            "{'text': '(STB', 'pos': [72, 76]}\n",
            "{'text': '\"Singapore', 'pos': [147, 157]}\n",
            "{'text': '/Ottawa', 'pos': [6, 13]}\n",
            "{'text': '(HTC', 'pos': [87, 91]}\n",
            "{'text': '(Nhà Xuất bản Hội Nhà văn', 'pos': [122, 147]}\n",
            "{'text': '(NL', 'pos': [36, 39]}\n",
            "{'text': '(Quỳnh Cư', 'pos': [128, 137]}\n",
            "{'text': '\\xa0Balearic', 'pos': [10, 19]}\n",
            "{'text': '(Tây Ban Nha', 'pos': [26, 38]}\n",
            "{'text': '(phố Trích Sài', 'pos': [51, 65]}\n",
            "{'text': '(Schwarzwald', 'pos': [62, 74]}\n",
            "{'text': '(phường Yên Phụ', 'pos': [67, 82]}\n",
            "{'text': '(Sở Văn hóa - Thể thao Hà Nội', 'pos': [47, 76]}\n",
            "{'text': '(Hòa Tiến', 'pos': [121, 130]}\n",
            "{'text': '(Nam Trực', 'pos': [51, 60]}\n",
            "{'text': '(Bình Thuận', 'pos': [114, 125]}\n",
            "{'text': '(Phan Thiết', 'pos': [157, 168]}\n",
            "{'text': '/Tiền Phong', 'pos': [15, 26]}\n",
            "{'text': '“CRDC', 'pos': [0, 5]}\n",
            "{'text': '“Hoàng Sa', 'pos': [282, 291]}\n",
            "{'text': '(quần đảo Hoàng Sa', 'pos': [72, 90]}\n",
            "{'text': '(tỉnh Quảng Ngãi', 'pos': [29, 45]}\n",
            "{'text': '(thôn Thanh Thủy', 'pos': [88, 104]}\n",
            "{'text': '(đường Lê Văn Việt', 'pos': [126, 144]}\n",
            "{'text': '(quận 9', 'pos': [90, 97]}\n",
            "{'text': '(Cẩm Thủy', 'pos': [127, 136]}\n",
            "{'text': '(Phú Yên', 'pos': [12, 20]}\n",
            "{'text': '(Bình Định', 'pos': [15, 25]}\n",
            "{'text': '“Tổng cục Du lịch VN', 'pos': [138, 158]}\n",
            "{'text': '(quận Hoàn Kiếm', 'pos': [87, 102]}\n",
            "{'text': '(Quận Thủ Đức', 'pos': [151, 164]}\n",
            "{'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "{'text': '(An Dương', 'pos': [195, 204]}\n",
            "{'text': '(Ninh Bình', 'pos': [207, 217]}\n",
            "{'text': '(60 Hồ Hảo Hớn', 'pos': [26, 40]}\n",
            "{'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "{'text': '(P.4', 'pos': [22, 26]}\n",
            "{'text': '(Q.3', 'pos': [22, 26]}\n",
            "{'text': '(P.Cầu Ông Lãnh', 'pos': [32, 47]}\n",
            "{'text': '(202 Nguyễn Thiện Thuật', 'pos': [28, 51]}\n",
            "{'text': '(369/25/28 Lý Thái Tổ', 'pos': [30, 51]}\n",
            "{'text': '(Q.4', 'pos': [32, 36]}\n",
            "{'text': '(Q.8', 'pos': [36, 40]}\n",
            "{'text': '(96 Camette', 'pos': [26, 37]}\n",
            "{'text': '(Q.12', 'pos': [22, 27]}\n",
            "{'text': '(26/20/4 Đinh Tiên Hoàng', 'pos': [24, 48]}\n",
            "{'text': '(413/36 Lê Văn Sỹ', 'pos': [24, 41]}\n",
            "{'text': '(307 Nguyễn Văn Trỗi', 'pos': [24, 44]}\n",
            "{'text': '(162 Nguyễn Công Trứ', 'pos': [36, 56]}\n",
            "{'text': '(448/15 Lê Văn Sỹ', 'pos': [28, 45]}\n",
            "{'text': '(38 Bà Hom', 'pos': [31, 41]}\n",
            "{'text': '(Q.Bình Thạnh', 'pos': [24, 37]}\n",
            "{'text': '(302/3/11 Lê Đình Cẩn', 'pos': [28, 49]}\n",
            "{'text': '(116/877B Nguyễn Kiệm', 'pos': [29, 50]}\n",
            "{'text': '(489/57/11 Huỳnh Văn Bánh', 'pos': [34, 59]}\n",
            "{'text': '(16 Trần Quang Khải', 'pos': [24, 43]}\n",
            "{'text': '(803/23A Huỳnh Tấn Phát', 'pos': [24, 47]}\n",
            "{'text': '(Q.Bình Tân', 'pos': [24, 35]}\n",
            "{'text': '(41 Lê Hồng Phong', 'pos': [31, 48]}\n",
            "{'text': '(266 Nguyễn Đình Chiểu', 'pos': [28, 50]}\n",
            "{'text': '(P.7', 'pos': [26, 30]}\n",
            "{'text': '(6 Đặng Tất', 'pos': [36, 47]}\n",
            "{'text': '(481 Hai Bà Trưng', 'pos': [24, 41]}\n",
            "{'text': '(P.1', 'pos': [24, 28]}\n",
            "{'text': '(6C2 Đinh Bộ Lĩnh', 'pos': [28, 45]}\n",
            "{'text': '(P.Bến Thành', 'pos': [30, 42]}\n",
            "{'text': '(1901G ấp Bến Nôm', 'pos': [32, 49]}\n",
            "{'text': '(Q.10', 'pos': [30, 35]}\n",
            "{'text': '(Đinh Tiên Hoàng', 'pos': [46, 62]}\n",
            "{'text': '(P.Tan Thuan Dong', 'pos': [37, 54]}\n",
            "{'text': '(331 Phan Dinh Phung', 'pos': [40, 60]}\n",
            "{'text': '(Cafe 90', 'pos': [33, 41]}\n",
            "{'text': '(tỉnh Đồng Tháp', 'pos': [88, 103]}\n",
            "{'text': '(huyện Nga Sơn', 'pos': [34, 48]}\n",
            "{'text': '(xã Tà Rụt', 'pos': [146, 156]}\n",
            "{'text': '(UNESCO', 'pos': [142, 149]}\n",
            "{'text': '(Yên Bái', 'pos': [145, 153]}\n",
            "{'text': '(Lào Cai', 'pos': [103, 111]}\n",
            "{'text': '(ASEAN FLE', 'pos': [145, 155]}\n",
            "{'text': '(Australia', 'pos': [165, 175]}\n",
            "{'text': '(LAVISA', 'pos': [121, 128]}\n",
            "{'text': '(WUR', 'pos': [111, 115]}\n",
            "{'text': '-Thời Đại', 'pos': [14, 23]}\n",
            "{'text': '(quận 1', 'pos': [114, 121]}\n",
            "{'text': '(Bộ GD&ĐT', 'pos': [56, 65]}\n",
            "{'text': '(TP.Cam Ranh', 'pos': [64, 76]}\n",
            "{'text': '/VTC News', 'pos': [13, 22]}\n",
            "{'text': '(Phú Vang', 'pos': [115, 124]}\n",
            "{'text': '(thị xã Hương Trà', 'pos': [24, 41]}\n",
            "{'text': '-TT Huế', 'pos': [42, 49]}\n",
            "{'text': '-Tứ Hạ', 'pos': [38, 44]}\n",
            "{'text': '-TX Hương Trà', 'pos': [45, 58]}\n",
            "{'text': '(TP. Hồ Chí Minh', 'pos': [29, 45]}\n",
            "{'text': '(H. Phong Điền', 'pos': [37, 51]}\n",
            "{'text': '(trường mầm non Sơn Ca', 'pos': [37, 59]}\n",
            "{'text': '(TP. Huế', 'pos': [30, 38]}\n",
            "{'text': '(Trường Đại học Nông Lâm Huế', 'pos': [281, 310]}\n",
            "{'text': '(Viettel', 'pos': [185, 193]}\n",
            "{'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi ”', 'pos': [120, 179]}\n",
            "{'text': 'CLB “Về với quê mình Quảng Ngãi ”', 'pos': [63, 96]}\n",
            "{'text': '(Công an tỉnh Hà Tĩnh', 'pos': [119, 140]}\n",
            "{'text': '(xã Phú An', 'pos': [107, 117]}\n",
            "{'text': '(Thừa Thiên- Huế', 'pos': [195, 211]}\n",
            "{'text': '(Kan Clinic', 'pos': [66, 77]}\n",
            "{'text': '\"Intel', 'pos': [0, 6]}\n",
            "{'text': '(JAMA', 'pos': [40, 45]}\n",
            "{'text': '(Canada', 'pos': [58, 65]}\n",
            "{'text': '(Ba Đình', 'pos': [15, 23]}\n",
            "{'text': '(Tổng cục Du lịch', 'pos': [61, 78]}\n",
            "{'text': '(Bình Dương', 'pos': [104, 115]}\n",
            "{'text': '(Hải Phòng', 'pos': [192, 202]}\n",
            "{'text': '(Q. Thủ Đức', 'pos': [429, 440]}\n",
            "{'text': '(ENV', 'pos': [163, 167]}\n",
            "{'text': '(ENV Nghệ An', 'pos': [135, 147]}\n",
            "{'text': '(Gothenburg', 'pos': [117, 128]}\n",
            "{'text': '(Na Uy', 'pos': [73, 79]}\n",
            "{'text': '(LTA', 'pos': [52, 56]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-IJH1DqRmhO",
        "outputId": "35046539-c58c-4378-816b-a2607b705ba6"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "# tuy nhiên những entity bắt đầu hoặc kết thúc bằng kí tự '.' hoặc '+' thì không phải là lỗi\n",
        "tmpppent = []\n",
        "for sentif in jtrain_data_use:\n",
        "    if (sentif['entity_1']['text'][0] == '+') or (sentif['entity_1']['text'][-1] == '+') \\\n",
        "    or (sentif['entity_1']['text'][0] == '.') or (sentif['entity_1']['text'][-1] == '.'):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (sentif['entity_2']['text'][0] == '+') or (sentif['entity_2']['text'][-1] == '.') \\\n",
        "    or (sentif['entity_2']['text'][0] == '.') or (sentif['entity_2']['text'][-1] == '+'):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'H.T.H.', 'pos': [46, 52]}\n",
            "{'text': 'H.', 'pos': [16, 18]}\n",
            "{'text': 'N.T.T.', 'pos': [68, 74]}\n",
            "{'text': 'N.C.', 'pos': [40, 44]}\n",
            "{'text': 'C.', 'pos': [112, 114]}\n",
            "{'text': 'T.', 'pos': [156, 158]}\n",
            "{'text': 'Cáp Trọng Th.', 'pos': [25, 38]}\n",
            "{'text': 'Cáp Trọng T.', 'pos': [39, 51]}\n",
            "{'text': 'Th.', 'pos': [76, 79]}\n",
            "{'text': 'Nguyễn Thị H.', 'pos': [46, 59]}\n",
            "{'text': 'N.', 'pos': [25, 27]}\n",
            "{'text': '/Vietnam+', 'pos': [9, 18]}\n",
            "{'text': 'Đ.', 'pos': [98, 100]}\n",
            "{'text': 'Trần Thị Đ.', 'pos': [164, 175]}\n",
            "{'text': '6+', 'pos': [105, 107]}\n",
            "{'text': '(Vietnam+', 'pos': [67, 76]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPM8Z8acSiDL",
        "outputId": "0e4e038f-cf3f-492c-afae-8323e4d2a1fb"
      },
      "source": [
        "# lỗi\n",
        "tmpppent = []\n",
        "for sentif in jtrain_data_use:\n",
        "    if (sentif['entity_1']['text'][0] == '\\xa0') or (sentif['entity_1']['text'][-1] == '\\xa0'):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (sentif['entity_2']['text'][0] == '\\xa0') or (sentif['entity_2']['text'][-1] == '\\xa0'):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '\\xa0Shin Jin Ju', 'pos': [18, 30]}\n",
            "{'text': '\\xa0Công ty Điện lực Sơn La', 'pos': [421, 445]}\n",
            "{'text': 'Nguyễn Danh Vĩnh\\xa0', 'pos': [196, 213]}\n",
            "{'text': '\\xa0(Thái Bình', 'pos': [9, 20]}\n",
            "{'text': '\\xa0Balearic', 'pos': [10, 19]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xXagTVqMwzU",
        "outputId": "67be3d5b-7828-4d50-e568-042de253f1d2"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "tmpppent = []\n",
        "for sentif in jtrain_data_use:\n",
        "\n",
        "    if sentif['entity_1']['text'] not in tmpppent:\n",
        "        for c in sentif['entity_1']['text'][1:-1]:\n",
        "            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n",
        "                print(sentif['entity_1'])\n",
        "        \n",
        "        tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "        '''\n",
        "        if '- Huế' in sentif['entity_1']['text']:\n",
        "            print(sentif)\n",
        "        '''\n",
        "    \n",
        "    \n",
        "    if sentif['entity_2']['text'] not in tmpppent:\n",
        "        for c in sentif['entity_2']['text'][1:-1]:\n",
        "            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n",
        "                print(sentif['entity_2'])\n",
        "        \n",
        "        tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "        '''\n",
        "        if '- Huế' in sentif['entity_2']['text']:\n",
        "            print(sentif)\n",
        "        '''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'Bộ GD&ĐT', 'pos': [24, 32]}\n",
            "{'text': 'Dai-ichi Life', 'pos': [103, 116]}\n",
            "{'text': 'Bát A-ca Dận Tự', 'pos': [41, 56]}\n",
            "{'text': 'khoa Cấp cứu, bệnh viện Đa khoa 115 Nghệ An', 'pos': [40, 83]}\n",
            "{'text': \"St Mary's\", 'pos': [143, 152]}\n",
            "{'text': 'Brighton & Hove Albion', 'pos': [16, 38]}\n",
            "{'text': 'Ban dược, vật tư y tế - Bảo hiểm Xã hội Việt Nam', 'pos': [31, 79]}\n",
            "{'text': 'Ban dược, vật tư y tế - Bảo hiểm Xã hội Việt Nam', 'pos': [31, 79]}\n",
            "{'text': '31/2016/TT-NHNN', 'pos': [125, 140]}\n",
            "{'text': '31/2016/TT-NHNN', 'pos': [125, 140]}\n",
            "{'text': '31/2016/TT-NHNN', 'pos': [125, 140]}\n",
            "{'text': '7295/NHNN', 'pos': [44, 53]}\n",
            "{'text': \"L'Equipe\", 'pos': [99, 107]}\n",
            "{'text': 'Nasser Al-Khelaifi', 'pos': [35, 53]}\n",
            "{'text': 'Việt “đỏ”', 'pos': [105, 114]}\n",
            "{'text': 'Vụ Kế hoạch - Tài chính, Bộ GD&ĐT', 'pos': [35, 68]}\n",
            "{'text': 'Vụ Kế hoạch - Tài chính, Bộ GD&ĐT', 'pos': [35, 68]}\n",
            "{'text': 'Vụ Kế hoạch - Tài chính, Bộ GD&ĐT', 'pos': [35, 68]}\n",
            "{'text': 'Ri Yong-ho', 'pos': [111, 121]}\n",
            "{'text': 'N’Golo Kante', 'pos': [7, 19]}\n",
            "{'text': 'Báo TN&MT', 'pos': [112, 121]}\n",
            "{'text': ';\\xa0Tập đoàn xăng dầu Việt Nam', 'pos': [38, 66]}\n",
            "{'text': ';\\xa0Công ty TNHH xuất nhập khẩu 3A Việt Nam', 'pos': [207, 248]}\n",
            "{'text': 'Sở TN&MT tỉnh Sơn La', 'pos': [472, 492]}\n",
            "{'text': 'Erdene-Orchir', 'pos': [78, 91]}\n",
            "{'text': 'từ\\xa0Philippines', 'pos': [127, 141]}\n",
            "{'text': 'tại\\xa0xã Chu Minh', 'pos': [62, 77]}\n",
            "{'text': 'Viện kiểm sát nhân dân (VKSND) Hà Nội', 'pos': [83, 120]}\n",
            "{'text': 'Viện kiểm sát nhân dân (VKSND) Hà Nội', 'pos': [83, 120]}\n",
            "{'text': 'Ủy ban Văn hóa, giáo dục, thanh niên, thiếu niên và nhi đồng', 'pos': [80, 140]}\n",
            "{'text': 'Ủy ban Văn hóa, giáo dục, thanh niên, thiếu niên và nhi đồng', 'pos': [80, 140]}\n",
            "{'text': 'Ủy ban Văn hóa, giáo dục, thanh niên, thiếu niên và nhi đồng', 'pos': [80, 140]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': '55/2011/TT-BGDĐT', 'pos': [168, 184]}\n",
            "{'text': 'Phòng LĐTB&XH huyện Hướng Hóa', 'pos': [175, 204]}\n",
            "{'text': 'Seo Ok-ryol', 'pos': [131, 142]}\n",
            "{'text': 'Đông-Nam Á', 'pos': [181, 191]}\n",
            "{'text': 'Nghiên cứu Đông-Nam Á', 'pos': [39, 60]}\n",
            "{'text': 'Frankfurt (Đức', 'pos': [85, 99]}\n",
            "{'text': 'Abercrombie & Filch', 'pos': [93, 112]}\n",
            "{'text': 'Pierre-Emerick Aubameyang', 'pos': [42, 67]}\n",
            "{'text': '“Bộ GD&ĐT', 'pos': [0, 9]}\n",
            "{'text': 'S&P', 'pos': [0, 3]}\n",
            "{'text': \"Standard & Poor's\", 'pos': [60, 77]}\n",
            "{'text': \"Standard & Poor's\", 'pos': [60, 77]}\n",
            "{'text': \"Moody's\", 'pos': [18, 25]}\n",
            "{'text': 'Bộ Thương mại, Công nghiệp và Năng lượng Hàn Quốc', 'pos': [55, 104]}\n",
            "{'text': 'Paik Un-gyu', 'pos': [105, 116]}\n",
            "{'text': 'Standard & Poor', 'pos': [0, 15]}\n",
            "{'text': '(S&P', 'pos': [16, 20]}\n",
            "{'text': 'Bộ NN-PTNT', 'pos': [12, 22]}\n",
            "{'text': 'Tổng cục Phòng, Chống thiên tai', 'pos': [196, 227]}\n",
            "{'text': '(Bộ NN&PTNT', 'pos': [228, 239]}\n",
            "{'text': 'Mizuho Okimoto-Kaewtathip', 'pos': [25, 50]}\n",
            "{'text': 'Tổng cục Phòng, chống thiên tai', 'pos': [38, 69]}\n",
            "{'text': 'Châu\\xa0Á', 'pos': [32, 38]}\n",
            "{'text': 'khi\\xa0Triều Tiên', 'pos': [58, 72]}\n",
            "{'text': 'Phòng CSGT Đường bộ, Đường sắt Công an TP HCM', 'pos': [60, 105]}\n",
            "{'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [12, 43]}\n",
            "{'text': 'PC67, Công an TP HCM', 'pos': [36, 56]}\n",
            "{'text': 'Công ty CP 27/7 Đống Đa', 'pos': [224, 247]}\n",
            "{'text': 'Sở Giao thông – Vận tải tỉnh Phú Yên', 'pos': [38, 74]}\n",
            "{'text': 'báo\\xa0The Nation', 'pos': [5, 19]}\n",
            "{'text': 'chức\\xa0Việt Nam', 'pos': [7, 20]}\n",
            "{'text': 'Hiệp hội Chữ thập đỏ-Trăng lưỡi liềm đỏ quốc tế', 'pos': [128, 175]}\n",
            "{'text': 'Hiệp hội Chữ thập đỏ -Trăng lưỡi liềm đỏ quốc tế', 'pos': [54, 102]}\n",
            "{'text': 'Hiệp hội Chữ thập đỏ - Trăng lưỡi liềm đỏ quốc tế', 'pos': [169, 218]}\n",
            "{'text': 'Hay’at Tahrir al-Sham', 'pos': [173, 194]}\n",
            "{'text': 'Hay’at Tahrir al-Sham', 'pos': [173, 194]}\n",
            "{'text': 'Jabhat Fatah al-Sham', 'pos': [223, 243]}\n",
            "{'text': 'Jabhat al-Nusra', 'pos': [267, 282]}\n",
            "{'text': 'al-Qaeda', 'pos': [295, 303]}\n",
            "{'text': 'Bashar al-Assad', 'pos': [277, 292]}\n",
            "{'text': 'Trung tâm Nghiệp vụ, Nghiên cứu khoa học và tư liệu', 'pos': [34, 85]}\n",
            "{'text': 'Oradour-sur-Glane', 'pos': [26, 43]}\n",
            "{'text': 'Oradour-sur-Glane', 'pos': [26, 43]}\n",
            "{'text': 'Moon Jae-in', 'pos': [66, 77]}\n",
            "{'text': 'Bali (Indonesia', 'pos': [94, 109]}\n",
            "{'text': 'HLV\\xa0Pep Guardiola', 'pos': [0, 17]}\n",
            "{'text': 'Loftus-Cheek', 'pos': [77, 89]}\n",
            "{'text': 'tới\\xa0sân St. Mary', 'pos': [76, 92]}\n",
            "{'text': 'HLV\\xa0Mauricio Pellegrino', 'pos': [0, 23]}\n",
            "{'text': 'thủ,\\xa0Pellegrino', 'pos': [23, 38]}\n",
            "{'text': 'thủ,\\xa0Pellegrino', 'pos': [23, 38]}\n",
            "{'text': 'luyện,\\xa0Mauricio Pellegrino', 'pos': [33, 59]}\n",
            "{'text': 'luyện,\\xa0Mauricio Pellegrino', 'pos': [33, 59]}\n",
            "{'text': 'này,\\xa0Pellegrino', 'pos': [49, 64]}\n",
            "{'text': 'này,\\xa0Pellegrino', 'pos': [49, 64]}\n",
            "{'text': 'gồm\\xa0Estudiantes', 'pos': [130, 145]}\n",
            "{'text': 'và\\xa0Alavés', 'pos': [162, 171]}\n",
            "{'text': 'Alex Oxlade-Chamberlain', 'pos': [123, 146]}\n",
            "{'text': 'BSR-BF', 'pos': [47, 53]}\n",
            "{'text': 'Nhà máy Thép Việt – Trung', 'pos': [81, 106]}\n",
            "{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [105, 138]}\n",
            "{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [105, 138]}\n",
            "{'text': 'AFP /TTXVN', 'pos': [0, 10]}\n",
            "{'text': 'cao tốc Pháp Vân – Cầu Giẽ', 'pos': [24, 50]}\n",
            "{'text': 'Bộ Giao thông, vận tải', 'pos': [63, 85]}\n",
            "{'text': 'thị trấn al-Tabani', 'pos': [138, 156]}\n",
            "{'text': 'al-Bavitieh', 'pos': [49, 60]}\n",
            "{'text': 'Al-Hawi', 'pos': [122, 129]}\n",
            "{'text': 'Al-Hamd', 'pos': [133, 140]}\n",
            "{'text': 'al-Shamitiyeh', 'pos': [168, 181]}\n",
            "{'text': \"L'Oréal\", 'pos': [48, 55]}\n",
            "{'text': 'Procter & Gamble', 'pos': [37, 53]}\n",
            "{'text': 'Johnson & Johnson', 'pos': [67, 84]}\n",
            "{'text': \"L'Oreal\", 'pos': [103, 110]}\n",
            "{'text': 'GD&ĐT', 'pos': [126, 131]}\n",
            "{'text': 'Ủy ban Văn hóa giáo dục Thanh Thiếu niên & Nhi đồng', 'pos': [86, 137]}\n",
            "{'text': 'Ủy ban Khoa học, Công nghệ và Môi trường', 'pos': [151, 191]}\n",
            "{'text': 'Mặt trận Al-Nursa', 'pos': [133, 150]}\n",
            "{'text': 'Al-Qaeda', 'pos': [65, 73]}\n",
            "{'text': 'tỉnh Deir ez-Zor', 'pos': [168, 184]}\n",
            "{'text': 'Bashar Al-Assad', 'pos': [186, 201]}\n",
            "{'text': 'Bộ VHTT&DL', 'pos': [5, 15]}\n",
            "{'text': 'Vụ Kế hoạch Tài chính, Bộ VHTT&DL', 'pos': [27, 60]}\n",
            "{'text': 'Vụ Kế hoạch Tài chính, Bộ VHTT&DL', 'pos': [27, 60]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': '127/2014/TT-BTC', 'pos': [130, 145]}\n",
            "{'text': 'Bộ KH&CN', 'pos': [121, 129]}\n",
            "{'text': 'khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội', 'pos': [116, 188]}\n",
            "{'text': 'khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội', 'pos': [116, 188]}\n",
            "{'text': 'khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội', 'pos': [116, 188]}\n",
            "{'text': 'số 193/7, đường Hoàng Diệu', 'pos': [147, 173]}\n",
            "{'text': 'số 193/7, đường Hoàng Diệu', 'pos': [147, 173]}\n",
            "{'text': 'Thừa Thiên - Huế', 'pos': [68, 84]}\n",
            "{'text': 'Hans-Peter Dosoczil', 'pos': [79, 98]}\n",
            "{'text': 'Neuilly-sur-Seine', 'pos': [183, 200]}\n",
            "{'text': 'Neuilly-sur-Seine', 'pos': [183, 200]}\n",
            "{'text': 'Bác sỹ\\xa0xuyên Biên giới', 'pos': [21, 43]}\n",
            "{'text': \"thành phố Cox's Bazar\", 'pos': [89, 110]}\n",
            "{'text': '(Bộ KH&ĐT', 'pos': [61, 70]}\n",
            "{'text': 'Ủy ban Văn hóa, Giáo dục, Thanh niên, Thiếu niên và Nhi đồng', 'pos': [61, 121]}\n",
            "{'text': 'Ủy ban Văn hóa, Giáo dục, Thanh niên, Thiếu niên và Nhi đồng', 'pos': [61, 121]}\n",
            "{'text': 'Ủy ban Văn hóa, Giáo dục, Thanh niên, Thiếu niên và Nhi đồng', 'pos': [61, 121]}\n",
            "{'text': 'Viện Quản trị Đại học - ĐHQG TP.HCM', 'pos': [57, 92]}\n",
            "{'text': 'Sở GD&ĐT Nghệ An', 'pos': [89, 105]}\n",
            "{'text': 'Sở GD&ĐT Thừa Thiên - Huế', 'pos': [57, 82]}\n",
            "{'text': 'Sở GD&ĐT Thừa Thiên - Huế', 'pos': [57, 82]}\n",
            "{'text': 'sở GD&ĐT Thừa Thiên Huế', 'pos': [29, 52]}\n",
            "{'text': 'Bà Rịa - Vũng Tàu', 'pos': [71, 88]}\n",
            "{'text': 'Ai-len', 'pos': [35, 41]}\n",
            "{'text': 'Cộng hòa Mô-rítx', 'pos': [79, 95]}\n",
            "{'text': 'Mê-hi-cô', 'pos': [129, 137]}\n",
            "{'text': 'Mê-hi-cô', 'pos': [129, 137]}\n",
            "{'text': 'Ma-rốc', 'pos': [140, 146]}\n",
            "{'text': 'Lee Nak-yon', 'pos': [176, 187]}\n",
            "{'text': 'Nhóm P5+1', 'pos': [159, 168]}\n",
            "{'text': 'Kim Jong-un', 'pos': [23, 34]}\n",
            "{'text': 'tin\\xa0AP', 'pos': [198, 204]}\n",
            "{'text': 'nhóm P5+1', 'pos': [41, 50]}\n",
            "{'text': ',\\xa0ABC News', 'pos': [73, 83]}\n",
            "{'text': '\\xa0(Thái Bình', 'pos': [9, 20]}\n",
            "{'text': '42-44 Hàng Bạc', 'pos': [33, 47]}\n",
            "{'text': 'Trung tâm Y tế Cedars-Sinai', 'pos': [21, 48]}\n",
            "{'text': 'trung tâm Thương mại Hà Nội - Mátxcơva', 'pos': [103, 141]}\n",
            "{'text': 'Trung tâm thương mại Hà Nội – Mátxcơva', 'pos': [71, 109]}\n",
            "{'text': 'Trung tâm Thương mại Hà Nội – Mátxcơva', 'pos': [13, 51]}\n",
            "{'text': 'Nutmeg & Clove', 'pos': [30, 44]}\n",
            "{'text': 'Tần\\xa0 Dũng', 'pos': [4, 13]}\n",
            "{'text': 'Việt-Đức', 'pos': [122, 130]}\n",
            "{'text': 'ngách 35/15', 'pos': [38, 49]}\n",
            "{'text': 'ban Quản lý di tích - danh thắng Hà Nội', 'pos': [7, 46]}\n",
            "{'text': '(Sở Văn hóa - Thể thao Hà Nội', 'pos': [47, 76]}\n",
            "{'text': 'Trung tâm Nghiên cứu, Bảo tồn và Phát triển Ẩm thực Việt Nam', 'pos': [106, 166]}\n",
            "{'text': 'O’Henry', 'pos': [210, 217]}\n",
            "{'text': 'Plus/GĐVN', 'pos': [23, 32]}\n",
            "{'text': 'Bộ TT&TT', 'pos': [38, 46]}\n",
            "{'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "{'text': 'Bà\\xa0NGUYỄN THỊ THU HIỀN', 'pos': [0, 22]}\n",
            "{'text': 'phòng GD&ĐT quận 9', 'pos': [32, 50]}\n",
            "{'text': 'Văn Miếu - Quốc Tử Giám', 'pos': [106, 129]}\n",
            "{'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "{'text': 'Bộ Tư lệnh Vùng 3 Hải quân', 'pos': [130, 158]}\n",
            "{'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "{'text': 'Bộ Thông tin và Truyền thông', 'pos': [183, 213]}\n",
            "{'text': 'Việt Nam', 'pos': [299, 308]}\n",
            "{'text': 'Biển Đông', 'pos': [170, 180]}\n",
            "{'text': 'miền Nam', 'pos': [76, 85]}\n",
            "{'text': 'Trung Quốc', 'pos': [158, 169]}\n",
            "{'text': 'quần đảo Hoàng Sa', 'pos': [190, 208]}\n",
            "{'text': 'Trường trung học cơ sở - trung học phổ thông Nguyễn Khuyến', 'pos': [120, 178]}\n",
            "{'text': '(369/25/28 Lý Thái Tổ', 'pos': [30, 51]}\n",
            "{'text': '(369/25/28 Lý Thái Tổ', 'pos': [30, 51]}\n",
            "{'text': '(26/20/4 Đinh Tiên Hoàng', 'pos': [24, 48]}\n",
            "{'text': '(26/20/4 Đinh Tiên Hoàng', 'pos': [24, 48]}\n",
            "{'text': '(413/36 Lê Văn Sỹ', 'pos': [24, 41]}\n",
            "{'text': '(448/15 Lê Văn Sỹ', 'pos': [28, 45]}\n",
            "{'text': '(302/3/11 Lê Đình Cẩn', 'pos': [28, 49]}\n",
            "{'text': '(302/3/11 Lê Đình Cẩn', 'pos': [28, 49]}\n",
            "{'text': '(116/877B Nguyễn Kiệm', 'pos': [29, 50]}\n",
            "{'text': '(489/57/11 Huỳnh Văn Bánh', 'pos': [34, 59]}\n",
            "{'text': '(489/57/11 Huỳnh Văn Bánh', 'pos': [34, 59]}\n",
            "{'text': '(803/23A Huỳnh Tấn Phát', 'pos': [24, 47]}\n",
            "{'text': 'CSGT đường bộ - đường sắt', 'pos': [135, 160]}\n",
            "{'text': 'Bộ GD-ĐT', 'pos': [0, 8]}\n",
            "{'text': 'Sở GD-ĐT Hà Tĩnh', 'pos': [57, 73]}\n",
            "{'text': 'tỉnh Đồng Tháp', 'pos': [101, 116]}\n",
            "{'text': 'H.\\xa0 Hải Dương', 'pos': [257, 270]}\n",
            "{'text': 'TP Hà Nội', 'pos': [322, 332]}\n",
            "{'text': 'Bộ GD&ĐT', 'pos': [34, 43]}\n",
            "{'text': 'Bộ GD&ĐT', 'pos': [34, 43]}\n",
            "{'text': 'GD-ĐT Q.Tây Hồ', 'pos': [84, 98]}\n",
            "{'text': 'Úc (SIC', 'pos': [113, 120]}\n",
            "{'text': 'Văn phòng Tổ chức Giáo dục, Khoa học và Văn hóa Liên hợp quốc', 'pos': [80, 141]}\n",
            "{'text': 'Bộ GD- ĐT', 'pos': [33, 42]}\n",
            "{'text': 'Trường tiểu học &THCS Thị trấn Mù Cang Chải', 'pos': [101, 144]}\n",
            "{'text': 'khoa Giáo dục tiểu học, đại học Sư phạm Hà Nội', 'pos': [74, 120]}\n",
            "{'text': '(Bộ GD&ĐT', 'pos': [56, 65]}\n",
            "{'text': 'Hiệp hội các trường đại học, cao đẳng Việt Nam', 'pos': [68, 114]}\n",
            "{'text': 'Sở GD-ĐT tỉnh Nghệ An', 'pos': [66, 87]}\n",
            "{'text': 'Hội đồng KH&CN tỉnh Bắc Kạn', 'pos': [66, 93]}\n",
            "{'text': 'tỉnh TT- Huế', 'pos': [81, 93]}\n",
            "{'text': '56/4 Hồng Lĩnh', 'pos': [241, 255]}\n",
            "{'text': 'Nguyễn Anh Nhiên', 'pos': [198, 215]}\n",
            "{'text': 'Hồ Sơn Công', 'pos': [232, 244]}\n",
            "{'text': 'Sở Cảnh sát Phòng cháy, chữa cháy (PCCC) và cứu nạn, cứu hộ Hà Nội', 'pos': [83, 149]}\n",
            "{'text': 'Sở Cảnh sát Phòng cháy, chữa cháy (PCCC) và cứu nạn, cứu hộ Hà Nội', 'pos': [83, 149]}\n",
            "{'text': 'Sở Cảnh sát Phòng cháy, chữa cháy (PCCC) và cứu nạn, cứu hộ Hà Nội', 'pos': [83, 149]}\n",
            "{'text': 'Sở Cảnh sát Phòng cháy, chữa cháy (PCCC) và cứu nạn, cứu hộ Hà Nội', 'pos': [83, 149]}\n",
            "{'text': 'Bệnh viện Phục hồi chức năng - Điều trị bệnh nghề nghiệp TP.HCM', 'pos': [54, 117]}\n",
            "{'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi ”', 'pos': [120, 179]}\n",
            "{'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi ”', 'pos': [120, 179]}\n",
            "{'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi ”', 'pos': [120, 179]}\n",
            "{'text': 'Báo\\xa0Thanh Niên', 'pos': [185, 199]}\n",
            "{'text': 'CLB “Về với quê mình Quảng Ngãi ”', 'pos': [63, 96]}\n",
            "{'text': 'trên\\xa0Thanh Niên', 'pos': [80, 95]}\n",
            "{'text': 'Phòng Cảnh sát giao thông đường bộ - đường sắt', 'pos': [72, 118]}\n",
            "{'text': 'phòng Cảnh sát giao thông đường bộ - đường sắt', 'pos': [22, 68]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'văn phòng kiến trúc 1+1>2', 'pos': [145, 170]}\n",
            "{'text': 'Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio', 'pos': [243, 297]}\n",
            "{'text': 'Văn phòng kiến trúc 1+1>2', 'pos': [95, 120]}\n",
            "{'text': 'Văn phòng kiến trúc 1+1>2', 'pos': [95, 120]}\n",
            "{'text': 'Hiệp hội Sáng chế Đài Loan - Trung Quốc', 'pos': [220, 259]}\n",
            "{'text': 'Qualcomm Technologies, Inc', 'pos': [44, 70]}\n",
            "{'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [77, 107]}\n",
            "{'text': 'Trung tâm dạy trẻ khuyết tật', 'pos': [77, 107]}\n",
            "{'text': 'Trường Chuyên biệt Tương Lai', 'pos': [120, 149]}\n",
            "{'text': 'Nguyễn Duy Quy', 'pos': [6, 21]}\n",
            "{'text': 'Thừa Thiên- Huế', 'pos': [133, 148]}\n",
            "{'text': '(Thừa Thiên- Huế', 'pos': [195, 211]}\n",
            "{'text': 'Viện Nghiên cứu Phát triển (NCPT) Du lịch', 'pos': [63, 104]}\n",
            "{'text': 'Viện Nghiên cứu Phát triển (NCPT) Du lịch', 'pos': [63, 104]}\n",
            "{'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "{'text': 'PV\\xa0VTC', 'pos': [18, 24]}\n",
            "{'text': 'Ủy ban An toàn giao thông (ATGT) Quốc gia', 'pos': [156, 197]}\n",
            "{'text': 'Ủy ban An toàn giao thông (ATGT) Quốc gia', 'pos': [156, 197]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHYNrku-MjjI"
      },
      "source": [
        "#### fix start end of entity in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB4ozP6FFVTh",
        "outputId": "4e187085-6cb6-4301-ee98-e5893631edaf"
      },
      "source": [
        "jtrain_data_v2 = copy.deepcopy(fix_start_end_of_entity(jtrain_data_use))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "original:       {'text': '(Hà Nội', 'pos': [177, 184]}\n",
            "new_entity:     {'text': 'Hà Nội', 'pos': [178, 184]}\n",
            "\n",
            "original:       {'text': '(Thái Nguyên', 'pos': [212, 224]}\n",
            "new_entity:     {'text': 'Thái Nguyên', 'pos': [213, 224]}\n",
            "\n",
            "original:       {'text': '(Techcombank', 'pos': [170, 182]}\n",
            "new_entity:     {'text': 'Techcombank', 'pos': [171, 182]}\n",
            "\n",
            "original:       {'text': '“Việt Nam', 'pos': [0, 9]}\n",
            "new_entity:     {'text': 'Việt Nam', 'pos': [1, 9]}\n",
            "\n",
            "original:       {'text': '(Thụy Sĩ', 'pos': [106, 114]}\n",
            "new_entity:     {'text': 'Thụy Sĩ', 'pos': [107, 114]}\n",
            "\n",
            "original:       {'text': '(IEA', 'pos': [141, 145]}\n",
            "new_entity:     {'text': 'IEA', 'pos': [142, 145]}\n",
            "\n",
            "original:       {'text': '(BNEF', 'pos': [175, 180]}\n",
            "new_entity:     {'text': 'BNEF', 'pos': [176, 180]}\n",
            "\n",
            "original:       {'text': '\\ufeffTrung Quốc', 'pos': [0, 11]}\n",
            "new_entity:     {'text': 'Trung Quốc', 'pos': [1, 11]}\n",
            "\n",
            "original:       {'text': '(CCTV', 'pos': [56, 61]}\n",
            "new_entity:     {'text': 'CCTV', 'pos': [57, 61]}\n",
            "\n",
            "original:       {'text': \"'Đông Phương Bất Bại\", 'pos': [13, 33]}\n",
            "new_entity:     {'text': 'Đông Phương Bất Bại', 'pos': [14, 33]}\n",
            "\n",
            "original:       {'text': '\"Đông Phương Bất Bại', 'pos': [51, 71]}\n",
            "new_entity:     {'text': 'Đông Phương Bất Bại', 'pos': [52, 71]}\n",
            "\n",
            "original:       {'text': '\"Trần Kiều Ân', 'pos': [0, 13]}\n",
            "new_entity:     {'text': 'Trần Kiều Ân', 'pos': [1, 13]}\n",
            "\n",
            "original:       {'text': '(Trung Quốc', 'pos': [34, 45]}\n",
            "new_entity:     {'text': 'Trung Quốc', 'pos': [35, 45]}\n",
            "\n",
            "original:       {'text': '(TP.HCM', 'pos': [27, 34]}\n",
            "new_entity:     {'text': 'TP.HCM', 'pos': [28, 34]}\n",
            "\n",
            "original:       {'text': '(quận 3', 'pos': [67, 74]}\n",
            "new_entity:     {'text': 'quận 3', 'pos': [68, 74]}\n",
            "\n",
            "original:       {'text': '(TITC', 'pos': [56, 61]}\n",
            "new_entity:     {'text': 'TITC', 'pos': [57, 61]}\n",
            "\n",
            "original:       {'text': '-TP.Hồ Chí Minh', 'pos': [144, 159]}\n",
            "new_entity:     {'text': 'TP.Hồ Chí Minh', 'pos': [145, 159]}\n",
            "\n",
            "original:       {'text': '(Vinachem', 'pos': [219, 228]}\n",
            "new_entity:     {'text': 'Vinachem', 'pos': [220, 228]}\n",
            "\n",
            "original:       {'text': '(Vietinbank', 'pos': [191, 202]}\n",
            "new_entity:     {'text': 'Vietinbank', 'pos': [192, 202]}\n",
            "\n",
            "original:       {'text': '(Ban Tuyên giáo LĐLĐ TP Đà Nẵng', 'pos': [9, 40]}\n",
            "new_entity:     {'text': 'Ban Tuyên giáo LĐLĐ TP Đà Nẵng', 'pos': [10, 40]}\n",
            "\n",
            "original:       {'text': '\\xa0Shin Jin Ju', 'pos': [18, 30]}\n",
            "new_entity:     {'text': 'Shin Jin Ju', 'pos': [19, 30]}\n",
            "\n",
            "original:       {'text': '(tỉnh Quảng Nam', 'pos': [170, 185]}\n",
            "new_entity:     {'text': 'tỉnh Quảng Nam', 'pos': [171, 185]}\n",
            "\n",
            "original:       {'text': '(Lệ Thủy', 'pos': [117, 125]}\n",
            "new_entity:     {'text': 'Lệ Thủy', 'pos': [118, 125]}\n",
            "\n",
            "original:       {'text': '(AFF', 'pos': [16, 20]}\n",
            "new_entity:     {'text': 'AFF', 'pos': [17, 20]}\n",
            "\n",
            "original:       {'text': '(ILO', 'pos': [26, 30]}\n",
            "new_entity:     {'text': 'ILO', 'pos': [27, 30]}\n",
            "\n",
            "original:       {'text': '(OECD', 'pos': [120, 125]}\n",
            "new_entity:     {'text': 'OECD', 'pos': [121, 125]}\n",
            "\n",
            "original:       {'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n",
            "new_entity:     {'text': 'tỉnh Thái Nguyên', 'pos': [53, 69]}\n",
            "\n",
            "original:       {'text': '(PC45', 'pos': [230, 235]}\n",
            "new_entity:     {'text': 'PC45', 'pos': [231, 235]}\n",
            "\n",
            "original:       {'text': '(PC 45', 'pos': [31, 37]}\n",
            "new_entity:     {'text': 'PC 45', 'pos': [32, 37]}\n",
            "\n",
            "original:       {'text': '(NHNN', 'pos': [35, 40]}\n",
            "new_entity:     {'text': 'NHNN', 'pos': [36, 40]}\n",
            "\n",
            "original:       {'text': '(MBB', 'pos': [88, 92]}\n",
            "new_entity:     {'text': 'MBB', 'pos': [89, 92]}\n",
            "\n",
            "original:       {'text': '(OCB', 'pos': [106, 110]}\n",
            "new_entity:     {'text': 'OCB', 'pos': [107, 110]}\n",
            "\n",
            "original:       {'text': '(VIB', 'pos': [61, 65]}\n",
            "new_entity:     {'text': 'VIB', 'pos': [62, 65]}\n",
            "\n",
            "original:       {'text': '(NCB', 'pos': [50, 54]}\n",
            "new_entity:     {'text': 'NCB', 'pos': [51, 54]}\n",
            "\n",
            "original:       {'text': '(OceanBank', 'pos': [134, 144]}\n",
            "new_entity:     {'text': 'OceanBank', 'pos': [135, 144]}\n",
            "\n",
            "original:       {'text': '(Singapore', 'pos': [19, 29]}\n",
            "new_entity:     {'text': 'Singapore', 'pos': [20, 29]}\n",
            "\n",
            "original:       {'text': '(quận 12', 'pos': [87, 95]}\n",
            "new_entity:     {'text': 'quận 12', 'pos': [88, 95]}\n",
            "\n",
            "original:       {'text': '(PC64', 'pos': [114, 119]}\n",
            "new_entity:     {'text': 'PC64', 'pos': [115, 119]}\n",
            "\n",
            "original:       {'text': '(QL13', 'pos': [84, 89]}\n",
            "new_entity:     {'text': 'QL13', 'pos': [85, 89]}\n",
            "\n",
            "original:       {'text': '(Quảng Trị', 'pos': [250, 260]}\n",
            "new_entity:     {'text': 'Quảng Trị', 'pos': [251, 260]}\n",
            "\n",
            "original:       {'text': \"'Cavani\", 'pos': [0, 7]}\n",
            "new_entity:     {'text': 'Cavani', 'pos': [1, 7]}\n",
            "\n",
            "original:       {'text': '(Pháp', 'pos': [12, 17]}\n",
            "new_entity:     {'text': 'Pháp', 'pos': [13, 17]}\n",
            "\n",
            "original:       {'text': 'Việt “đỏ”', 'pos': [105, 114]}\n",
            "new_entity:     {'text': 'Việt “đỏ', 'pos': [105, 113]}\n",
            "\n",
            "original:       {'text': '(Mỹ Đức', 'pos': [33, 40]}\n",
            "new_entity:     {'text': 'Mỹ Đức', 'pos': [34, 40]}\n",
            "\n",
            "original:       {'text': '(Mường La', 'pos': [38, 47]}\n",
            "new_entity:     {'text': 'Mường La', 'pos': [39, 47]}\n",
            "\n",
            "original:       {'text': ';\\xa0Tập đoàn xăng dầu Việt Nam', 'pos': [38, 66]}\n",
            "new_entity:     {'text': 'Tập đoàn xăng dầu Việt Nam', 'pos': [40, 66]}\n",
            "\n",
            "original:       {'text': ';\\xa0Công ty TNHH xuất nhập khẩu 3A Việt Nam', 'pos': [207, 248]}\n",
            "new_entity:     {'text': 'Công ty TNHH xuất nhập khẩu 3A Việt Nam', 'pos': [209, 248]}\n",
            "\n",
            "original:       {'text': 'Công ty CP du lịch văn hóa An Nguyên;', 'pos': [310, 347]}\n",
            "new_entity:     {'text': 'Công ty CP du lịch văn hóa An Nguyên', 'pos': [310, 346]}\n",
            "\n",
            "original:       {'text': '\\xa0Công ty Điện lực Sơn La', 'pos': [421, 445]}\n",
            "new_entity:     {'text': 'Công ty Điện lực Sơn La', 'pos': [422, 445]}\n",
            "\n",
            "original:       {'text': '(Gia Lai', 'pos': [87, 95]}\n",
            "new_entity:     {'text': 'Gia Lai', 'pos': [88, 95]}\n",
            "\n",
            "original:       {'text': '(MTTQVN', 'pos': [152, 159]}\n",
            "new_entity:     {'text': 'MTTQVN', 'pos': [153, 159]}\n",
            "\n",
            "original:       {'text': '(WHO', 'pos': [65, 69]}\n",
            "new_entity:     {'text': 'WHO', 'pos': [66, 69]}\n",
            "\n",
            "original:       {'text': 'Nguyễn Danh Vĩnh\\xa0', 'pos': [196, 213]}\n",
            "new_entity:     {'text': 'Nguyễn Danh Vĩnh', 'pos': [196, 212]}\n",
            "\n",
            "original:       {'text': '(USAID', 'pos': [268, 274]}\n",
            "new_entity:     {'text': 'USAID', 'pos': [269, 274]}\n",
            "\n",
            "original:       {'text': '(Q.1', 'pos': [153, 157]}\n",
            "new_entity:     {'text': 'Q.1', 'pos': [154, 157]}\n",
            "\n",
            "original:       {'text': '(Đồng Tháp', 'pos': [68, 78]}\n",
            "new_entity:     {'text': 'Đồng Tháp', 'pos': [69, 78]}\n",
            "\n",
            "original:       {'text': '-Uông Bí', 'pos': [19, 27]}\n",
            "new_entity:     {'text': 'Uông Bí', 'pos': [20, 27]}\n",
            "\n",
            "original:       {'text': '/Vietnam+', 'pos': [9, 18]}\n",
            "new_entity:     {'text': 'Vietnam+', 'pos': [10, 18]}\n",
            "\n",
            "original:       {'text': '(phường 3', 'pos': [67, 76]}\n",
            "new_entity:     {'text': 'phường 3', 'pos': [68, 76]}\n",
            "\n",
            "original:       {'text': '(TAC', 'pos': [74, 78]}\n",
            "new_entity:     {'text': 'TAC', 'pos': [75, 78]}\n",
            "\n",
            "original:       {'text': '(quận Tây Hồ', 'pos': [154, 166]}\n",
            "new_entity:     {'text': 'quận Tây Hồ', 'pos': [155, 166]}\n",
            "\n",
            "original:       {'text': '(quận Hoàng Mai', 'pos': [41, 56]}\n",
            "new_entity:     {'text': 'quận Hoàng Mai', 'pos': [42, 56]}\n",
            "\n",
            "original:       {'text': '-HIẾU MINH', 'pos': [12, 22]}\n",
            "new_entity:     {'text': 'HIẾU MINH', 'pos': [13, 22]}\n",
            "\n",
            "original:       {'text': '(Cộng hòa Czech', 'pos': [51, 66]}\n",
            "new_entity:     {'text': 'Cộng hòa Czech', 'pos': [52, 66]}\n",
            "\n",
            "original:       {'text': '(Anh', 'pos': [123, 127]}\n",
            "new_entity:     {'text': 'Anh', 'pos': [124, 127]}\n",
            "\n",
            "original:       {'text': '(TP Cần Thơ', 'pos': [60, 71]}\n",
            "new_entity:     {'text': 'TP Cần Thơ', 'pos': [61, 71]}\n",
            "\n",
            "original:       {'text': '“Câu lạc bộ điểm vườn du lịch Phong Điền', 'pos': [120, 160]}\n",
            "new_entity:     {'text': 'Câu lạc bộ điểm vườn du lịch Phong Điền', 'pos': [121, 160]}\n",
            "\n",
            "original:       {'text': '(Phòng CSGT Thanh Hóa', 'pos': [84, 105]}\n",
            "new_entity:     {'text': 'Phòng CSGT Thanh Hóa', 'pos': [85, 105]}\n",
            "\n",
            "original:       {'text': \"'Real Madrid\", 'pos': [0, 12]}\n",
            "new_entity:     {'text': 'Real Madrid', 'pos': [1, 12]}\n",
            "\n",
            "original:       {'text': '“Bộ GD&ĐT', 'pos': [0, 9]}\n",
            "new_entity:     {'text': 'Bộ GD&ĐT', 'pos': [1, 9]}\n",
            "\n",
            "original:       {'text': '(IMF', 'pos': [51, 55]}\n",
            "new_entity:     {'text': 'IMF', 'pos': [52, 55]}\n",
            "\n",
            "original:       {'text': '(PBOC', 'pos': [105, 110]}\n",
            "new_entity:     {'text': 'PBOC', 'pos': [106, 110]}\n",
            "\n",
            "original:       {'text': '(Long An', 'pos': [153, 161]}\n",
            "new_entity:     {'text': 'Long An', 'pos': [154, 161]}\n",
            "\n",
            "original:       {'text': '(WTO', 'pos': [209, 213]}\n",
            "new_entity:     {'text': 'WTO', 'pos': [210, 213]}\n",
            "\n",
            "original:       {'text': '(Bỉ', 'pos': [113, 116]}\n",
            "new_entity:     {'text': 'Bỉ', 'pos': [114, 116]}\n",
            "\n",
            "original:       {'text': '(Hàn Quốc', 'pos': [148, 157]}\n",
            "new_entity:     {'text': 'Hàn Quốc', 'pos': [149, 157]}\n",
            "\n",
            "original:       {'text': '(ASEAN', 'pos': [85, 91]}\n",
            "new_entity:     {'text': 'ASEAN', 'pos': [86, 91]}\n",
            "\n",
            "original:       {'text': '(EU', 'pos': [115, 118]}\n",
            "new_entity:     {'text': 'EU', 'pos': [116, 118]}\n",
            "\n",
            "original:       {'text': '(S&P', 'pos': [16, 20]}\n",
            "new_entity:     {'text': 'S&P', 'pos': [17, 20]}\n",
            "\n",
            "original:       {'text': '(Pháp luật TPHCM', 'pos': [15, 31]}\n",
            "new_entity:     {'text': 'Pháp luật TPHCM', 'pos': [16, 31]}\n",
            "\n",
            "original:       {'text': '(Bộ NN&PTNT', 'pos': [228, 239]}\n",
            "new_entity:     {'text': 'Bộ NN&PTNT', 'pos': [229, 239]}\n",
            "\n",
            "original:       {'text': '\"UNICEF', 'pos': [0, 7]}\n",
            "new_entity:     {'text': 'UNICEF', 'pos': [1, 7]}\n",
            "\n",
            "original:       {'text': '-Thái Bình Dương', 'pos': [396, 412]}\n",
            "new_entity:     {'text': 'Thái Bình Dương', 'pos': [397, 412]}\n",
            "\n",
            "original:       {'text': '(Dân Việt', 'pos': [14, 23]}\n",
            "new_entity:     {'text': 'Dân Việt', 'pos': [15, 23]}\n",
            "\n",
            "original:       {'text': '(Quảng Bình', 'pos': [276, 287]}\n",
            "new_entity:     {'text': 'Quảng Bình', 'pos': [277, 287]}\n",
            "\n",
            "original:       {'text': '(MSN', 'pos': [31, 35]}\n",
            "new_entity:     {'text': 'MSN', 'pos': [32, 35]}\n",
            "\n",
            "original:       {'text': '(HNX', 'pos': [34, 38]}\n",
            "new_entity:     {'text': 'HNX', 'pos': [35, 38]}\n",
            "\n",
            "original:       {'text': '(Kido Foods', 'pos': [126, 137]}\n",
            "new_entity:     {'text': 'Kido Foods', 'pos': [127, 137]}\n",
            "\n",
            "original:       {'text': '(UBCKNN', 'pos': [28, 35]}\n",
            "new_entity:     {'text': 'UBCKNN', 'pos': [29, 35]}\n",
            "\n",
            "original:       {'text': '(VISecurities', 'pos': [99, 112]}\n",
            "new_entity:     {'text': 'VISecurities', 'pos': [100, 112]}\n",
            "\n",
            "original:       {'text': '(HAGL Agrico', 'pos': [54, 66]}\n",
            "new_entity:     {'text': 'HAGL Agrico', 'pos': [55, 66]}\n",
            "\n",
            "original:       {'text': '(Vinh Râu', 'pos': [71, 80]}\n",
            "new_entity:     {'text': 'Vinh Râu', 'pos': [72, 80]}\n",
            "\n",
            "original:       {'text': '(Diệu Nhi', 'pos': [105, 114]}\n",
            "new_entity:     {'text': 'Diệu Nhi', 'pos': [106, 114]}\n",
            "\n",
            "original:       {'text': '(PC67', 'pos': [44, 49]}\n",
            "new_entity:     {'text': 'PC67', 'pos': [45, 49]}\n",
            "\n",
            "original:       {'text': '(Báo Tuổi Trẻ', 'pos': [44, 57]}\n",
            "new_entity:     {'text': 'Báo Tuổi Trẻ', 'pos': [45, 57]}\n",
            "\n",
            "original:       {'text': '/TTXVN', 'pos': [14, 20]}\n",
            "new_entity:     {'text': 'TTXVN', 'pos': [15, 20]}\n",
            "\n",
            "original:       {'text': '(Thăng Long', 'pos': [80, 91]}\n",
            "new_entity:     {'text': 'Thăng Long', 'pos': [81, 91]}\n",
            "\n",
            "original:       {'text': '(Thái Bình', 'pos': [72, 82]}\n",
            "new_entity:     {'text': 'Thái Bình', 'pos': [73, 82]}\n",
            "\n",
            "original:       {'text': '(DQS', 'pos': [59, 63]}\n",
            "new_entity:     {'text': 'DQS', 'pos': [60, 63]}\n",
            "\n",
            "original:       {'text': '(TISCO', 'pos': [73, 79]}\n",
            "new_entity:     {'text': 'TISCO', 'pos': [74, 79]}\n",
            "\n",
            "original:       {'text': '‘thánh Andres’', 'pos': [160, 174]}\n",
            "new_entity:     {'text': 'thánh Andres', 'pos': [161, 173]}\n",
            "\n",
            "original:       {'text': '‘Neymar', 'pos': [60, 67]}\n",
            "new_entity:     {'text': 'Neymar', 'pos': [61, 67]}\n",
            "\n",
            "original:       {'text': '/VOV', 'pos': [10, 14]}\n",
            "new_entity:     {'text': 'VOV', 'pos': [11, 14]}\n",
            "\n",
            "original:       {'text': '-Miền Trung', 'pos': [15, 26]}\n",
            "new_entity:     {'text': 'Miền Trung', 'pos': [16, 26]}\n",
            "\n",
            "original:       {'text': '“Real Madrid', 'pos': [40, 52]}\n",
            "new_entity:     {'text': 'Real Madrid', 'pos': [41, 52]}\n",
            "\n",
            "original:       {'text': '(Các tiểu vương quốc Ả Rập thống nhất', 'pos': [128, 165]}\n",
            "new_entity:     {'text': 'Các tiểu vương quốc Ả Rập thống nhất', 'pos': [129, 165]}\n",
            "\n",
            "original:       {'text': '(CH Séc', 'pos': [12, 19]}\n",
            "new_entity:     {'text': 'CH Séc', 'pos': [13, 19]}\n",
            "\n",
            "original:       {'text': '(Bulgaria', 'pos': [53, 62]}\n",
            "new_entity:     {'text': 'Bulgaria', 'pos': [54, 62]}\n",
            "\n",
            "original:       {'text': '(Phạm Thị Hương', 'pos': [114, 129]}\n",
            "new_entity:     {'text': 'Phạm Thị Hương', 'pos': [115, 129]}\n",
            "\n",
            "original:       {'text': '(Trần Thị Bích Thủy', 'pos': [175, 194]}\n",
            "new_entity:     {'text': 'Trần Thị Bích Thủy', 'pos': [176, 194]}\n",
            "\n",
            "original:       {'text': '(HTS', 'pos': [195, 199]}\n",
            "new_entity:     {'text': 'HTS', 'pos': [196, 199]}\n",
            "\n",
            "original:       {'text': '“Zvezda', 'pos': [22, 29]}\n",
            "new_entity:     {'text': 'Zvezda', 'pos': [23, 29]}\n",
            "\n",
            "original:       {'text': '(SDF', 'pos': [137, 141]}\n",
            "new_entity:     {'text': 'SDF', 'pos': [138, 141]}\n",
            "\n",
            "original:       {'text': '(IS', 'pos': [299, 302]}\n",
            "new_entity:     {'text': 'IS', 'pos': [300, 302]}\n",
            "\n",
            "original:       {'text': '-Iraq', 'pos': [414, 419]}\n",
            "new_entity:     {'text': 'Iraq', 'pos': [415, 419]}\n",
            "\n",
            "original:       {'text': '(SAA', 'pos': [34, 38]}\n",
            "new_entity:     {'text': 'SAA', 'pos': [35, 38]}\n",
            "\n",
            "original:       {'text': \"'Ronaldo xứ Nghệ'\", 'pos': [10, 27]}\n",
            "new_entity:     {'text': 'Ronaldo xứ Nghệ', 'pos': [11, 26]}\n",
            "\n",
            "original:       {'text': '\"Ronaldo xứ Nghệ\"', 'pos': [108, 125]}\n",
            "new_entity:     {'text': 'Ronaldo xứ Nghệ', 'pos': [109, 124]}\n",
            "\n",
            "original:       {'text': '(VFF', 'pos': [140, 144]}\n",
            "new_entity:     {'text': 'VFF', 'pos': [141, 144]}\n",
            "\n",
            "original:       {'text': '(Indonesia', 'pos': [113, 123]}\n",
            "new_entity:     {'text': 'Indonesia', 'pos': [114, 123]}\n",
            "\n",
            "original:       {'text': '(FAT', 'pos': [97, 101]}\n",
            "new_entity:     {'text': 'FAT', 'pos': [98, 101]}\n",
            "\n",
            "original:       {'text': '(Thành', 'pos': [79, 85]}\n",
            "new_entity:     {'text': 'Thành', 'pos': [80, 85]}\n",
            "\n",
            "original:       {'text': '(Phương', 'pos': [100, 107]}\n",
            "new_entity:     {'text': 'Phương', 'pos': [101, 107]}\n",
            "\n",
            "original:       {'text': '(Sơn', 'pos': [124, 128]}\n",
            "new_entity:     {'text': 'Sơn', 'pos': [125, 128]}\n",
            "\n",
            "original:       {'text': '(Mai', 'pos': [166, 170]}\n",
            "new_entity:     {'text': 'Mai', 'pos': [167, 170]}\n",
            "\n",
            "original:       {'text': '(Trang', 'pos': [13, 19]}\n",
            "new_entity:     {'text': 'Trang', 'pos': [14, 19]}\n",
            "\n",
            "original:       {'text': '(Lực', 'pos': [31, 35]}\n",
            "new_entity:     {'text': 'Lực', 'pos': [32, 35]}\n",
            "\n",
            "original:       {'text': '(Hiệp', 'pos': [48, 53]}\n",
            "new_entity:     {'text': 'Hiệp', 'pos': [49, 53]}\n",
            "\n",
            "original:       {'text': '(Châu', 'pos': [70, 75]}\n",
            "new_entity:     {'text': 'Châu', 'pos': [71, 75]}\n",
            "\n",
            "original:       {'text': '(Liêm', 'pos': [88, 93]}\n",
            "new_entity:     {'text': 'Liêm', 'pos': [89, 93]}\n",
            "\n",
            "original:       {'text': '(AfD', 'pos': [108, 112]}\n",
            "new_entity:     {'text': 'AfD', 'pos': [109, 112]}\n",
            "\n",
            "original:       {'text': '(Ban Tuyên giáo Trung ương', 'pos': [86, 112]}\n",
            "new_entity:     {'text': 'Ban Tuyên giáo Trung ương', 'pos': [87, 112]}\n",
            "\n",
            "original:       {'text': '(Hà Tĩnh', 'pos': [253, 261]}\n",
            "new_entity:     {'text': 'Hà Tĩnh', 'pos': [254, 261]}\n",
            "\n",
            "original:       {'text': '(huyện Kỳ Anh', 'pos': [283, 296]}\n",
            "new_entity:     {'text': 'huyện Kỳ Anh', 'pos': [284, 296]}\n",
            "\n",
            "original:       {'text': '(TP.Biên Hoà', 'pos': [115, 127]}\n",
            "new_entity:     {'text': 'TP.Biên Hoà', 'pos': [116, 127]}\n",
            "\n",
            "original:       {'text': '(Việt Nam', 'pos': [140, 149]}\n",
            "new_entity:     {'text': 'Việt Nam', 'pos': [141, 149]}\n",
            "\n",
            "original:       {'text': '(Tisco', 'pos': [114, 120]}\n",
            "new_entity:     {'text': 'Tisco', 'pos': [115, 120]}\n",
            "\n",
            "original:       {'text': '(PVN', 'pos': [83, 87]}\n",
            "new_entity:     {'text': 'PVN', 'pos': [84, 87]}\n",
            "\n",
            "original:       {'text': '(LĐBĐ Đông Nam Á', 'pos': [63, 79]}\n",
            "new_entity:     {'text': 'LĐBĐ Đông Nam Á', 'pos': [64, 79]}\n",
            "\n",
            "original:       {'text': '(PVTex', 'pos': [59, 65]}\n",
            "new_entity:     {'text': 'PVTex', 'pos': [60, 65]}\n",
            "\n",
            "original:       {'text': '\\ufeffJang Dong Gun', 'pos': [0, 14]}\n",
            "new_entity:     {'text': 'Jang Dong Gun', 'pos': [1, 14]}\n",
            "\n",
            "original:       {'text': '(Công ty Tín Thành', 'pos': [135, 153]}\n",
            "new_entity:     {'text': 'Công ty Tín Thành', 'pos': [136, 153]}\n",
            "\n",
            "original:       {'text': '(BSR', 'pos': [29, 33]}\n",
            "new_entity:     {'text': 'BSR', 'pos': [30, 33]}\n",
            "\n",
            "original:       {'text': '(PVFCCo', 'pos': [53, 60]}\n",
            "new_entity:     {'text': 'PVFCCo', 'pos': [54, 60]}\n",
            "\n",
            "original:       {'text': '(SCIC', 'pos': [134, 139]}\n",
            "new_entity:     {'text': 'SCIC', 'pos': [135, 139]}\n",
            "\n",
            "original:       {'text': '(VTM', 'pos': [107, 111]}\n",
            "new_entity:     {'text': 'VTM', 'pos': [108, 111]}\n",
            "\n",
            "original:       {'text': '(UAE', 'pos': [92, 96]}\n",
            "new_entity:     {'text': 'UAE', 'pos': [93, 96]}\n",
            "\n",
            "original:       {'text': '(Vivaso', 'pos': [199, 206]}\n",
            "new_entity:     {'text': 'Vivaso', 'pos': [200, 206]}\n",
            "\n",
            "original:       {'text': '(TTF', 'pos': [49, 53]}\n",
            "new_entity:     {'text': 'TTF', 'pos': [50, 53]}\n",
            "\n",
            "original:       {'text': '(TTI', 'pos': [182, 186]}\n",
            "new_entity:     {'text': 'TTI', 'pos': [183, 186]}\n",
            "\n",
            "original:       {'text': '(HOSE', 'pos': [36, 41]}\n",
            "new_entity:     {'text': 'HOSE', 'pos': [37, 41]}\n",
            "\n",
            "original:       {'text': '(Sabeco', 'pos': [71, 78]}\n",
            "new_entity:     {'text': 'Sabeco', 'pos': [72, 78]}\n",
            "\n",
            "original:       {'text': '(Teen Top', 'pos': [15, 24]}\n",
            "new_entity:     {'text': 'Teen Top', 'pos': [16, 24]}\n",
            "\n",
            "original:       {'text': '(Đà Nẵng', 'pos': [53, 61]}\n",
            "new_entity:     {'text': 'Đà Nẵng', 'pos': [54, 61]}\n",
            "\n",
            "original:       {'text': '/Thế Phong', 'pos': [4, 14]}\n",
            "new_entity:     {'text': 'Thế Phong', 'pos': [5, 14]}\n",
            "\n",
            "original:       {'text': '(Mỹ', 'pos': [79, 82]}\n",
            "new_entity:     {'text': 'Mỹ', 'pos': [80, 82]}\n",
            "\n",
            "original:       {'text': '-Ấn Độ', 'pos': [32, 38]}\n",
            "new_entity:     {'text': 'Ấn Độ', 'pos': [33, 38]}\n",
            "\n",
            "original:       {'text': '(TfL', 'pos': [32, 36]}\n",
            "new_entity:     {'text': 'TfL', 'pos': [33, 36]}\n",
            "\n",
            "original:       {'text': '(SOHR', 'pos': [38, 43]}\n",
            "new_entity:     {'text': 'SOHR', 'pos': [39, 43]}\n",
            "\n",
            "original:       {'text': '(xã Phước Hòa', 'pos': [115, 128]}\n",
            "new_entity:     {'text': 'xã Phước Hòa', 'pos': [116, 128]}\n",
            "\n",
            "original:       {'text': '(thôn Kim Tây', 'pos': [119, 132]}\n",
            "new_entity:     {'text': 'thôn Kim Tây', 'pos': [120, 132]}\n",
            "\n",
            "original:       {'text': '-Mỹ', 'pos': [31, 34]}\n",
            "new_entity:     {'text': 'Mỹ', 'pos': [32, 34]}\n",
            "\n",
            "original:       {'text': '/GĐVN', 'pos': [15, 20]}\n",
            "new_entity:     {'text': 'GĐVN', 'pos': [16, 20]}\n",
            "\n",
            "original:       {'text': '/Phương Liên', 'pos': [4, 16]}\n",
            "new_entity:     {'text': 'Phương Liên', 'pos': [5, 16]}\n",
            "\n",
            "original:       {'text': '(Quảng Ninh', 'pos': [112, 123]}\n",
            "new_entity:     {'text': 'Quảng Ninh', 'pos': [113, 123]}\n",
            "\n",
            "original:       {'text': '(Thái Thụy', 'pos': [97, 107]}\n",
            "new_entity:     {'text': 'Thái Thụy', 'pos': [98, 107]}\n",
            "\n",
            "original:       {'text': '(Tổng cục Chính trị', 'pos': [71, 90]}\n",
            "new_entity:     {'text': 'Tổng cục Chính trị', 'pos': [72, 90]}\n",
            "\n",
            "original:       {'text': '\"miền Nam', 'pos': [153, 162]}\n",
            "new_entity:     {'text': 'miền Nam', 'pos': [154, 162]}\n",
            "\n",
            "original:       {'text': '(Thanh Thủy', 'pos': [120, 131]}\n",
            "new_entity:     {'text': 'Thanh Thủy', 'pos': [121, 131]}\n",
            "\n",
            "original:       {'text': '/Dân Việt', 'pos': [15, 24]}\n",
            "new_entity:     {'text': 'Dân Việt', 'pos': [16, 24]}\n",
            "\n",
            "original:       {'text': '/Người Lao Động', 'pos': [15, 30]}\n",
            "new_entity:     {'text': 'Người Lao Động', 'pos': [16, 30]}\n",
            "\n",
            "original:       {'text': '(Đắk Lắk', 'pos': [90, 98]}\n",
            "new_entity:     {'text': 'Đắk Lắk', 'pos': [91, 98]}\n",
            "\n",
            "original:       {'text': '\"Royal Zone', 'pos': [102, 113]}\n",
            "new_entity:     {'text': 'Royal Zone', 'pos': [103, 113]}\n",
            "\n",
            "original:       {'text': '\"Private Zone', 'pos': [167, 180]}\n",
            "new_entity:     {'text': 'Private Zone', 'pos': [168, 180]}\n",
            "\n",
            "original:       {'text': '(MSF', 'pos': [97, 101]}\n",
            "new_entity:     {'text': 'MSF', 'pos': [98, 101]}\n",
            "\n",
            "original:       {'text': '(Bộ Công thương', 'pos': [64, 79]}\n",
            "new_entity:     {'text': 'Bộ Công thương', 'pos': [65, 79]}\n",
            "\n",
            "original:       {'text': '(Bộ KH&ĐT', 'pos': [61, 70]}\n",
            "new_entity:     {'text': 'Bộ KH&ĐT', 'pos': [62, 70]}\n",
            "\n",
            "original:       {'text': '(Trung tâm Đào tạo Quản lý tiên tiến', 'pos': [18, 54]}\n",
            "new_entity:     {'text': 'Trung tâm Đào tạo Quản lý tiên tiến', 'pos': [19, 54]}\n",
            "\n",
            "original:       {'text': '(Nhật Bản', 'pos': [101, 110]}\n",
            "new_entity:     {'text': 'Nhật Bản', 'pos': [102, 110]}\n",
            "\n",
            "original:       {'text': '(Mạnh Trường', 'pos': [67, 79]}\n",
            "new_entity:     {'text': 'Mạnh Trường', 'pos': [68, 79]}\n",
            "\n",
            "original:       {'text': '(Hà Việt Dũng', 'pos': [38, 51]}\n",
            "new_entity:     {'text': 'Hà Việt Dũng', 'pos': [39, 51]}\n",
            "\n",
            "original:       {'text': '(Phương Oanh', 'pos': [88, 100]}\n",
            "new_entity:     {'text': 'Phương Oanh', 'pos': [89, 100]}\n",
            "\n",
            "original:       {'text': '(Trang Cherry', 'pos': [97, 110]}\n",
            "new_entity:     {'text': 'Trang Cherry', 'pos': [98, 110]}\n",
            "\n",
            "original:       {'text': '(Quận 10', 'pos': [55, 63]}\n",
            "new_entity:     {'text': 'Quận 10', 'pos': [56, 63]}\n",
            "\n",
            "original:       {'text': '(ICAO', 'pos': [119, 124]}\n",
            "new_entity:     {'text': 'ICAO', 'pos': [120, 124]}\n",
            "\n",
            "original:       {'text': '(Italia', 'pos': [42, 49]}\n",
            "new_entity:     {'text': 'Italia', 'pos': [43, 49]}\n",
            "\n",
            "original:       {'text': '“Ông già cao nguyên đá”', 'pos': [0, 23]}\n",
            "new_entity:     {'text': 'Ông già cao nguyên đá', 'pos': [1, 22]}\n",
            "\n",
            "original:       {'text': '“Bác Dùng đại đoàn kết”', 'pos': [26, 49]}\n",
            "new_entity:     {'text': 'Bác Dùng đại đoàn kết', 'pos': [27, 48]}\n",
            "\n",
            "original:       {'text': '“Ông già Dùng có tài”', 'pos': [52, 73]}\n",
            "new_entity:     {'text': 'Ông già Dùng có tài', 'pos': [53, 72]}\n",
            "\n",
            "original:       {'text': '“Ông già Dùng Mặt trận”', 'pos': [76, 99]}\n",
            "new_entity:     {'text': 'Ông già Dùng Mặt trận', 'pos': [77, 98]}\n",
            "\n",
            "original:       {'text': '“Dùng Mặt trận”', 'pos': [68, 83]}\n",
            "new_entity:     {'text': 'Dùng Mặt trận', 'pos': [69, 82]}\n",
            "\n",
            "original:       {'text': '(Mauritius', 'pos': [96, 106]}\n",
            "new_entity:     {'text': 'Mauritius', 'pos': [97, 106]}\n",
            "\n",
            "original:       {'text': '(huyện Con Cuông', 'pos': [130, 146]}\n",
            "new_entity:     {'text': 'huyện Con Cuông', 'pos': [131, 146]}\n",
            "\n",
            "original:       {'text': '(JICA', 'pos': [172, 177]}\n",
            "new_entity:     {'text': 'JICA', 'pos': [173, 177]}\n",
            "\n",
            "original:       {'text': '\"Mỹ', 'pos': [0, 3]}\n",
            "new_entity:     {'text': 'Mỹ', 'pos': [1, 3]}\n",
            "\n",
            "original:       {'text': '(Global Taiwan Institute', 'pos': [204, 228]}\n",
            "new_entity:     {'text': 'Global Taiwan Institute', 'pos': [205, 228]}\n",
            "\n",
            "original:       {'text': '\"Trung Quốc', 'pos': [0, 11]}\n",
            "new_entity:     {'text': 'Trung Quốc', 'pos': [1, 11]}\n",
            "\n",
            "original:       {'text': '(NATO', 'pos': [79, 84]}\n",
            "new_entity:     {'text': 'NATO', 'pos': [80, 84]}\n",
            "\n",
            "original:       {'text': '(TQ', 'pos': [88, 91]}\n",
            "new_entity:     {'text': 'TQ', 'pos': [89, 91]}\n",
            "\n",
            "original:       {'text': ',\\xa0ABC News', 'pos': [73, 83]}\n",
            "new_entity:     {'text': 'ABC News', 'pos': [75, 83]}\n",
            "\n",
            "original:       {'text': '(Lebanon', 'pos': [131, 139]}\n",
            "new_entity:     {'text': 'Lebanon', 'pos': [132, 139]}\n",
            "\n",
            "original:       {'text': '\\xa0(Thái Bình', 'pos': [9, 20]}\n",
            "new_entity:     {'text': 'Thái Bình', 'pos': [11, 20]}\n",
            "\n",
            "original:       {'text': '(AAP', 'pos': [25, 29]}\n",
            "new_entity:     {'text': 'AAP', 'pos': [26, 29]}\n",
            "\n",
            "original:       {'text': '-Thành Hữu', 'pos': [13, 23]}\n",
            "new_entity:     {'text': 'Thành Hữu', 'pos': [14, 23]}\n",
            "\n",
            "original:       {'text': '/Tokyo', 'pos': [60, 66]}\n",
            "new_entity:     {'text': 'Tokyo', 'pos': [61, 66]}\n",
            "\n",
            "original:       {'text': '(Vietnam+', 'pos': [67, 76]}\n",
            "new_entity:     {'text': 'Vietnam+', 'pos': [68, 76]}\n",
            "\n",
            "original:       {'text': '-Chợ Lớn', 'pos': [33, 41]}\n",
            "new_entity:     {'text': 'Chợ Lớn', 'pos': [34, 41]}\n",
            "\n",
            "original:       {'text': '(thành phố Hồ Chí Minh', 'pos': [155, 177]}\n",
            "new_entity:     {'text': 'thành phố Hồ Chí Minh', 'pos': [156, 177]}\n",
            "\n",
            "original:       {'text': '(Cambridgeshire', 'pos': [105, 120]}\n",
            "new_entity:     {'text': 'Cambridgeshire', 'pos': [106, 120]}\n",
            "\n",
            "original:       {'text': '(Melbourne', 'pos': [29, 39]}\n",
            "new_entity:     {'text': 'Melbourne', 'pos': [30, 39]}\n",
            "\n",
            "original:       {'text': '(Cambridge', 'pos': [80, 90]}\n",
            "new_entity:     {'text': 'Cambridge', 'pos': [81, 90]}\n",
            "\n",
            "original:       {'text': '(xã Núa Ngam', 'pos': [41, 53]}\n",
            "new_entity:     {'text': 'xã Núa Ngam', 'pos': [42, 53]}\n",
            "\n",
            "original:       {'text': '(xã Sa Lông', 'pos': [71, 82]}\n",
            "new_entity:     {'text': 'xã Sa Lông', 'pos': [72, 82]}\n",
            "\n",
            "original:       {'text': '(xã An Đồng', 'pos': [25, 36]}\n",
            "new_entity:     {'text': 'xã An Đồng', 'pos': [26, 36]}\n",
            "\n",
            "original:       {'text': '(xã An Khê', 'pos': [20, 30]}\n",
            "new_entity:     {'text': 'xã An Khê', 'pos': [21, 30]}\n",
            "\n",
            "original:       {'text': '(xã Ngư Lộc', 'pos': [15, 26]}\n",
            "new_entity:     {'text': 'xã Ngư Lộc', 'pos': [16, 26]}\n",
            "\n",
            "original:       {'text': '(xã Đông Anh', 'pos': [36, 48]}\n",
            "new_entity:     {'text': 'xã Đông Anh', 'pos': [37, 48]}\n",
            "\n",
            "original:       {'text': '(STB', 'pos': [72, 76]}\n",
            "new_entity:     {'text': 'STB', 'pos': [73, 76]}\n",
            "\n",
            "original:       {'text': '\"Singapore', 'pos': [147, 157]}\n",
            "new_entity:     {'text': 'Singapore', 'pos': [148, 157]}\n",
            "\n",
            "original:       {'text': '/Ottawa', 'pos': [6, 13]}\n",
            "new_entity:     {'text': 'Ottawa', 'pos': [7, 13]}\n",
            "\n",
            "original:       {'text': '(HTC', 'pos': [87, 91]}\n",
            "new_entity:     {'text': 'HTC', 'pos': [88, 91]}\n",
            "\n",
            "original:       {'text': '(Nhà Xuất bản Hội Nhà văn', 'pos': [122, 147]}\n",
            "new_entity:     {'text': 'Nhà Xuất bản Hội Nhà văn', 'pos': [123, 147]}\n",
            "\n",
            "original:       {'text': '(NL', 'pos': [36, 39]}\n",
            "new_entity:     {'text': 'NL', 'pos': [37, 39]}\n",
            "\n",
            "original:       {'text': '(Quỳnh Cư', 'pos': [128, 137]}\n",
            "new_entity:     {'text': 'Quỳnh Cư', 'pos': [129, 137]}\n",
            "\n",
            "original:       {'text': '\\xa0Balearic', 'pos': [10, 19]}\n",
            "new_entity:     {'text': 'Balearic', 'pos': [11, 19]}\n",
            "\n",
            "original:       {'text': '(Tây Ban Nha', 'pos': [26, 38]}\n",
            "new_entity:     {'text': 'Tây Ban Nha', 'pos': [27, 38]}\n",
            "\n",
            "original:       {'text': '(phố Trích Sài', 'pos': [51, 65]}\n",
            "new_entity:     {'text': 'phố Trích Sài', 'pos': [52, 65]}\n",
            "\n",
            "original:       {'text': '(Schwarzwald', 'pos': [62, 74]}\n",
            "new_entity:     {'text': 'Schwarzwald', 'pos': [63, 74]}\n",
            "\n",
            "original:       {'text': '(phường Yên Phụ', 'pos': [67, 82]}\n",
            "new_entity:     {'text': 'phường Yên Phụ', 'pos': [68, 82]}\n",
            "\n",
            "original:       {'text': '(Sở Văn hóa - Thể thao Hà Nội', 'pos': [47, 76]}\n",
            "new_entity:     {'text': 'Sở Văn hóa - Thể thao Hà Nội', 'pos': [48, 76]}\n",
            "\n",
            "original:       {'text': '(Hòa Tiến', 'pos': [121, 130]}\n",
            "new_entity:     {'text': 'Hòa Tiến', 'pos': [122, 130]}\n",
            "\n",
            "original:       {'text': '(Nam Trực', 'pos': [51, 60]}\n",
            "new_entity:     {'text': 'Nam Trực', 'pos': [52, 60]}\n",
            "\n",
            "original:       {'text': '(Bình Thuận', 'pos': [114, 125]}\n",
            "new_entity:     {'text': 'Bình Thuận', 'pos': [115, 125]}\n",
            "\n",
            "original:       {'text': '(Phan Thiết', 'pos': [157, 168]}\n",
            "new_entity:     {'text': 'Phan Thiết', 'pos': [158, 168]}\n",
            "\n",
            "original:       {'text': '/Tiền Phong', 'pos': [15, 26]}\n",
            "new_entity:     {'text': 'Tiền Phong', 'pos': [16, 26]}\n",
            "\n",
            "original:       {'text': '“CRDC', 'pos': [0, 5]}\n",
            "new_entity:     {'text': 'CRDC', 'pos': [1, 5]}\n",
            "\n",
            "original:       {'text': '“Hoàng Sa', 'pos': [282, 291]}\n",
            "new_entity:     {'text': 'Hoàng Sa', 'pos': [283, 291]}\n",
            "\n",
            "original:       {'text': '(quần đảo Hoàng Sa', 'pos': [72, 90]}\n",
            "new_entity:     {'text': 'quần đảo Hoàng Sa', 'pos': [73, 90]}\n",
            "\n",
            "original:       {'text': '(tỉnh Quảng Ngãi', 'pos': [29, 45]}\n",
            "new_entity:     {'text': 'tỉnh Quảng Ngãi', 'pos': [30, 45]}\n",
            "\n",
            "original:       {'text': '(thôn Thanh Thủy', 'pos': [88, 104]}\n",
            "new_entity:     {'text': 'thôn Thanh Thủy', 'pos': [89, 104]}\n",
            "\n",
            "original:       {'text': '(đường Lê Văn Việt', 'pos': [126, 144]}\n",
            "new_entity:     {'text': 'đường Lê Văn Việt', 'pos': [127, 144]}\n",
            "\n",
            "original:       {'text': '(quận 9', 'pos': [90, 97]}\n",
            "new_entity:     {'text': 'quận 9', 'pos': [91, 97]}\n",
            "\n",
            "original:       {'text': '(Cẩm Thủy', 'pos': [127, 136]}\n",
            "new_entity:     {'text': 'Cẩm Thủy', 'pos': [128, 136]}\n",
            "\n",
            "original:       {'text': '(Phú Yên', 'pos': [12, 20]}\n",
            "new_entity:     {'text': 'Phú Yên', 'pos': [13, 20]}\n",
            "\n",
            "original:       {'text': '(Bình Định', 'pos': [15, 25]}\n",
            "new_entity:     {'text': 'Bình Định', 'pos': [16, 25]}\n",
            "\n",
            "original:       {'text': '“Tổng cục Du lịch VN', 'pos': [138, 158]}\n",
            "new_entity:     {'text': 'Tổng cục Du lịch VN', 'pos': [139, 158]}\n",
            "\n",
            "original:       {'text': '(quận Hoàn Kiếm', 'pos': [87, 102]}\n",
            "new_entity:     {'text': 'quận Hoàn Kiếm', 'pos': [88, 102]}\n",
            "\n",
            "original:       {'text': '(Quận Thủ Đức', 'pos': [151, 164]}\n",
            "new_entity:     {'text': 'Quận Thủ Đức', 'pos': [152, 164]}\n",
            "\n",
            "original:       {'text': \"'Hoàng Sa\", 'pos': [39, 48]}\n",
            "new_entity:     {'text': 'Hoàng Sa', 'pos': [40, 48]}\n",
            "\n",
            "original:       {'text': '(An Dương', 'pos': [195, 204]}\n",
            "new_entity:     {'text': 'An Dương', 'pos': [196, 204]}\n",
            "\n",
            "original:       {'text': '(Ninh Bình', 'pos': [207, 217]}\n",
            "new_entity:     {'text': 'Ninh Bình', 'pos': [208, 217]}\n",
            "\n",
            "original:       {'text': '(60 Hồ Hảo Hớn', 'pos': [26, 40]}\n",
            "new_entity:     {'text': '60 Hồ Hảo Hớn', 'pos': [27, 40]}\n",
            "\n",
            "original:       {'text': '(40 đường 30', 'pos': [24, 36]}\n",
            "new_entity:     {'text': '40 đường 30', 'pos': [25, 36]}\n",
            "\n",
            "original:       {'text': '(P.4', 'pos': [22, 26]}\n",
            "new_entity:     {'text': 'P.4', 'pos': [23, 26]}\n",
            "\n",
            "original:       {'text': '(Q.3', 'pos': [22, 26]}\n",
            "new_entity:     {'text': 'Q.3', 'pos': [23, 26]}\n",
            "\n",
            "original:       {'text': '(P.Cầu Ông Lãnh', 'pos': [32, 47]}\n",
            "new_entity:     {'text': 'P.Cầu Ông Lãnh', 'pos': [33, 47]}\n",
            "\n",
            "original:       {'text': '(202 Nguyễn Thiện Thuật', 'pos': [28, 51]}\n",
            "new_entity:     {'text': '202 Nguyễn Thiện Thuật', 'pos': [29, 51]}\n",
            "\n",
            "original:       {'text': '(369/25/28 Lý Thái Tổ', 'pos': [30, 51]}\n",
            "new_entity:     {'text': '369/25/28 Lý Thái Tổ', 'pos': [31, 51]}\n",
            "\n",
            "original:       {'text': '(Q.4', 'pos': [32, 36]}\n",
            "new_entity:     {'text': 'Q.4', 'pos': [33, 36]}\n",
            "\n",
            "original:       {'text': '(Q.8', 'pos': [36, 40]}\n",
            "new_entity:     {'text': 'Q.8', 'pos': [37, 40]}\n",
            "\n",
            "original:       {'text': '(96 Camette', 'pos': [26, 37]}\n",
            "new_entity:     {'text': '96 Camette', 'pos': [27, 37]}\n",
            "\n",
            "original:       {'text': '(Q.12', 'pos': [22, 27]}\n",
            "new_entity:     {'text': 'Q.12', 'pos': [23, 27]}\n",
            "\n",
            "original:       {'text': '(26/20/4 Đinh Tiên Hoàng', 'pos': [24, 48]}\n",
            "new_entity:     {'text': '26/20/4 Đinh Tiên Hoàng', 'pos': [25, 48]}\n",
            "\n",
            "original:       {'text': '(413/36 Lê Văn Sỹ', 'pos': [24, 41]}\n",
            "new_entity:     {'text': '413/36 Lê Văn Sỹ', 'pos': [25, 41]}\n",
            "\n",
            "original:       {'text': '(307 Nguyễn Văn Trỗi', 'pos': [24, 44]}\n",
            "new_entity:     {'text': '307 Nguyễn Văn Trỗi', 'pos': [25, 44]}\n",
            "\n",
            "original:       {'text': '(162 Nguyễn Công Trứ', 'pos': [36, 56]}\n",
            "new_entity:     {'text': '162 Nguyễn Công Trứ', 'pos': [37, 56]}\n",
            "\n",
            "original:       {'text': '(448/15 Lê Văn Sỹ', 'pos': [28, 45]}\n",
            "new_entity:     {'text': '448/15 Lê Văn Sỹ', 'pos': [29, 45]}\n",
            "\n",
            "original:       {'text': '(38 Bà Hom', 'pos': [31, 41]}\n",
            "new_entity:     {'text': '38 Bà Hom', 'pos': [32, 41]}\n",
            "\n",
            "original:       {'text': '(Q.Bình Thạnh', 'pos': [24, 37]}\n",
            "new_entity:     {'text': 'Q.Bình Thạnh', 'pos': [25, 37]}\n",
            "\n",
            "original:       {'text': '(302/3/11 Lê Đình Cẩn', 'pos': [28, 49]}\n",
            "new_entity:     {'text': '302/3/11 Lê Đình Cẩn', 'pos': [29, 49]}\n",
            "\n",
            "original:       {'text': '(116/877B Nguyễn Kiệm', 'pos': [29, 50]}\n",
            "new_entity:     {'text': '116/877B Nguyễn Kiệm', 'pos': [30, 50]}\n",
            "\n",
            "original:       {'text': '(489/57/11 Huỳnh Văn Bánh', 'pos': [34, 59]}\n",
            "new_entity:     {'text': '489/57/11 Huỳnh Văn Bánh', 'pos': [35, 59]}\n",
            "\n",
            "original:       {'text': '(16 Trần Quang Khải', 'pos': [24, 43]}\n",
            "new_entity:     {'text': '16 Trần Quang Khải', 'pos': [25, 43]}\n",
            "\n",
            "original:       {'text': '(803/23A Huỳnh Tấn Phát', 'pos': [24, 47]}\n",
            "new_entity:     {'text': '803/23A Huỳnh Tấn Phát', 'pos': [25, 47]}\n",
            "\n",
            "original:       {'text': '(Q.Bình Tân', 'pos': [24, 35]}\n",
            "new_entity:     {'text': 'Q.Bình Tân', 'pos': [25, 35]}\n",
            "\n",
            "original:       {'text': '(41 Lê Hồng Phong', 'pos': [31, 48]}\n",
            "new_entity:     {'text': '41 Lê Hồng Phong', 'pos': [32, 48]}\n",
            "\n",
            "original:       {'text': '(266 Nguyễn Đình Chiểu', 'pos': [28, 50]}\n",
            "new_entity:     {'text': '266 Nguyễn Đình Chiểu', 'pos': [29, 50]}\n",
            "\n",
            "original:       {'text': '(P.7', 'pos': [26, 30]}\n",
            "new_entity:     {'text': 'P.7', 'pos': [27, 30]}\n",
            "\n",
            "original:       {'text': '(6 Đặng Tất', 'pos': [36, 47]}\n",
            "new_entity:     {'text': '6 Đặng Tất', 'pos': [37, 47]}\n",
            "\n",
            "original:       {'text': '(481 Hai Bà Trưng', 'pos': [24, 41]}\n",
            "new_entity:     {'text': '481 Hai Bà Trưng', 'pos': [25, 41]}\n",
            "\n",
            "original:       {'text': '(P.1', 'pos': [24, 28]}\n",
            "new_entity:     {'text': 'P.1', 'pos': [25, 28]}\n",
            "\n",
            "original:       {'text': '(6C2 Đinh Bộ Lĩnh', 'pos': [28, 45]}\n",
            "new_entity:     {'text': '6C2 Đinh Bộ Lĩnh', 'pos': [29, 45]}\n",
            "\n",
            "original:       {'text': '(P.Bến Thành', 'pos': [30, 42]}\n",
            "new_entity:     {'text': 'P.Bến Thành', 'pos': [31, 42]}\n",
            "\n",
            "original:       {'text': '(1901G ấp Bến Nôm', 'pos': [32, 49]}\n",
            "new_entity:     {'text': '1901G ấp Bến Nôm', 'pos': [33, 49]}\n",
            "\n",
            "original:       {'text': '(Q.10', 'pos': [30, 35]}\n",
            "new_entity:     {'text': 'Q.10', 'pos': [31, 35]}\n",
            "\n",
            "original:       {'text': '(Đinh Tiên Hoàng', 'pos': [46, 62]}\n",
            "new_entity:     {'text': 'Đinh Tiên Hoàng', 'pos': [47, 62]}\n",
            "\n",
            "original:       {'text': '(P.Tan Thuan Dong', 'pos': [37, 54]}\n",
            "new_entity:     {'text': 'P.Tan Thuan Dong', 'pos': [38, 54]}\n",
            "\n",
            "original:       {'text': '(331 Phan Dinh Phung', 'pos': [40, 60]}\n",
            "new_entity:     {'text': '331 Phan Dinh Phung', 'pos': [41, 60]}\n",
            "\n",
            "original:       {'text': '(Cafe 90', 'pos': [33, 41]}\n",
            "new_entity:     {'text': 'Cafe 90', 'pos': [34, 41]}\n",
            "\n",
            "original:       {'text': '(tỉnh Đồng Tháp', 'pos': [88, 103]}\n",
            "new_entity:     {'text': 'tỉnh Đồng Tháp', 'pos': [89, 103]}\n",
            "\n",
            "original:       {'text': '(huyện Nga Sơn', 'pos': [34, 48]}\n",
            "new_entity:     {'text': 'huyện Nga Sơn', 'pos': [35, 48]}\n",
            "\n",
            "original:       {'text': '(xã Tà Rụt', 'pos': [146, 156]}\n",
            "new_entity:     {'text': 'xã Tà Rụt', 'pos': [147, 156]}\n",
            "\n",
            "original:       {'text': '(UNESCO', 'pos': [142, 149]}\n",
            "new_entity:     {'text': 'UNESCO', 'pos': [143, 149]}\n",
            "\n",
            "original:       {'text': '(Yên Bái', 'pos': [145, 153]}\n",
            "new_entity:     {'text': 'Yên Bái', 'pos': [146, 153]}\n",
            "\n",
            "original:       {'text': '(Lào Cai', 'pos': [103, 111]}\n",
            "new_entity:     {'text': 'Lào Cai', 'pos': [104, 111]}\n",
            "\n",
            "original:       {'text': '(ASEAN FLE', 'pos': [145, 155]}\n",
            "new_entity:     {'text': 'ASEAN FLE', 'pos': [146, 155]}\n",
            "\n",
            "original:       {'text': '(Australia', 'pos': [165, 175]}\n",
            "new_entity:     {'text': 'Australia', 'pos': [166, 175]}\n",
            "\n",
            "original:       {'text': '(LAVISA', 'pos': [121, 128]}\n",
            "new_entity:     {'text': 'LAVISA', 'pos': [122, 128]}\n",
            "\n",
            "original:       {'text': '(WUR', 'pos': [111, 115]}\n",
            "new_entity:     {'text': 'WUR', 'pos': [112, 115]}\n",
            "\n",
            "original:       {'text': '-Thời Đại', 'pos': [14, 23]}\n",
            "new_entity:     {'text': 'Thời Đại', 'pos': [15, 23]}\n",
            "\n",
            "original:       {'text': '(quận 1', 'pos': [114, 121]}\n",
            "new_entity:     {'text': 'quận 1', 'pos': [115, 121]}\n",
            "\n",
            "original:       {'text': '(Bộ GD&ĐT', 'pos': [56, 65]}\n",
            "new_entity:     {'text': 'Bộ GD&ĐT', 'pos': [57, 65]}\n",
            "\n",
            "original:       {'text': '(TP.Cam Ranh', 'pos': [64, 76]}\n",
            "new_entity:     {'text': 'TP.Cam Ranh', 'pos': [65, 76]}\n",
            "\n",
            "original:       {'text': '/VTC News', 'pos': [13, 22]}\n",
            "new_entity:     {'text': 'VTC News', 'pos': [14, 22]}\n",
            "\n",
            "original:       {'text': '(Phú Vang', 'pos': [115, 124]}\n",
            "new_entity:     {'text': 'Phú Vang', 'pos': [116, 124]}\n",
            "\n",
            "original:       {'text': '(thị xã Hương Trà', 'pos': [24, 41]}\n",
            "new_entity:     {'text': 'thị xã Hương Trà', 'pos': [25, 41]}\n",
            "\n",
            "original:       {'text': '-TT Huế', 'pos': [42, 49]}\n",
            "new_entity:     {'text': 'TT Huế', 'pos': [43, 49]}\n",
            "\n",
            "original:       {'text': '-Tứ Hạ', 'pos': [38, 44]}\n",
            "new_entity:     {'text': 'Tứ Hạ', 'pos': [39, 44]}\n",
            "\n",
            "original:       {'text': '-TX Hương Trà', 'pos': [45, 58]}\n",
            "new_entity:     {'text': 'TX Hương Trà', 'pos': [46, 58]}\n",
            "\n",
            "original:       {'text': '(TP. Hồ Chí Minh', 'pos': [29, 45]}\n",
            "new_entity:     {'text': 'TP. Hồ Chí Minh', 'pos': [30, 45]}\n",
            "\n",
            "original:       {'text': '(H. Phong Điền', 'pos': [37, 51]}\n",
            "new_entity:     {'text': 'H. Phong Điền', 'pos': [38, 51]}\n",
            "\n",
            "original:       {'text': '(trường mầm non Sơn Ca', 'pos': [37, 59]}\n",
            "new_entity:     {'text': 'trường mầm non Sơn Ca', 'pos': [38, 59]}\n",
            "\n",
            "original:       {'text': '(TP. Huế', 'pos': [30, 38]}\n",
            "new_entity:     {'text': 'TP. Huế', 'pos': [31, 38]}\n",
            "\n",
            "original:       {'text': '(Trường Đại học Nông Lâm Huế', 'pos': [270, 298]}\n",
            "new_entity:     {'text': 'Trường Đại học Nông Lâm Huế', 'pos': [271, 298]}\n",
            "\n",
            "original:       {'text': '(Viettel', 'pos': [185, 193]}\n",
            "new_entity:     {'text': 'Viettel', 'pos': [186, 193]}\n",
            "\n",
            "original:       {'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi ”', 'pos': [120, 179]}\n",
            "new_entity:     {'text': 'Câu lạc bộ (CLB) thiện nguyện “Về với quê mình Quảng Ngãi', 'pos': [120, 177]}\n",
            "\n",
            "original:       {'text': 'CLB “Về với quê mình Quảng Ngãi ”', 'pos': [63, 96]}\n",
            "new_entity:     {'text': 'CLB “Về với quê mình Quảng Ngãi', 'pos': [63, 94]}\n",
            "\n",
            "original:       {'text': '(Công an tỉnh Hà Tĩnh', 'pos': [119, 140]}\n",
            "new_entity:     {'text': 'Công an tỉnh Hà Tĩnh', 'pos': [120, 140]}\n",
            "\n",
            "original:       {'text': '(xã Phú An', 'pos': [107, 117]}\n",
            "new_entity:     {'text': 'xã Phú An', 'pos': [108, 117]}\n",
            "\n",
            "original:       {'text': '(Thừa Thiên- Huế', 'pos': [195, 211]}\n",
            "new_entity:     {'text': 'Thừa Thiên- Huế', 'pos': [196, 211]}\n",
            "\n",
            "original:       {'text': '(Kan Clinic', 'pos': [66, 77]}\n",
            "new_entity:     {'text': 'Kan Clinic', 'pos': [67, 77]}\n",
            "\n",
            "original:       {'text': '\"Intel', 'pos': [0, 6]}\n",
            "new_entity:     {'text': 'Intel', 'pos': [1, 6]}\n",
            "\n",
            "original:       {'text': '(JAMA', 'pos': [40, 45]}\n",
            "new_entity:     {'text': 'JAMA', 'pos': [41, 45]}\n",
            "\n",
            "original:       {'text': '(Canada', 'pos': [58, 65]}\n",
            "new_entity:     {'text': 'Canada', 'pos': [59, 65]}\n",
            "\n",
            "original:       {'text': '(Ba Đình', 'pos': [15, 23]}\n",
            "new_entity:     {'text': 'Ba Đình', 'pos': [16, 23]}\n",
            "\n",
            "original:       {'text': '(Tổng cục Du lịch', 'pos': [61, 78]}\n",
            "new_entity:     {'text': 'Tổng cục Du lịch', 'pos': [62, 78]}\n",
            "\n",
            "original:       {'text': '(Bình Dương', 'pos': [104, 115]}\n",
            "new_entity:     {'text': 'Bình Dương', 'pos': [105, 115]}\n",
            "\n",
            "original:       {'text': '(Hải Phòng', 'pos': [192, 202]}\n",
            "new_entity:     {'text': 'Hải Phòng', 'pos': [193, 202]}\n",
            "\n",
            "original:       {'text': '(Q. Thủ Đức', 'pos': [429, 440]}\n",
            "new_entity:     {'text': 'Q. Thủ Đức', 'pos': [430, 440]}\n",
            "\n",
            "original:       {'text': '(ENV', 'pos': [163, 167]}\n",
            "new_entity:     {'text': 'ENV', 'pos': [164, 167]}\n",
            "\n",
            "original:       {'text': '(ENV Nghệ An', 'pos': [135, 147]}\n",
            "new_entity:     {'text': 'ENV Nghệ An', 'pos': [136, 147]}\n",
            "\n",
            "original:       {'text': '(Gothenburg', 'pos': [117, 128]}\n",
            "new_entity:     {'text': 'Gothenburg', 'pos': [118, 128]}\n",
            "\n",
            "original:       {'text': '(Na Uy', 'pos': [73, 79]}\n",
            "new_entity:     {'text': 'Na Uy', 'pos': [74, 79]}\n",
            "\n",
            "original:       {'text': '(LTA', 'pos': [52, 56]}\n",
            "new_entity:     {'text': 'LTA', 'pos': [53, 56]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F2EbtGIhZY_"
      },
      "source": [
        "## Clean dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF7krGOHhZY_"
      },
      "source": [
        "### Normalize dev data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUyGGJYyhZY_"
      },
      "source": [
        "#### check overlap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9uqIffhZY_"
      },
      "source": [
        "CHÚ Ý: Cần review data để xem có xảy ra overlap entity không vì code find_nth bên dưới dùng là cho không overlap.\n",
        "\n",
        "Ví dụ: overlap: ACACA\n",
        "\n",
        "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string\n",
        "\n",
        "https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKRfSSVehZZA",
        "outputId": "3b516ca4-53fd-4aa7-89fd-d6c6c6489a95"
      },
      "source": [
        "tmpppsent = []\n",
        "counttt = 0\n",
        "\n",
        "for sentif in jdev_data:\n",
        "\n",
        "    if (sentif['sentence'] != unicodedata.normalize(\"NFC\", sentif['sentence'])):\n",
        "        counttt += 1\n",
        "\n",
        "        if (sentif['sentence'] not in tmpppsent):\n",
        "            print(sentif['sent_id'])\n",
        "            print(sentif['sentence'])\n",
        "            tmpppsent.append(sentif['sentence'])\n",
        "\n",
        "print(counttt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8405\n",
            "Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n",
            "8406\n",
            "Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "8424\n",
            "Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "8428\n",
            "Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYqWH67fhZZD"
      },
      "source": [
        "#### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvV6M2rhZZD",
        "outputId": "b6c2d904-1f7f-4b8d-ba03-b52baae5dcc7"
      },
      "source": [
        "jdev_data_v1 = copy.deepcopy(normalize_sentif(jdev_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-----  1  - sent_id:  8405\n",
            "Original sent:    Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n",
            "Normalized sent:  Người hâm mộ được khám phá chuyến hành trình trở về năm 1873 khi Heineken bắt đầu hành trình chinh phục thế giới với hương vị hoàn hảo, đồng thời du hành đến 192 quốc gia nơi Heineken được triệu triệu tín đồ yêu thích.\n",
            "Previous entity 1:    {'text': 'Heineken', 'pos': [66, 74]}\n",
            "Normalized entity 1:  {'text': 'Heineken', 'pos': [65, 73]}\n",
            "Previous entity 2:    {'text': 'Heineken', 'pos': [176, 184]}\n",
            "Normalized entity 2:  {'text': 'Heineken', 'pos': [175, 183]}\n",
            "\n",
            "\n",
            "-----  2  - sent_id:  8406\n",
            "Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Previous entity 1:    {'text': 'Heineken', 'pos': [111, 119]}\n",
            "Normalized entity 1:  {'text': 'Heineken', 'pos': [104, 112]}\n",
            "Previous entity 2:    {'text': 'Willem vans Waesberghe', 'pos': [126, 148]}\n",
            "Normalized entity 2:  {'text': 'Willem vans Waesberghe', 'pos': [119, 141]}\n",
            "\n",
            "\n",
            "-----  3  - sent_id:  8407\n",
            "Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Previous entity 1:    {'text': 'Heineken', 'pos': [111, 119]}\n",
            "Normalized entity 1:  {'text': 'Heineken', 'pos': [104, 112]}\n",
            "Previous entity 2:    {'text': 'Victor Vũ', 'pos': [182, 191]}\n",
            "Normalized entity 2:  {'text': 'Victor Vũ', 'pos': [174, 183]}\n",
            "\n",
            "\n",
            "-----  4  - sent_id:  8408\n",
            "Original sent:    Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Normalized sent:  Điểm nhấn đặc biệt trong chiến dịch lần này là sự có mặt lần đầu tiên của chuyên gia ủ bia toàn cầu của Heineken - ông Willem vans Waesberghe trong cuộc gặp gỡ cùng đạo diễn Victor Vũ trước ống kính máy quay.\n",
            "Previous entity 1:    {'text': 'Willem vans Waesberghe', 'pos': [126, 148]}\n",
            "Normalized entity 1:  {'text': 'Willem vans Waesberghe', 'pos': [119, 141]}\n",
            "Previous entity 2:    {'text': 'Victor Vũ', 'pos': [182, 191]}\n",
            "Normalized entity 2:  {'text': 'Victor Vũ', 'pos': [174, 183]}\n",
            "\n",
            "\n",
            "-----  5  - sent_id:  8424\n",
            "Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Previous entity 1:    {'text': 'Victor Vũ', 'pos': [0, 9]}\n",
            "Normalized entity 1:  {'text': 'Victor Vũ', 'pos': [0, 9]}\n",
            "Previous entity 2:    {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n",
            "Normalized entity 2:  {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n",
            "\n",
            "\n",
            "-----  6  - sent_id:  8425\n",
            "Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Previous entity 1:    {'text': 'Victor Vũ', 'pos': [0, 9]}\n",
            "Normalized entity 1:  {'text': 'Victor Vũ', 'pos': [0, 9]}\n",
            "Previous entity 2:    {'text': 'Heineken', 'pos': [266, 274]}\n",
            "Normalized entity 2:  {'text': 'Heineken', 'pos': [265, 273]}\n",
            "\n",
            "\n",
            "-----  7  - sent_id:  8426\n",
            "Original sent:    Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Normalized sent:  Victor Vũ và Willem van Waesberghe như hai đại diện tiêu biểu luôn vươn đến sự hoàn hảo trong điện ảnh cũng như nghệ thuật ủ bia, sẽ dẫn dắt người hâm mộ đến với những câu chuyện đầy cảm hứng về nghệ thuật và những tinh hoa đằng sau hương vị bia thượng hạng đến từ Heineken .\n",
            "Previous entity 1:    {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n",
            "Normalized entity 1:  {'text': 'Willem van Waesberghe', 'pos': [13, 34]}\n",
            "Previous entity 2:    {'text': 'Heineken', 'pos': [266, 274]}\n",
            "Normalized entity 2:  {'text': 'Heineken', 'pos': [265, 273]}\n",
            "\n",
            "\n",
            "-----  8  - sent_id:  8428\n",
            "Original sent:    Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n",
            "Normalized sent:  Heineken luôn cam kết đem đến những trải nghiệm đỉnh cao, đẳng cấp nhằm kết nối mọi cuộc vui và mang đến những khoảnh khắc tuyệt vời nhất cho người tiêu dùng Việt Nam và sứ mệnh đó tiếp tục được khẳng định thông qua những câu chuyện được kể đầy cảm hứng này.\n",
            "Previous entity 1:    {'text': 'Heineken', 'pos': [0, 8]}\n",
            "Normalized entity 1:  {'text': 'Heineken', 'pos': [0, 8]}\n",
            "Previous entity 2:    {'text': 'Việt Nam', 'pos': [158, 166]}\n",
            "Normalized entity 2:  {'text': 'Việt Nam', 'pos': [158, 166]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibDYFDo5hZZE"
      },
      "source": [
        "### fix start end of entity in dev data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVKO5QHZhZZE"
      },
      "source": [
        "jdev_data_use = copy.deepcopy(jdev_data_v1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJJS0PLthZZE"
      },
      "source": [
        "#### Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du2XIqDChZZE",
        "outputId": "3c7fc6da-db64-4df4-8a2c-a42056ca104d"
      },
      "source": [
        "tmpppsent = []\n",
        "allchar_lst = []\n",
        "alnum_char_lst = []\n",
        "not_alnum_char_lst = []\n",
        "\n",
        "for sentif in jdev_data_use:\n",
        "    if sentif['sentence'] not in tmpppsent:\n",
        "        for ch in sentif['sentence']:\n",
        "            if ch not in allchar_lst:\n",
        "                allchar_lst.append(ch)\n",
        "\n",
        "            if ch.isalnum() and (ch not in alnum_char_lst):\n",
        "                alnum_char_lst.append(ch)\n",
        "\n",
        "            if (not ch.isalnum()) and (ch not in not_alnum_char_lst):\n",
        "                not_alnum_char_lst.append(ch)\n",
        "              \n",
        "        tmpppsent.append(sentif['sentence'])\n",
        "\n",
        "\n",
        "print(len(allchar_lst))\n",
        "for i in range(0, len(allchar_lst), 30):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 30, len(allchar_lst) + 1)\n",
        "\n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(allchar_lst[i:end])))\n",
        "\n",
        "\n",
        "print('\\n', len(alnum_char_lst))\n",
        "for i in range(0, len(alnum_char_lst), 20):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 20, len(alnum_char_lst) + 1)\n",
        "\n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(alnum_char_lst[i:end])))\n",
        "\n",
        "\n",
        "print('\\n', len(not_alnum_char_lst))\n",
        "for i in range(0, len(not_alnum_char_lst), 20):\n",
        "    # Limit the end index so we don't go past the end of the list.\n",
        "    end = min(i + 20, len(not_alnum_char_lst) + 1)\n",
        "    \n",
        "    # Print out the tokens, separated by a space.\n",
        "    print(repr(' '.join(not_alnum_char_lst[i:end])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184\n",
            "\"U 1 6   V i ệ t N a m d ộ ' ư g ô n v à o l ớ M C ổ K h ằ ự\"\n",
            "'đ á , ã c ó ế ắ ễ r . ậ y ạ b ả I ò â u Á 2 0 8 A s ể T q ặ'\n",
            "'p ù ị ỡ - ấ ờ ở ú ẫ ơ x 5 B ứ ủ ầ ý ề 4 / 9 ố ọ k ă ợ ê H 3'\n",
            "'( 7 ) ỷ ừ ỗ ữ ụ é S L ũ ồ ẽ õ R í ì Đ ‘ ’ e ẻ ỏ z G Z J “ ”'\n",
            "'ỉ D P | : O % ử – \" ẳ Q Ô ỹ ĩ ẩ \\xa0 X ? \\u200b ẵ ỳ Ả f E W F w Â ẹ'\n",
            "'ỵ + j ; … & Ủ Y \\ufeff Ă Ð * è Ư ! Ấ Ở Ú Í Ó Ồ Ý Ệ ± ~ Ẩ • ö ü ́'\n",
            "'̉ ̣ ̀ Ì'\n",
            "\n",
            " 150\n",
            "'U 1 6 V i ệ t N a m d ộ ư g ô n v à o l'\n",
            "'ớ M C ổ K h ằ ự đ á ã c ó ế ắ ễ r ậ y ạ'\n",
            "'b ả I ò â u Á 2 0 8 A s ể T q ặ p ù ị ỡ'\n",
            "'ấ ờ ở ú ẫ ơ x 5 B ứ ủ ầ ý ề 4 9 ố ọ k ă'\n",
            "'ợ ê H 3 7 ỷ ừ ỗ ữ ụ é S L ũ ồ ẽ õ R í ì'\n",
            "'Đ e ẻ ỏ z G Z J ỉ D P O ử ẳ Q Ô ỹ ĩ ẩ X'\n",
            "'ẵ ỳ Ả f E W F w Â ẹ ỵ j Ủ Y Ă Ð è Ư Ấ Ở'\n",
            "'Ú Í Ó Ồ Ý Ệ Ẩ ö ü Ì'\n",
            "\n",
            " 34\n",
            "'  \\' , . - / ( ) ‘ ’ “ ” | : % – \" \\xa0 ? \\u200b'\n",
            "'+ ; … & \\ufeff * ! ± ~ • ́ ̉ ̣ ̀'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jMWWYbkhZZE",
        "outputId": "f81fb7f4-1fd2-4d16-d994-bfbd384c873e"
      },
      "source": [
        "# review data\n",
        "# có vẻ là nếu trong entity có kí tự bắt đầu hoặc kết thúc là số thì k phải lỗi.\n",
        "\n",
        "for sentif in jdev_data_use:\n",
        "    if (sentif['entity_1']['text'][0].isnumeric()) or (sentif['entity_1']['text'][-1].isnumeric()):\n",
        "        print(sentif['entity_1'])\n",
        "\n",
        "    if (sentif['entity_2']['text'][0].isnumeric()) or (sentif['entity_2']['text'][-1].isnumeric()):\n",
        "        print(sentif['entity_2'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'nhóm G7', 'pos': [33, 40]}\n",
            "{'text': 'nhóm G7', 'pos': [33, 40]}\n",
            "{'text': 'PC67', 'pos': [21, 25]}\n",
            "{'text': 'PC67', 'pos': [57, 61]}\n",
            "{'text': 'PC67', 'pos': [177, 181]}\n",
            "{'text': 'PC67', 'pos': [37, 41]}\n",
            "{'text': 'PC67', 'pos': [82, 86]}\n",
            "{'text': 'quận 1', 'pos': [85, 91]}\n",
            "{'text': 'quận 1', 'pos': [85, 91]}\n",
            "{'text': 'quận 1', 'pos': [85, 91]}\n",
            "{'text': 'quận 1', 'pos': [110, 116]}\n",
            "{'text': 'quận 1', 'pos': [110, 116]}\n",
            "{'text': 'quận 1', 'pos': [110, 116]}\n",
            "{'text': 'quận 1', 'pos': [110, 116]}\n",
            "{'text': 'Bệnh viện Quân y 175', 'pos': [87, 107]}\n",
            "{'text': 'Bệnh viện Quân y 175', 'pos': [87, 107]}\n",
            "{'text': 'BV Quân y 175', 'pos': [161, 174]}\n",
            "{'text': 'BV Quân y 175', 'pos': [161, 174]}\n",
            "{'text': 'Bệnh viện Quân y 175', 'pos': [34, 54]}\n",
            "{'text': '(Quận 3', 'pos': [58, 65]}\n",
            "{'text': '(Quận 3', 'pos': [58, 65]}\n",
            "{'text': '(Quận 3', 'pos': [58, 65]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 7', 'pos': [226, 232]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': 'thôn 5', 'pos': [65, 71]}\n",
            "{'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "{'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "{'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "{'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "{'text': 'ngõ 16', 'pos': [34, 40]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n",
            "{'text': 'ngõ 16', 'pos': [34, 40]}\n",
            "{'text': 'ngõ 16', 'pos': [34, 40]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [43, 61]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'Ngõ 16', 'pos': [123, 129]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'tổ dân phố Hà Vị 2', 'pos': [132, 150]}\n",
            "{'text': 'PC67', 'pos': [72, 76]}\n",
            "{'text': 'PC67', 'pos': [72, 76]}\n",
            "{'text': 'PC67', 'pos': [8, 12]}\n",
            "{'text': 'PC 67', 'pos': [13, 18]}\n",
            "{'text': 'Phường 1', 'pos': [0, 8]}\n",
            "{'text': '(quận 10', 'pos': [9, 17]}\n",
            "{'text': 'Phường 1', 'pos': [0, 8]}\n",
            "{'text': '(quận 10', 'pos': [9, 17]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': 'phường 1', 'pos': [135, 143]}\n",
            "{'text': 'quận 10', 'pos': [146, 153]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': 'phường 1', 'pos': [135, 143]}\n",
            "{'text': 'quận 10', 'pos': [146, 153]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': 'phường 1', 'pos': [135, 143]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': 'quận 10', 'pos': [146, 153]}\n",
            "{'text': 'phường 1', 'pos': [135, 143]}\n",
            "{'text': 'quận 10', 'pos': [146, 153]}\n",
            "{'text': 'phường 1', 'pos': [135, 143]}\n",
            "{'text': 'quận 10', 'pos': [146, 153]}\n",
            "{'text': '(quận 10', 'pos': [24, 32]}\n",
            "{'text': '(quận 10', 'pos': [24, 32]}\n",
            "{'text': '(quận 10', 'pos': [24, 32]}\n",
            "{'text': '223 Trích Sài', 'pos': [65, 78]}\n",
            "{'text': '223 Trích Sài', 'pos': [65, 78]}\n",
            "{'text': 'khối 5', 'pos': [64, 70]}\n",
            "{'text': 'khối 5', 'pos': [64, 70]}\n",
            "{'text': 'khối 5', 'pos': [64, 70]}\n",
            "{'text': 'khối 5', 'pos': [63, 69]}\n",
            "{'text': 'khối 5', 'pos': [63, 69]}\n",
            "{'text': 'khối 5', 'pos': [63, 69]}\n",
            "{'text': 'khối 5', 'pos': [63, 69]}\n",
            "{'text': 'quận 12', 'pos': [88, 95]}\n",
            "{'text': 'quận 12', 'pos': [88, 95]}\n",
            "{'text': 'quận 12', 'pos': [88, 95]}\n",
            "{'text': 'quận 12', 'pos': [88, 95]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': 'thôn 3', 'pos': [296, 302]}\n",
            "{'text': '(phường 10', 'pos': [69, 79]}\n",
            "{'text': '(phường 10', 'pos': [69, 79]}\n",
            "{'text': '(phường 10', 'pos': [69, 79]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'xóm 2', 'pos': [150, 155]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 7', 'pos': [30, 57]}\n",
            "{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n",
            "{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n",
            "{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n",
            "{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n",
            "{'text': 'Đội Quản lý thị trường số 4', 'pos': [218, 245]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'P.12', 'pos': [123, 127]}\n",
            "{'text': 'Q.10', 'pos': [130, 134]}\n",
            "{'text': 'Công an quận 3', 'pos': [45, 59]}\n",
            "{'text': 'Công an quận 3', 'pos': [45, 59]}\n",
            "{'text': 'Công an quận 3', 'pos': [45, 59]}\n",
            "{'text': 'phường 3', 'pos': [133, 141]}\n",
            "{'text': 'quận 3', 'pos': [144, 150]}\n",
            "{'text': 'phường 3', 'pos': [133, 141]}\n",
            "{'text': 'quận 3', 'pos': [144, 150]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': 'PC45', 'pos': [113, 117]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [84, 88]}\n",
            "{'text': 'PC45', 'pos': [17, 21]}\n",
            "{'text': 'PC45', 'pos': [17, 21]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'đường Vành đai 3', 'pos': [192, 208]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': '4Minute', 'pos': [176, 183]}\n",
            "{'text': '4Minute', 'pos': [176, 183]}\n",
            "{'text': '4Minute', 'pos': [176, 183]}\n",
            "{'text': '4Minute', 'pos': [176, 183]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [117, 130]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [32, 45]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [32, 45]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [28, 41]}\n",
            "{'text': 'Đội CSGT số 2', 'pos': [41, 54]}\n",
            "{'text': 'phường 8', 'pos': [131, 139]}\n",
            "{'text': 'phường 8', 'pos': [131, 139]}\n",
            "{'text': 'phường 8', 'pos': [131, 139]}\n",
            "{'text': 'Cảnh sát 113', 'pos': [18, 30]}\n",
            "{'text': 'Cảnh sát 113', 'pos': [18, 30]}\n",
            "{'text': 'G7', 'pos': [73, 75]}\n",
            "{'text': 'G7', 'pos': [73, 75]}\n",
            "{'text': 'G7', 'pos': [73, 75]}\n",
            "{'text': 'G7', 'pos': [73, 75]}\n",
            "{'text': '2017 SQ2', 'pos': [111, 119]}\n",
            "{'text': '2017 SM2', 'pos': [122, 130]}\n",
            "{'text': '2017 SR2', 'pos': [134, 142]}\n",
            "{'text': '2017 SQ2', 'pos': [111, 119]}\n",
            "{'text': '2017 SM2', 'pos': [122, 130]}\n",
            "{'text': '2017 SQ2', 'pos': [111, 119]}\n",
            "{'text': '2017 SR2', 'pos': [134, 142]}\n",
            "{'text': '2017 SM2', 'pos': [122, 130]}\n",
            "{'text': '2017 SR2', 'pos': [134, 142]}\n",
            "{'text': '2017 SQ2', 'pos': [15, 23]}\n",
            "{'text': '2017 SQ2', 'pos': [15, 23]}\n",
            "{'text': '2017 SM2', 'pos': [30, 38]}\n",
            "{'text': '2017 SR2', 'pos': [42, 50]}\n",
            "{'text': '2017 SM2', 'pos': [30, 38]}\n",
            "{'text': '2017 SR2', 'pos': [42, 50]}\n",
            "{'text': '2017 SR2', 'pos': [46, 54]}\n",
            "{'text': 'tiểu khu 556', 'pos': [92, 104]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'thôn 3', 'pos': [278, 284]}\n",
            "{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n",
            "{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n",
            "{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n",
            "{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n",
            "{'text': 'CR7', 'pos': [21, 24]}\n",
            "{'text': 'CR7', 'pos': [21, 24]}\n",
            "{'text': 'sân Bet365', 'pos': [52, 62]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [173, 188]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [281, 296]}\n",
            "{'text': 'đội 6', 'pos': [51, 56]}\n",
            "{'text': 'đội 6', 'pos': [51, 56]}\n",
            "{'text': 'đội 6', 'pos': [51, 56]}\n",
            "{'text': 'đội 6', 'pos': [51, 56]}\n",
            "{'text': 'đội 6', 'pos': [51, 56]}\n",
            "{'text': 'đội CSGT số 2', 'pos': [30, 43]}\n",
            "{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n",
            "{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n",
            "{'text': 'đội CSGT số 2', 'pos': [55, 68]}\n",
            "{'text': 'đội CSGT số 2', 'pos': [6, 19]}\n",
            "{'text': 'khối 2', 'pos': [154, 160]}\n",
            "{'text': 'khối 2', 'pos': [154, 160]}\n",
            "{'text': 'khối 2', 'pos': [154, 160]}\n",
            "{'text': 'khối 2', 'pos': [154, 160]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIEWzlcthZZF"
      },
      "source": [
        "for sentif in jdev_data_use:\n",
        "    if ('½' in sentif['entity_1']['text']) or ('²' in sentif['entity_1']['text']) or ('ï' in sentif['entity_1']['text']):\n",
        "        print(sentif['entity_1'])\n",
        "\n",
        "    if ('½' in sentif['entity_2']['text']) or ('²' in sentif['entity_2']['text']) or ('ï' in sentif['entity_2']['text']):\n",
        "        print(sentif['entity_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQw7TkpyhZZF",
        "outputId": "be45ecd0-eab7-4160-fb47-53d530efd02d"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "tmpppent = []\n",
        "for sentif in jdev_data_use:\n",
        "    if (not sentif['entity_1']['text'][0].isalnum()) or (not sentif['entity_1']['text'][-1].isalnum()):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (not sentif['entity_2']['text'][0].isalnum()) or (not sentif['entity_2']['text'][-1].isalnum()):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '(Quảng Bình', 'pos': [219, 230]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '/Nikkei', 'pos': [10, 17]}\n",
            "{'text': '(CNPC', 'pos': [168, 173]}\n",
            "{'text': '/Reuters', 'pos': [10, 18]}\n",
            "{'text': '\"Merkel', 'pos': [0, 7]}\n",
            "{'text': '\"Trump', 'pos': [0, 6]}\n",
            "{'text': '\"Hillary Clinton', 'pos': [0, 16]}\n",
            "{'text': '(Cầu Giấy', 'pos': [45, 54]}\n",
            "{'text': '“Joel Matip', 'pos': [0, 11]}\n",
            "{'text': '“Cơ quan Cảnh sát điều tra', 'pos': [203, 229]}\n",
            "{'text': '(NHNN', 'pos': [90, 95]}\n",
            "{'text': '(quận Cầu Giấy', 'pos': [154, 168]}\n",
            "{'text': '(số 45 Lý thường Kiệt', 'pos': [243, 264]}\n",
            "{'text': '(VSP', 'pos': [129, 133]}\n",
            "{'text': '(BSR', 'pos': [175, 179]}\n",
            "{'text': '(PVEP', 'pos': [222, 227]}\n",
            "{'text': '(HTS', 'pos': [252, 256]}\n",
            "{'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n",
            "{'text': '“Damascus', 'pos': [9, 18]}\n",
            "{'text': '(Đắk Lắk', 'pos': [31, 39]}\n",
            "{'text': '\\ufeffĐịch Lệ Nhiệt Ba', 'pos': [0, 17]}\n",
            "{'text': \"'Lệ cơ\", 'pos': [86, 92]}\n",
            "{'text': '(Phường Vĩnh Phúc', 'pos': [97, 114]}\n",
            "{'text': '(thị xã Thuận An', 'pos': [131, 147]}\n",
            "{'text': '(phường Phạm Ngũ Lão', 'pos': [87, 107]}\n",
            "{'text': '(IS', 'pos': [26, 29]}\n",
            "{'text': '(Thanh Hóa', 'pos': [64, 74]}\n",
            "{'text': '(Đồng Nai', 'pos': [95, 104]}\n",
            "{'text': '(Nam Định', 'pos': [121, 130]}\n",
            "{'text': '(CLB Vũ Lê', 'pos': [54, 64]}\n",
            "{'text': '(Củ Chi', 'pos': [88, 95]}\n",
            "{'text': '(Quận 3', 'pos': [58, 65]}\n",
            "{'text': '(Phú Nhuận', 'pos': [92, 102]}\n",
            "{'text': '(TP.HCM', 'pos': [168, 175]}\n",
            "{'text': '(tỉnh Đắk Nông', 'pos': [63, 77]}\n",
            "{'text': '\"Real', 'pos': [133, 138]}\n",
            "{'text': '\"Người ngoài hành tinh\"', 'pos': [40, 63]}\n",
            "{'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "{'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n",
            "{'text': '(Sài Gòn', 'pos': [199, 207]}\n",
            "{'text': '(Hải Dương', 'pos': [230, 240]}\n",
            "{'text': '(Bình Dương', 'pos': [95, 106]}\n",
            "{'text': '(Trung Quốc', 'pos': [74, 85]}\n",
            "{'text': '-Trung', 'pos': [197, 203]}\n",
            "{'text': 'Nguyễn Văn Q.', 'pos': [127, 140]}\n",
            "{'text': '(OceanBank', 'pos': [184, 194]}\n",
            "{'text': '(Hà Nội', 'pos': [290, 297]}\n",
            "{'text': \"'MU\", 'pos': [0, 3]}\n",
            "{'text': '(Dân Việt', 'pos': [25, 34]}\n",
            "{'text': '/VOV', 'pos': [12, 16]}\n",
            "{'text': '-ĐBSCL', 'pos': [17, 23]}\n",
            "{'text': '(quận 10', 'pos': [9, 17]}\n",
            "{'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "{'text': '(Bắc Ninh', 'pos': [110, 119]}\n",
            "{'text': 'H.', 'pos': [104, 106]}\n",
            "{'text': '\\xa0Thảo', 'pos': [40, 45]}\n",
            "{'text': '(Hoàng Thị Hồng Tứ', 'pos': [84, 102]}\n",
            "{'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n",
            "{'text': '(huyện Phú Lộc', 'pos': [28, 42]}\n",
            "{'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n",
            "{'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n",
            "{'text': '(phường Đông Hưng Thuận', 'pos': [62, 85]}\n",
            "{'text': 'T.N.H.', 'pos': [40, 46]}\n",
            "{'text': '/TTXVN', 'pos': [4, 10]}\n",
            "{'text': '(Anh', 'pos': [106, 110]}\n",
            "{'text': '(Mỹ', 'pos': [215, 218]}\n",
            "{'text': '(Pháp', 'pos': [258, 263]}\n",
            "{'text': '\\xa0Fukushima', 'pos': [217, 227]}\n",
            "{'text': '(Đông Đức', 'pos': [256, 265]}\n",
            "{'text': '(KGB', 'pos': [184, 188]}\n",
            "{'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n",
            "{'text': '(Quảng Ninh', 'pos': [108, 119]}\n",
            "{'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n",
            "{'text': '(SPJD', 'pos': [138, 143]}\n",
            "{'text': 'Trần Thị Trúc L.', 'pos': [70, 86]}\n",
            "{'text': 'L.', 'pos': [24, 26]}\n",
            "{'text': '(phường 10', 'pos': [69, 79]}\n",
            "{'text': '(quận Bình Tân', 'pos': [75, 89]}\n",
            "{'text': '(Oceanbank', 'pos': [101, 111]}\n",
            "{'text': '(Sa Pa', 'pos': [164, 170]}\n",
            "{'text': '(huyện Bắc Hà', 'pos': [46, 59]}\n",
            "{'text': '(CMC Innovation Fund', 'pos': [190, 210]}\n",
            "{'text': '“Ngân hàng Chính sách xã hội', 'pos': [189, 217]}\n",
            "{'text': '(NHCSXH', 'pos': [331, 338]}\n",
            "{'text': '\"Ngân hàng Chính sách xã hội', 'pos': [402, 430]}\n",
            "{'text': \"'Hà\", 'pos': [15, 18]}\n",
            "{'text': '(Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [58, 98]}\n",
            "{'text': 'Đ.', 'pos': [48, 50]}\n",
            "{'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n",
            "{'text': '-Thái Bình Dương', 'pos': [59, 75]}\n",
            "{'text': '(TTXVN', 'pos': [0, 6]}\n",
            "{'text': '/Vietnam+', 'pos': [7, 16]}\n",
            "{'text': '(AFC', 'pos': [25, 29]}\n",
            "{'text': '(Vietnam+', 'pos': [10, 19]}\n",
            "{'text': '(TP HCM', 'pos': [60, 67]}\n",
            "{'text': 'Hoàng Thu H.', 'pos': [138, 150]}\n",
            "{'text': '(FA', 'pos': [197, 200]}\n",
            "{'text': 'Nguyễn Thị H.', 'pos': [25, 38]}\n",
            "{'text': '(PC 45', 'pos': [208, 214]}\n",
            "{'text': '(Bộ Tài nguyên và Môi trường', 'pos': [156, 184]}\n",
            "{'text': '“Tỉnh Hải Dương', 'pos': [0, 15]}\n",
            "{'text': '(Hải Phòng', 'pos': [73, 83]}\n",
            "{'text': '-Cầu Giẽ', 'pos': [154, 162]}\n",
            "{'text': '-Nga', 'pos': [3, 7]}\n",
            "{'text': '(IAEA', 'pos': [275, 280]}\n",
            "{'text': '(LHQ', 'pos': [418, 422]}\n",
            "{'text': '(NATO', 'pos': [35, 40]}\n",
            "{'text': \"'Biển chết\", 'pos': [0, 10]}\n",
            "{'text': \"'biển Chết\", 'pos': [81, 91]}\n",
            "{'text': '(huyện Cần Giuộc', 'pos': [63, 79]}\n",
            "{'text': '(NAPAS', 'pos': [79, 85]}\n",
            "{'text': '(Thượng Hóa', 'pos': [81, 92]}\n",
            "{'text': '(Thái Lan', 'pos': [150, 159]}\n",
            "{'text': '-đảng Xanh', 'pos': [290, 300]}\n",
            "{'text': '(Phòng CSGT Thanh Hóa', 'pos': [131, 152]}\n",
            "{'text': '(Indonesia', 'pos': [26, 36]}\n",
            "{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n",
            "{'text': '(Bộ TT&TT', 'pos': [20, 29]}\n",
            "{'text': '\\ufeffBảo Anh', 'pos': [0, 8]}\n",
            "{'text': '(NCA', 'pos': [165, 169]}\n",
            "{'text': '(Nghệ An', 'pos': [44, 52]}\n",
            "{'text': 'Nguyễn Xuân Huân -', 'pos': [91, 109]}\n",
            "{'text': '(TP Vinh', 'pos': [140, 148]}\n",
            "{'text': '(CDU', 'pos': [93, 97]}\n",
            "{'text': '/AP', 'pos': [8, 11]}\n",
            "{'text': '(phường Trung Hòa', 'pos': [76, 93]}\n",
            "{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': '-Syria', 'pos': [45, 51]}\n",
            "{'text': '(Al-Qaeda', 'pos': [120, 129]}\n",
            "{'text': '–HTS', 'pos': [136, 140]}\n",
            "{'text': '-Mỹ', 'pos': [163, 166]}\n",
            "{'text': '“Ủy ban tiếp quản Deir Ezzor', 'pos': [25, 53]}\n",
            "{'text': '-SDF', 'pos': [3, 7]}\n",
            "{'text': '(VINASA', 'pos': [170, 177]}\n",
            "{'text': '“tiểu Kompany”', 'pos': [32, 46]}\n",
            "{'text': '(Quảng Nam', 'pos': [125, 135]}\n",
            "{'text': '(TP Quy Nhơn', 'pos': [105, 117]}\n",
            "{'text': '(huyện Bình Sơn', 'pos': [161, 176]}\n",
            "{'text': '(Phú Yên', 'pos': [104, 112]}\n",
            "{'text': \"'Bao Thanh Thiên\", 'pos': [0, 16]}\n",
            "{'text': '\"Bao Thanh Thiên', 'pos': [9, 25]}\n",
            "{'text': '(Viettel', 'pos': [130, 138]}\n",
            "{'text': 'Lê Quý D.', 'pos': [86, 95]}\n",
            "{'text': '-Liên Xô', 'pos': [43, 51]}\n",
            "{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n",
            "{'text': '(Hà Văn Thắm', 'pos': [183, 195]}\n",
            "{'text': '(DongA Bank', 'pos': [201, 212]}\n",
            "{'text': '(Agribank', 'pos': [46, 55]}\n",
            "{'text': '(HDBank', 'pos': [180, 187]}\n",
            "{'text': '/Dân Việt', 'pos': [50, 59]}\n",
            "{'text': '(Lào Cai', 'pos': [86, 94]}\n",
            "{'text': 'Lương Văn T.', 'pos': [40, 52]}\n",
            "{'text': '(xã Gia Phú', 'pos': [53, 64]}\n",
            "{'text': '(VAS', 'pos': [75, 79]}\n",
            "{'text': '(VietCham Singapore', 'pos': [120, 139]}\n",
            "{'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n",
            "{'text': '(Vietnammese Association in Singapore', 'pos': [58, 95]}\n",
            "{'text': '(Jake Gyllenhaal', 'pos': [72, 88]}\n",
            "{'text': '-Tây Nguyên', 'pos': [14, 25]}\n",
            "{'text': '“Tevez', 'pos': [0, 6]}\n",
            "{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n",
            "{'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n",
            "{'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n",
            "{'text': '(EU', 'pos': [112, 115]}\n",
            "{'text': '(CSU', 'pos': [163, 167]}\n",
            "{'text': '(SPD', 'pos': [291, 295]}\n",
            "{'text': '/CSU', 'pos': [85, 89]}\n",
            "{'text': '(FDP', 'pos': [53, 57]}\n",
            "{'text': '(đảng Xanh', 'pos': [90, 100]}\n",
            "{'text': '(AfD', 'pos': [48, 52]}\n",
            "{'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n",
            "{'text': '(PVV', 'pos': [400, 404]}\n",
            "{'text': '(huyện Năm Căn', 'pos': [104, 118]}\n",
            "{'text': '(Cà Mau', 'pos': [60, 67]}\n",
            "{'text': '(VOV', 'pos': [0, 4]}\n",
            "{'text': '(VnExpress', 'pos': [0, 10]}\n",
            "{'text': '(Thanh niên', 'pos': [0, 11]}\n",
            "{'text': \"'Đông Phương Bất Bại\", 'pos': [79, 99]}\n",
            "{'text': '(Vĩnh Long', 'pos': [56, 66]}\n",
            "{'text': '(Bản Yên Sơn', 'pos': [64, 76]}\n",
            "{'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n",
            "{'text': 'Cáp Trọng Th.', 'pos': [39, 52]}\n",
            "{'text': 'Dương Thị T.', 'pos': [70, 82]}\n",
            "{'text': 'Th.', 'pos': [56, 59]}\n",
            "{'text': '(Hà Đông', 'pos': [20, 28]}\n",
            "{'text': '(Đống Đa', 'pos': [6, 14]}\n",
            "{'text': '(Australia', 'pos': [139, 149]}\n",
            "{'text': '-\\xa0Nam', 'pos': [68, 73]}\n",
            "{'text': '(IOM', 'pos': [164, 168]}\n",
            "{'text': 'Vi Thị O.', 'pos': [21, 30]}\n",
            "{'text': '(Hàn Quốc', 'pos': [38, 47]}\n",
            "{'text': '(Hà Nội)', 'pos': [128, 136]}\n",
            "{'text': '(Fed New York', 'pos': [170, 183]}\n",
            "{'text': '-Việt Nam', 'pos': [247, 256]}\n",
            "{'text': '(Bình Định', 'pos': [192, 202]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZpC3s97hZZF",
        "outputId": "9a7953c2-525f-4025-861c-f260cf8984d4"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "# tuy nhiên những entity bắt đầu hoặc kết thúc bằng kí tự '.' hoặc '+' thì không phải là lỗi\n",
        "tmpppent = []\n",
        "for sentif in jdev_data_use:\n",
        "    if (sentif['entity_1']['text'][0] == '+') or (sentif['entity_1']['text'][-1] == '+') \\\n",
        "    or (sentif['entity_1']['text'][0] == '.') or (sentif['entity_1']['text'][-1] == '.'):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (sentif['entity_2']['text'][0] == '+') or (sentif['entity_2']['text'][-1] == '.') \\\n",
        "    or (sentif['entity_2']['text'][0] == '.') or (sentif['entity_2']['text'][-1] == '+'):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'Nguyễn Văn Q.', 'pos': [127, 140]}\n",
            "{'text': 'H.', 'pos': [104, 106]}\n",
            "{'text': 'T.N.H.', 'pos': [40, 46]}\n",
            "{'text': 'Trần Thị Trúc L.', 'pos': [70, 86]}\n",
            "{'text': 'L.', 'pos': [24, 26]}\n",
            "{'text': 'Đ.', 'pos': [48, 50]}\n",
            "{'text': '/Vietnam+', 'pos': [7, 16]}\n",
            "{'text': '(Vietnam+', 'pos': [10, 19]}\n",
            "{'text': 'Hoàng Thu H.', 'pos': [138, 150]}\n",
            "{'text': 'Nguyễn Thị H.', 'pos': [25, 38]}\n",
            "{'text': 'Lê Quý D.', 'pos': [86, 95]}\n",
            "{'text': 'Lương Văn T.', 'pos': [40, 52]}\n",
            "{'text': 'Cáp Trọng Th.', 'pos': [39, 52]}\n",
            "{'text': 'Dương Thị T.', 'pos': [70, 82]}\n",
            "{'text': 'Th.', 'pos': [56, 59]}\n",
            "{'text': 'Vi Thị O.', 'pos': [21, 30]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzMKF60qhZZF",
        "outputId": "ed63e70a-b539-4bf1-8ca3-285577dfd408"
      },
      "source": [
        "# lỗi\n",
        "tmpppent = []\n",
        "for sentif in jdev_data_use:\n",
        "    if (sentif['entity_1']['text'][0] == '\\xa0') or (sentif['entity_1']['text'][-1] == '\\xa0'):\n",
        "        if sentif['entity_1']['text'] not in tmpppent:\n",
        "            print(sentif['entity_1'])\n",
        "            tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_1']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n",
        "\n",
        "    if (sentif['entity_2']['text'][0] == '\\xa0') or (sentif['entity_2']['text'][-1] == '\\xa0'):\n",
        "        if sentif['entity_2']['text'] not in tmpppent:\n",
        "            print(sentif['entity_2'])\n",
        "            tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "            '''\n",
        "            if '.' == sentif['entity_2']['text'][0]:\n",
        "                print(sentif)\n",
        "            '''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '\\xa0Thảo', 'pos': [40, 45]}\n",
            "{'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n",
            "{'text': '\\xa0Fukushima', 'pos': [217, 227]}\n",
            "{'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n",
            "{'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n",
            "{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n",
            "{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcokotVKhZZF",
        "outputId": "57d97ef6-b3f7-4167-a630-7504bf06c492"
      },
      "source": [
        "# những entity bắt đầu hoặc kết thúc bằng kí tự không phải chữ cái hay chữ số\n",
        "tmpppent = []\n",
        "for sentif in jdev_data_use:\n",
        "\n",
        "    if sentif['entity_1']['text'] not in tmpppent:\n",
        "        for c in sentif['entity_1']['text'][1:-1]:\n",
        "            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n",
        "                print(sentif['entity_1'])\n",
        "        \n",
        "        tmpppent.append(sentif['entity_1']['text'])\n",
        "\n",
        "        '''\n",
        "        if '- Huế' in sentif['entity_1']['text']:\n",
        "            print(sentif)\n",
        "        '''\n",
        "    \n",
        "    \n",
        "    if sentif['entity_2']['text'] not in tmpppent:\n",
        "        for c in sentif['entity_2']['text'][1:-1]:\n",
        "            if (not c.isalnum()) and (c != ' ') and (c != '.'):\n",
        "                print(sentif['entity_2'])\n",
        "        \n",
        "        tmpppent.append(sentif['entity_2']['text'])\n",
        "\n",
        "        '''\n",
        "        if '- Huế' in sentif['entity_2']['text']:\n",
        "            print(sentif)\n",
        "        '''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': 'Phong Nha – Kẻ Bàng', 'pos': [111, 130]}\n",
            "{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n",
            "{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n",
            "{'text': 'Hạt Kiểm lâm Vườn quốc gia (VQG) Phong Nha – Kẻ Bàng', 'pos': [7, 59]}\n",
            "{'text': 'VQG Phong Nha – Kẻ Bàng', 'pos': [57, 80]}\n",
            "{'text': 'Ban quản lý VQG Phong Nha – Kẻ Bàng', 'pos': [29, 64]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "{'text': 'Kim Jong-un', 'pos': [24, 35]}\n",
            "{'text': 'Ả-rập Saudi', 'pos': [66, 77]}\n",
            "{'text': 'và\\xa0Đinh Thanh Trung', 'pos': [54, 73]}\n",
            "{'text': 'Hayat Tahrir al-Sham', 'pos': [231, 251]}\n",
            "{'text': 'nguyênJabhat al-Nusra', 'pos': [259, 280]}\n",
            "{'text': 'al-Qaeda', 'pos': [293, 301]}\n",
            "{'text': 'Hayat Tahrlr al-Sham', 'pos': [295, 315]}\n",
            "{'text': 'chị\\xa0Đào Thị Thơm', 'pos': [114, 130]}\n",
            "{'text': 'Bộ TT&TT', 'pos': [89, 97]}\n",
            "{'text': 'Sở TT&TT Gia Lai', 'pos': [65, 81]}\n",
            "{'text': 'phòng CSGT đường bộ-đường sắt', 'pos': [62, 91]}\n",
            "{'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n",
            "{'text': 'Phòng CSGT đường bộ-đường sắt', 'pos': [15, 44]}\n",
            "{'text': 'TAND huyện Cư M’gar', 'pos': [11, 30]}\n",
            "{'text': 'H’A Byă', 'pos': [52, 59]}\n",
            "{'text': 'huyện Cư M’gar', 'pos': [104, 118]}\n",
            "{'text': 'H’M', 'pos': [94, 97]}\n",
            "{'text': 'Dolce&Gabbana', 'pos': [51, 64]}\n",
            "{'text': 'Phòng GD&ĐT Ba Đình', 'pos': [204, 223]}\n",
            "{'text': 'KCN Việt Nam – Singapore', 'pos': [106, 130]}\n",
            "{'text': 'Let’s Việt', 'pos': [259, 269]}\n",
            "{'text': 'VKSND huyện Đắk R’Lấp', 'pos': [41, 62]}\n",
            "{'text': 'huyện Đắk R’Lấp', 'pos': [248, 263]}\n",
            "{'text': 'Đắk R’Lấp', 'pos': [161, 170]}\n",
            "{'text': 'công an huyện Đắk R’Lấp', 'pos': [58, 81]}\n",
            "{'text': 'Erdene-Orchir', 'pos': [78, 91]}\n",
            "{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [55, 88]}\n",
            "{'text': 'Ủy ban Kiểm tra (UBKT) Trung ương', 'pos': [55, 88]}\n",
            "{'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n",
            "{'text': 'hội nạn nhân chất độc màu da cam/Dioxin Việt Nam', 'pos': [252, 300]}\n",
            "{'text': 'Bộ GD-ĐT', 'pos': [176, 184]}\n",
            "{'text': 'CSGT Đường bộ - Đường sắt', 'pos': [54, 79]}\n",
            "{'text': 'AFP /TTXVN', 'pos': [0, 10]}\n",
            "{'text': 'là\\xa0Nguyễn Thị Thảo', 'pos': [122, 140]}\n",
            "{'text': 'tịch\\xa0tỉnh Quảng Nam', 'pos': [27, 46]}\n",
            "{'text': 'Công an tỉnh TT-Huế', 'pos': [42, 61]}\n",
            "{'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n",
            "{'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n",
            "{'text': 'Hải đội 2 – Bộ đội Biên phòng tỉnh Quảng Ninh', 'pos': [114, 159]}\n",
            "{'text': 'Nhật /Nhật', 'pos': [174, 184]}\n",
            "{'text': 'Hiệp hội Phòng cháy chữa cháy (PCCC) Nhật Bản', 'pos': [75, 120]}\n",
            "{'text': 'Hiệp hội Phòng cháy chữa cháy (PCCC) Nhật Bản', 'pos': [75, 120]}\n",
            "{'text': 'Ri Yong-ho', 'pos': [52, 62]}\n",
            "{'text': 'Kang Kyung-wha', 'pos': [56, 70]}\n",
            "{'text': 'tỉnh Bà Rịa - Vũng Tàu', 'pos': [60, 82]}\n",
            "{'text': 'Salman Bin Abdulaziz Al-Saud', 'pos': [285, 313]}\n",
            "{'text': 'viên\\xa0Thanh Niên', 'pos': [58, 73]}\n",
            "{'text': 'Bệnh viện (BV) phẫu thuật thẩm mỹ EMCSA', 'pos': [55, 94]}\n",
            "{'text': 'Bệnh viện (BV) phẫu thuật thẩm mỹ EMCSA', 'pos': [55, 94]}\n",
            "{'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n",
            "{'text': 'cao tốc Pháp Vân-Cầu Giẽ', 'pos': [28, 52]}\n",
            "{'text': 'đường cao tốc Pháp Vân-Cầu Giẽ', 'pos': [35, 65]}\n",
            "{'text': 'nhóm P5+1', 'pos': [107, 116]}\n",
            "{'text': 'Công ty Cổ phần du lịch – thương mại và đầu tư Thiên Trường', 'pos': [29, 88]}\n",
            "{'text': 'tội,\\xa0Nguyễn Xuân Sơn', 'pos': [31, 51]}\n",
            "{'text': 'tội,\\xa0Nguyễn Xuân Sơn', 'pos': [31, 51]}\n",
            "{'text': 'trẻ,\\xa0Soobin Hoàng Sơn', 'pos': [80, 101]}\n",
            "{'text': 'trẻ,\\xa0Soobin Hoàng Sơn', 'pos': [80, 101]}\n",
            "{'text': 'do\\xa0Hoàng Touliver', 'pos': [131, 148]}\n",
            "{'text': 'nhà máy dệt Kim Jong-suk', 'pos': [78, 102]}\n",
            "{'text': 'Ri Sol-ju', 'pos': [36, 45]}\n",
            "{'text': 'Paekhak-dong', 'pos': [98, 110]}\n",
            "{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n",
            "{'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n",
            "{'text': '(Bộ TT&TT', 'pos': [20, 29]}\n",
            "{'text': 'Hiệp hội Chữ thập đỏ - Trăng lưỡi liềm đỏ quốc tế', 'pos': [33, 82]}\n",
            "{'text': 'Hiệp Hội Chữ thập Đỏ - Trăng lưỡi liềm Đỏ quốc tế', 'pos': [77, 126]}\n",
            "{'text': 'Hiệp hội Chữ thập Đỏ - Trăng lưỡi liềm Đỏ quốc tế', 'pos': [155, 204]}\n",
            "{'text': 'Bộ thông tin - Truyền thông', 'pos': [69, 96]}\n",
            "{'text': 'Plus/GĐVN', 'pos': [91, 100]}\n",
            "{'text': 'Al-Qaeda', 'pos': [151, 159]}\n",
            "{'text': 'tỉnh Deir al-Zour', 'pos': [157, 174]}\n",
            "{'text': 'Như\\xa0Pháp Luật TP.HCM', 'pos': [0, 20]}\n",
            "{'text': 'mất\\xa0Theo Hernandez', 'pos': [68, 86]}\n",
            "{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n",
            "{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n",
            "{'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "{'text': 'Rô-lăng', 'pos': [94, 101]}\n",
            "{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n",
            "{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n",
            "{'text': 'Or’-lan-đô', 'pos': [111, 121]}\n",
            "{'text': 'Sở TN&MT Hà Nội', 'pos': [37, 52]}\n",
            "{'text': 'Hay’at Tahrir Al-Sham', 'pos': [98, 119]}\n",
            "{'text': 'Hay’at Tahrir Al-Sham', 'pos': [98, 119]}\n",
            "{'text': '(Al-Qaeda', 'pos': [120, 129]}\n",
            "{'text': 'Hải đội 2, BĐBP Quảng Ninh', 'pos': [100, 126]}\n",
            "{'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [36, 67]}\n",
            "{'text': 'Quỹ Tấm lòng Việt - Đài Truyền hình Việt Nam', 'pos': [46, 90]}\n",
            "{'text': 'hầm Serpukhov-15', 'pos': [142, 158]}\n",
            "{'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '02/2011/TT-NHNN', 'pos': [206, 221]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': '14/2011/TT-NHNN', 'pos': [312, 327]}\n",
            "{'text': 'EPA/TTXVN', 'pos': [0, 9]}\n",
            "{'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n",
            "{'text': 'của\\xa0Vũ Ngọc Nhạ', 'pos': [167, 182]}\n",
            "{'text': \"L'Oreal\", 'pos': [37, 44]}\n",
            "{'text': 'Bà\\xa0Liliane Bettencourt', 'pos': [53, 75]}\n",
            "{'text': 'L’Oreal', 'pos': [5, 12]}\n",
            "{'text': 'La Roche-Posay', 'pos': [88, 102]}\n",
            "{'text': 'Jean-Paul Agon', 'pos': [177, 191]}\n",
            "{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n",
            "{'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n",
            "{'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n",
            "{'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n",
            "{'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n",
            "{'text': 'Rostov-on-Don', 'pos': [137, 150]}\n",
            "{'text': 'Rostov-on-Don', 'pos': [137, 150]}\n",
            "{'text': '-\\xa0Nam', 'pos': [68, 73]}\n",
            "{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "{'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "{'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "{'text': 'Sở LĐ-TB-XH Bình Định', 'pos': [0, 21]}\n",
            "{'text': 'Sở LĐ-TB-XH Bình Định', 'pos': [0, 21]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpCdj0TVhZZF"
      },
      "source": [
        "#### fix start end of entity in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3v80f4whZZF",
        "outputId": "76851701-b3bf-4c04-8da1-68dc0cb21215"
      },
      "source": [
        "jdev_data_v2 = copy.deepcopy(fix_start_end_of_entity(jdev_data_use))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "original:       {'text': '(Quảng Bình', 'pos': [219, 230]}\n",
            "new_entity:     {'text': 'Quảng Bình', 'pos': [220, 230]}\n",
            "\n",
            "original:       {'text': '\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200bTriều Tiên', 'pos': [0, 17]}\n",
            "new_entity:     {'text': 'Triều Tiên', 'pos': [7, 17]}\n",
            "\n",
            "original:       {'text': '/Nikkei', 'pos': [10, 17]}\n",
            "new_entity:     {'text': 'Nikkei', 'pos': [11, 17]}\n",
            "\n",
            "original:       {'text': '(CNPC', 'pos': [168, 173]}\n",
            "new_entity:     {'text': 'CNPC', 'pos': [169, 173]}\n",
            "\n",
            "original:       {'text': '/Reuters', 'pos': [10, 18]}\n",
            "new_entity:     {'text': 'Reuters', 'pos': [11, 18]}\n",
            "\n",
            "original:       {'text': '\"Merkel', 'pos': [0, 7]}\n",
            "new_entity:     {'text': 'Merkel', 'pos': [1, 7]}\n",
            "\n",
            "original:       {'text': '\"Trump', 'pos': [0, 6]}\n",
            "new_entity:     {'text': 'Trump', 'pos': [1, 6]}\n",
            "\n",
            "original:       {'text': '\"Hillary Clinton', 'pos': [0, 16]}\n",
            "new_entity:     {'text': 'Hillary Clinton', 'pos': [1, 16]}\n",
            "\n",
            "original:       {'text': '(Cầu Giấy', 'pos': [45, 54]}\n",
            "new_entity:     {'text': 'Cầu Giấy', 'pos': [46, 54]}\n",
            "\n",
            "original:       {'text': '“Joel Matip', 'pos': [0, 11]}\n",
            "new_entity:     {'text': 'Joel Matip', 'pos': [1, 11]}\n",
            "\n",
            "original:       {'text': '“Cơ quan Cảnh sát điều tra', 'pos': [203, 229]}\n",
            "new_entity:     {'text': 'Cơ quan Cảnh sát điều tra', 'pos': [204, 229]}\n",
            "\n",
            "original:       {'text': '(NHNN', 'pos': [90, 95]}\n",
            "new_entity:     {'text': 'NHNN', 'pos': [91, 95]}\n",
            "\n",
            "original:       {'text': '(quận Cầu Giấy', 'pos': [154, 168]}\n",
            "new_entity:     {'text': 'quận Cầu Giấy', 'pos': [155, 168]}\n",
            "\n",
            "original:       {'text': '(số 45 Lý thường Kiệt', 'pos': [243, 264]}\n",
            "new_entity:     {'text': 'số 45 Lý thường Kiệt', 'pos': [244, 264]}\n",
            "\n",
            "original:       {'text': '(VSP', 'pos': [129, 133]}\n",
            "new_entity:     {'text': 'VSP', 'pos': [130, 133]}\n",
            "\n",
            "original:       {'text': '(BSR', 'pos': [175, 179]}\n",
            "new_entity:     {'text': 'BSR', 'pos': [176, 179]}\n",
            "\n",
            "original:       {'text': '(PVEP', 'pos': [222, 227]}\n",
            "new_entity:     {'text': 'PVEP', 'pos': [223, 227]}\n",
            "\n",
            "original:       {'text': '(HTS', 'pos': [252, 256]}\n",
            "new_entity:     {'text': 'HTS', 'pos': [253, 256]}\n",
            "\n",
            "original:       {'text': '(PC67-Công an TP.HCM', 'pos': [92, 112]}\n",
            "new_entity:     {'text': 'PC67-Công an TP.HCM', 'pos': [93, 112]}\n",
            "\n",
            "original:       {'text': '“Damascus', 'pos': [9, 18]}\n",
            "new_entity:     {'text': 'Damascus', 'pos': [10, 18]}\n",
            "\n",
            "original:       {'text': '(Đắk Lắk', 'pos': [31, 39]}\n",
            "new_entity:     {'text': 'Đắk Lắk', 'pos': [32, 39]}\n",
            "\n",
            "original:       {'text': '\\ufeffĐịch Lệ Nhiệt Ba', 'pos': [0, 17]}\n",
            "new_entity:     {'text': 'Địch Lệ Nhiệt Ba', 'pos': [1, 17]}\n",
            "\n",
            "original:       {'text': \"'Lệ cơ\", 'pos': [86, 92]}\n",
            "new_entity:     {'text': 'Lệ cơ', 'pos': [87, 92]}\n",
            "\n",
            "original:       {'text': '(Phường Vĩnh Phúc', 'pos': [97, 114]}\n",
            "new_entity:     {'text': 'Phường Vĩnh Phúc', 'pos': [98, 114]}\n",
            "\n",
            "original:       {'text': '(thị xã Thuận An', 'pos': [131, 147]}\n",
            "new_entity:     {'text': 'thị xã Thuận An', 'pos': [132, 147]}\n",
            "\n",
            "original:       {'text': '(phường Phạm Ngũ Lão', 'pos': [87, 107]}\n",
            "new_entity:     {'text': 'phường Phạm Ngũ Lão', 'pos': [88, 107]}\n",
            "\n",
            "original:       {'text': '(IS', 'pos': [26, 29]}\n",
            "new_entity:     {'text': 'IS', 'pos': [27, 29]}\n",
            "\n",
            "original:       {'text': '(Thanh Hóa', 'pos': [64, 74]}\n",
            "new_entity:     {'text': 'Thanh Hóa', 'pos': [65, 74]}\n",
            "\n",
            "original:       {'text': '(Đồng Nai', 'pos': [95, 104]}\n",
            "new_entity:     {'text': 'Đồng Nai', 'pos': [96, 104]}\n",
            "\n",
            "original:       {'text': '(Nam Định', 'pos': [121, 130]}\n",
            "new_entity:     {'text': 'Nam Định', 'pos': [122, 130]}\n",
            "\n",
            "original:       {'text': '(CLB Vũ Lê', 'pos': [54, 64]}\n",
            "new_entity:     {'text': 'CLB Vũ Lê', 'pos': [55, 64]}\n",
            "\n",
            "original:       {'text': '(Củ Chi', 'pos': [88, 95]}\n",
            "new_entity:     {'text': 'Củ Chi', 'pos': [89, 95]}\n",
            "\n",
            "original:       {'text': '(Quận 3', 'pos': [58, 65]}\n",
            "new_entity:     {'text': 'Quận 3', 'pos': [59, 65]}\n",
            "\n",
            "original:       {'text': '(Phú Nhuận', 'pos': [92, 102]}\n",
            "new_entity:     {'text': 'Phú Nhuận', 'pos': [93, 102]}\n",
            "\n",
            "original:       {'text': '(TP.HCM', 'pos': [168, 175]}\n",
            "new_entity:     {'text': 'TP.HCM', 'pos': [169, 175]}\n",
            "\n",
            "original:       {'text': '(tỉnh Đắk Nông', 'pos': [63, 77]}\n",
            "new_entity:     {'text': 'tỉnh Đắk Nông', 'pos': [64, 77]}\n",
            "\n",
            "original:       {'text': '\"Real', 'pos': [133, 138]}\n",
            "new_entity:     {'text': 'Real', 'pos': [134, 138]}\n",
            "\n",
            "original:       {'text': '\"Người ngoài hành tinh\"', 'pos': [40, 63]}\n",
            "new_entity:     {'text': 'Người ngoài hành tinh', 'pos': [41, 62]}\n",
            "\n",
            "original:       {'text': '(quốc lộ 13', 'pos': [164, 175]}\n",
            "new_entity:     {'text': 'quốc lộ 13', 'pos': [165, 175]}\n",
            "\n",
            "original:       {'text': '),Vũ Thị Thùy Dương', 'pos': [151, 170]}\n",
            "new_entity:     {'text': 'Vũ Thị Thùy Dương', 'pos': [153, 170]}\n",
            "\n",
            "original:       {'text': '(Sài Gòn', 'pos': [199, 207]}\n",
            "new_entity:     {'text': 'Sài Gòn', 'pos': [200, 207]}\n",
            "\n",
            "original:       {'text': '(Hải Dương', 'pos': [230, 240]}\n",
            "new_entity:     {'text': 'Hải Dương', 'pos': [231, 240]}\n",
            "\n",
            "original:       {'text': '(Bình Dương', 'pos': [95, 106]}\n",
            "new_entity:     {'text': 'Bình Dương', 'pos': [96, 106]}\n",
            "\n",
            "original:       {'text': '(Trung Quốc', 'pos': [74, 85]}\n",
            "new_entity:     {'text': 'Trung Quốc', 'pos': [75, 85]}\n",
            "\n",
            "original:       {'text': '-Trung', 'pos': [197, 203]}\n",
            "new_entity:     {'text': 'Trung', 'pos': [198, 203]}\n",
            "\n",
            "original:       {'text': '(OceanBank', 'pos': [184, 194]}\n",
            "new_entity:     {'text': 'OceanBank', 'pos': [185, 194]}\n",
            "\n",
            "original:       {'text': '(Hà Nội', 'pos': [290, 297]}\n",
            "new_entity:     {'text': 'Hà Nội', 'pos': [291, 297]}\n",
            "\n",
            "original:       {'text': \"'MU\", 'pos': [0, 3]}\n",
            "new_entity:     {'text': 'MU', 'pos': [1, 3]}\n",
            "\n",
            "original:       {'text': '(Dân Việt', 'pos': [25, 34]}\n",
            "new_entity:     {'text': 'Dân Việt', 'pos': [26, 34]}\n",
            "\n",
            "original:       {'text': '/VOV', 'pos': [12, 16]}\n",
            "new_entity:     {'text': 'VOV', 'pos': [13, 16]}\n",
            "\n",
            "original:       {'text': '-ĐBSCL', 'pos': [17, 23]}\n",
            "new_entity:     {'text': 'ĐBSCL', 'pos': [18, 23]}\n",
            "\n",
            "original:       {'text': '(quận 10', 'pos': [9, 17]}\n",
            "new_entity:     {'text': 'quận 10', 'pos': [10, 17]}\n",
            "\n",
            "original:       {'text': '(hẻm 438', 'pos': [108, 116]}\n",
            "new_entity:     {'text': 'hẻm 438', 'pos': [109, 116]}\n",
            "\n",
            "original:       {'text': '(Bắc Ninh', 'pos': [110, 119]}\n",
            "new_entity:     {'text': 'Bắc Ninh', 'pos': [111, 119]}\n",
            "\n",
            "original:       {'text': '\\xa0Thảo', 'pos': [40, 45]}\n",
            "new_entity:     {'text': 'Thảo', 'pos': [41, 45]}\n",
            "\n",
            "original:       {'text': '(Hoàng Thị Hồng Tứ', 'pos': [84, 102]}\n",
            "new_entity:     {'text': 'Hoàng Thị Hồng Tứ', 'pos': [85, 102]}\n",
            "\n",
            "original:       {'text': '(tỉnh TT-Huế', 'pos': [124, 136]}\n",
            "new_entity:     {'text': 'tỉnh TT-Huế', 'pos': [125, 136]}\n",
            "\n",
            "original:       {'text': '(huyện Phú Lộc', 'pos': [28, 42]}\n",
            "new_entity:     {'text': 'huyện Phú Lộc', 'pos': [29, 42]}\n",
            "\n",
            "original:       {'text': 'Ro ‘Béo’', 'pos': [6, 14]}\n",
            "new_entity:     {'text': 'Ro ‘Béo', 'pos': [6, 13]}\n",
            "\n",
            "original:       {'text': '\\xa0Nguyễn Công Thành', 'pos': [103, 121]}\n",
            "new_entity:     {'text': 'Nguyễn Công Thành', 'pos': [104, 121]}\n",
            "\n",
            "original:       {'text': '(phường Đông Hưng Thuận', 'pos': [62, 85]}\n",
            "new_entity:     {'text': 'phường Đông Hưng Thuận', 'pos': [63, 85]}\n",
            "\n",
            "original:       {'text': '/TTXVN', 'pos': [4, 10]}\n",
            "new_entity:     {'text': 'TTXVN', 'pos': [5, 10]}\n",
            "\n",
            "original:       {'text': '(Anh', 'pos': [106, 110]}\n",
            "new_entity:     {'text': 'Anh', 'pos': [107, 110]}\n",
            "\n",
            "original:       {'text': '(Mỹ', 'pos': [215, 218]}\n",
            "new_entity:     {'text': 'Mỹ', 'pos': [216, 218]}\n",
            "\n",
            "original:       {'text': '(Pháp', 'pos': [258, 263]}\n",
            "new_entity:     {'text': 'Pháp', 'pos': [259, 263]}\n",
            "\n",
            "original:       {'text': '\\xa0Fukushima', 'pos': [217, 227]}\n",
            "new_entity:     {'text': 'Fukushima', 'pos': [218, 227]}\n",
            "\n",
            "original:       {'text': '(Đông Đức', 'pos': [256, 265]}\n",
            "new_entity:     {'text': 'Đông Đức', 'pos': [257, 265]}\n",
            "\n",
            "original:       {'text': '(KGB', 'pos': [184, 188]}\n",
            "new_entity:     {'text': 'KGB', 'pos': [185, 188]}\n",
            "\n",
            "original:       {'text': '\\xa0Helmut Kohl', 'pos': [64, 76]}\n",
            "new_entity:     {'text': 'Helmut Kohl', 'pos': [65, 76]}\n",
            "\n",
            "original:       {'text': '(Quảng Ninh', 'pos': [108, 119]}\n",
            "new_entity:     {'text': 'Quảng Ninh', 'pos': [109, 119]}\n",
            "\n",
            "original:       {'text': '\\xa0Shinawatra', 'pos': [156, 167]}\n",
            "new_entity:     {'text': 'Shinawatra', 'pos': [157, 167]}\n",
            "\n",
            "original:       {'text': '(SPJD', 'pos': [138, 143]}\n",
            "new_entity:     {'text': 'SPJD', 'pos': [139, 143]}\n",
            "\n",
            "original:       {'text': '(phường 10', 'pos': [69, 79]}\n",
            "new_entity:     {'text': 'phường 10', 'pos': [70, 79]}\n",
            "\n",
            "original:       {'text': '(quận Bình Tân', 'pos': [75, 89]}\n",
            "new_entity:     {'text': 'quận Bình Tân', 'pos': [76, 89]}\n",
            "\n",
            "original:       {'text': '(Oceanbank', 'pos': [101, 111]}\n",
            "new_entity:     {'text': 'Oceanbank', 'pos': [102, 111]}\n",
            "\n",
            "original:       {'text': '(Sa Pa', 'pos': [164, 170]}\n",
            "new_entity:     {'text': 'Sa Pa', 'pos': [165, 170]}\n",
            "\n",
            "original:       {'text': '(huyện Bắc Hà', 'pos': [46, 59]}\n",
            "new_entity:     {'text': 'huyện Bắc Hà', 'pos': [47, 59]}\n",
            "\n",
            "original:       {'text': '(CMC Innovation Fund', 'pos': [190, 210]}\n",
            "new_entity:     {'text': 'CMC Innovation Fund', 'pos': [191, 210]}\n",
            "\n",
            "original:       {'text': '“Ngân hàng Chính sách xã hội', 'pos': [189, 217]}\n",
            "new_entity:     {'text': 'Ngân hàng Chính sách xã hội', 'pos': [190, 217]}\n",
            "\n",
            "original:       {'text': '(NHCSXH', 'pos': [331, 338]}\n",
            "new_entity:     {'text': 'NHCSXH', 'pos': [332, 338]}\n",
            "\n",
            "original:       {'text': '\"Ngân hàng Chính sách xã hội', 'pos': [402, 430]}\n",
            "new_entity:     {'text': 'Ngân hàng Chính sách xã hội', 'pos': [403, 430]}\n",
            "\n",
            "original:       {'text': \"'Hà\", 'pos': [15, 18]}\n",
            "new_entity:     {'text': 'Hà', 'pos': [16, 18]}\n",
            "\n",
            "original:       {'text': '(Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [58, 98]}\n",
            "new_entity:     {'text': 'Chi cục Quản lý thị trường tỉnh Hà Tĩnh', 'pos': [59, 98]}\n",
            "\n",
            "original:       {'text': '(số 14/27 Hoàng Dư Khương', 'pos': [95, 120]}\n",
            "new_entity:     {'text': 'số 14/27 Hoàng Dư Khương', 'pos': [96, 120]}\n",
            "\n",
            "original:       {'text': '-Thái Bình Dương', 'pos': [59, 75]}\n",
            "new_entity:     {'text': 'Thái Bình Dương', 'pos': [60, 75]}\n",
            "\n",
            "original:       {'text': '(TTXVN', 'pos': [0, 6]}\n",
            "new_entity:     {'text': 'TTXVN', 'pos': [1, 6]}\n",
            "\n",
            "original:       {'text': '/Vietnam+', 'pos': [7, 16]}\n",
            "new_entity:     {'text': 'Vietnam+', 'pos': [8, 16]}\n",
            "\n",
            "original:       {'text': '(AFC', 'pos': [25, 29]}\n",
            "new_entity:     {'text': 'AFC', 'pos': [26, 29]}\n",
            "\n",
            "original:       {'text': '(Vietnam+', 'pos': [10, 19]}\n",
            "new_entity:     {'text': 'Vietnam+', 'pos': [11, 19]}\n",
            "\n",
            "original:       {'text': '(TP HCM', 'pos': [60, 67]}\n",
            "new_entity:     {'text': 'TP HCM', 'pos': [61, 67]}\n",
            "\n",
            "original:       {'text': '(FA', 'pos': [197, 200]}\n",
            "new_entity:     {'text': 'FA', 'pos': [198, 200]}\n",
            "\n",
            "original:       {'text': '(PC 45', 'pos': [208, 214]}\n",
            "new_entity:     {'text': 'PC 45', 'pos': [209, 214]}\n",
            "\n",
            "original:       {'text': '(Bộ Tài nguyên và Môi trường', 'pos': [156, 184]}\n",
            "new_entity:     {'text': 'Bộ Tài nguyên và Môi trường', 'pos': [157, 184]}\n",
            "\n",
            "original:       {'text': '“Tỉnh Hải Dương', 'pos': [0, 15]}\n",
            "new_entity:     {'text': 'Tỉnh Hải Dương', 'pos': [1, 15]}\n",
            "\n",
            "original:       {'text': '(Hải Phòng', 'pos': [73, 83]}\n",
            "new_entity:     {'text': 'Hải Phòng', 'pos': [74, 83]}\n",
            "\n",
            "original:       {'text': '-Cầu Giẽ', 'pos': [154, 162]}\n",
            "new_entity:     {'text': 'Cầu Giẽ', 'pos': [155, 162]}\n",
            "\n",
            "original:       {'text': '-Nga', 'pos': [3, 7]}\n",
            "new_entity:     {'text': 'Nga', 'pos': [4, 7]}\n",
            "\n",
            "original:       {'text': '(IAEA', 'pos': [275, 280]}\n",
            "new_entity:     {'text': 'IAEA', 'pos': [276, 280]}\n",
            "\n",
            "original:       {'text': '(LHQ', 'pos': [418, 422]}\n",
            "new_entity:     {'text': 'LHQ', 'pos': [419, 422]}\n",
            "\n",
            "original:       {'text': '(NATO', 'pos': [35, 40]}\n",
            "new_entity:     {'text': 'NATO', 'pos': [36, 40]}\n",
            "\n",
            "original:       {'text': \"'Biển chết\", 'pos': [0, 10]}\n",
            "new_entity:     {'text': 'Biển chết', 'pos': [1, 10]}\n",
            "\n",
            "original:       {'text': \"'biển Chết\", 'pos': [81, 91]}\n",
            "new_entity:     {'text': 'biển Chết', 'pos': [82, 91]}\n",
            "\n",
            "original:       {'text': '(huyện Cần Giuộc', 'pos': [63, 79]}\n",
            "new_entity:     {'text': 'huyện Cần Giuộc', 'pos': [64, 79]}\n",
            "\n",
            "original:       {'text': '(NAPAS', 'pos': [79, 85]}\n",
            "new_entity:     {'text': 'NAPAS', 'pos': [80, 85]}\n",
            "\n",
            "original:       {'text': '(Thượng Hóa', 'pos': [81, 92]}\n",
            "new_entity:     {'text': 'Thượng Hóa', 'pos': [82, 92]}\n",
            "\n",
            "original:       {'text': '(Thái Lan', 'pos': [150, 159]}\n",
            "new_entity:     {'text': 'Thái Lan', 'pos': [151, 159]}\n",
            "\n",
            "original:       {'text': '-đảng Xanh', 'pos': [290, 300]}\n",
            "new_entity:     {'text': 'đảng Xanh', 'pos': [291, 300]}\n",
            "\n",
            "original:       {'text': '(Phòng CSGT Thanh Hóa', 'pos': [131, 152]}\n",
            "new_entity:     {'text': 'Phòng CSGT Thanh Hóa', 'pos': [132, 152]}\n",
            "\n",
            "original:       {'text': '(Indonesia', 'pos': [26, 36]}\n",
            "new_entity:     {'text': 'Indonesia', 'pos': [27, 36]}\n",
            "\n",
            "original:       {'text': '(Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [83, 148]}\n",
            "new_entity:     {'text': 'Phòng Cảnh sát giao thông đường bộ, đường sắt- Công an TP.Hà Nội', 'pos': [84, 148]}\n",
            "\n",
            "original:       {'text': '(Bộ TT&TT', 'pos': [20, 29]}\n",
            "new_entity:     {'text': 'Bộ TT&TT', 'pos': [21, 29]}\n",
            "\n",
            "original:       {'text': '\\ufeffBảo Anh', 'pos': [0, 8]}\n",
            "new_entity:     {'text': 'Bảo Anh', 'pos': [1, 8]}\n",
            "\n",
            "original:       {'text': '(NCA', 'pos': [165, 169]}\n",
            "new_entity:     {'text': 'NCA', 'pos': [166, 169]}\n",
            "\n",
            "original:       {'text': '(Nghệ An', 'pos': [44, 52]}\n",
            "new_entity:     {'text': 'Nghệ An', 'pos': [45, 52]}\n",
            "\n",
            "original:       {'text': 'Nguyễn Xuân Huân -', 'pos': [91, 109]}\n",
            "new_entity:     {'text': 'Nguyễn Xuân Huân', 'pos': [91, 107]}\n",
            "\n",
            "original:       {'text': '(TP Vinh', 'pos': [140, 148]}\n",
            "new_entity:     {'text': 'TP Vinh', 'pos': [141, 148]}\n",
            "\n",
            "original:       {'text': '(CDU', 'pos': [93, 97]}\n",
            "new_entity:     {'text': 'CDU', 'pos': [94, 97]}\n",
            "\n",
            "original:       {'text': '/AP', 'pos': [8, 11]}\n",
            "new_entity:     {'text': 'AP', 'pos': [9, 11]}\n",
            "\n",
            "original:       {'text': '(phường Trung Hòa', 'pos': [76, 93]}\n",
            "new_entity:     {'text': 'phường Trung Hòa', 'pos': [77, 93]}\n",
            "\n",
            "original:       {'text': '(A-ri-ô-xtô', 'pos': [17, 28]}\n",
            "new_entity:     {'text': 'A-ri-ô-xtô', 'pos': [18, 28]}\n",
            "\n",
            "original:       {'text': 'Charlemagne (Sar’-lơ-ma-nhơ)', 'pos': [9, 37]}\n",
            "new_entity:     {'text': 'Charlemagne (Sar’-lơ-ma-nhơ', 'pos': [9, 36]}\n",
            "\n",
            "original:       {'text': '-Syria', 'pos': [45, 51]}\n",
            "new_entity:     {'text': 'Syria', 'pos': [46, 51]}\n",
            "\n",
            "original:       {'text': '(Al-Qaeda', 'pos': [120, 129]}\n",
            "new_entity:     {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "\n",
            "original:       {'text': '–HTS', 'pos': [136, 140]}\n",
            "new_entity:     {'text': 'HTS', 'pos': [137, 140]}\n",
            "\n",
            "original:       {'text': '-Mỹ', 'pos': [163, 166]}\n",
            "new_entity:     {'text': 'Mỹ', 'pos': [164, 166]}\n",
            "\n",
            "original:       {'text': '“Ủy ban tiếp quản Deir Ezzor', 'pos': [25, 53]}\n",
            "new_entity:     {'text': 'Ủy ban tiếp quản Deir Ezzor', 'pos': [26, 53]}\n",
            "\n",
            "original:       {'text': '-SDF', 'pos': [3, 7]}\n",
            "new_entity:     {'text': 'SDF', 'pos': [4, 7]}\n",
            "\n",
            "original:       {'text': '(VINASA', 'pos': [170, 177]}\n",
            "new_entity:     {'text': 'VINASA', 'pos': [171, 177]}\n",
            "\n",
            "original:       {'text': '“tiểu Kompany”', 'pos': [32, 46]}\n",
            "new_entity:     {'text': 'tiểu Kompany', 'pos': [33, 45]}\n",
            "\n",
            "original:       {'text': '(Quảng Nam', 'pos': [125, 135]}\n",
            "new_entity:     {'text': 'Quảng Nam', 'pos': [126, 135]}\n",
            "\n",
            "original:       {'text': '(TP Quy Nhơn', 'pos': [105, 117]}\n",
            "new_entity:     {'text': 'TP Quy Nhơn', 'pos': [106, 117]}\n",
            "\n",
            "original:       {'text': '(huyện Bình Sơn', 'pos': [161, 176]}\n",
            "new_entity:     {'text': 'huyện Bình Sơn', 'pos': [162, 176]}\n",
            "\n",
            "original:       {'text': '(Phú Yên', 'pos': [104, 112]}\n",
            "new_entity:     {'text': 'Phú Yên', 'pos': [105, 112]}\n",
            "\n",
            "original:       {'text': \"'Bao Thanh Thiên\", 'pos': [0, 16]}\n",
            "new_entity:     {'text': 'Bao Thanh Thiên', 'pos': [1, 16]}\n",
            "\n",
            "original:       {'text': '\"Bao Thanh Thiên', 'pos': [9, 25]}\n",
            "new_entity:     {'text': 'Bao Thanh Thiên', 'pos': [10, 25]}\n",
            "\n",
            "original:       {'text': '(Viettel', 'pos': [130, 138]}\n",
            "new_entity:     {'text': 'Viettel', 'pos': [131, 138]}\n",
            "\n",
            "original:       {'text': '-Liên Xô', 'pos': [43, 51]}\n",
            "new_entity:     {'text': 'Liên Xô', 'pos': [44, 51]}\n",
            "\n",
            "original:       {'text': '\\xa0khách sạn Pierre & Vacances', 'pos': [56, 84]}\n",
            "new_entity:     {'text': 'khách sạn Pierre & Vacances', 'pos': [57, 84]}\n",
            "\n",
            "original:       {'text': '(Hà Văn Thắm', 'pos': [183, 195]}\n",
            "new_entity:     {'text': 'Hà Văn Thắm', 'pos': [184, 195]}\n",
            "\n",
            "original:       {'text': '(DongA Bank', 'pos': [201, 212]}\n",
            "new_entity:     {'text': 'DongA Bank', 'pos': [202, 212]}\n",
            "\n",
            "original:       {'text': '(Agribank', 'pos': [46, 55]}\n",
            "new_entity:     {'text': 'Agribank', 'pos': [47, 55]}\n",
            "\n",
            "original:       {'text': '(HDBank', 'pos': [180, 187]}\n",
            "new_entity:     {'text': 'HDBank', 'pos': [181, 187]}\n",
            "\n",
            "original:       {'text': '/Dân Việt', 'pos': [50, 59]}\n",
            "new_entity:     {'text': 'Dân Việt', 'pos': [51, 59]}\n",
            "\n",
            "original:       {'text': '(Lào Cai', 'pos': [86, 94]}\n",
            "new_entity:     {'text': 'Lào Cai', 'pos': [87, 94]}\n",
            "\n",
            "original:       {'text': '(xã Gia Phú', 'pos': [53, 64]}\n",
            "new_entity:     {'text': 'xã Gia Phú', 'pos': [54, 64]}\n",
            "\n",
            "original:       {'text': '(VAS', 'pos': [75, 79]}\n",
            "new_entity:     {'text': 'VAS', 'pos': [76, 79]}\n",
            "\n",
            "original:       {'text': '(VietCham Singapore', 'pos': [120, 139]}\n",
            "new_entity:     {'text': 'VietCham Singapore', 'pos': [121, 139]}\n",
            "\n",
            "original:       {'text': ',\\xa0Việt Nam', 'pos': [25, 35]}\n",
            "new_entity:     {'text': 'Việt Nam', 'pos': [27, 35]}\n",
            "\n",
            "original:       {'text': '(Vietnammese Association in Singapore', 'pos': [58, 95]}\n",
            "new_entity:     {'text': 'Vietnammese Association in Singapore', 'pos': [59, 95]}\n",
            "\n",
            "original:       {'text': '(Jake Gyllenhaal', 'pos': [72, 88]}\n",
            "new_entity:     {'text': 'Jake Gyllenhaal', 'pos': [73, 88]}\n",
            "\n",
            "original:       {'text': '-Tây Nguyên', 'pos': [14, 25]}\n",
            "new_entity:     {'text': 'Tây Nguyên', 'pos': [15, 25]}\n",
            "\n",
            "original:       {'text': '“Tevez', 'pos': [0, 6]}\n",
            "new_entity:     {'text': 'Tevez', 'pos': [1, 6]}\n",
            "\n",
            "original:       {'text': '\\xa00-9\\xa0U16 Việt Nam', 'pos': [28, 45]}\n",
            "new_entity:     {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "\n",
            "original:       {'text': '(sân\\xa0MFF Football Centre', 'pos': [46, 70]}\n",
            "new_entity:     {'text': 'sân\\xa0MFF Football Centre', 'pos': [47, 70]}\n",
            "\n",
            "original:       {'text': ',\\xa0Ulan Bator', 'pos': [71, 83]}\n",
            "new_entity:     {'text': 'Ulan Bator', 'pos': [73, 83]}\n",
            "\n",
            "original:       {'text': '(EU', 'pos': [112, 115]}\n",
            "new_entity:     {'text': 'EU', 'pos': [113, 115]}\n",
            "\n",
            "original:       {'text': '(CSU', 'pos': [163, 167]}\n",
            "new_entity:     {'text': 'CSU', 'pos': [164, 167]}\n",
            "\n",
            "original:       {'text': '(SPD', 'pos': [291, 295]}\n",
            "new_entity:     {'text': 'SPD', 'pos': [292, 295]}\n",
            "\n",
            "original:       {'text': '/CSU', 'pos': [85, 89]}\n",
            "new_entity:     {'text': 'CSU', 'pos': [86, 89]}\n",
            "\n",
            "original:       {'text': '(FDP', 'pos': [53, 57]}\n",
            "new_entity:     {'text': 'FDP', 'pos': [54, 57]}\n",
            "\n",
            "original:       {'text': '(đảng Xanh', 'pos': [90, 100]}\n",
            "new_entity:     {'text': 'đảng Xanh', 'pos': [91, 100]}\n",
            "\n",
            "original:       {'text': '(AfD', 'pos': [48, 52]}\n",
            "new_entity:     {'text': 'AfD', 'pos': [49, 52]}\n",
            "\n",
            "original:       {'text': 'đảng “Vì tự do”', 'pos': [384, 399]}\n",
            "new_entity:     {'text': 'đảng “Vì tự do', 'pos': [384, 398]}\n",
            "\n",
            "original:       {'text': '(PVV', 'pos': [400, 404]}\n",
            "new_entity:     {'text': 'PVV', 'pos': [401, 404]}\n",
            "\n",
            "original:       {'text': '(huyện Năm Căn', 'pos': [104, 118]}\n",
            "new_entity:     {'text': 'huyện Năm Căn', 'pos': [105, 118]}\n",
            "\n",
            "original:       {'text': '(Cà Mau', 'pos': [60, 67]}\n",
            "new_entity:     {'text': 'Cà Mau', 'pos': [61, 67]}\n",
            "\n",
            "original:       {'text': '(VOV', 'pos': [0, 4]}\n",
            "new_entity:     {'text': 'VOV', 'pos': [1, 4]}\n",
            "\n",
            "original:       {'text': '(VnExpress', 'pos': [0, 10]}\n",
            "new_entity:     {'text': 'VnExpress', 'pos': [1, 10]}\n",
            "\n",
            "original:       {'text': '(Thanh niên', 'pos': [0, 11]}\n",
            "new_entity:     {'text': 'Thanh niên', 'pos': [1, 11]}\n",
            "\n",
            "original:       {'text': \"'Đông Phương Bất Bại\", 'pos': [79, 99]}\n",
            "new_entity:     {'text': 'Đông Phương Bất Bại', 'pos': [80, 99]}\n",
            "\n",
            "original:       {'text': '(Vĩnh Long', 'pos': [56, 66]}\n",
            "new_entity:     {'text': 'Vĩnh Long', 'pos': [57, 66]}\n",
            "\n",
            "original:       {'text': '(Bản Yên Sơn', 'pos': [64, 76]}\n",
            "new_entity:     {'text': 'Bản Yên Sơn', 'pos': [65, 76]}\n",
            "\n",
            "original:       {'text': '(tỉnh Thái Nguyên', 'pos': [52, 69]}\n",
            "new_entity:     {'text': 'tỉnh Thái Nguyên', 'pos': [53, 69]}\n",
            "\n",
            "original:       {'text': '(Hà Đông', 'pos': [20, 28]}\n",
            "new_entity:     {'text': 'Hà Đông', 'pos': [21, 28]}\n",
            "\n",
            "original:       {'text': '(Đống Đa', 'pos': [6, 14]}\n",
            "new_entity:     {'text': 'Đống Đa', 'pos': [7, 14]}\n",
            "\n",
            "original:       {'text': '(Australia', 'pos': [139, 149]}\n",
            "new_entity:     {'text': 'Australia', 'pos': [140, 149]}\n",
            "\n",
            "original:       {'text': '-\\xa0Nam', 'pos': [68, 73]}\n",
            "new_entity:     {'text': 'Nam', 'pos': [70, 73]}\n",
            "\n",
            "original:       {'text': '(IOM', 'pos': [164, 168]}\n",
            "new_entity:     {'text': 'IOM', 'pos': [165, 168]}\n",
            "\n",
            "original:       {'text': '(Hàn Quốc', 'pos': [38, 47]}\n",
            "new_entity:     {'text': 'Hàn Quốc', 'pos': [39, 47]}\n",
            "\n",
            "original:       {'text': '(Hà Nội)', 'pos': [128, 136]}\n",
            "new_entity:     {'text': 'Hà Nội', 'pos': [129, 135]}\n",
            "\n",
            "original:       {'text': '(Fed New York', 'pos': [170, 183]}\n",
            "new_entity:     {'text': 'Fed New York', 'pos': [171, 183]}\n",
            "\n",
            "original:       {'text': '-Việt Nam', 'pos': [247, 256]}\n",
            "new_entity:     {'text': 'Việt Nam', 'pos': [248, 256]}\n",
            "\n",
            "original:       {'text': '(Bình Định', 'pos': [192, 202]}\n",
            "new_entity:     {'text': 'Bình Định', 'pos': [193, 202]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcwMQApng86X"
      },
      "source": [
        "# Install Pytorch/XLA for using TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44bbgzl_g_2h"
      },
      "source": [
        "###import os\n",
        "###assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnJK-U0OhCJg"
      },
      "source": [
        "###!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhLi-foUnFyS"
      },
      "source": [
        "###os.environ['XLA_USE_BF16'] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrfoTuISvWoh"
      },
      "source": [
        "###!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "###!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ5JPjBUvq1g"
      },
      "source": [
        "###os.environ['XLA_USE_BF16'] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYgSRt5lcdsA"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7COIdSRHZww2"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPco5igPEJfC"
      },
      "source": [
        "\"\"\" All model config \"\"\"\n",
        "\n",
        "flags = {\n",
        "\n",
        "    'vnlib': 'underthesea',  # underthesea, vncorenlp  <- not implemented\n",
        "\n",
        "    ###### implemented\n",
        "    'model_save_folder': 'rec_save_model',\n",
        "\n",
        "    'use_phobert': True,   # True, False   (có dùng phobert hay không)\n",
        "    'phobert_model': 'phobert_base', # phobert_base, phobert_large\n",
        "    'pb_entity_handle_type': 'average_pooling',       # max_pooling, average_pooling, sum, random.  lấy max hay average pooling, ... word_piece\n",
        "    'pb_emb_layer_lst': [10,11,12,13],             # danh sách các layer mà ta sẽ lấy embedding. từ 1 -> 13 cho phobert_base, 1 -> 25 cho phobert_large. \n",
        "                                                   # layer số 1 là initial embedding\n",
        "    'pb_emb_layer_handle_type': 'sum',   # sum, concat, max_pooling, average_pooling. cách ta xử lý các layer mà ta lấy embedding. \n",
        "                                         # như concat hay lấy sum 4 layer cuối của 1 word_piece\n",
        "    'pb_combine_ents_rule': ['ent_1', 'ent_2', 'mul', 'add', 'abs_sub'], # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n",
        "                                                                         # curent not implemented, just use case above.\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # nếu sau này đổi mà khiến số lượng element của list thay đổi (khác 5)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # thì cần phải cập nhật chiều dài trong calculate_len_sent_embedding\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # sent_emb_len = entity_emb_len * 5\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # đổi 5 thành chiều dài mới của list.\n",
        "\n",
        "\n",
        "\n",
        "    'use_xlmr': True,   # True, False   (có dùng XLM-RoBERTa hay không)\n",
        "    'xlmr_model': 'xlmr_large', # xlmr_base, xlmr_large\n",
        "    'xlmr_entity_handle_type': 'average_pooling',       # max_pooling, average_pooling, sum, random.  lấy max hay average pooling, ... word_piece\n",
        "    'xlmr_emb_layer_lst': [22,23,24,25],             # danh sách các layer mà ta sẽ lấy embedding. từ 1 -> 13 cho xlmr_base, 1 -> 25 cho xlmr_large. \n",
        "                                                     # layer số 1 là initial embedding\n",
        "    'xlmr_emb_layer_handle_type': 'sum',   # sum, concat, max_pooling, average_pooling. cách ta xử lý các layer mà ta lấy embedding. \n",
        "                                           # như concat hay lấy sum 4 layer cuối của 1 word_piece\n",
        "    'xlmr_combine_ents_rule': ['ent_1', 'ent_2', 'mul', 'add', 'abs_sub'], # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n",
        "                                                                           # curent not implemented, just use case above.\n",
        "\n",
        "    # we will huggingface adamw as optimizer for phobert and xlmr\n",
        "    'phobert_num_epochs': 3,    # num epoch of fintune phobert. after this epoch, we will freeze phobert layer. 0 mean no finetune.\n",
        "    'xlmr_num_epochs': 0,       # num epoch of fintune xlmr. after this epoch, we will freeze xlmr layer. 0 mean no finetune.\n",
        "    \n",
        "\n",
        "    # implemented\n",
        "    'total_epochs': 100,       #\n",
        "    'batch_size': 32,        # 8, 16, 64\n",
        "\t\n",
        "    'dropout1_rate': 0.6,\n",
        "    'out_linear1': 1024,\n",
        "    'dropout2_rate': 0.2,\n",
        "\n",
        "    'clip_grad_norm_rate': 5.0,\n",
        "\t\n",
        "    #Note: In this notebook, I use only one optimizer for all networks, so the below parameters will also be bert layer's parameters \n",
        "    'linear_lr': 0.00001,\n",
        "    'linear_lr_schedule_epoch': 6,\n",
        "    'linear_lr_schedule_rate': 0.9,\n",
        "    'linear_weight_decay': 0.15,\n",
        "\t\n",
        "    #\n",
        "    'linear_betas': (0.9, 0.999),\n",
        "    'linear_eps': 1e-6,\n",
        "\t\n",
        "\n",
        "    'seed': 5,\n",
        "    'log_batch': 30,\n",
        "\n",
        "\n",
        "\t\n",
        "    ##### not implemented\n",
        "    'phobert_lr': 0.001,\n",
        "    'phobert_weight_decay': 0,\n",
        "    'phobert_betas': (0.9, 0.999),\n",
        "    'phobert_eps': 1e-6,\n",
        "\t\n",
        "\n",
        "    'xlmr_lr': 0.001,\n",
        "    'xlmr_weight_decay': 0,\n",
        "    'xlmr_betas': (0.9, 0.999),\n",
        "    'xlmr_eps': 1e-6,\n",
        "\t\n",
        "    \n",
        "    'num_workers': 8         # Number of tpu core. Colab has TPU V2-8 which have 8 cores.\n",
        "\n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5kMJ-VC2Iz"
      },
      "source": [
        "## Import, turn on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLGpzWTJMY7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "67aa6ac5-eb71-45e5-f506-c0b939dde5cf"
      },
      "source": [
        "import os, time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, Sampler, TensorDataset, random_split\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, XLMRobertaModel, XLMRobertaTokenizer, AdamW\n",
        "\n",
        "'''\n",
        "# TPU\n",
        "# imports the torch_xla package\n",
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# TPU\\n# imports the torch_xla package\\nimport torch\\nimport torch_xla\\nimport torch_xla.core.xla_model as xm\\nimport torch_xla.distributed.xla_multiprocessing as xmp\\n\\nimport torch_xla.distributed.parallel_loader as pl\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OWIkCz9aYyV"
      },
      "source": [
        "## Generate model and tokenier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "8d7f00da78bf4a35b98eb42551454ce0",
            "0c6e00c25d184732984eb4f161467538",
            "821e311883d942e0b2180b69ee1b552b",
            "15bdaf4a33d440fd88ab0488822edf99",
            "4db21fd4c0674c71962f5442ac94d281",
            "3fc417b825d64da68ac40858a782deef",
            "263df059f87a4150a8fca099ad6067e5",
            "afd2538138724373900eaeb1688efc36",
            "d004fe82ffb54950842e3683f45a309b",
            "a73fbf27691f4f5289c44827473d39ef",
            "433a8c5175904673921361eeb8bfd1ba",
            "dec43ca8bb29462e91bb43d0e9ffa978",
            "1305cccaccf6479d96e09db5c005129c",
            "fb6b1d045aef47e99f9b418def4d0169",
            "346844a9be4f4ad188fe618f881f97f8",
            "5b628fc67f254f2681523e7c5487c501",
            "8d4a5d444df64f63ac64fe7584abf918",
            "5032d3c7e2304bb1bac5cf7e8dd10c72",
            "8ad7137a1031403092e96267fae4d24b",
            "2b0c545137bc40089039d5d1015d8b69",
            "4114fe8078014918ae5708dd85c796b9",
            "62c0689e8e504d0faf0b01eab120ce55",
            "43aa4d7c474144b1a57173cfd8d1e693",
            "ce72904d84c04769b5137f66e79c7f73",
            "bddeeb58fc7a4b628a1d8d8e4606fb33",
            "d8f8002c48cd4d3b926ed85db70ebb78",
            "fb8a88fab00d40c8b07451fb61042e03",
            "7eb0ab1f07c34319a3b57213c52b1332",
            "6958d23cc3ae48849c07b67ecba633f4",
            "b8488973986942d8952a61359447d156",
            "bf95b4b7083b46939f8cd24b3ff9a434",
            "ae4f8237097f4350bbeab107c0da65e6",
            "e7a1671d0c0942be898144f641a3ed2b",
            "296423fb5efa40cf85745233ab577aee",
            "878eae72d87f44c5a6ab1780ec8c9269",
            "ce6743197a0a4079be034d281145fb8f",
            "d9216513b21e47bfbda01a5c3719f435",
            "2d0b964f51f24542ac84c52f7c4af45b",
            "3749cca31f1946caadb28688e9a4ca01",
            "37ad6e4238244db5a9d3afda80aeab92",
            "41dc90e15bcd4b97a2cb4f5bdf465fd9",
            "2d257cba9d5c4a108647cb05cd904cf7",
            "e179b041303643739798dfda57722b64",
            "d70aaeda98444f55b1b497a62a633d21",
            "a2a5c7ab676c42e29bd8af517c7fb4e6",
            "19b49917d2b74af9a82023ba82d769d7",
            "9b8e40e3349d4648932f2253025891bb",
            "3de39172d5fc4362965ea32ff6450466",
            "7012c91beb9548e78be43a7960c27eb3",
            "1e60446ae7734a2cbeeea429b65ff3d6",
            "907ecc2709e24f7d829dec1f581b2467",
            "edae3026e7414ab28a6439feba02d4ff",
            "16196fbd2c1e4f289788caf18374a3f5",
            "2f09a5358d8a4651b6b0d069ea914ec9",
            "4dc477952e814770aac51ae024ec07fa",
            "23a138725d914d3fad90b14c74be7979"
          ]
        },
        "id": "M5gepmeCzx1H",
        "outputId": "ea7b24ef-85ac-42a1-e169-239b798008d3"
      },
      "source": [
        "if flags['use_phobert'] == True:\n",
        "    if flags['phobert_model'] == 'phobert_base':\n",
        "        print('Using phobert_base.')\n",
        "        pb_model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "    elif flags['phobert_model'] == 'phobert_large':\n",
        "        print('Using phobert_large.')\n",
        "        pb_model = AutoModel.from_pretrained(\"vinai/phobert-large\")\n",
        "        pb_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n",
        "\n",
        "    else:\n",
        "        assert False, str('Unknown phobert model: ' + flags['phobert_model'] + '. Allowed: phobert_base and phobert_large')\n",
        "\n",
        "if flags['use_xlmr'] == True:\n",
        "    if flags['xlmr_model'] == 'xlmr_base':\n",
        "        print('Using xlmr_base.')\n",
        "        xlmr_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
        "        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "    elif flags['xlmr_model'] == 'xlmr_large':\n",
        "        print('Using xlmr_large.')\n",
        "        xlmr_model = XLMRobertaModel.from_pretrained('xlm-roberta-large')\n",
        "        xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
        "\n",
        "    else:\n",
        "        assert False, str('Unknown phobert model: ' + flags['xlmr_model'] + '. Allowed: xlmr_base and xlmr_large')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using phobert_base.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d7f00da78bf4a35b98eb42551454ce0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d004fe82ffb54950842e3683f45a309b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=542923308.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d4a5d444df64f63ac64fe7584abf918",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddeeb58fc7a4b628a1d8d8e4606fb33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using xlmr_large.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7a1671d0c0942be898144f641a3ed2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41dc90e15bcd4b97a2cb4f5bdf465fd9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7012c91beb9548e78be43a7960c27eb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMsPwfmbCx_v"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia9OejTRI52-"
      },
      "source": [
        "\n",
        "# GPU\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IADdZhElb4D4"
      },
      "source": [
        "## Create model input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DVZCoLqGFNh"
      },
      "source": [
        "Một điểm cần chú ý:\n",
        "- PhoBERT cần câu input được word tokenize sẵn (dùng VNCoreNLP hoặc Underthesea). Có vẻ là để tạo N-gram\n",
        "- XLMR thì không cần, ta cứ truyền trực tiếp câu thô vào làm input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc2MsmAt4zDF"
      },
      "source": [
        "### Get entity's word_tokenize index (PhoBERT need this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWb98FjG46cV"
      },
      "source": [
        "#### Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyVtt9BSy2ji"
      },
      "source": [
        "Một entity có thể có nhiều từ, và các từ này lại được tokenize thành nhiều word_piece. Nên một entity có thể có rất nhiều vector word_piece. Ta có thể chọn đại diện 1 vector để làm đại diện cho entity, hoặc là pooling các vector word_piece để ra 1 vector đại diện duy nhất cho entity.\n",
        "\n",
        "Để có thể pooling thì ta cần biết các word_piece nào thuộc entity. hay nói cách khác là ta cần lấy được index của các entity word_piece trong danh sách word_piece của cả câu.\n",
        "\n",
        "\n",
        "**Với Phobert**:\n",
        "- Do đầu vào cần là câu được Underthesea nên xảy ra vấn đề là word_tokenize của Underthesea cho ra kết quả không khớp với NER của entity trong dữ liệu. Ví dụ:\n",
        "  + \"Hôm nay, là ngày Quốc Tế Lao Động.\"\n",
        "  + entity: \"Quốc Tế Lao Động\"\n",
        "  + word_tokenize: [\"Hôm nay\", \"là\", \"ngày Quốc Tế\", \"Lao Động\"]\n",
        "  + tức là entity lại word_tokenize ra kết quả không trùng với entity. Nếu mà ra là: [\"Hôm nay\", \"là\", \"ngày\", \"Quốc Tế\", \"Lao Động\"] thì đẹp.\n",
        "  + Trên chỉ là một ví dụ, còn nhiều trường hợp Underthesea ra xấu hơn và phi lý vô cùng khi đọc.\n",
        "  + entity: B C D\n",
        "  + nhưng underthesea có thể ra là: [..., 'A B C D E F', ...], [..., 'A B', 'C', 'D', ...], [..., 'A B', 'C', 'D E F K'], ...\n",
        "- Nhưng tổng quát vấn đề này có các khả năng:\n",
        "  + Đầu entity trùng đầu 1 token. [..., 'B C', 'D E F',...]\n",
        "  + Đầu entity là cuối 1 token:  [..., 'A B C', 'D',...]\n",
        "  \n",
        "  + Cuối entity trùng cuối 1 token. [..., 'A B C', 'D',...]\n",
        "  + Cuối entity là đầu 1 token:  [..., 'B C', 'D E F',...]\n",
        "\n",
        "\n",
        "- Ý tưởng: biến [\"Hôm nay\", \"là\", \"ngày Quốc Tế\", \"Lao Động\"] thành [\"Hôm nay\", \"là\", \"ngày\", \"Quốc Tế\", \"Lao Động\"]. Tức là nếu đầu hay cuối entity bị lẫn, là một phần con trong một token thì ta sẽ cắt token đấy ra. Tức là ta sẽ tạo ra phiên bản word_tokenize mới dựa trên word_tokenize của Underthesea\n",
        "- Nên để lấy index của PhoBERT cần qua 2 bước:\n",
        "  + tạo word_tokenize mới và lấy index token trong entity trong word_tokenize này\n",
        "  + lấy index của word_piece các token trong câu word_tokenize mới.\n",
        "  + entity -> token -> word_piece : index_word_piece -> token <-> index token -> entity\n",
        "- ta bắt buộc phải trải qua 2 bước trên vì ta không thể tách token dựa trên word_piece của phobert được.ta phải tách trước thì word_piece của Phobert mới đẹp theo.\n",
        "\n",
        "\n",
        "Với **XLMR BERT**:\n",
        "- thì mọi thứ đơn giản hơn, ta chỉ việc fed câu gốc vào mà không cần qua Underthesea nên dễ dàng hơn không cần sửa trước như trên.\n",
        "- Nên để lấy index của XLMR thì ta chỉ việc từ index word_piece ra thẳng entity mà thôi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKLlYYYY4-r4"
      },
      "source": [
        "#### Func"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anngy6FArdp1"
      },
      "source": [
        "def my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, split_token_index, split_pos, sentence):\n",
        "\n",
        "    '''\n",
        "    word_tokenize_lst: word_tokenize_lst cần được sửa\n",
        "    tokens_non_space_pos_lst: vị trí pos indice của mọi token trong word_tokenize_lst đối với câu không có space\n",
        "    split_token_index: index của token cần được tách trong word_tokenize_lst\n",
        "    sentence: sentence gốc có space\n",
        "    split_pos: vị trí (NON SPACE) đối với câu (tại vị trí này ta sẽ tách token cần tách thành 2 phần, từ đầu token tới vị trí này,\n",
        "    và từ vị trí này đến hết token)\n",
        "    vị trí này sẽ nằm giữa đầu vs cuối của token)\n",
        "    ..... vitri_dau_token  vitri_tach_token   vitri_cuoi_token ...\n",
        "    '''\n",
        "\n",
        "    new_word_tokenize_lst = []\n",
        "    new_tokens_non_space_pos_lst = []\n",
        "\n",
        "    for itk, tk in enumerate(word_tokenize_lst):\n",
        "\n",
        "        # nếu không phải token cần tách thì cứ thêm vào list word_tokenize mới\n",
        "        if itk != split_token_index:\n",
        "            # in 'else' part below, I create same (duplicate) variable (name) for debugging easier\n",
        "            sent_non_space = ''.join(sentence.split())   # remove all space from original sentence\n",
        "            token_non_space = ''.join(tk.split())  # remove all space from current tk\n",
        "            token_non_space_pos = tokens_non_space_pos_lst[itk]\n",
        "\n",
        "            assert (sent_non_space[token_non_space_pos[0]:token_non_space_pos[1]] == token_non_space), \\\n",
        "            str('Token_non_space not match with non_space_pos.')\n",
        "                \n",
        "\n",
        "            new_word_tokenize_lst.append(tk)  # tk with space\n",
        "            new_tokens_non_space_pos_lst.append(copy.deepcopy(tokens_non_space_pos_lst[itk]))  # non space pos\n",
        "\n",
        "        \n",
        "        \n",
        "        else:   # token cần tách\n",
        "            # token: [A B C D] [E F], entity: C D E F\n",
        "            # ...      C D   E F  ...\n",
        "            # ... [A B C D] [E F] ...\n",
        "\n",
        "            #     C D E F\n",
        "            # A B C D E F\n",
        "\n",
        "            #   CDEF\n",
        "            # ABCDEF\n",
        "\n",
        "            token_space = copy.deepcopy(word_tokenize_lst[split_token_index])   # A B C D\n",
        "\n",
        "            sent_non_space = ''.join(sentence.split())   # ...ABCDEF...\n",
        "            token_non_space = ''.join(token_space.split())  # ABCD\n",
        "\n",
        "            token_non_space_pos = tokens_non_space_pos_lst[split_token_index]  # <----- pos trong sent_non_space\n",
        "                                                                               # pos ABCD trong ...ABCDEF...\n",
        "\n",
        "            # just a check\n",
        "            assert (sent_non_space[token_non_space_pos[0]:token_non_space_pos[1]] == token_non_space), \\\n",
        "            str('Token non space not match with token non space pos.')\n",
        "\n",
        "\n",
        "            token_head_non_space = sent_non_space[token_non_space_pos[0]:split_pos]   # AB\n",
        "            token_tail_non_space = sent_non_space[split_pos:token_non_space_pos[1]]   # CD\n",
        "\n",
        "            # just check even no necessary: AB+CD = ABCD\n",
        "            assert ((token_head_non_space + token_tail_non_space) == token_non_space), \\\n",
        "            str('AB+CD != ABCD')  # -.- so tired\n",
        "\n",
        "\n",
        "            subtoken_lst = token_space.split() # ['A', 'B', 'C', 'D']\n",
        "\n",
        "            \n",
        "            num_space_in_token_space = 0\n",
        "            for ctk in token_space:\n",
        "                if ctk.isspace():\n",
        "                    num_space_in_token_space += 1\n",
        "            \n",
        "\n",
        "            # 'A B C D'  ->  4 - 1 = 3 space \n",
        "            # Note: Nếu mà không bằng chính tỏ là giữa hai từ đơn trong một token (cụm từ) không chỉ có 1 dấu cách\n",
        "            # lúc này thì có thể tạo ra một list chứ số dấu cách trong token. \n",
        "            # 'A  B C   D'  ->  [2, 1, 3] \n",
        "            # giữa 'A  B' có 2 dấu cách. giữa 'B C' có 1 dấu cách. giữa 'C   D' có 3 cách. \n",
        "            assert (len(subtoken_lst) == (num_space_in_token_space + 1)), \\\n",
        "            str('Seem that underthesea word tokenize does not contain only one space between words')\n",
        "\n",
        "\n",
        "\n",
        "            sub_token_head_lst = []\n",
        "\n",
        "            for subtoken in subtoken_lst:          \n",
        "                sub_token_head_lst.append(subtoken)  # iter:  0        1\n",
        "                                                     #        ['A'] -> ['A', 'B']\n",
        "\n",
        "                if ''.join(sub_token_head_lst) == token_head_non_space:    # ''.join['A', 'B'] == 'AB'\n",
        "                    break\n",
        "                \n",
        "            # [A, B] < [A, B, C, D]   (nếu có LỖI tức là k chạy vào break ở vòng for trên thì sub_token_head_lst sẽ giống hệt subtoken_lst)\n",
        "            assert (len(sub_token_head_lst) < len(subtoken_lst)), str('[A, B] not < [A, B, C, D]')\n",
        "\n",
        "            # [A, B, C, D] - [A, B] = [C, D]\n",
        "            sub_token_tail_lst = subtoken_lst[len(sub_token_head_lst):]   # [C, D]\n",
        "\n",
        "            # ''.join(['C', 'D']) == 'CD'\n",
        "            assert (''.join(sub_token_tail_lst) == token_tail_non_space), str(\"''.join(['C', 'D']) != 'CD'\")\n",
        "\n",
        "            # just anotherrrrr checkkkkkkkkkkkkkkkkkkkkkkkk\n",
        "            # chỉ đúng nếu giữa các từ trong một token có đúng 1 dấu cách. nếu có nhiều hơn 1 thì phải dùng lst space như NOTE bên trên\n",
        "            assert (str(' '.join(sub_token_head_lst) + ' ' + ' '.join(sub_token_tail_lst)) == token_space), \\\n",
        "            str(\"' '.join(['A', 'B']) + ' ' + ' '.join(['C', 'D']) != 'A B C D'\")\n",
        "\n",
        "            # append 'A B'\n",
        "            new_word_tokenize_lst.append(' '.join(sub_token_head_lst))\n",
        "\n",
        "            token_head_non_space_pos_start = token_non_space_pos[0]\n",
        "            token_head_non_space_pos_end = token_head_non_space_pos_start + sum([len(tmp) for tmp in sub_token_head_lst])\n",
        "\n",
        "            # just check even maybe not necessary\n",
        "            assert (token_head_non_space_pos_end == split_pos), str('token_head end pos not equal to split pos.')\n",
        "            assert (sent_non_space[token_head_non_space_pos_start:token_head_non_space_pos_end] == token_head_non_space), \\\n",
        "            str('token_head_non_space not match with pos found in sent_no_space.')\n",
        "\n",
        "            new_tokens_non_space_pos_lst.append([token_head_non_space_pos_start, token_head_non_space_pos_end])\n",
        "\n",
        "                \n",
        "            # append 'C D'\n",
        "            new_word_tokenize_lst.append(' '.join(sub_token_tail_lst))\n",
        "\n",
        "            token_tail_non_space_pos_start = split_pos\n",
        "            token_tail_non_space_pos_end = token_tail_non_space_pos_start + sum([len(tmp) for tmp in sub_token_tail_lst]) # = token_non_space_pos[1]\n",
        "\n",
        "            # just check even maybe not necessary\n",
        "            assert (token_tail_non_space_pos_end == token_non_space_pos[1]), str('token_tail end pos not equal to originial token_non_space end pos.')\n",
        "            assert (sent_non_space[token_tail_non_space_pos_start:token_tail_non_space_pos_end] == token_tail_non_space), \\\n",
        "            str('token_tail_non_space not match with pos found in sent_no_space.')\n",
        "\n",
        "            new_tokens_non_space_pos_lst.append([token_tail_non_space_pos_start, token_tail_non_space_pos_end])\n",
        "                \n",
        "\n",
        "    return new_word_tokenize_lst, new_tokens_non_space_pos_lst\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCBFXtDOcytv"
      },
      "source": [
        "def get_entity_index_in_underthesea_word_tokenize(sent_id, sentence, word_tokenize_lst, entity):\n",
        "    \n",
        "    entity_text = entity['text']\n",
        "    entity_pos = entity['pos']\n",
        "\n",
        "    ##### CHECK\n",
        "\n",
        "    assert (sentence[entity_pos[0]:entity_pos[1]] == entity_text), str('\\nEntity_pos not match entity. Entity: ' + entity + '\\nsent-id: ' + str(sent_id))\n",
        "\n",
        "    assert (type(word_tokenize_lst) is list), str('word_tokenize_lst must be a list. Use Underthesea\\'s word_tokenize with out format=\"text\" option.')\n",
        "\n",
        "    # vì ta sẽ không tính đến dấu cách nên nếu kí tự đầu hoặc cuối entity là khoảng cách thì sẽ có vấn đề\n",
        "    # tức là vì không tính đến khoảng cách nên nếu mà start pos hay end pos của entity là vị trí khoảng trắng thừa thì sẽ không bao giờ match được\n",
        "    # bên trên trong phần clean data đã loại bỏ rồi nhưng cứ check lại cho chắc\n",
        "    if (entity_text[0].isspace()) or (entity_text[-1].isspace()):\n",
        "        assert False, str('\\nFirst or last character in entity is space. Entity: ' + repr(entity) + '\\nsent-id: ' + str(sent_id))\n",
        "        #print(str('\\nFirst or last character in entity is space. Entity: ' + repr(entity) + '\\nsent-id: ' + str(sent_id)))\n",
        "    \n",
        "    ##### END CHECK\n",
        "\n",
        "\n",
        "    # đếm khoảng trắng từ đầu câu đến entity start_pos\n",
        "    count_to_estart = 0\n",
        "    for c in sentence[:entity_pos[0]]:\n",
        "        if c.isspace():\n",
        "            count_to_estart += 1\n",
        "    new_estart_pos = entity_pos[0] - count_to_estart\n",
        "\n",
        "    # đếm khoảng trắng từ đầu câu đến entity end_pos\n",
        "    count_to_eend = 0\n",
        "    for c in sentence[:entity_pos[1]]:\n",
        "        if c.isspace():\n",
        "            count_to_eend += 1\n",
        "    new_eend_pos = entity_pos[1] - count_to_eend\n",
        "\n",
        "    # đếm khoảng trắng trong entity\n",
        "    '''\n",
        "    count_in_e = 0\n",
        "    for i in entity:\n",
        "        if i.isspace():\n",
        "            count_in_e += 1\n",
        "    '''\n",
        "\n",
        "    sent_no_space = ''.join(sentence.split())\n",
        "    entity_text_no_space = ''.join(entity_text.split())\n",
        "\n",
        "    assert (sent_no_space[new_estart_pos:new_eend_pos] == entity_text_no_space), \\\n",
        "    str('\\nEntity_text without space not match entity_pos without space. ' + sent_no_space + ' ' + entity_text_no_space)\n",
        "\n",
        "    #\n",
        "    pre_tkend_pos = 0\n",
        "\n",
        "    found_start = False\n",
        "    found_end = False\n",
        "\n",
        "    start_index = None\n",
        "    end_index = None\n",
        "    \n",
        "    \n",
        "    sent_non_space = ''.join(sentence.split())   # <----- câu không có khoảng trắng\n",
        "\n",
        "    tokens_non_space_pos_lst = []   # <----- pos token không khoảng trắng trong câu không có khoảng trắng\n",
        "\n",
        "\n",
        "    for itk, tk in enumerate(word_tokenize_lst):\n",
        "        # tìm pos của từng token trong câu segment\n",
        "        tkstart_pos = pre_tkend_pos   # do không tính khoảng trắng nên end của 1 token sẽ là start của token ngay sau nó (nếu có)\n",
        "        tkend_pos = tkstart_pos + sum([len(tmp) for tmp in tk.split()])\n",
        "\n",
        "        token_non_space = ''.join(tk.split())\n",
        "\n",
        "        assert (sent_non_space[tkstart_pos:tkend_pos] == token_non_space), \\\n",
        "        str('Token non space not match with token non space pos.')\n",
        "\n",
        "\n",
        "        tokens_non_space_pos_lst.append([tkstart_pos, tkend_pos])\n",
        "\n",
        "        # cập nhật pre_tkend_pos\n",
        "        pre_tkend_pos = tkend_pos\n",
        "\n",
        "\n",
        "        if tkstart_pos == new_estart_pos:\n",
        "            found_start = True\n",
        "            start_index = copy.deepcopy(itk)\n",
        "\n",
        "        if tkend_pos == new_eend_pos:\n",
        "            found_end = True\n",
        "            end_index = copy.deepcopy(itk)\n",
        "\n",
        "        #  token này sẽ phải chứa đoạn đầu của entity\n",
        "        #  ví dụ: \n",
        "        #  token: ... trưởng_phòng Cảnh_sát   ...\n",
        "        # entity:     ...    phòng Cảnh sát   ...\n",
        "        if (tkstart_pos < new_estart_pos) and (new_estart_pos < tkend_pos):\n",
        "            start_index = copy.deepcopy(itk)    # <----- có start_index nhưng found_start vẫn là false\n",
        "\n",
        "\n",
        "        #  token này sẽ phải chứa đoạn đầu của entity\n",
        "        #  ví dụ: \n",
        "        #  token: ... Nguyễn_Hiền_đỗ ...   <-----   lỗi có thật khi dùng underthesea word_tokenize\n",
        "        # entity: ... Nguyễn Hiền    ...\n",
        "        if (tkstart_pos < new_eend_pos) and (new_eend_pos < tkend_pos):\n",
        "            end_index = copy.deepcopy(itk)    # <----- có end_index nhưng found_end vẫn là false\n",
        "\n",
        "    \n",
        "    entity_eids_lst = []\n",
        "    new_word_tokenize_lst = []\n",
        "    new_tokens_non_space_pos_lst = []\n",
        "\n",
        "    if (found_start == True):\n",
        "        new_word_tokenize_lst = copy.deepcopy(word_tokenize_lst)\n",
        "        new_tokens_non_space_pos_lst = copy.deepcopy(tokens_non_space_pos_lst)\n",
        "\n",
        "    if found_start == False:\n",
        "        \n",
        "        # ta sẽ cắt token chứa phần đầu entity ra thành 2 token\n",
        "        #  token: ... [trưởng phòng] [Cảnh sát]   ...\n",
        "        # entity:     ...     phòng Cảnh sát   ... \n",
        "        #  token: ... [trưởng] [phòng] [Cảnh sát]   ...\n",
        "        # entity:     ...       phòng Cảnh sát   ... \n",
        "        \n",
        "\n",
        "        # Vì found_start = False nên phần đầu entity (một từ hoặc một vài từ đầu trong entity) sẽ nằm trong token tại vị trí start_index\n",
        "        # và phần đầu entity sẽ là phần cuối token này. và phần đầu token này (một, hay vài từ khác) sẽ phải được ngăn cách với\n",
        "        # phần đầu entity bằng dấu cách. \n",
        "        #  token:     |          |\n",
        "        #  token: ... trưởng phòng Cảnh sát   ...\n",
        "        # entity:     ...    phòng Cảnh sát   ... \n",
        "        #             |    | |   |\n",
        "        # nếu mà không có dấu cách trong token nghĩa là kiểu lỗi: token (phòng) entity (òng Cảng Sát)\n",
        "        \n",
        "        token_space = word_tokenize_lst[start_index]\n",
        "\n",
        "        num_space_in_token_space = 0\n",
        "        for ctk in token_space:\n",
        "            if ctk.isspace():\n",
        "                num_space_in_token_space += 1\n",
        "\n",
        "        assert (num_space_in_token_space > 0), \\\n",
        "        str('Found start FALSE. Token at start_index does not has space. token: ' + word_tokenize_lst[start_index] + ' entity: ' + entity_text)\n",
        "\n",
        "        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n",
        "        my_word_tokenize(word_tokenize_lst, tokens_non_space_pos_lst, start_index, new_estart_pos, sentence)\n",
        "        \n",
        "        # old_start_index: osi\n",
        "        #      osi      osi+1\n",
        "        # ... [A B C D] [E F]\n",
        "\n",
        "        # sau khi tách:\n",
        "        #      osi  osi+1 osi+2\n",
        "        # ... [A B] [C D] [E F]\n",
        "\n",
        "        start_index = start_index + 1  # osi + 1\n",
        "        end_index = end_index + 1\n",
        "\n",
        "\n",
        "                \n",
        "    if found_end == True:\n",
        "        # no need run two below commented line because we dont change anything\n",
        "        # new_word_tokenize_lst = copy.deepcopy(new_word_tokenize_lst)\n",
        "        # new_tokens_non_space_pos_lst = copy.deepcopy(new_tokens_non_space_pos_lst)\n",
        "\n",
        "        entity_eids_lst = list(range(start_index, (end_index+1)))\n",
        "\n",
        "\n",
        "    if found_end == False:\n",
        "\n",
        "        new_word_tokenize_lst, new_tokens_non_space_pos_lst = \\\n",
        "        my_word_tokenize(copy.deepcopy(new_word_tokenize_lst), copy.deepcopy(new_tokens_non_space_pos_lst), end_index, new_eend_pos, sentence)\n",
        "\n",
        "        entity_eids_lst = list(range(start_index, (end_index+1)))\n",
        "\n",
        "\n",
        "\n",
        "    entity_text_no_space = ''.join(entity_text.split()) # <- tren co roi nhung ke cu tao lai cho de theo doi\n",
        "    entity_subtoken_lst = new_word_tokenize_lst[entity_eids_lst[0]:(entity_eids_lst[-1]+1)]\n",
        "\n",
        "    entity_singleword_lst = []\n",
        "    for entity_subtoken in entity_subtoken_lst:\n",
        "        entity_singleword_lst.extend(entity_subtoken.split())\n",
        "\n",
        "    assert (entity_text_no_space == ''.join(entity_singleword_lst)), \\\n",
        "    str('FOUND ENTITY INDEX NOT MATCH WITH ENTITY TEXT')\n",
        "\n",
        "    '''\n",
        "    # k check cai nay. vi split co the khac do co dau cau nhu / hay ,\n",
        "    # DOUBLE CHECKKKKKKKKKK\n",
        "    assert (entity_singleword_lst == entity_text.split()), \\\n",
        "    str('FOUND ENTITY INDEX NOT MATCH WITH ENTITY TEXT')\n",
        "    '''\n",
        "\n",
        "    assert (sent_non_space == ''.join([itm.replace(' ', '') for itm in new_word_tokenize_lst])), \\\n",
        "    str('sent_non_space not match new_word_tokenize_lst')\n",
        "\n",
        "    assert (new_tokens_non_space_pos_lst[entity_eids_lst[0]][0] == new_estart_pos) \\\n",
        "    and (new_tokens_non_space_pos_lst[entity_eids_lst[-1]][1] == new_eend_pos), \\\n",
        "    str('TWO ENITY NON SPACE POS NOT MATCH.')\n",
        "\n",
        "    entity_pos_no_space = [new_estart_pos, new_eend_pos]\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return new_word_tokenize_lst, entity_eids_lst, entity_pos_no_space\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CuCMaFHwNuV"
      },
      "source": [
        "#### Add entity index and word_tokenize to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6LFPE13ceDo"
      },
      "source": [
        "def add_word_tokenize_and_entity_index(jdata, train_or_dev, print_output='True'):\n",
        "\n",
        "    new_jdata = []\n",
        "\n",
        "    for sentif in jdata:\n",
        "\n",
        "        word_tokenize_lst = word_tokenize(sentif['new_sentence'])\n",
        "\n",
        "        # Có duy nhất 1 câu trong tập train, chứa token bên dưới, tức là có 1 trường hợp duy nhất mà 2 từ trong 1 token nối với nhau bằng - thay vì khoảng trắng\n",
        "        # và 'Tập' là một từ trong entity\n",
        "        # có thể code để chạy được cho trường hợp dấu - này, tuy nhiên, chỉ có 1 câu duy nhất bị. và còn chưa biết các khả năng có thể xảy khi từ\n",
        "        # được ngăn bởi dấu - thay vì khoảng trắng. nhỡ một phần entity lại là ẹ-Tập thay vì Tập thì sao\n",
        "        # nên để hiểu rõ hơn về dữ liệu chỉ sửa tạm như dưới, có nhiều hơn 1 thì mới tính đến thêm vào func bên trên\n",
        "        # bên dưới ta tạo word_tokenize_lst mới bằng tay để code trong func không lỗi \n",
        "        if ('mẹ-Tập' in word_tokenize_lst) and (train_or_dev == 'train'):\n",
        "            specia_index = word_tokenize_lst.index('mẹ-Tập')\n",
        "            word_tokenize_lst.insert((specia_index+1), 'Tập')\n",
        "            word_tokenize_lst[specia_index] = 'mẹ-'\n",
        "\n",
        "        \n",
        "\n",
        "        new_word_tokenize_lst_1, entity_1_eids_lst, entity_1_pos_no_space = \\\n",
        "        get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], word_tokenize_lst, sentif['new_entity_1'])\n",
        "\n",
        "        new_word_tokenize_lst_2, entity_2_eids_lst, entity_2_pos_no_space = \\\n",
        "        get_entity_index_in_underthesea_word_tokenize(sentif['sent_id'], sentif['new_sentence'], copy.deepcopy(new_word_tokenize_lst_1), sentif['new_entity_2'])\n",
        "        \n",
        "\n",
        "        ######## HOT FIX\n",
        "        # trong câu có sent_id là 1216 , có cụm từ 'CĐ Sư phạm Mỹ thuật'\n",
        "        # trong new_word_tokenize_lst_2 thì sẽ là: 'CĐ Sư phạm', 'Mỹ thuật'\n",
        "        # có vẻ ổn, nhìn vào thì thấy k có vấn đề gì nhưng khi fed vào phobert thì CĐ_Sư_phạm phobert word piece thành 'CĐ', '_S', 'ư_phạm'\n",
        "        # dẫn tới việc 'ư_phạm' k có trong vocab và bị thành <UNK> và k tìm được index word piece cho entity này\n",
        "        # nên ta cần sửa lại trong new_word_tokenize_lst_2, biến 'CĐ Sư phạm' thành 'CĐ', 'Sư phạm' thì k bị lỗi nữa\n",
        "        # và cũng cần đổi entity wtk_index.\n",
        "        # chỉ duy nhất 1 câu bị lỗi này trong tập train nên ta chỉ cần tách thủ công\n",
        "\n",
        "        if (sentif['sent_id'] == 1216) and (train_or_dev == 'train'):\n",
        "            nfix_tk_id = new_word_tokenize_lst_2.index('CĐ Sư phạm')\n",
        "\n",
        "            new_word_tokenize_lst_2.insert((nfix_tk_id+1), unicodedata.normalize(\"NFC\", 'Sư phạm'))\n",
        "            new_word_tokenize_lst_2[nfix_tk_id] = copy.deepcopy(unicodedata.normalize(\"NFC\", 'CĐ'))\n",
        "\n",
        "            # chi co entity_2_eids_lst bi anh huong boi viec tach tren\n",
        "            entity_2_eids_lst.append(entity_2_eids_lst[-1] + 1)\n",
        "\n",
        "        ########\n",
        "\n",
        "\n",
        "\n",
        "        new_sentif = copy.deepcopy(sentif)\n",
        "\n",
        "        # from underthesea: https://github.com/undertheseanlp/underthesea/blob/master/underthesea/word_tokenize/__init__.py#L45\n",
        "        # new_sentif['word_tokenize_sentence'] = copy.deepcopy(u\" \".join([item.replace(\" \", \"_\") for item in new_word_tokenize_lst_2]))\n",
        "        new_sentif['word_tokenize_lst'] = copy.deepcopy(new_word_tokenize_lst_2)\n",
        "\n",
        "        new_sentif['new_entity_1']['wtk_index_lst'] = copy.deepcopy(entity_1_eids_lst)\n",
        "        new_sentif['new_entity_2']['wtk_index_lst'] = copy.deepcopy(entity_2_eids_lst)\n",
        "\n",
        "        new_sentif['new_entity_1']['pos_no_space'] = copy.deepcopy(entity_1_pos_no_space)\n",
        "        new_sentif['new_entity_2']['pos_no_space'] = copy.deepcopy(entity_2_pos_no_space)\n",
        "\n",
        "\n",
        "        new_jdata.append(copy.deepcopy(new_sentif))\n",
        "\n",
        "        # phần cũ vẫn phải y nguyên. bên trên chỉ thêm 'word_tokenize_sentence', và thêm 'wtk_index_lst' vào 'new_entity_1' và 'new_entity_2'\n",
        "        assert (new_jdata[-1]['sent_id'] == sentif['sent_id']), str('FAILED TO COPY sent_id. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['doc_id'] == sentif['doc_id']), str('FAILED TO COPY doc_id. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['sentence'] == sentif['sentence']), str('FAILED TO COPY sentence. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['entity_1'] == sentif['entity_1']), str('FAILED TO COPY entity_1. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['entity_2'] == sentif['entity_2']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['label'] == sentif['label']), str('FAILED TO COPY SENT_ID. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['spos'] == sentif['spos']), str('FAILED TO COPY spos. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['new_sentence'] == sentif['new_sentence']), str('FAILED TO COPY new_sentence. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['new_entity_1']['text'] == sentif['new_entity_1']['text']), str('FAILED TO COPY new_entity_1 text. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['new_entity_2']['text'] == sentif['new_entity_2']['text']), str('FAILED TO COPY new_entity_2 text. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['new_entity_1']['pos'] == sentif['new_entity_1']['pos']), str('FAILED TO COPY new_entity_1 pos. sent_id: ' + sentif['sent_id'])\n",
        "        assert (new_jdata[-1]['new_entity_2']['pos'] == sentif['new_entity_2']['pos']), str('FAILED TO COPY new_entity_2 pos. sent_id: ' + sentif['sent_id'])\n",
        "        \n",
        "\n",
        "        assert (new_jdata[-1]['new_entity_1']['wtk_index_lst'] == entity_1_eids_lst), str('Fail to copy or add entity_1_eids_lst')\n",
        "        assert (new_jdata[-1]['new_entity_2']['wtk_index_lst'] == entity_2_eids_lst), str('Fail to copy or add entity_2_eids_lst')\n",
        "\n",
        "        if print_output == True:\n",
        "            if (new_word_tokenize_lst_1 != word_tokenize_lst) or (new_word_tokenize_lst_2 != word_tokenize_lst):\n",
        "\n",
        "                print('\\n\\n---------- sent_id: ', sentif['sent_id'])\n",
        "                print('sentence: ', sentif['sentence'])\n",
        "\n",
        "                if (new_word_tokenize_lst_1 != word_tokenize_lst):\n",
        "                    print('\\nentity: ', sentif['new_entity_1'])\n",
        "                    print('entity index list: ', entity_1_eids_lst)\n",
        "                    print(new_word_tokenize_lst_1[entity_1_eids_lst[0]:(entity_1_eids_lst[-1]+1)])\n",
        "                    print(entity_1_pos_no_space)\n",
        "                    print('Underthesea word_tokenize: ', word_tokenize_lst)\n",
        "                    print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n",
        "\n",
        "                if (new_word_tokenize_lst_2 != new_word_tokenize_lst_1):\n",
        "                    print('\\nentity: ', sentif['new_entity_2'])\n",
        "                    print('entity index list: ', entity_2_eids_lst)\n",
        "                    print(entity_2_pos_no_space)\n",
        "                    print(new_word_tokenize_lst_2[entity_2_eids_lst[0]:(entity_2_eids_lst[-1]+1)])\n",
        "                    print('My word_tokenize 1:        ', new_word_tokenize_lst_1)\n",
        "                    print('My word_tokenize 2:        ', new_word_tokenize_lst_2)\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    print('Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.')\n",
        "\n",
        "    return new_jdata\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pQSd9DT2nAR"
      },
      "source": [
        "### Get entity's wordpice index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwH8NmK2tRp"
      },
      "source": [
        "def get_entity_word_piece_index(sent_id, bert_tokenize_lst, entity, sentence, model_name, input_ids, train_or_dev):\n",
        "\n",
        "    '''\n",
        "    bert_tokenize_lst là list thu đuọc từ tokenizer.tokenize(sentence)\n",
        "    tức là chưa có special_token. nên start, end index sẽ phải +1 vì sau này khi encode sẽ có thêm 1 special token ở đầu\n",
        "\n",
        "    '''\n",
        "\n",
        "    entity_pos_no_space = entity['pos_no_space']\n",
        "\n",
        "    sent_non_space = ''.join(sentence.split())\n",
        "\n",
        "    found_start, found_end = None, None\n",
        "    start_index, end_index = None, None\n",
        "\n",
        "    pre_wpiend_pos = 0\n",
        "\n",
        "    # có 1 vài câu có là kí tự bắt đầu câu, nhưng xlmr tokenize sẽ bỏ nó đi, k coi n là 1 token\n",
        "    # nên token đầu tiên trong xlmr tokenize là từ thứ 2 trong câu và bắt đầu từ pos là 1.\n",
        "    # phobert k bỏ cái này nên k cần sửa\n",
        "    if ('\\ufeff' in sent_non_space) and (model_name == 'xlmr') and (train_or_dev == 'train'):\n",
        "        assert ('\\ufeff' == sent_non_space[0]), str('\\\\ufeff in sentence but not the first character of sentence.')\n",
        "\n",
        "        pre_wpiend_pos = 1\n",
        "\n",
        "\n",
        "    if ('\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b\\u200b' in sent_non_space) and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n",
        "        assert (sent_non_space.count('\\u200b') == 7), str('sent_non_space count \\\\u200b not equal 7.')\n",
        "\n",
        "        pre_wpiend_pos = 7\n",
        "    \n",
        "    if ('\\ufeff' in sent_non_space) and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n",
        "        assert ('\\ufeff' == sent_non_space[0]), str('\\\\ufeff in sentence but not the first character of sentence.')\n",
        "\n",
        "        pre_wpiend_pos = 1\n",
        "\n",
        "\n",
        "    for iwpi, wpi in enumerate(bert_tokenize_lst):\n",
        "\n",
        "        assert ((' ' not in wpi) and ('\\xa0' not in wpi)), str(' there is space in word piece.')\n",
        "\n",
        "        # phobert\n",
        "        clean_wpi = wpi.replace('_', '')\n",
        "        clean_wpi = clean_wpi.replace('@@', '')\n",
        "        # xlmr\n",
        "        clean_wpi = clean_wpi.replace('▁', '')\n",
        "\n",
        "        wpi_start_pos = copy.deepcopy(pre_wpiend_pos)\n",
        "        wpi_end_pos = wpi_start_pos + len(clean_wpi)\n",
        "\n",
        "        pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "\n",
        "        #assert (sent_non_space[wpi_start_pos:wpi_end_pos] == clean_wpi), str('Word_piece not match with non space pos.')\n",
        "\n",
        "        if sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi:\n",
        "\n",
        "            # xlmr biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n",
        "            # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n",
        "            # tương tự với ½ thành 1⁄2\n",
        "            if (clean_wpi == '...') and (sent_non_space[wpi_start_pos] == '…') and (model_name == 'xlmr') and (train_or_dev == 'train'):\n",
        "                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n",
        "                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "            elif (clean_wpi == '1⁄2') and (sent_non_space[wpi_start_pos] == '½') and (model_name == 'xlmr') and (train_or_dev == 'train'):\n",
        "                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n",
        "                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "            \n",
        "            # trường hợp bên dưới thì chỉ đơn giản là so sánh thì k giống nhau nhưng pos k đổi nên k k cần làm gì hết\n",
        "            elif (clean_wpi == '2') and (sent_non_space[wpi_start_pos] == '²') and (model_name == 'xlmr') and (train_or_dev == 'train'):\n",
        "                #wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n",
        "                #pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "                pass\n",
        "\n",
        "            \n",
        "            elif (clean_wpi == '...') and (sent_non_space[wpi_start_pos] == '…') and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n",
        "                wpi_end_pos = copy.deepcopy(wpi_start_pos + 1)\n",
        "                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "\n",
        "            elif (clean_wpi == 'một') and (sent_non_space[wpi_start_pos] == '\\u200b') and (model_name == 'xlmr') and (train_or_dev == 'dev'):\n",
        "                wpi_start_pos = copy.deepcopy(wpi_start_pos + 1)\n",
        "                wpi_end_pos = copy.deepcopy(wpi_start_pos + len(clean_wpi))\n",
        "                pre_wpiend_pos = copy.deepcopy(wpi_end_pos)\n",
        "\n",
        "                assert (sent_non_space[wpi_start_pos:wpi_end_pos] == clean_wpi), str('AFTER FIX: Word_piece not match with non space pos.')\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                print('-----sent_id: ', str(sent_id))\n",
        "                print('sentence:       ', repr(sentence))\n",
        "                print('sent_non_space: ', repr(sent_non_space))\n",
        "                print('cut from sent_non_space: ', repr(sent_non_space[wpi_start_pos:wpi_end_pos]))\n",
        "                print('wpi: ', repr(wpi))\n",
        "                print('clean_wpi: ', repr(clean_wpi))\n",
        "                print('wpi_start_pos: ', wpi_start_pos)\n",
        "                print('wpi_end_pos: ', wpi_end_pos)\n",
        "                print(bert_tokenize_lst)\n",
        "\n",
        "                assert False, str('Word_piece not match with non space pos.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if wpi_start_pos == entity_pos_no_space[0]:\n",
        "            start_index = iwpi\n",
        "            found_start = True\n",
        "\n",
        "        if wpi_end_pos == entity_pos_no_space[1]:\n",
        "            end_index = iwpi\n",
        "            found_end = True\n",
        "            break # k duoc xoa break, vi trong xlmr co truong hop wpi la '▁' ngay sau entity nen bi lan vao entity\n",
        "\n",
        "\n",
        "    # check\n",
        "    assert ((found_start == True) and (found_end == True)), str('No word piece non space pos match with entity non space pos.')\n",
        "\n",
        "    found_entity_text = ''.join(bert_tokenize_lst[start_index:(end_index+1)])\n",
        "    found_entity_text = found_entity_text.replace('_', '')\n",
        "    found_entity_text = found_entity_text.replace('@@', '')\n",
        "    found_entity_text = found_entity_text.replace('▁', '')\n",
        "\n",
        "\n",
        "    entity_text_no_space = ''.join(entity['text'].split())\n",
        "\n",
        "    assert (found_entity_text == entity_text_no_space), str('found entity text not match entity text.' + found_entity_text + ' ' + entity_text_no_space)\n",
        "\n",
        "    # start_index, end_index đều được tăng lên 1 vì sau này sẽ có thêm 1 special token ở đầu input_ids\n",
        "    entity_wpi_ids_lst = list(range((start_index+1), (end_index+2)))\n",
        "\n",
        "\n",
        "    tmp_ent_txt = ''\n",
        "\n",
        "    for entity_wpi_id in entity_wpi_ids_lst:\n",
        "        if model_name == 'phobert':\n",
        "            tmp_ent_txt += pb_tokenizer.decode([input_ids[entity_wpi_id]])\n",
        "        elif model_name == 'xlmr':\n",
        "            tmp_ent_txt += xlmr_tokenizer.decode([input_ids[entity_wpi_id]])\n",
        "        \n",
        "        else:\n",
        "            assert False, str('Unknown model_name. Alow: phobert, xlmr')\n",
        "    \n",
        "    tmp_ent_txt = tmp_ent_txt.replace(' ', '')\n",
        "    tmp_ent_txt = tmp_ent_txt.replace('_', '')\n",
        "    tmp_ent_txt = tmp_ent_txt.replace('@@', '')\n",
        "    tmp_ent_txt = tmp_ent_txt.replace('▁', '')\n",
        "\n",
        "    assert (tmp_ent_txt == entity_text_no_space), str('entity text decode not match entity text. ' + str(sent_id) + ' ' + tmp_ent_txt + ' ' + entity_text_no_space)\n",
        "    \n",
        "\n",
        "    return entity_wpi_ids_lst\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAeHqITIgWdI"
      },
      "source": [
        "### Encode label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vspAwSYXgeuB"
      },
      "source": [
        "def encode_label(sentence_label):\n",
        "    label = -1\n",
        "    if sentence_label == \"LOCATED\":\n",
        "        label = 0\n",
        "    elif sentence_label == \"PART_WHOLE\":\n",
        "        label = 1\n",
        "    elif sentence_label == \"PERSONAL_SOCIAL\":\n",
        "        label = 2\n",
        "    elif sentence_label == \"AFFILIATION\":\n",
        "        label = 3\n",
        "    elif sentence_label == \"IS_LOCATED\":\n",
        "        label = 4\n",
        "    elif sentence_label == \"WHOLE_PART\":\n",
        "        label = 5\n",
        "    elif sentence_label == \"AFFILIATION_TO\":\n",
        "        label = 6\n",
        "    elif sentence_label == \"OTHERS\":\n",
        "        label = 7\n",
        "    else:\n",
        "        assert False, \"UNKNOWN LABEL\"\n",
        "    \n",
        "    return label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nFiNJVV5DTf"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0Pwkh5W6wZ4"
      },
      "source": [
        "##### Add entity index and word_tokenize to traindata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Howkrjf35HV5",
        "outputId": "8b46a495-99e7-4f5c-986c-96a3fb70cffe"
      },
      "source": [
        "# sẽ in ra việc những câu mà underthesea word_tokenize bị thay đổi cho đúng với entity_text\n",
        "jtrain_data_v3 = copy.deepcopy(add_word_tokenize_and_entity_index(jtrain_data_v2, 'train', print_output=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "---------- sent_id:  7787\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "[80, 90]\n",
            "['Nina', 'Nguyễn']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7792\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7794\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7795\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7796\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7797\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7798\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [40, 41]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7799\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Nina Nguyễn', 'pos': [102, 113]}\n",
            "entity index list:  [19, 20]\n",
            "['Nina', 'Nguyễn']\n",
            "[80, 90]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn', '(', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7803\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7807\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7810\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7812\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "[167, 177]\n",
            "['Minh', 'Trường']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7814\n",
            "sentence:  Bà Minh Tâm (nguyên thư ký tòa soạn báo Lao Động ); ông Trình Lê (phóng viên đài SBS Australia ); chị Nina Nguyễn (Hoa hậu Việt Nam tại Úc 2014); chị Ha Young Chul (nữ doanh nhân thành đạt người Hàn Quốc ) và anh Minh Trường (MC nổi tiếng tại Úc ).\n",
            "\n",
            "entity:  {'text': 'Minh Trường', 'pos': [213, 224]}\n",
            "entity index list:  [39, 40]\n",
            "['Minh', 'Trường']\n",
            "[167, 177]\n",
            "Underthesea word_tokenize:  ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Minh Tâm', '(', 'nguyên', 'thư ký', 'tòa soạn', 'báo', 'Lao Động', ')', ';', 'ông', 'Trình Lê', '(', 'phóng viên', 'đài', 'SBS Australia', ')', ';', 'chị', 'Nina', 'Nguyễn (', 'Hoa hậu', 'Việt Nam', 'tại', 'Úc', '2014', ')', ';', 'chị', 'Ha Young Chul', '(', 'nữ', 'doanh nhân', 'thành đạt', 'người', 'Hàn Quốc', ')', 'và', 'anh', 'Minh', 'Trường', '(', 'MC', 'nổi tiếng', 'tại', 'Úc', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7824\n",
            "sentence:  Chính thức giảm 25% phí cao tốc Pháp Vân – Cầu Giẽ Chiều 22/9, Bộ Giao thông, vận tải đã chính thức đồng ý với đề xuất giảm 25% giá vé trên tuyến BOT Pháp Vân - Cầu Giẽ .\n",
            "\n",
            "entity:  {'text': 'cao tốc Pháp Vân – Cầu Giẽ', 'pos': [24, 50]}\n",
            "entity index list:  [5, 6, 7, 8]\n",
            "['cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ']\n",
            "[19, 39]\n",
            "Underthesea word_tokenize:  ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "My word_tokenize 1:         ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ', 'Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7825\n",
            "sentence:  Chính thức giảm 25% phí cao tốc Pháp Vân – Cầu Giẽ Chiều 22/9, Bộ Giao thông, vận tải đã chính thức đồng ý với đề xuất giảm 25% giá vé trên tuyến BOT Pháp Vân - Cầu Giẽ .\n",
            "\n",
            "entity:  {'text': 'cao tốc Pháp Vân – Cầu Giẽ', 'pos': [24, 50]}\n",
            "entity index list:  [5, 6, 7, 8]\n",
            "['cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ']\n",
            "[19, 39]\n",
            "Underthesea word_tokenize:  ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "My word_tokenize 1:         ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ', 'Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7826\n",
            "sentence:  Chính thức giảm 25% phí cao tốc Pháp Vân – Cầu Giẽ Chiều 22/9, Bộ Giao thông, vận tải đã chính thức đồng ý với đề xuất giảm 25% giá vé trên tuyến BOT Pháp Vân - Cầu Giẽ .\n",
            "\n",
            "entity:  {'text': 'cao tốc Pháp Vân – Cầu Giẽ', 'pos': [24, 50]}\n",
            "entity index list:  [5, 6, 7, 8]\n",
            "['cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ']\n",
            "[19, 39]\n",
            "Underthesea word_tokenize:  ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "My word_tokenize 1:         ['Chính thức', 'giảm', '25', '%', 'phí', 'cao tốc', 'Pháp Vân', '–', 'Cầu Giẽ', 'Chiều', '22/9', ',', 'Bộ', 'Giao thông', ',', 'vận tải', 'đã', 'chính thức', 'đồng ý', 'với', 'đề xuất', 'giảm', '25', '%', 'giá', 'vé', 'trên', 'tuyến', 'BOT', 'Pháp Vân', '-', 'Cầu Giẽ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7961\n",
            "sentence:  Tổng Giám đốc Uber tại London Tom Elvidge cho biết sẽ lập tức đưa vụ việc lên tòa án.\n",
            "\n",
            "entity:  {'text': 'London', 'pos': [23, 29]}\n",
            "entity index list:  [3]\n",
            "[18, 24]\n",
            "['London']\n",
            "My word_tokenize 1:         ['Tổng Giám đốc', 'Uber', 'tại', 'London Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "My word_tokenize 2:         ['Tổng Giám đốc', 'Uber', 'tại', 'London', 'Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7962\n",
            "sentence:  Tổng Giám đốc Uber tại London Tom Elvidge cho biết sẽ lập tức đưa vụ việc lên tòa án.\n",
            "\n",
            "entity:  {'text': 'Tom Elvidge', 'pos': [30, 41]}\n",
            "entity index list:  [4]\n",
            "[24, 34]\n",
            "['Tom Elvidge']\n",
            "My word_tokenize 1:         ['Tổng Giám đốc', 'Uber', 'tại', 'London Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "My word_tokenize 2:         ['Tổng Giám đốc', 'Uber', 'tại', 'London', 'Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7963\n",
            "sentence:  Tổng Giám đốc Uber tại London Tom Elvidge cho biết sẽ lập tức đưa vụ việc lên tòa án.\n",
            "\n",
            "entity:  {'text': 'London', 'pos': [23, 29]}\n",
            "entity index list:  [3]\n",
            "['London']\n",
            "[18, 24]\n",
            "Underthesea word_tokenize:  ['Tổng Giám đốc', 'Uber', 'tại', 'London Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "My word_tokenize 1:         ['Tổng Giám đốc', 'Uber', 'tại', 'London', 'Tom Elvidge', 'cho', 'biết', 'sẽ', 'lập tức', 'đưa', 'vụ việc', 'lên', 'tòa án', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7975\n",
            "sentence:  Thị trưởng London Sadiq Khan tuyên bố ủng hộ quyết định của TfL không gia hạn giấy phép của Uber .\n",
            "\n",
            "entity:  {'text': 'London', 'pos': [11, 17]}\n",
            "entity index list:  [1]\n",
            "['London']\n",
            "[9, 15]\n",
            "Underthesea word_tokenize:  ['Thị trưởng', 'London Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "My word_tokenize 1:         ['Thị trưởng', 'London', 'Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7976\n",
            "sentence:  Thị trưởng London Sadiq Khan tuyên bố ủng hộ quyết định của TfL không gia hạn giấy phép của Uber .\n",
            "\n",
            "entity:  {'text': 'London', 'pos': [11, 17]}\n",
            "entity index list:  [1]\n",
            "['London']\n",
            "[9, 15]\n",
            "Underthesea word_tokenize:  ['Thị trưởng', 'London Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "My word_tokenize 1:         ['Thị trưởng', 'London', 'Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7977\n",
            "sentence:  Thị trưởng London Sadiq Khan tuyên bố ủng hộ quyết định của TfL không gia hạn giấy phép của Uber .\n",
            "\n",
            "entity:  {'text': 'London', 'pos': [11, 17]}\n",
            "entity index list:  [1]\n",
            "['London']\n",
            "[9, 15]\n",
            "Underthesea word_tokenize:  ['Thị trưởng', 'London Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "My word_tokenize 1:         ['Thị trưởng', 'London', 'Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7978\n",
            "sentence:  Thị trưởng London Sadiq Khan tuyên bố ủng hộ quyết định của TfL không gia hạn giấy phép của Uber .\n",
            "\n",
            "entity:  {'text': 'Sadiq Khan', 'pos': [18, 28]}\n",
            "entity index list:  [2]\n",
            "['Sadiq Khan']\n",
            "[15, 24]\n",
            "Underthesea word_tokenize:  ['Thị trưởng', 'London Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "My word_tokenize 1:         ['Thị trưởng', 'London', 'Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7979\n",
            "sentence:  Thị trưởng London Sadiq Khan tuyên bố ủng hộ quyết định của TfL không gia hạn giấy phép của Uber .\n",
            "\n",
            "entity:  {'text': 'Sadiq Khan', 'pos': [18, 28]}\n",
            "entity index list:  [2]\n",
            "['Sadiq Khan']\n",
            "[15, 24]\n",
            "Underthesea word_tokenize:  ['Thị trưởng', 'London Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "My word_tokenize 1:         ['Thị trưởng', 'London', 'Sadiq Khan', 'tuyên bố', 'ủng hộ', 'quyết định', 'của', 'TfL', 'không', 'gia hạn', 'giấy phép', 'của', 'Uber', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8022\n",
            "sentence:  Trong khi đó, Giám đốc điều hành Văn phòng quản lý Thiên tai và Tình trạng khẩn cấp Puerto Rico Abner Gomez Cortes cho hay, hệ thống mạng viễn thông trên toàn đảo cũng “sụp đổ” trước sức tàn phá của bão Maria.\n",
            "\n",
            "entity:  {'text': 'Văn phòng quản lý Thiên tai và Tình trạng khẩn cấp Puerto Rico', 'pos': [33, 95]}\n",
            "entity index list:  [6, 7, 8, 9, 10, 11, 12]\n",
            "['Văn phòng', 'quản lý', 'Thiên tai', 'và', 'Tình trạng', 'khẩn cấp', 'Puerto Rico']\n",
            "[26, 76]\n",
            "Underthesea word_tokenize:  ['Trong', 'khi', 'đó', ',', 'Giám đốc', 'điều hành Văn phòng', 'quản lý', 'Thiên tai', 'và', 'Tình trạng', 'khẩn cấp', 'Puerto Rico Abner Gomez Cortes', 'cho', 'hay', ',', 'hệ thống', 'mạng', 'viễn thông', 'trên', 'toàn', 'đảo', 'cũng', '“', 'sụp đổ', '”', 'trước', 'sức', 'tàn phá', 'của', 'bão', 'Maria', '.']\n",
            "My word_tokenize 1:         ['Trong', 'khi', 'đó', ',', 'Giám đốc', 'điều hành', 'Văn phòng', 'quản lý', 'Thiên tai', 'và', 'Tình trạng', 'khẩn cấp', 'Puerto Rico', 'Abner Gomez Cortes', 'cho', 'hay', ',', 'hệ thống', 'mạng', 'viễn thông', 'trên', 'toàn', 'đảo', 'cũng', '“', 'sụp đổ', '”', 'trước', 'sức', 'tàn phá', 'của', 'bão', 'Maria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8030\n",
            "sentence:  Trần Khánh Tận dụng việc FLC Thanh Hóa , Hà Nội FC và Sài Gòn FC thi đấu muộn, Quảng Nam FC giành chiến thắng đầy nhọc nhằn trước Hải Phòng để vươn lên vị trí đầu bảng.\n",
            "\n",
            "entity:  {'text': 'Trần Khánh', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Trần Khánh']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Trần Khánh Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "My word_tokenize 1:         ['Trần Khánh', 'Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8031\n",
            "sentence:  Trần Khánh Tận dụng việc FLC Thanh Hóa , Hà Nội FC và Sài Gòn FC thi đấu muộn, Quảng Nam FC giành chiến thắng đầy nhọc nhằn trước Hải Phòng để vươn lên vị trí đầu bảng.\n",
            "\n",
            "entity:  {'text': 'Trần Khánh', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Trần Khánh']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Trần Khánh Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "My word_tokenize 1:         ['Trần Khánh', 'Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8032\n",
            "sentence:  Trần Khánh Tận dụng việc FLC Thanh Hóa , Hà Nội FC và Sài Gòn FC thi đấu muộn, Quảng Nam FC giành chiến thắng đầy nhọc nhằn trước Hải Phòng để vươn lên vị trí đầu bảng.\n",
            "\n",
            "entity:  {'text': 'Trần Khánh', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Trần Khánh']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Trần Khánh Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "My word_tokenize 1:         ['Trần Khánh', 'Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8033\n",
            "sentence:  Trần Khánh Tận dụng việc FLC Thanh Hóa , Hà Nội FC và Sài Gòn FC thi đấu muộn, Quảng Nam FC giành chiến thắng đầy nhọc nhằn trước Hải Phòng để vươn lên vị trí đầu bảng.\n",
            "\n",
            "entity:  {'text': 'Trần Khánh', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Trần Khánh']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Trần Khánh Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "My word_tokenize 1:         ['Trần Khánh', 'Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8034\n",
            "sentence:  Trần Khánh Tận dụng việc FLC Thanh Hóa , Hà Nội FC và Sài Gòn FC thi đấu muộn, Quảng Nam FC giành chiến thắng đầy nhọc nhằn trước Hải Phòng để vươn lên vị trí đầu bảng.\n",
            "\n",
            "entity:  {'text': 'Trần Khánh', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Trần Khánh']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Trần Khánh Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "My word_tokenize 1:         ['Trần Khánh', 'Tận dụng', 'việc', 'FLC', 'Thanh Hóa', ',', 'Hà Nội', 'FC', 'và', 'Sài Gòn', 'FC', 'thi đấu', 'muộn', ',', 'Quảng Nam', 'FC', 'giành', 'chiến thắng', 'đầy', 'nhọc nhằn', 'trước', 'Hải Phòng', 'để', 'vươn', 'lên', 'vị trí', 'đầu bảng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8053\n",
            "sentence:  Đánh IS tơi bời, quân đội Syria thắng lớn ở bờ Tây sông Euphrates Quân đội Syria tiếp tục hoạt động quân sự chống lại IS ở Tây Deir Ezzur , và giành lại quyền kiểm soát nhiều khu vực trong tỉnh.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [127, 137]}\n",
            "entity index list:  [23]\n",
            "[99, 108]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "My word_tokenize 2:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8057\n",
            "sentence:  Đánh IS tơi bời, quân đội Syria thắng lớn ở bờ Tây sông Euphrates Quân đội Syria tiếp tục hoạt động quân sự chống lại IS ở Tây Deir Ezzur , và giành lại quyền kiểm soát nhiều khu vực trong tỉnh.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [127, 137]}\n",
            "entity index list:  [23]\n",
            "[99, 108]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "My word_tokenize 2:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8060\n",
            "sentence:  Đánh IS tơi bời, quân đội Syria thắng lớn ở bờ Tây sông Euphrates Quân đội Syria tiếp tục hoạt động quân sự chống lại IS ở Tây Deir Ezzur , và giành lại quyền kiểm soát nhiều khu vực trong tỉnh.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [127, 137]}\n",
            "entity index list:  [23]\n",
            "[99, 108]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "My word_tokenize 2:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8062\n",
            "sentence:  Đánh IS tơi bời, quân đội Syria thắng lớn ở bờ Tây sông Euphrates Quân đội Syria tiếp tục hoạt động quân sự chống lại IS ở Tây Deir Ezzur , và giành lại quyền kiểm soát nhiều khu vực trong tỉnh.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [127, 137]}\n",
            "entity index list:  [23]\n",
            "[99, 108]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "My word_tokenize 2:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8063\n",
            "sentence:  Đánh IS tơi bời, quân đội Syria thắng lớn ở bờ Tây sông Euphrates Quân đội Syria tiếp tục hoạt động quân sự chống lại IS ở Tây Deir Ezzur , và giành lại quyền kiểm soát nhiều khu vực trong tỉnh.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [127, 137]}\n",
            "entity index list:  [23]\n",
            "[99, 108]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "My word_tokenize 2:         ['Đánh', 'IS', 'tơi bời', ',', 'quân đội', 'Syria', 'thắng', 'lớn', 'ở', 'bờ', 'Tây', 'sông', 'Euphrates', 'Quân đội', 'Syria', 'tiếp tục', 'hoạt động', 'quân sự', 'chống', 'lại', 'IS', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'giành', 'lại', 'quyền', 'kiểm soát', 'nhiều', 'khu vực', 'trong', 'tỉnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8065\n",
            "sentence:  Nguồn tin quân sự cho hay, quân đội chính phủ Syria tiếp tục tiến lên bờ Tây sông Euphrates ở Tây Deir Ezzur , và lấy lại quyền kiểm soát thị trấn al-Tabani .\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [98, 108]}\n",
            "entity index list:  [18]\n",
            "[77, 86]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "My word_tokenize 2:         ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8067\n",
            "sentence:  Nguồn tin quân sự cho hay, quân đội chính phủ Syria tiếp tục tiến lên bờ Tây sông Euphrates ở Tây Deir Ezzur , và lấy lại quyền kiểm soát thị trấn al-Tabani .\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [98, 108]}\n",
            "entity index list:  [18]\n",
            "[77, 86]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "My word_tokenize 2:         ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8069\n",
            "sentence:  Nguồn tin quân sự cho hay, quân đội chính phủ Syria tiếp tục tiến lên bờ Tây sông Euphrates ở Tây Deir Ezzur , và lấy lại quyền kiểm soát thị trấn al-Tabani .\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [98, 108]}\n",
            "entity index list:  [18]\n",
            "['Deir Ezzur']\n",
            "[77, 86]\n",
            "Underthesea word_tokenize:  ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "My word_tokenize 1:         ['Nguồn', 'tin', 'quân sự', 'cho', 'hay', ',', 'quân đội', 'chính phủ', 'Syria', 'tiếp tục', 'tiến', 'lên', 'bờ', 'Tây', 'sông', 'Euphrates', 'ở', 'Tây', 'Deir Ezzur', ',', 'và', 'lấy', 'lại', 'quyền', 'kiểm soát', 'thị trấn', 'al-Tabani', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8084\n",
            "sentence:  Trong thời gian đó, đơn vị khác của quân đội Syria đã vây hãm IS ở vùng nông thôn Đông Nam Deir Ezzur bằng cách tiến xa hơn trong các khu vực bị khủng bố.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [91, 101]}\n",
            "entity index list:  [16]\n",
            "[70, 79]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Trong', 'thời gian', 'đó', ',', 'đơn vị', 'khác', 'của', 'quân đội', 'Syria', 'đã', 'vây hãm', 'IS', 'ở', 'vùng', 'nông thôn', 'Đông Nam Deir Ezzur', 'bằng', 'cách', 'tiến', 'xa', 'hơn', 'trong', 'các', 'khu vực', 'bị', 'khủng bố', '.']\n",
            "My word_tokenize 2:         ['Trong', 'thời gian', 'đó', ',', 'đơn vị', 'khác', 'của', 'quân đội', 'Syria', 'đã', 'vây hãm', 'IS', 'ở', 'vùng', 'nông thôn', 'Đông Nam', 'Deir Ezzur', 'bằng', 'cách', 'tiến', 'xa', 'hơn', 'trong', 'các', 'khu vực', 'bị', 'khủng bố', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8085\n",
            "sentence:  Trong thời gian đó, đơn vị khác của quân đội Syria đã vây hãm IS ở vùng nông thôn Đông Nam Deir Ezzur bằng cách tiến xa hơn trong các khu vực bị khủng bố.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [91, 101]}\n",
            "entity index list:  [16]\n",
            "[70, 79]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Trong', 'thời gian', 'đó', ',', 'đơn vị', 'khác', 'của', 'quân đội', 'Syria', 'đã', 'vây hãm', 'IS', 'ở', 'vùng', 'nông thôn', 'Đông Nam Deir Ezzur', 'bằng', 'cách', 'tiến', 'xa', 'hơn', 'trong', 'các', 'khu vực', 'bị', 'khủng bố', '.']\n",
            "My word_tokenize 2:         ['Trong', 'thời gian', 'đó', ',', 'đơn vị', 'khác', 'của', 'quân đội', 'Syria', 'đã', 'vây hãm', 'IS', 'ở', 'vùng', 'nông thôn', 'Đông Nam', 'Deir Ezzur', 'bằng', 'cách', 'tiến', 'xa', 'hơn', 'trong', 'các', 'khu vực', 'bị', 'khủng bố', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8101\n",
            "sentence:  Trước đó, nhiều dân thường ở thị trấn Albu Kamal thuộc Đông Nam Deir Ezzur đã phục kích một xe quân sự của IS gần đường sắt của thị trấn, phá hủy chiếc xe và giết chết 5 tên khủng bố.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [64, 74]}\n",
            "entity index list:  [10]\n",
            "[51, 60]\n",
            "['Deir Ezzur']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'nhiều', 'dân thường', 'ở', 'thị trấn', 'Albu Kamal', 'thuộc', 'Đông Nam Deir Ezzur', 'đã', 'phục kích', 'một', 'xe', 'quân sự', 'của', 'IS', 'gần', 'đường sắt', 'của', 'thị trấn', ',', 'phá hủy', 'chiếc', 'xe', 'và', 'giết', 'chết', '5', 'tên', 'khủng bố', '.']\n",
            "My word_tokenize 2:         ['Trước', 'đó', ',', 'nhiều', 'dân thường', 'ở', 'thị trấn', 'Albu Kamal', 'thuộc', 'Đông Nam', 'Deir Ezzur', 'đã', 'phục kích', 'một', 'xe', 'quân sự', 'của', 'IS', 'gần', 'đường sắt', 'của', 'thị trấn', ',', 'phá hủy', 'chiếc', 'xe', 'và', 'giết', 'chết', '5', 'tên', 'khủng bố', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8103\n",
            "sentence:  Trước đó, nhiều dân thường ở thị trấn Albu Kamal thuộc Đông Nam Deir Ezzur đã phục kích một xe quân sự của IS gần đường sắt của thị trấn, phá hủy chiếc xe và giết chết 5 tên khủng bố.\n",
            "\n",
            "entity:  {'text': 'Deir Ezzur', 'pos': [64, 74]}\n",
            "entity index list:  [10]\n",
            "['Deir Ezzur']\n",
            "[51, 60]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'nhiều', 'dân thường', 'ở', 'thị trấn', 'Albu Kamal', 'thuộc', 'Đông Nam Deir Ezzur', 'đã', 'phục kích', 'một', 'xe', 'quân sự', 'của', 'IS', 'gần', 'đường sắt', 'của', 'thị trấn', ',', 'phá hủy', 'chiếc', 'xe', 'và', 'giết', 'chết', '5', 'tên', 'khủng bố', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'nhiều', 'dân thường', 'ở', 'thị trấn', 'Albu Kamal', 'thuộc', 'Đông Nam', 'Deir Ezzur', 'đã', 'phục kích', 'một', 'xe', 'quân sự', 'của', 'IS', 'gần', 'đường sắt', 'của', 'thị trấn', ',', 'phá hủy', 'chiếc', 'xe', 'và', 'giết', 'chết', '5', 'tên', 'khủng bố', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8119\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8120\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8121\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8122\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8128\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8129\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8130\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8131\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8136\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8137\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8138\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8139\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8143\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8144\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8145\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8146\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8149\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8150\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8151\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8152\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8154\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "[50, 54]\n",
            "['Mr.', 'T']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8155\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8156\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8157\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8159\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "['Mr.', 'T']\n",
            "[50, 54]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 64]\n",
            "['Cường', 'Seven']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8160\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "['Mr.', 'T']\n",
            "[50, 54]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [16]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8161\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "['Mr.', 'T']\n",
            "[50, 54]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [16]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8162\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Mr.T', 'pos': [63, 67]}\n",
            "entity index list:  [12, 13]\n",
            "['Mr.', 'T']\n",
            "[50, 54]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8163\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "['Cường', 'Seven']\n",
            "[54, 64]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [16]\n",
            "[64, 68]\n",
            "['MLee']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8164\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "['Cường', 'Seven']\n",
            "[54, 64]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [17]\n",
            "[68, 76]\n",
            "['BigDaddy']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 2:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8165\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'Cường Seven', 'pos': [68, 79]}\n",
            "entity index list:  [14, 15]\n",
            "['Cường', 'Seven']\n",
            "[54, 64]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T', 'Cường', 'Seven', 'MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8166\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "['MLee']\n",
            "[64, 68]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8167\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'MLee', 'pos': [80, 84]}\n",
            "entity index list:  [15]\n",
            "['MLee']\n",
            "[64, 68]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven', 'MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8168\n",
            "sentence:  Ông Cao Thắng Bích Phương Lip B Ưng Đại Vệ Kelvin Khánh Andrea Mr.T Cường Seven MLee BigDaddy Đào Thanh Tâm\n",
            "\n",
            "entity:  {'text': 'BigDaddy', 'pos': [85, 93]}\n",
            "entity index list:  [15]\n",
            "['BigDaddy']\n",
            "[68, 76]\n",
            "Underthesea word_tokenize:  ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "My word_tokenize 1:         ['Ông', 'Cao Thắng', 'Bích', 'Phương', 'Lip', 'B', 'Ưng', 'Đại', 'Vệ', 'Kelvin', 'Khánh', 'Andrea', 'Mr.', 'T Cường', 'Seven MLee', 'BigDaddy', 'Đào', 'Thanh Tâm']\n",
            "\n",
            "\n",
            "---------- sent_id:  8309\n",
            "sentence:  Đáng chú ý, công ty thực phẩm Thụy Sĩ Nestlé đã trở thành nhà đầu tư lớn của L'Oréal kể từ năm 1974.\n",
            "\n",
            "entity:  {'text': 'Thụy Sĩ', 'pos': [30, 37]}\n",
            "entity index list:  [5]\n",
            "['Thụy Sĩ']\n",
            "[23, 29]\n",
            "Underthesea word_tokenize:  ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "My word_tokenize 1:         ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ', 'Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8310\n",
            "sentence:  Đáng chú ý, công ty thực phẩm Thụy Sĩ Nestlé đã trở thành nhà đầu tư lớn của L'Oréal kể từ năm 1974.\n",
            "\n",
            "entity:  {'text': 'Thụy Sĩ', 'pos': [30, 37]}\n",
            "entity index list:  [5]\n",
            "['Thụy Sĩ']\n",
            "[23, 29]\n",
            "Underthesea word_tokenize:  ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "My word_tokenize 1:         ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ', 'Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8311\n",
            "sentence:  Đáng chú ý, công ty thực phẩm Thụy Sĩ Nestlé đã trở thành nhà đầu tư lớn của L'Oréal kể từ năm 1974.\n",
            "\n",
            "entity:  {'text': 'Nestlé', 'pos': [38, 44]}\n",
            "entity index list:  [6]\n",
            "['Nestlé']\n",
            "[29, 35]\n",
            "Underthesea word_tokenize:  ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "My word_tokenize 1:         ['Đáng', 'chú ý', ',', 'công ty', 'thực phẩm', 'Thụy Sĩ', 'Nestlé', 'đã', 'trở thành', 'nhà đầu tư', 'lớn', 'của', \"L'Oréal\", 'kể', 'từ', 'năm', '1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8312\n",
            "sentence:  Tại thời điểm đó, bà Bettencourt ủy thác cho Nestlé gần một nửa số cổ phần của chính mình trong công ty để đổi lấy 3% cổ phần trong Nestlé .\n",
            "\n",
            "entity:  {'text': 'Bettencourt', 'pos': [21, 32]}\n",
            "entity index list:  [5]\n",
            "['Bettencourt']\n",
            "[16, 27]\n",
            "Underthesea word_tokenize:  ['Tại', 'thời điểm', 'đó', ',', 'bà', 'Bettencourt ủy thác', 'cho', 'Nestlé', 'gần', 'một nửa', 'số', 'cổ phần', 'của', 'chính', 'mình', 'trong', 'công ty', 'để', 'đổi', 'lấy', '3', '%', 'cổ phần', 'trong', 'Nestlé', '.']\n",
            "My word_tokenize 1:         ['Tại', 'thời điểm', 'đó', ',', 'bà', 'Bettencourt', 'ủy thác', 'cho', 'Nestlé', 'gần', 'một nửa', 'số', 'cổ phần', 'của', 'chính', 'mình', 'trong', 'công ty', 'để', 'đổi', 'lấy', '3', '%', 'cổ phần', 'trong', 'Nestlé', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8313\n",
            "sentence:  Tại thời điểm đó, bà Bettencourt ủy thác cho Nestlé gần một nửa số cổ phần của chính mình trong công ty để đổi lấy 3% cổ phần trong Nestlé .\n",
            "\n",
            "entity:  {'text': 'Bettencourt', 'pos': [21, 32]}\n",
            "entity index list:  [5]\n",
            "['Bettencourt']\n",
            "[16, 27]\n",
            "Underthesea word_tokenize:  ['Tại', 'thời điểm', 'đó', ',', 'bà', 'Bettencourt ủy thác', 'cho', 'Nestlé', 'gần', 'một nửa', 'số', 'cổ phần', 'của', 'chính', 'mình', 'trong', 'công ty', 'để', 'đổi', 'lấy', '3', '%', 'cổ phần', 'trong', 'Nestlé', '.']\n",
            "My word_tokenize 1:         ['Tại', 'thời điểm', 'đó', ',', 'bà', 'Bettencourt', 'ủy thác', 'cho', 'Nestlé', 'gần', 'một nửa', 'số', 'cổ phần', 'của', 'chính', 'mình', 'trong', 'công ty', 'để', 'đổi', 'lấy', '3', '%', 'cổ phần', 'trong', 'Nestlé', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8316\n",
            "sentence:  Trang CNBC cho biết sự ra đi của bà Bettencourt có thể sẽ làm thay đổi mối quan hệ giữa 2 công ty.\n",
            "\n",
            "entity:  {'text': 'CNBC', 'pos': [6, 10]}\n",
            "entity index list:  [1]\n",
            "['CNBC']\n",
            "[5, 9]\n",
            "Underthesea word_tokenize:  ['Trang CNBC', 'cho', 'biết', 'sự', 'ra', 'đi', 'của', 'bà', 'Bettencourt', 'có thể', 'sẽ', 'làm', 'thay đổi', 'mối', 'quan hệ', 'giữa', '2', 'công ty', '.']\n",
            "My word_tokenize 1:         ['Trang', 'CNBC', 'cho', 'biết', 'sự', 'ra', 'đi', 'của', 'bà', 'Bettencourt', 'có thể', 'sẽ', 'làm', 'thay đổi', 'mối', 'quan hệ', 'giữa', '2', 'công ty', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8342\n",
            "sentence:  Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không liên quan đến những quảng cáo trên mạng xã hội Facebook được cho là đã tác động tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [71, 73]}\n",
            "entity index list:  [10]\n",
            "[56, 58]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8343\n",
            "sentence:  Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không liên quan đến những quảng cáo trên mạng xã hội Facebook được cho là đã tác động tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [74, 86]}\n",
            "entity index list:  [11]\n",
            "[58, 69]\n",
            "['Điện Kremlin']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8345\n",
            "sentence:  Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không liên quan đến những quảng cáo trên mạng xã hội Facebook được cho là đã tác động tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [71, 73]}\n",
            "entity index list:  [10]\n",
            "['Mỹ']\n",
            "[56, 58]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8346\n",
            "sentence:  Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không liên quan đến những quảng cáo trên mạng xã hội Facebook được cho là đã tác động tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [71, 73]}\n",
            "entity index list:  [10]\n",
            "['Mỹ']\n",
            "[56, 58]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8347\n",
            "sentence:  Nga phủ nhận liên quan tới các quảng cáo trên Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không liên quan đến những quảng cáo trên mạng xã hội Facebook được cho là đã tác động tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [74, 86]}\n",
            "entity index list:  [11]\n",
            "['Điện Kremlin']\n",
            "[58, 69]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'các', 'quảng cáo', 'trên', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'liên quan', 'đến', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'được', 'cho', 'là', 'đã', 'tác động', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8348\n",
            "sentence:  Phát biểu với báo giới, người phát ngôn Điện Kremlin Dmitry Peskov nêu rõ Nga không biết ai đã đăng quảng cáo lên Facebook và bằng cách nào.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [40, 52]}\n",
            "entity index list:  [6]\n",
            "['Điện Kremlin']\n",
            "[32, 43]\n",
            "Underthesea word_tokenize:  ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "My word_tokenize 1:         ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin', 'Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8349\n",
            "sentence:  Phát biểu với báo giới, người phát ngôn Điện Kremlin Dmitry Peskov nêu rõ Nga không biết ai đã đăng quảng cáo lên Facebook và bằng cách nào.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [40, 52]}\n",
            "entity index list:  [6]\n",
            "['Điện Kremlin']\n",
            "[32, 43]\n",
            "Underthesea word_tokenize:  ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "My word_tokenize 1:         ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin', 'Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8350\n",
            "sentence:  Phát biểu với báo giới, người phát ngôn Điện Kremlin Dmitry Peskov nêu rõ Nga không biết ai đã đăng quảng cáo lên Facebook và bằng cách nào.\n",
            "\n",
            "entity:  {'text': 'Dmitry Peskov', 'pos': [53, 66]}\n",
            "entity index list:  [7]\n",
            "['Dmitry Peskov']\n",
            "[43, 55]\n",
            "Underthesea word_tokenize:  ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "My word_tokenize 1:         ['Phát biểu', 'với', 'báo giới', ',', 'người', 'phát ngôn', 'Điện Kremlin', 'Dmitry Peskov', 'nêu', 'rõ', 'Nga', 'không', 'biết', 'ai', 'đã', 'đăng', 'quảng cáo', 'lên', 'Facebook', 'và', 'bằng', 'cách', 'nào', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8352\n",
            "sentence:  Trước đó, ngày 21/9, Giám đốc điều hành (CEO) Facebook Mark Zuckerberg khẳng định sự ủng hộ đối với cuộc điều tra của Quốc hội Mỹ liên quan cáo buộc Nga can thiệp cuộc bầu cử tổng thống Mỹ 2016, điều mà Moskva luôn bác bỏ.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [55, 70]}\n",
            "entity index list:  [12]\n",
            "['Mark Zuckerberg']\n",
            "[45, 59]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook', 'Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8353\n",
            "sentence:  Trước đó, ngày 21/9, Giám đốc điều hành (CEO) Facebook Mark Zuckerberg khẳng định sự ủng hộ đối với cuộc điều tra của Quốc hội Mỹ liên quan cáo buộc Nga can thiệp cuộc bầu cử tổng thống Mỹ 2016, điều mà Moskva luôn bác bỏ.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [55, 70]}\n",
            "entity index list:  [12]\n",
            "['Mark Zuckerberg']\n",
            "[45, 59]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook', 'Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8354\n",
            "sentence:  Trước đó, ngày 21/9, Giám đốc điều hành (CEO) Facebook Mark Zuckerberg khẳng định sự ủng hộ đối với cuộc điều tra của Quốc hội Mỹ liên quan cáo buộc Nga can thiệp cuộc bầu cử tổng thống Mỹ 2016, điều mà Moskva luôn bác bỏ.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [55, 70]}\n",
            "entity index list:  [12]\n",
            "['Mark Zuckerberg']\n",
            "[45, 59]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook', 'Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8355\n",
            "sentence:  Trước đó, ngày 21/9, Giám đốc điều hành (CEO) Facebook Mark Zuckerberg khẳng định sự ủng hộ đối với cuộc điều tra của Quốc hội Mỹ liên quan cáo buộc Nga can thiệp cuộc bầu cử tổng thống Mỹ 2016, điều mà Moskva luôn bác bỏ.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [55, 70]}\n",
            "entity index list:  [12]\n",
            "['Mark Zuckerberg']\n",
            "[45, 59]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'ngày', '21/9', ',', 'Giám đốc', 'điều hành', '(', 'CEO', ')', 'Facebook', 'Mark Zuckerberg', 'khẳng định', 'sự', 'ủng hộ', 'đối với', 'cuộc', 'điều tra', 'của', 'Quốc hội', 'Mỹ', 'liên quan', 'cáo buộc', 'Nga', 'can thiệp', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', '2016', ',', 'điều', 'mà', 'Moskva', 'luôn', 'bác bỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8385\n",
            "sentence:  Bộ đôi này đã thua dễ dàng trước Kyrgios và Sock 3-6 trong set 1.\n",
            "\n",
            "entity:  {'text': 'Sock', 'pos': [44, 48]}\n",
            "entity index list:  [9]\n",
            "[34, 38]\n",
            "['Sock']\n",
            "My word_tokenize 1:         ['Bộ', 'đôi', 'này', 'đã', 'thua', 'dễ dàng', 'trước', 'Kyrgios', 'và', 'Sock 3-6', 'trong', 'set', '1', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'đôi', 'này', 'đã', 'thua', 'dễ dàng', 'trước', 'Kyrgios', 'và', 'Sock', '3-6', 'trong', 'set', '1', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8398\n",
            "sentence:  Bước vào loạt super tie-break, Thiem chơi tốt hơn và hạ gục Isner 10-7, qua đó giúp đội châu Âu nâng tỷ số lên 2-0.\n",
            "\n",
            "entity:  {'text': 'Isner', 'pos': [60, 65]}\n",
            "entity index list:  [13]\n",
            "[48, 53]\n",
            "['Isner']\n",
            "My word_tokenize 1:         ['Bước', 'vào', 'loạt', 'super', 'tie-break', ',', 'Thiem', 'chơi', 'tốt', 'hơn', 'và', 'hạ', 'gục', 'Isner 10-7', ',', 'qua', 'đó', 'giúp', 'đội', 'châu Âu', 'nâng', 'tỷ số', 'lên', '2-0', '.']\n",
            "My word_tokenize 2:         ['Bước', 'vào', 'loạt', 'super', 'tie-break', ',', 'Thiem', 'chơi', 'tốt', 'hơn', 'và', 'hạ', 'gục', 'Isner', '10-7', ',', 'qua', 'đó', 'giúp', 'đội', 'châu Âu', 'nâng', 'tỷ số', 'lên', '2-0', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8400\n",
            "sentence:  Bước vào loạt super tie-break, Thiem chơi tốt hơn và hạ gục Isner 10-7, qua đó giúp đội châu Âu nâng tỷ số lên 2-0.\n",
            "\n",
            "entity:  {'text': 'Isner', 'pos': [60, 65]}\n",
            "entity index list:  [13]\n",
            "['Isner']\n",
            "[48, 53]\n",
            "Underthesea word_tokenize:  ['Bước', 'vào', 'loạt', 'super', 'tie-break', ',', 'Thiem', 'chơi', 'tốt', 'hơn', 'và', 'hạ', 'gục', 'Isner 10-7', ',', 'qua', 'đó', 'giúp', 'đội', 'châu Âu', 'nâng', 'tỷ số', 'lên', '2-0', '.']\n",
            "My word_tokenize 1:         ['Bước', 'vào', 'loạt', 'super', 'tie-break', ',', 'Thiem', 'chơi', 'tốt', 'hơn', 'và', 'hạ', 'gục', 'Isner', '10-7', ',', 'qua', 'đó', 'giúp', 'đội', 'châu Âu', 'nâng', 'tỷ số', 'lên', '2-0', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8469\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [180, 185]}\n",
            "entity index list:  [32]\n",
            "[140, 145]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8470\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar Al-Assad', 'pos': [186, 201]}\n",
            "entity index list:  [33]\n",
            "[145, 159]\n",
            "['Bashar Al-Assad']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8472\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [180, 185]}\n",
            "entity index list:  [32]\n",
            "[140, 145]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8473\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar Al-Assad', 'pos': [186, 201]}\n",
            "entity index list:  [33]\n",
            "[145, 159]\n",
            "['Bashar Al-Assad']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8474\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [180, 185]}\n",
            "entity index list:  [32]\n",
            "[140, 145]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8475\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar Al-Assad', 'pos': [186, 201]}\n",
            "entity index list:  [33]\n",
            "[145, 159]\n",
            "['Bashar Al-Assad']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 2:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8476\n",
            "sentence:  RT Trong vài tháng qua, Hải quân Nga đã phát động nhiều đợt tấn công tên lửa hành trình tiêu diệt khủng bố tại Syria kể từ khi nước này nhận được lời đề nghị giúp đỡ từ Tổng thống Syria Bashar Al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [180, 185]}\n",
            "entity index list:  [32]\n",
            "['Syria']\n",
            "[140, 145]\n",
            "Underthesea word_tokenize:  ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria Bashar Al-Assad', '.']\n",
            "My word_tokenize 1:         ['RT', 'Trong', 'vài', 'tháng', 'qua', ',', 'Hải quân', 'Nga', 'đã', 'phát động', 'nhiều', 'đợt', 'tấn công', 'tên', 'lửa', 'hành trình', 'tiêu diệt', 'khủng bố', 'tại', 'Syria', 'kể', 'từ', 'khi', 'nước', 'này', 'nhận', 'được', 'lời', 'đề nghị', 'giúp đỡ', 'từ', 'Tổng thống', 'Syria', 'Bashar Al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8486\n",
            "sentence:  Theo Bộ VHTT&DL , việc quyết định lựa chọn Tổng Công ty Vận tải thủy – Công ty cổ phần là nhà đầu tư chiến lược của Công ty TNHH MTV Hãng Phim truyện Việt Nam được thực hiện theo quy định của Nghị định số 59/2011-NĐ-CP về chuyển doanh nghiệp 100% vốn nhà nước thành công ty cổ phần.\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải thủy', 'pos': [43, 68]}\n",
            "entity index list:  [6, 7, 8]\n",
            "[34, 54]\n",
            "['Tổng Công ty', 'Vận tải', 'thủy']\n",
            "My word_tokenize 1:         ['Theo', 'Bộ VHTT&DL', ',', 'việc', 'quyết định', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', 'được', 'thực hiện', 'theo', 'quy định', 'của', 'Nghị định', 'số', '59/2011', '-', 'NĐ-CP', 'về', 'chuyển', 'doanh nghiệp', '100', '%', 'vốn nhà nước', 'thành công ty', 'cổ phần', '.']\n",
            "My word_tokenize 2:         ['Theo', 'Bộ VHTT&DL', ',', 'việc', 'quyết định', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', 'được', 'thực hiện', 'theo', 'quy định', 'của', 'Nghị định', 'số', '59/2011', '-', 'NĐ-CP', 'về', 'chuyển', 'doanh nghiệp', '100', '%', 'vốn nhà nước', 'thành công ty', 'cổ phần', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8488\n",
            "sentence:  Theo Bộ VHTT&DL , việc quyết định lựa chọn Tổng Công ty Vận tải thủy – Công ty cổ phần là nhà đầu tư chiến lược của Công ty TNHH MTV Hãng Phim truyện Việt Nam được thực hiện theo quy định của Nghị định số 59/2011-NĐ-CP về chuyển doanh nghiệp 100% vốn nhà nước thành công ty cổ phần.\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải thủy', 'pos': [43, 68]}\n",
            "entity index list:  [6, 7, 8]\n",
            "['Tổng Công ty', 'Vận tải', 'thủy']\n",
            "[34, 54]\n",
            "Underthesea word_tokenize:  ['Theo', 'Bộ VHTT&DL', ',', 'việc', 'quyết định', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', 'được', 'thực hiện', 'theo', 'quy định', 'của', 'Nghị định', 'số', '59/2011', '-', 'NĐ-CP', 'về', 'chuyển', 'doanh nghiệp', '100', '%', 'vốn nhà nước', 'thành công ty', 'cổ phần', '.']\n",
            "My word_tokenize 1:         ['Theo', 'Bộ VHTT&DL', ',', 'việc', 'quyết định', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', 'được', 'thực hiện', 'theo', 'quy định', 'của', 'Nghị định', 'số', '59/2011', '-', 'NĐ-CP', 'về', 'chuyển', 'doanh nghiệp', '100', '%', 'vốn nhà nước', 'thành công ty', 'cổ phần', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8489\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [142, 167]}\n",
            "entity index list:  [20, 21, 22]\n",
            "[107, 127]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 2:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8491\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [314, 339]}\n",
            "entity index list:  [43, 44, 45]\n",
            "[239, 259]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 2:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8493\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [142, 167]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "[107, 127]\n",
            "Underthesea word_tokenize:  ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8494\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [142, 167]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "[107, 127]\n",
            "Underthesea word_tokenize:  ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [314, 339]}\n",
            "entity index list:  [44, 45, 46]\n",
            "[239, 259]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 2:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8495\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [142, 167]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "[107, 127]\n",
            "Underthesea word_tokenize:  ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8496\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [314, 339]}\n",
            "entity index list:  [43, 44, 45]\n",
            "[239, 259]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 2:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8498\n",
            "sentence:  Căn cứ đề nghị của Công ty TNHH MTV Hãng Phim truyện Việt Nam , ý kiến đánh giá của đơn vị tư vấn về Hồ sơ tham gia nhà đầu tư chiến lược của Tổng Công ty Vận tải Thủy – Công ty cổ phần và căn cứ quy định về việc lựa chọn nhà đầu tư chiến lược tại Nghị định số 59, Bộ VHTT&DL quyết định phê duyệt kết quả lựa chọn Tổng Công ty Vận tải Thủy – Công ty cổ phần là nhà đầu tư chiến lược tham gia mua cổ phần Công ty TNHH MTV Hãng Phim truyện Việt Nam .\n",
            "\n",
            "entity:  {'text': 'Tổng Công ty Vận tải Thủy', 'pos': [314, 339]}\n",
            "entity index list:  [43, 44, 45]\n",
            "['Tổng Công ty', 'Vận tải', 'Thủy']\n",
            "[239, 259]\n",
            "Underthesea word_tokenize:  ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "My word_tokenize 1:         ['Căn cứ', 'đề nghị', 'của', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', ',', 'ý kiến', 'đánh giá', 'của', 'đơn vị', 'tư vấn', 'về', 'Hồ sơ', 'tham gia', 'nhà đầu tư', 'chiến lược', 'của', 'Tổng Công ty', 'Vận tải', 'Thủy –', 'Công ty', 'cổ phần', 'và', 'căn cứ', 'quy định', 'về', 'việc', 'lựa chọn', 'nhà đầu tư', 'chiến lược', 'tại', 'Nghị định', 'số', '59', ',', 'Bộ VHTT&DL', 'quyết định', 'phê duyệt', 'kết quả', 'lựa chọn', 'Tổng Công ty', 'Vận tải', 'Thủy', '–', 'Công ty', 'cổ phần', 'là', 'nhà đầu tư', 'chiến lược', 'tham gia', 'mua', 'cổ phần', 'Công ty', 'TNHH', 'MTV Hãng', 'Phim truyện', 'Việt Nam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8517\n",
            "sentence:  Thí sinh Miss Photo 2017: Nguyễn Thu Hà Thí sinh Nguyễn Thu Hà - Số báo danh: 234, đến từ Hà Nội , trong bộ ảnh dự thi vòng Sơ khảo, chủ đề tháng 9: Màu Đỏ.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [26, 39]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[21, 32]\n",
            "Underthesea word_tokenize:  ['Thí sinh', 'Miss Photo', '2017', ':', 'Nguyễn Thu Hà Thí sinh', 'Nguyễn Thu Hà', '-', 'Số báo danh', ':', '234', ',', 'đến', 'từ', 'Hà Nội', ',', 'trong', 'bộ', 'ảnh', 'dự', 'thi', 'vòng', 'Sơ khảo', ',', 'chủ đề', 'tháng', '9', ':', 'Màu Đỏ', '.']\n",
            "My word_tokenize 1:         ['Thí sinh', 'Miss Photo', '2017', ':', 'Nguyễn Thu Hà', 'Thí sinh', 'Nguyễn Thu Hà', '-', 'Số báo danh', ':', '234', ',', 'đến', 'từ', 'Hà Nội', ',', 'trong', 'bộ', 'ảnh', 'dự', 'thi', 'vòng', 'Sơ khảo', ',', 'chủ đề', 'tháng', '9', ':', 'Màu Đỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8518\n",
            "sentence:  Thí sinh Miss Photo 2017: Nguyễn Thu Hà Thí sinh Nguyễn Thu Hà - Số báo danh: 234, đến từ Hà Nội , trong bộ ảnh dự thi vòng Sơ khảo, chủ đề tháng 9: Màu Đỏ.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [26, 39]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[21, 32]\n",
            "Underthesea word_tokenize:  ['Thí sinh', 'Miss Photo', '2017', ':', 'Nguyễn Thu Hà Thí sinh', 'Nguyễn Thu Hà', '-', 'Số báo danh', ':', '234', ',', 'đến', 'từ', 'Hà Nội', ',', 'trong', 'bộ', 'ảnh', 'dự', 'thi', 'vòng', 'Sơ khảo', ',', 'chủ đề', 'tháng', '9', ':', 'Màu Đỏ', '.']\n",
            "My word_tokenize 1:         ['Thí sinh', 'Miss Photo', '2017', ':', 'Nguyễn Thu Hà', 'Thí sinh', 'Nguyễn Thu Hà', '-', 'Số báo danh', ':', '234', ',', 'đến', 'từ', 'Hà Nội', ',', 'trong', 'bộ', 'ảnh', 'dự', 'thi', 'vòng', 'Sơ khảo', ',', 'chủ đề', 'tháng', '9', ':', 'Màu Đỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8520\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [10, 23]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[7, 18]\n",
            "Underthesea word_tokenize:  ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8521\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [10, 23]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[7, 18]\n",
            "Underthesea word_tokenize:  ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8522\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [10, 23]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[7, 18]\n",
            "Underthesea word_tokenize:  ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "entity:  {'text': 'Hà Nội', 'pos': [91, 97]}\n",
            "entity index list:  [18]\n",
            "[71, 76]\n",
            "['Hà Nội']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 2:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội', 'Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8523\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Thu Hà', 'pos': [10, 23]}\n",
            "entity index list:  [4]\n",
            "['Nguyễn Thu Hà']\n",
            "[7, 18]\n",
            "Underthesea word_tokenize:  ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà', 'Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8525\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Hà Nội', 'pos': [91, 97]}\n",
            "entity index list:  [17]\n",
            "[71, 76]\n",
            "['Hà Nội']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 2:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội', 'Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8527\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Hà Nội', 'pos': [91, 97]}\n",
            "entity index list:  [17]\n",
            "[71, 76]\n",
            "['Hà Nội']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 2:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội', 'Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8529\n",
            "sentence:  Họ & tên: Nguyễn Thu Hà Sinh ngày: 18/12/1998 Quê quán: Hà Nội Chỗ ở hiện tại: Q.Đống Đa , Hà Nội Hiện là sinh viên khoa Báo chí & Truyền thông, Trường ĐH Khoa học xã hội & Nhân văn Hà Nội Chiều cao: 1m70 - Cân nặng: 50kg - Số đo 3 vòng: 83-62-90cm Sở thích: Đọc sách, du lịch Ước mơ: Trở thành nhà báo.\n",
            "\n",
            "entity:  {'text': 'Hà Nội', 'pos': [91, 97]}\n",
            "entity index list:  [17]\n",
            "['Hà Nội']\n",
            "[71, 76]\n",
            "Underthesea word_tokenize:  ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "My word_tokenize 1:         ['Họ', '&', 'tên', ':', 'Nguyễn Thu Hà Sinh', 'ngày', ':', '18/12/1998', 'Quê quán', ':', 'Hà Nội', 'Chỗ', 'ở', 'hiện tại', ':', 'Q.Đống Đa', ',', 'Hà Nội', 'Hiện', 'là', 'sinh viên', 'khoa', 'Báo chí', '&', 'Truyền thông', ',', 'Trường', 'ĐH', 'Khoa học', 'xã hội', '&', 'Nhân văn', 'Hà Nội', 'Chiều', 'cao', ':', '1', 'm70', '-', 'Cân nặng', ':', '50', 'kg', '-', 'Số đo', '3', 'vòng', ':', '83-62-90', 'cm', 'Sở thích', ':', 'Đọc', 'sách', ',', 'du lịch', 'Ước mơ', ':', 'Trở thành', 'nhà báo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8543\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8544\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8545\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8546\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8547\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8548\n",
            "sentence:  Hiện nay trên thị trường đã xuất hiện nhiều món ăn chế biến sẵn từ rong biển, trong đó phải kể đến sản phẩm Rong biển rang giòn Tâm An Tọa lạc tại số 193/7, đường Hoàng Diệu , P Nam Dương , Quận Hải Châu , Thành phố Đà Nẵng , cơ sở sản xuất rong biển rang giòn Tâm An do bà Võ Thị Lan làm chủ cơ sở.\n",
            "\n",
            "entity:  {'text': 'Tâm An', 'pos': [128, 134]}\n",
            "entity index list:  [23, 24]\n",
            "['Tâm', 'An']\n",
            "[100, 105]\n",
            "Underthesea word_tokenize:  ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "My word_tokenize 1:         ['Hiện nay', 'trên', 'thị trường', 'đã', 'xuất hiện', 'nhiều', 'món', 'ăn', 'chế biến', 'sẵn', 'từ', 'rong', 'biển', ',', 'trong', 'đó', 'phải', 'kể', 'đến', 'sản phẩm', 'Rong biển', 'rang', 'giòn', 'Tâm', 'An', 'Tọa lạc', 'tại', 'số', '193', '/', '7', ',', 'đường Hoàng Diệu', ',', 'P Nam Dương', ',', 'Quận', 'Hải Châu', ',', 'Thành phố', 'Đà Nẵng', ',', 'cơ sở', 'sản xuất', 'rong', 'biển', 'rang', 'giòn', 'Tâm An', 'do', 'bà', 'Võ Thị Lan', 'làm chủ', 'cơ sở', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8912\n",
            "sentence:  Điều phối viên y tế khẩn cấp của MSF Kate White cho biết mỗi ngày đều có các bệnh nhân đang chết dần do mất nước, một nguyên nhân tử vong rất hiếm gặp đối với người trưởng thành.\n",
            "\n",
            "entity:  {'text': 'MSF', 'pos': [33, 36]}\n",
            "entity index list:  [4]\n",
            "['MSF']\n",
            "[25, 28]\n",
            "Underthesea word_tokenize:  ['Điều phối viên', 'y tế', 'khẩn cấp', 'của', 'MSF Kate White', 'cho', 'biết', 'mỗi', 'ngày', 'đều', 'có', 'các', 'bệnh nhân', 'đang', 'chết', 'dần', 'do', 'mất', 'nước', ',', 'một', 'nguyên nhân', 'tử vong', 'rất', 'hiếm', 'gặp', 'đối với', 'người', 'trưởng thành', '.']\n",
            "My word_tokenize 1:         ['Điều phối viên', 'y tế', 'khẩn cấp', 'của', 'MSF', 'Kate White', 'cho', 'biết', 'mỗi', 'ngày', 'đều', 'có', 'các', 'bệnh nhân', 'đang', 'chết', 'dần', 'do', 'mất', 'nước', ',', 'một', 'nguyên nhân', 'tử vong', 'rất', 'hiếm', 'gặp', 'đối với', 'người', 'trưởng thành', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8913\n",
            "sentence:  Điều phối viên MSF Robert Onus nhấn mạnh chỉ một sự cố nhỏ cũng có thể dẫn đến một đợt bùng phát dịch và đó là lúc cuộc khủng hoảng biến thành thảm kịch.\n",
            "\n",
            "entity:  {'text': 'MSF', 'pos': [15, 18]}\n",
            "entity index list:  [1]\n",
            "['MSF']\n",
            "[12, 15]\n",
            "Underthesea word_tokenize:  ['Điều phối viên', 'MSF Robert Onus', 'nhấn mạnh', 'chỉ', 'một', 'sự cố', 'nhỏ', 'cũng', 'có thể', 'dẫn', 'đến', 'một', 'đợt', 'bùng phát', 'dịch', 'và', 'đó', 'là', 'lúc', 'cuộc', 'khủng hoảng', 'biến', 'thành', 'thảm kịch', '.']\n",
            "My word_tokenize 1:         ['Điều phối viên', 'MSF', 'Robert Onus', 'nhấn mạnh', 'chỉ', 'một', 'sự cố', 'nhỏ', 'cũng', 'có thể', 'dẫn', 'đến', 'một', 'đợt', 'bùng phát', 'dịch', 'và', 'đó', 'là', 'lúc', 'cuộc', 'khủng hoảng', 'biến', 'thành', 'thảm kịch', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8922\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': \"thành phố Cox's Bazar\", 'pos': [89, 110]}\n",
            "entity index list:  [17, 18]\n",
            "[71, 89]\n",
            "['thành phố', \"Cox's Bazar\"]\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 2:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8923\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': 'Bangladesh', 'pos': [111, 121]}\n",
            "entity index list:  [19]\n",
            "[89, 99]\n",
            "['Bangladesh']\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 2:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8925\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': \"thành phố Cox's Bazar\", 'pos': [89, 110]}\n",
            "entity index list:  [17, 18]\n",
            "[71, 89]\n",
            "['thành phố', \"Cox's Bazar\"]\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 2:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8926\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': 'Bangladesh', 'pos': [111, 121]}\n",
            "entity index list:  [19]\n",
            "[89, 99]\n",
            "['Bangladesh']\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 2:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8928\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': \"thành phố Cox's Bazar\", 'pos': [89, 110]}\n",
            "entity index list:  [17, 18]\n",
            "['thành phố', \"Cox's Bazar\"]\n",
            "[71, 89]\n",
            "Underthesea word_tokenize:  ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8929\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': \"thành phố Cox's Bazar\", 'pos': [89, 110]}\n",
            "entity index list:  [17, 18]\n",
            "['thành phố', \"Cox's Bazar\"]\n",
            "[71, 89]\n",
            "Underthesea word_tokenize:  ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8930\n",
            "sentence:  Kể từ cuối tháng 8 năm ngoái, hơn 420.000 người Hồi giáo Rohingya ở Myanmar đã chạy sang thành phố Cox's Bazar Bangladesh , gần biên giới giữa hai nước, để lánh nạn kể từ khi bạo động nổ ra tại bang Rakhine .\n",
            "\n",
            "entity:  {'text': 'Bangladesh', 'pos': [111, 121]}\n",
            "entity index list:  [19]\n",
            "['Bangladesh']\n",
            "[89, 99]\n",
            "Underthesea word_tokenize:  ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar Bangladesh\", ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "My word_tokenize 1:         ['Kể', 'từ', 'cuối', 'tháng', '8', 'năm ngoái', ',', 'hơn', '420.000', 'người', 'Hồi giáo', 'Rohingya', 'ở', 'Myanmar', 'đã', 'chạy', 'sang', 'thành phố', \"Cox's Bazar\", 'Bangladesh', ',', 'gần', 'biên giới', 'giữa', 'hai', 'nước', ',', 'để', 'lánh nạn', 'kể', 'từ', 'khi', 'bạo động', 'nổ', 'ra', 'tại', 'bang', 'Rakhine', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8935\n",
            "sentence:  Giới chức Myanmar cáo buộc các tay súng tấn công đó là thành viên lực lượng Tổ chức Thống nhất người Rohingya , một nhóm vũ trang sắc tộc nhỏ Rohingya hoạt động từ những năm 80-90 của thế kỷ trước.\n",
            "\n",
            "entity:  {'text': 'Myanmar', 'pos': [10, 17]}\n",
            "entity index list:  [1]\n",
            "['Myanmar']\n",
            "[8, 15]\n",
            "Underthesea word_tokenize:  ['Giới chức', 'Myanmar cáo buộc', 'các', 'tay', 'súng', 'tấn công', 'đó', 'là', 'thành viên', 'lực lượng', 'Tổ chức', 'Thống nhất', 'người', 'Rohingya', ',', 'một', 'nhóm', 'vũ trang', 'sắc tộc', 'nhỏ', 'Rohingya', 'hoạt động', 'từ', 'những', 'năm', '80-90', 'của', 'thế kỷ', 'trước', '.']\n",
            "My word_tokenize 1:         ['Giới chức', 'Myanmar', 'cáo buộc', 'các', 'tay', 'súng', 'tấn công', 'đó', 'là', 'thành viên', 'lực lượng', 'Tổ chức', 'Thống nhất', 'người', 'Rohingya', ',', 'một', 'nhóm', 'vũ trang', 'sắc tộc', 'nhỏ', 'Rohingya', 'hoạt động', 'từ', 'những', 'năm', '80-90', 'của', 'thế kỷ', 'trước', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9028\n",
            "sentence:  Phát hiện ra việc Sơn đưa Mai đi phá thai, ông Lâm (NSƯT Hoàng Hải ) vì quá tức giận nên đã ngã bệnh.\n",
            "\n",
            "entity:  {'text': 'Hoàng Hải', 'pos': [57, 66]}\n",
            "entity index list:  [13]\n",
            "[44, 52]\n",
            "['Hoàng Hải']\n",
            "My word_tokenize 1:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "My word_tokenize 2:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT', 'Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9030\n",
            "sentence:  Phát hiện ra việc Sơn đưa Mai đi phá thai, ông Lâm (NSƯT Hoàng Hải ) vì quá tức giận nên đã ngã bệnh.\n",
            "\n",
            "entity:  {'text': 'Hoàng Hải', 'pos': [57, 66]}\n",
            "entity index list:  [13]\n",
            "[44, 52]\n",
            "['Hoàng Hải']\n",
            "My word_tokenize 1:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "My word_tokenize 2:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT', 'Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9031\n",
            "sentence:  Phát hiện ra việc Sơn đưa Mai đi phá thai, ông Lâm (NSƯT Hoàng Hải ) vì quá tức giận nên đã ngã bệnh.\n",
            "\n",
            "entity:  {'text': 'Hoàng Hải', 'pos': [57, 66]}\n",
            "entity index list:  [13]\n",
            "[44, 52]\n",
            "['Hoàng Hải']\n",
            "My word_tokenize 1:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "My word_tokenize 2:         ['Phát hiện', 'ra', 'việc', 'Sơn', 'đưa', 'Mai', 'đi', 'phá thai', ',', 'ông', 'Lâm', '(', 'NSƯT', 'Hoàng Hải', ')', 'vì', 'quá', 'tức giận', 'nên', 'đã', 'ngã', 'bệnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9035\n",
            "sentence:  Việc Sơn quyết định lấy Mai khiến cả gia đình ai cũng vui mừng ngoại trừ bà Lâm (NSND Lan Hương ).\n",
            "\n",
            "entity:  {'text': 'Lan Hương', 'pos': [86, 95]}\n",
            "entity index list:  [16]\n",
            "[67, 75]\n",
            "['Lan Hương']\n",
            "My word_tokenize 1:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND Lan Hương', ')', '.']\n",
            "My word_tokenize 2:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND', 'Lan Hương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9037\n",
            "sentence:  Việc Sơn quyết định lấy Mai khiến cả gia đình ai cũng vui mừng ngoại trừ bà Lâm (NSND Lan Hương ).\n",
            "\n",
            "entity:  {'text': 'Lan Hương', 'pos': [86, 95]}\n",
            "entity index list:  [16]\n",
            "[67, 75]\n",
            "['Lan Hương']\n",
            "My word_tokenize 1:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND Lan Hương', ')', '.']\n",
            "My word_tokenize 2:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND', 'Lan Hương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9038\n",
            "sentence:  Việc Sơn quyết định lấy Mai khiến cả gia đình ai cũng vui mừng ngoại trừ bà Lâm (NSND Lan Hương ).\n",
            "\n",
            "entity:  {'text': 'Lan Hương', 'pos': [86, 95]}\n",
            "entity index list:  [16]\n",
            "[67, 75]\n",
            "['Lan Hương']\n",
            "My word_tokenize 1:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND Lan Hương', ')', '.']\n",
            "My word_tokenize 2:         ['Việc', 'Sơn', 'quyết định', 'lấy', 'Mai', 'khiến', 'cả', 'gia đình', 'ai', 'cũng', 'vui mừng', 'ngoại trừ', 'bà', 'Lâm', '(', 'NSND', 'Lan Hương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9062\n",
            "sentence:  Chính vì thế mà Châu liên tục móc mỉa Mai vì cho rằng cô bạn quá \"cao tay\" khi đã \"gài bẫy\" được giảng viên còn sắp được nhập khẩu thành người thủ đô.\n",
            "\n",
            "entity:  {'text': 'Mai', 'pos': [38, 41]}\n",
            "entity index list:  [7]\n",
            "[29, 32]\n",
            "['Mai']\n",
            "My word_tokenize 1:         ['Chính', 'vì thế', 'mà', 'Châu', 'liên tục', 'móc', 'mỉa Mai', 'vì', 'cho', 'rằng', 'cô', 'bạn', 'quá', '\"', 'cao tay', '\"', 'khi', 'đã', '\"', 'gài bẫy', '\"', 'được', 'giảng viên', 'còn', 'sắp', 'được', 'nhập khẩu', 'thành', 'người', 'thủ đô', '.']\n",
            "My word_tokenize 2:         ['Chính', 'vì thế', 'mà', 'Châu', 'liên tục', 'móc', 'mỉa', 'Mai', 'vì', 'cho', 'rằng', 'cô', 'bạn', 'quá', '\"', 'cao tay', '\"', 'khi', 'đã', '\"', 'gài bẫy', '\"', 'được', 'giảng viên', 'còn', 'sắp', 'được', 'nhập khẩu', 'thành', 'người', 'thủ đô', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9099\n",
            "sentence:  Mỹ chấp thuận hàng loạt biện pháp trừng phạt mới chống Triều Tiên Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [158, 160]}\n",
            "entity index list:  [22]\n",
            "[123, 125]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9102\n",
            "sentence:  Mỹ chấp thuận hàng loạt biện pháp trừng phạt mới chống Triều Tiên Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [158, 160]}\n",
            "entity index list:  [22]\n",
            "[123, 125]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9104\n",
            "sentence:  Mỹ chấp thuận hàng loạt biện pháp trừng phạt mới chống Triều Tiên Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [158, 160]}\n",
            "entity index list:  [22]\n",
            "[123, 125]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9106\n",
            "sentence:  Mỹ chấp thuận hàng loạt biện pháp trừng phạt mới chống Triều Tiên Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [158, 160]}\n",
            "entity index list:  [22]\n",
            "['Mỹ']\n",
            "[123, 125]\n",
            "Underthesea word_tokenize:  ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Mỹ', 'chấp thuận', 'hàng loạt', 'biện pháp', 'trừng phạt', 'mới', 'chống', 'Triều Tiên', 'Bộ', 'Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9138\n",
            "sentence:  Theo quy định trừng phạt mới mà Tổng thống Donald Trump mới ký thông qua, Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [166, 168]}\n",
            "entity index list:  [24]\n",
            "[129, 131]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9140\n",
            "sentence:  Theo quy định trừng phạt mới mà Tổng thống Donald Trump mới ký thông qua, Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [166, 168]}\n",
            "entity index list:  [24]\n",
            "[129, 131]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9142\n",
            "sentence:  Theo quy định trừng phạt mới mà Tổng thống Donald Trump mới ký thông qua, Bộ Tài chính Mỹ sẽ loại bỏ bất kỳ cá nhân, tổ chức ngân hàng nào ra khỏi hệ thống tài chính Mỹ nếu bị phát hiện có giao dịch với Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [166, 168]}\n",
            "entity index list:  [24]\n",
            "['Mỹ']\n",
            "[129, 131]\n",
            "Underthesea word_tokenize:  ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Theo', 'quy định', 'trừng phạt', 'mới', 'mà', 'Tổng thống', 'Donald Trump', 'mới', 'ký', 'thông qua', ',', 'Bộ Tài chính Mỹ', 'sẽ', 'loại bỏ', 'bất kỳ', 'cá nhân', ',', 'tổ chức', 'ngân hàng', 'nào', 'ra', 'khỏi', 'hệ thống', 'tài chính', 'Mỹ', 'nếu', 'bị', 'phát hiện', 'có', 'giao dịch', 'với', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9285\n",
            "sentence:  Dâng hương tưởng niệm các liệt sĩ tàu không số Nhân dịp kỷ niệm 50 năm mở đường Hồ Chí Minh trên biển, sáng 7-10, Bộ Chỉ huy BĐBP TP Hải Phòng đến dâng hương tưởng niệm các liệt sĩ đoàn tàu không số tại khu di tích bến K15 , phường Vạn Hương , quận Đồ Sơn , Hải Phòng .\n",
            "\n",
            "entity:  {'text': 'đường Hồ Chí Minh', 'pos': [74, 91]}\n",
            "entity index list:  [12, 13]\n",
            "['đường', 'Hồ Chí Minh']\n",
            "[57, 71]\n",
            "Underthesea word_tokenize:  ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "My word_tokenize 1:         ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở', 'đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9286\n",
            "sentence:  Dâng hương tưởng niệm các liệt sĩ tàu không số Nhân dịp kỷ niệm 50 năm mở đường Hồ Chí Minh trên biển, sáng 7-10, Bộ Chỉ huy BĐBP TP Hải Phòng đến dâng hương tưởng niệm các liệt sĩ đoàn tàu không số tại khu di tích bến K15 , phường Vạn Hương , quận Đồ Sơn , Hải Phòng .\n",
            "\n",
            "entity:  {'text': 'đường Hồ Chí Minh', 'pos': [74, 91]}\n",
            "entity index list:  [12, 13]\n",
            "['đường', 'Hồ Chí Minh']\n",
            "[57, 71]\n",
            "Underthesea word_tokenize:  ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "My word_tokenize 1:         ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở', 'đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9287\n",
            "sentence:  Dâng hương tưởng niệm các liệt sĩ tàu không số Nhân dịp kỷ niệm 50 năm mở đường Hồ Chí Minh trên biển, sáng 7-10, Bộ Chỉ huy BĐBP TP Hải Phòng đến dâng hương tưởng niệm các liệt sĩ đoàn tàu không số tại khu di tích bến K15 , phường Vạn Hương , quận Đồ Sơn , Hải Phòng .\n",
            "\n",
            "entity:  {'text': 'đường Hồ Chí Minh', 'pos': [74, 91]}\n",
            "entity index list:  [12, 13]\n",
            "['đường', 'Hồ Chí Minh']\n",
            "[57, 71]\n",
            "Underthesea word_tokenize:  ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "My word_tokenize 1:         ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở', 'đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9288\n",
            "sentence:  Dâng hương tưởng niệm các liệt sĩ tàu không số Nhân dịp kỷ niệm 50 năm mở đường Hồ Chí Minh trên biển, sáng 7-10, Bộ Chỉ huy BĐBP TP Hải Phòng đến dâng hương tưởng niệm các liệt sĩ đoàn tàu không số tại khu di tích bến K15 , phường Vạn Hương , quận Đồ Sơn , Hải Phòng .\n",
            "\n",
            "entity:  {'text': 'đường Hồ Chí Minh', 'pos': [74, 91]}\n",
            "entity index list:  [12, 13]\n",
            "['đường', 'Hồ Chí Minh']\n",
            "[57, 71]\n",
            "Underthesea word_tokenize:  ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "My word_tokenize 1:         ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở', 'đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9289\n",
            "sentence:  Dâng hương tưởng niệm các liệt sĩ tàu không số Nhân dịp kỷ niệm 50 năm mở đường Hồ Chí Minh trên biển, sáng 7-10, Bộ Chỉ huy BĐBP TP Hải Phòng đến dâng hương tưởng niệm các liệt sĩ đoàn tàu không số tại khu di tích bến K15 , phường Vạn Hương , quận Đồ Sơn , Hải Phòng .\n",
            "\n",
            "entity:  {'text': 'đường Hồ Chí Minh', 'pos': [74, 91]}\n",
            "entity index list:  [12, 13]\n",
            "['đường', 'Hồ Chí Minh']\n",
            "[57, 71]\n",
            "Underthesea word_tokenize:  ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "My word_tokenize 1:         ['Dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'tàu', 'không', 'số Nhân dịp', 'kỷ niệm', '50', 'năm', 'mở', 'đường', 'Hồ Chí Minh', 'trên', 'biển', ',', 'sáng', '7-10', ',', 'Bộ Chỉ huy', 'BĐBP', 'TP', 'Hải Phòng', 'đến', 'dâng', 'hương', 'tưởng niệm', 'các', 'liệt sĩ', 'đoàn', 'tàu', 'không', 'số', 'tại', 'khu', 'di tích', 'bến', 'K15', ',', 'phường', 'Vạn Hương', ',', 'quận', 'Đồ Sơn', ',', 'Hải Phòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9468\n",
            "sentence:  Lên vùng cao miền tây xứ Nghệ Anh đi khắp núi, khắp ngàn/Không đâu đẹp bằng đá Bàn , sông Giăng , đó là câu ca về dòng sông nơi miền tây xứ Nghệ , chảy qua huyện Con Cuông mà ai cũng phải nhắc đến khi có dịp tới đây.\n",
            "\n",
            "entity:  {'text': 'xứ Nghệ', 'pos': [22, 29]}\n",
            "entity index list:  [4, 5]\n",
            "['xứ', 'Nghệ']\n",
            "[17, 23]\n",
            "Underthesea word_tokenize:  ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "My word_tokenize 1:         ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ', 'Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9469\n",
            "sentence:  Lên vùng cao miền tây xứ Nghệ Anh đi khắp núi, khắp ngàn/Không đâu đẹp bằng đá Bàn , sông Giăng , đó là câu ca về dòng sông nơi miền tây xứ Nghệ , chảy qua huyện Con Cuông mà ai cũng phải nhắc đến khi có dịp tới đây.\n",
            "\n",
            "entity:  {'text': 'xứ Nghệ', 'pos': [22, 29]}\n",
            "entity index list:  [4, 5]\n",
            "['xứ', 'Nghệ']\n",
            "[17, 23]\n",
            "Underthesea word_tokenize:  ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "My word_tokenize 1:         ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ', 'Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9470\n",
            "sentence:  Lên vùng cao miền tây xứ Nghệ Anh đi khắp núi, khắp ngàn/Không đâu đẹp bằng đá Bàn , sông Giăng , đó là câu ca về dòng sông nơi miền tây xứ Nghệ , chảy qua huyện Con Cuông mà ai cũng phải nhắc đến khi có dịp tới đây.\n",
            "\n",
            "entity:  {'text': 'xứ Nghệ', 'pos': [22, 29]}\n",
            "entity index list:  [4, 5]\n",
            "['xứ', 'Nghệ']\n",
            "[17, 23]\n",
            "Underthesea word_tokenize:  ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "My word_tokenize 1:         ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ', 'Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9471\n",
            "sentence:  Lên vùng cao miền tây xứ Nghệ Anh đi khắp núi, khắp ngàn/Không đâu đẹp bằng đá Bàn , sông Giăng , đó là câu ca về dòng sông nơi miền tây xứ Nghệ , chảy qua huyện Con Cuông mà ai cũng phải nhắc đến khi có dịp tới đây.\n",
            "\n",
            "entity:  {'text': 'xứ Nghệ', 'pos': [22, 29]}\n",
            "entity index list:  [4, 5]\n",
            "['xứ', 'Nghệ']\n",
            "[17, 23]\n",
            "Underthesea word_tokenize:  ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "My word_tokenize 1:         ['Lên', 'vùng cao', 'miền', 'tây', 'xứ', 'Nghệ', 'Anh', 'đi', 'khắp', 'núi', ',', 'khắp', 'ngàn', '/', 'Không', 'đâu', 'đẹp', 'bằng', 'đá', 'Bàn', ',', 'sông', 'Giăng', ',', 'đó', 'là', 'câu', 'ca', 'về', 'dòng', 'sông', 'nơi', 'miền', 'tây', 'xứ', 'Nghệ', ',', 'chảy', 'qua', 'huyện', 'Con Cuông', 'mà', 'ai', 'cũng', 'phải', 'nhắc', 'đến', 'khi', 'có', 'dịp', 'tới', 'đây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9514\n",
            "sentence:  Bản cũng nhận được sự quan tâm, hỗ trợ từ nhiều đoàn khách đến tham quan…\", Phó Chủ tịch xã Môn Sơn Lương Văn Tuấn bày tỏ.\n",
            "\n",
            "entity:  {'text': 'xã Môn Sơn', 'pos': [89, 99]}\n",
            "entity index list:  [19, 20]\n",
            "['xã', 'Môn Sơn']\n",
            "[70, 78]\n",
            "Underthesea word_tokenize:  ['Bản', 'cũng', 'nhận', 'được', 'sự', 'quan tâm', ',', 'hỗ trợ', 'từ', 'nhiều', 'đoàn', 'khách', 'đến', 'tham quan', '…', '\"', ',', 'Phó', 'Chủ tịch', 'xã', 'Môn Sơn Lương Văn Tuấn', 'bày tỏ', '.']\n",
            "My word_tokenize 1:         ['Bản', 'cũng', 'nhận', 'được', 'sự', 'quan tâm', ',', 'hỗ trợ', 'từ', 'nhiều', 'đoàn', 'khách', 'đến', 'tham quan', '…', '\"', ',', 'Phó', 'Chủ tịch', 'xã', 'Môn Sơn', 'Lương Văn Tuấn', 'bày tỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9605\n",
            "sentence:  \"Mỹ cần thiết hỗ trợ Đài Loan có được khả năng phòng vệ cần thiết để ứng phó với mối đe dọa từ Trung Quốc Đại lục\".\n",
            "\n",
            "entity:  {'text': 'Trung Quốc', 'pos': [95, 105]}\n",
            "entity index list:  [16]\n",
            "[72, 81]\n",
            "['Trung Quốc']\n",
            "My word_tokenize 1:         ['\"', 'Mỹ', 'cần thiết', 'hỗ trợ', 'Đài Loan', 'có', 'được', 'khả năng', 'phòng vệ', 'cần thiết', 'để', 'ứng phó', 'với', 'mối', 'đe dọa', 'từ', 'Trung Quốc Đại lục', '\"', '.']\n",
            "My word_tokenize 2:         ['\"', 'Mỹ', 'cần thiết', 'hỗ trợ', 'Đài Loan', 'có', 'được', 'khả năng', 'phòng vệ', 'cần thiết', 'để', 'ứng phó', 'với', 'mối', 'đe dọa', 'từ', 'Trung Quốc', 'Đại lục', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9606\n",
            "sentence:  \"Mỹ cần thiết hỗ trợ Đài Loan có được khả năng phòng vệ cần thiết để ứng phó với mối đe dọa từ Trung Quốc Đại lục\".\n",
            "\n",
            "entity:  {'text': 'Trung Quốc', 'pos': [95, 105]}\n",
            "entity index list:  [16]\n",
            "[72, 81]\n",
            "['Trung Quốc']\n",
            "My word_tokenize 1:         ['\"', 'Mỹ', 'cần thiết', 'hỗ trợ', 'Đài Loan', 'có', 'được', 'khả năng', 'phòng vệ', 'cần thiết', 'để', 'ứng phó', 'với', 'mối', 'đe dọa', 'từ', 'Trung Quốc Đại lục', '\"', '.']\n",
            "My word_tokenize 2:         ['\"', 'Mỹ', 'cần thiết', 'hỗ trợ', 'Đài Loan', 'có', 'được', 'khả năng', 'phòng vệ', 'cần thiết', 'để', 'ứng phó', 'với', 'mối', 'đe dọa', 'từ', 'Trung Quốc', 'Đại lục', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9665\n",
            "sentence:  Trên thực tế từ đầu năm 2017 đến nay, một bộ phận người Mỹ liên tục đưa ra các vấn đề như \"bán vũ khí cho Đài Loan \", \"Luật du lịch Đài Loan \", \"tàu chiến Đài - Mỹ thăm nhau\"...\n",
            "\n",
            "entity:  {'text': 'Đài', 'pos': [155, 158]}\n",
            "entity index list:  [34]\n",
            "[118, 121]\n",
            "['Đài']\n",
            "My word_tokenize 1:         ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "My word_tokenize 2:         ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến', 'Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  9667\n",
            "sentence:  Trên thực tế từ đầu năm 2017 đến nay, một bộ phận người Mỹ liên tục đưa ra các vấn đề như \"bán vũ khí cho Đài Loan \", \"Luật du lịch Đài Loan \", \"tàu chiến Đài - Mỹ thăm nhau\"...\n",
            "\n",
            "entity:  {'text': 'Đài', 'pos': [155, 158]}\n",
            "entity index list:  [34]\n",
            "[118, 121]\n",
            "['Đài']\n",
            "My word_tokenize 1:         ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "My word_tokenize 2:         ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến', 'Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  9669\n",
            "sentence:  Trên thực tế từ đầu năm 2017 đến nay, một bộ phận người Mỹ liên tục đưa ra các vấn đề như \"bán vũ khí cho Đài Loan \", \"Luật du lịch Đài Loan \", \"tàu chiến Đài - Mỹ thăm nhau\"...\n",
            "\n",
            "entity:  {'text': 'Đài', 'pos': [155, 158]}\n",
            "entity index list:  [34]\n",
            "['Đài']\n",
            "[118, 121]\n",
            "Underthesea word_tokenize:  ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "My word_tokenize 1:         ['Trên', 'thực tế', 'từ', 'đầu', 'năm', '2017', 'đến', 'nay', ',', 'một', 'bộ phận', 'người', 'Mỹ', 'liên tục', 'đưa', 'ra', 'các', 'vấn đề', 'như', '\"', 'bán', 'vũ khí', 'cho', 'Đài Loan', '\"', ',', '\"', 'Luật', 'du lịch', 'Đài Loan', '\"', ',', '\"', 'tàu chiến', 'Đài', '-', 'Mỹ', 'thăm', 'nhau', '\"', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  9747\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "[51, 60]\n",
            "['Argentina']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 2:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9748\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Thomas Cooney', 'pos': [77, 90]}\n",
            "entity index list:  [14]\n",
            "[60, 72]\n",
            "['Thomas Cooney']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 2:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9752\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "[51, 60]\n",
            "['Argentina']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 2:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9753\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Thomas Cooney', 'pos': [77, 90]}\n",
            "entity index list:  [14]\n",
            "[60, 72]\n",
            "['Thomas Cooney']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 2:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9757\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "['Argentina']\n",
            "[51, 60]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9758\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "['Argentina']\n",
            "[51, 60]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9759\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "['Argentina']\n",
            "[51, 60]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9760\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [67, 76]}\n",
            "entity index list:  [13]\n",
            "['Argentina']\n",
            "[51, 60]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9761\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Thomas Cooney', 'pos': [77, 90]}\n",
            "entity index list:  [14]\n",
            "['Thomas Cooney']\n",
            "[60, 72]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9762\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Thomas Cooney', 'pos': [77, 90]}\n",
            "entity index list:  [14]\n",
            "['Thomas Cooney']\n",
            "[60, 72]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9763\n",
            "sentence:  Nối lại hợp tác quân sự với Mỹ Ngày 21-9, đại biện lâm thời Mỹ tại Argentina Thomas Cooney thông báo, Washington đã nối lại hợp tác quân sự với Buenos Aires trong việc đào tạo lực lượng gìn giữ hòa bình, trao đổi nghiệp vụ và tập trận chung tại Nam Cực .\n",
            "\n",
            "entity:  {'text': 'Thomas Cooney', 'pos': [77, 90]}\n",
            "entity index list:  [14]\n",
            "['Thomas Cooney']\n",
            "[60, 72]\n",
            "Underthesea word_tokenize:  ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "My word_tokenize 1:         ['Nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Mỹ', 'Ngày', '21-9', ',', 'đại biện', 'lâm thời', 'Mỹ', 'tại', 'Argentina', 'Thomas Cooney', 'thông báo', ',', 'Washington', 'đã', 'nối', 'lại', 'hợp tác', 'quân sự', 'với', 'Buenos Aires', 'trong', 'việc', 'đào tạo', 'lực lượng', 'gìn giữ', 'hòa bình', ',', 'trao đổi', 'nghiệp vụ', 'và', 'tập trận', 'chung', 'tại', 'Nam Cực', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9771\n",
            "sentence:  Quan hệ giữa Argentina và Mỹ đã được cải thiện nhanh chóng ngay sau khi Tổng thống Tổng thống Argentina Mauricio Macri lên cầm quyền.\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [94, 103]}\n",
            "entity index list:  [14]\n",
            "[75, 84]\n",
            "['Argentina']\n",
            "My word_tokenize 1:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "My word_tokenize 2:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina', 'Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9772\n",
            "sentence:  Quan hệ giữa Argentina và Mỹ đã được cải thiện nhanh chóng ngay sau khi Tổng thống Tổng thống Argentina Mauricio Macri lên cầm quyền.\n",
            "\n",
            "entity:  {'text': 'Mauricio Macri', 'pos': [104, 118]}\n",
            "entity index list:  [15]\n",
            "[84, 97]\n",
            "['Mauricio Macri']\n",
            "My word_tokenize 1:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "My word_tokenize 2:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina', 'Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9773\n",
            "sentence:  Quan hệ giữa Argentina và Mỹ đã được cải thiện nhanh chóng ngay sau khi Tổng thống Tổng thống Argentina Mauricio Macri lên cầm quyền.\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [94, 103]}\n",
            "entity index list:  [14]\n",
            "[75, 84]\n",
            "['Argentina']\n",
            "My word_tokenize 1:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "My word_tokenize 2:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina', 'Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9774\n",
            "sentence:  Quan hệ giữa Argentina và Mỹ đã được cải thiện nhanh chóng ngay sau khi Tổng thống Tổng thống Argentina Mauricio Macri lên cầm quyền.\n",
            "\n",
            "entity:  {'text': 'Mauricio Macri', 'pos': [104, 118]}\n",
            "entity index list:  [15]\n",
            "[84, 97]\n",
            "['Mauricio Macri']\n",
            "My word_tokenize 1:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "My word_tokenize 2:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina', 'Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9775\n",
            "sentence:  Quan hệ giữa Argentina và Mỹ đã được cải thiện nhanh chóng ngay sau khi Tổng thống Tổng thống Argentina Mauricio Macri lên cầm quyền.\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [94, 103]}\n",
            "entity index list:  [14]\n",
            "['Argentina']\n",
            "[75, 84]\n",
            "Underthesea word_tokenize:  ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "My word_tokenize 1:         ['Quan hệ', 'giữa', 'Argentina', 'và', 'Mỹ', 'đã', 'được', 'cải thiện', 'nhanh chóng', 'ngay', 'sau', 'khi', 'Tổng thống', 'Tổng thống', 'Argentina', 'Mauricio Macri', 'lên', 'cầm quyền', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9857\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Iraq', 'pos': [37, 41]}\n",
            "entity index list:  [4]\n",
            "['Iraq']\n",
            "[29, 33]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9858\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Iraq', 'pos': [37, 41]}\n",
            "entity index list:  [4]\n",
            "['Iraq']\n",
            "[29, 33]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9859\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Iraq', 'pos': [37, 41]}\n",
            "entity index list:  [4]\n",
            "['Iraq']\n",
            "[29, 33]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9860\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Iraq', 'pos': [37, 41]}\n",
            "entity index list:  [4]\n",
            "['Iraq']\n",
            "[29, 33]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9861\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Raed Shaker Jawdat', 'pos': [42, 60]}\n",
            "entity index list:  [5]\n",
            "['Raed Shaker Jawdat']\n",
            "[33, 49]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9862\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Raed Shaker Jawdat', 'pos': [42, 60]}\n",
            "entity index list:  [5]\n",
            "['Raed Shaker Jawdat']\n",
            "[33, 49]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9863\n",
            "sentence:  Tư lệnh Lực lượng cảnh sát liên bang Iraq Raed Shaker Jawdat nêu rõ, các lực lượng của Iraq giải phóng chín ngôi làng từ tay IS , tiêu diệt 45 phần tử khủng bố và phá hủy bảy chiếc xe chứa chất nổ ở phía tây thị trấn Hawijah .\n",
            "\n",
            "entity:  {'text': 'Raed Shaker Jawdat', 'pos': [42, 60]}\n",
            "entity index list:  [5]\n",
            "['Raed Shaker Jawdat']\n",
            "[33, 49]\n",
            "Underthesea word_tokenize:  ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "My word_tokenize 1:         ['Tư lệnh', 'Lực lượng', 'cảnh sát', 'liên bang', 'Iraq', 'Raed Shaker Jawdat', 'nêu', 'rõ', ',', 'các', 'lực lượng', 'của', 'Iraq', 'giải phóng', 'chín', 'ngôi', 'làng', 'từ', 'tay', 'IS', ',', 'tiêu diệt', '45', 'phần tử', 'khủng bố', 'và', 'phá hủy', 'bảy', 'chiếc', 'xe', 'chứa chất nổ', 'ở', 'phía', 'tây', 'thị trấn', 'Hawijah', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9889\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9890\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [9]\n",
            "[55, 59]\n",
            "['Iran']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 2:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9891\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [10]\n",
            "[59, 72]\n",
            "['Hassan Rouhani']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 2:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9892\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9893\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9894\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9895\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9896\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Nhật Bản', 'pos': [19, 27]}\n",
            "entity index list:  [3]\n",
            "['Nhật Bản']\n",
            "[15, 22]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9897\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [9]\n",
            "[55, 59]\n",
            "['Iran']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 2:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9898\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [10]\n",
            "[59, 72]\n",
            "['Hassan Rouhani']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 2:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9899\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9900\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9901\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9902\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9903\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Shinzo Abe', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "['Shinzo Abe']\n",
            "[22, 31]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản', 'Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9904\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9905\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9906\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9907\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9908\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9909\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [69, 73]}\n",
            "entity index list:  [8]\n",
            "['Iran']\n",
            "[55, 59]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9910\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [9]\n",
            "['Hassan Rouhani']\n",
            "[59, 72]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9911\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [9]\n",
            "['Hassan Rouhani']\n",
            "[59, 72]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9912\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [9]\n",
            "['Hassan Rouhani']\n",
            "[59, 72]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9913\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [9]\n",
            "['Hassan Rouhani']\n",
            "[59, 72]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9914\n",
            "sentence:  Mới đây, Thủ tướng Nhật Bản Shinzo Abe tuyên bố thẳng với Tổng thống Iran Hassan Rouhani rằng, Nhật Bản tiếp tục ủng hộ thỏa thuận hạt nhân lịch sử mà Iran và Nhóm P5+1 (gồm năm nước Thường trực Hội đồng Bảo an Liên hợp quốc và Ðức ) đạt được năm 2015.\n",
            "\n",
            "entity:  {'text': 'Hassan Rouhani', 'pos': [74, 88]}\n",
            "entity index list:  [9]\n",
            "['Hassan Rouhani']\n",
            "[59, 72]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'Thủ tướng', 'Nhật Bản Shinzo Abe', 'tuyên bố', 'thẳng', 'với', 'Tổng thống', 'Iran', 'Hassan Rouhani', 'rằng', ',', 'Nhật Bản', 'tiếp tục', 'ủng hộ', 'thỏa thuận', 'hạt nhân', 'lịch sử', 'mà', 'Iran', 'và', 'Nhóm', 'P5', '+', '1', '(', 'gồm', 'năm', 'nước', 'Thường trực', 'Hội đồng', 'Bảo an', 'Liên hợp quốc', 'và', 'Ðức', ')', 'đạt', 'được', 'năm', '2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10042\n",
            "sentence:  Phát biểu tại kỳ họp, Ngoại trưởng Nga Sergei Lavrov và Bộ trưởng Ngoại giao TQ Vương Nghị không bỏ qua cơ hội cảnh báo:\n",
            "\n",
            "entity:  {'text': 'TQ', 'pos': [77, 79]}\n",
            "entity index list:  [11]\n",
            "[62, 64]\n",
            "['TQ']\n",
            "My word_tokenize 1:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "My word_tokenize 2:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ', 'Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10043\n",
            "sentence:  Phát biểu tại kỳ họp, Ngoại trưởng Nga Sergei Lavrov và Bộ trưởng Ngoại giao TQ Vương Nghị không bỏ qua cơ hội cảnh báo:\n",
            "\n",
            "entity:  {'text': 'Vương Nghị', 'pos': [80, 90]}\n",
            "entity index list:  [12]\n",
            "[64, 73]\n",
            "['Vương Nghị']\n",
            "My word_tokenize 1:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "My word_tokenize 2:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ', 'Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10044\n",
            "sentence:  Phát biểu tại kỳ họp, Ngoại trưởng Nga Sergei Lavrov và Bộ trưởng Ngoại giao TQ Vương Nghị không bỏ qua cơ hội cảnh báo:\n",
            "\n",
            "entity:  {'text': 'TQ', 'pos': [77, 79]}\n",
            "entity index list:  [11]\n",
            "[62, 64]\n",
            "['TQ']\n",
            "My word_tokenize 1:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "My word_tokenize 2:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ', 'Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10045\n",
            "sentence:  Phát biểu tại kỳ họp, Ngoại trưởng Nga Sergei Lavrov và Bộ trưởng Ngoại giao TQ Vương Nghị không bỏ qua cơ hội cảnh báo:\n",
            "\n",
            "entity:  {'text': 'Vương Nghị', 'pos': [80, 90]}\n",
            "entity index list:  [12]\n",
            "[64, 73]\n",
            "['Vương Nghị']\n",
            "My word_tokenize 1:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "My word_tokenize 2:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ', 'Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10046\n",
            "sentence:  Phát biểu tại kỳ họp, Ngoại trưởng Nga Sergei Lavrov và Bộ trưởng Ngoại giao TQ Vương Nghị không bỏ qua cơ hội cảnh báo:\n",
            "\n",
            "entity:  {'text': 'TQ', 'pos': [77, 79]}\n",
            "entity index list:  [11]\n",
            "['TQ']\n",
            "[62, 64]\n",
            "Underthesea word_tokenize:  ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "My word_tokenize 1:         ['Phát biểu', 'tại', 'kỳ', 'họp', ',', 'Ngoại trưởng', 'Nga', 'Sergei Lavrov', 'và', 'Bộ trưởng', 'Ngoại giao', 'TQ', 'Vương Nghị', 'không', 'bỏ qua', 'cơ hội', 'cảnh báo', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10065\n",
            "sentence:  Ông nhấn mạnh lập trường của Nga là cộng đồng quốc tế cần khuyến khích các bên ở Venezuela hòa giải và thỏa hiệp.\n",
            "\n",
            "entity:  {'text': 'Venezuela', 'pos': [81, 90]}\n",
            "entity index list:  [13]\n",
            "[63, 72]\n",
            "['Venezuela']\n",
            "My word_tokenize 1:         ['Ông', 'nhấn mạnh', 'lập trường', 'của', 'Nga', 'là', 'cộng đồng', 'quốc tế', 'cần', 'khuyến khích', 'các', 'bên', 'ở', 'Venezuela hòa giải', 'và', 'thỏa hiệp', '.']\n",
            "My word_tokenize 2:         ['Ông', 'nhấn mạnh', 'lập trường', 'của', 'Nga', 'là', 'cộng đồng', 'quốc tế', 'cần', 'khuyến khích', 'các', 'bên', 'ở', 'Venezuela', 'hòa giải', 'và', 'thỏa hiệp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10108\n",
            "sentence:  Mỹ muốn thương lượng lại, cho rằng thỏa thuận hiện tại quá nhân nhượng Iran , không phục vụ quyền lợi an ninh Mỹ , hạn chế khả năng làm áp lực lên Iran của Mỹ .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [110, 112]}\n",
            "entity index list:  [17]\n",
            "[87, 89]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "My word_tokenize 2:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh', 'Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10111\n",
            "sentence:  Mỹ muốn thương lượng lại, cho rằng thỏa thuận hiện tại quá nhân nhượng Iran , không phục vụ quyền lợi an ninh Mỹ , hạn chế khả năng làm áp lực lên Iran của Mỹ .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [110, 112]}\n",
            "entity index list:  [17]\n",
            "[87, 89]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "My word_tokenize 2:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh', 'Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10114\n",
            "sentence:  Mỹ muốn thương lượng lại, cho rằng thỏa thuận hiện tại quá nhân nhượng Iran , không phục vụ quyền lợi an ninh Mỹ , hạn chế khả năng làm áp lực lên Iran của Mỹ .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [110, 112]}\n",
            "entity index list:  [17]\n",
            "['Mỹ']\n",
            "[87, 89]\n",
            "Underthesea word_tokenize:  ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "My word_tokenize 1:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh', 'Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10115\n",
            "sentence:  Mỹ muốn thương lượng lại, cho rằng thỏa thuận hiện tại quá nhân nhượng Iran , không phục vụ quyền lợi an ninh Mỹ , hạn chế khả năng làm áp lực lên Iran của Mỹ .\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [110, 112]}\n",
            "entity index list:  [17]\n",
            "['Mỹ']\n",
            "[87, 89]\n",
            "Underthesea word_tokenize:  ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "My word_tokenize 1:         ['Mỹ', 'muốn', 'thương lượng', 'lại', ',', 'cho', 'rằng', 'thỏa thuận', 'hiện tại', 'quá', 'nhân nhượng', 'Iran', ',', 'không', 'phục vụ', 'quyền lợi', 'an ninh', 'Mỹ', ',', 'hạn chế', 'khả năng', 'làm', 'áp lực', 'lên', 'Iran', 'của', 'Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10134\n",
            "sentence:  Về phía TQ , Ngoại trưởng Vương Nghị cho rằng thỏa thuận Iran dù không hoàn hảo nhưng nếu Iran bị hủy bỏ sẽ ảnh hưởng đến nỗ lực chống phổ biến vũ khí hạt nhân.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [57, 61]}\n",
            "entity index list:  [9]\n",
            "[45, 49]\n",
            "['Iran']\n",
            "My word_tokenize 1:         ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "My word_tokenize 2:         ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran', 'dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10136\n",
            "sentence:  Về phía TQ , Ngoại trưởng Vương Nghị cho rằng thỏa thuận Iran dù không hoàn hảo nhưng nếu Iran bị hủy bỏ sẽ ảnh hưởng đến nỗ lực chống phổ biến vũ khí hạt nhân.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [57, 61]}\n",
            "entity index list:  [9]\n",
            "[45, 49]\n",
            "['Iran']\n",
            "My word_tokenize 1:         ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "My word_tokenize 2:         ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran', 'dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10138\n",
            "sentence:  Về phía TQ , Ngoại trưởng Vương Nghị cho rằng thỏa thuận Iran dù không hoàn hảo nhưng nếu Iran bị hủy bỏ sẽ ảnh hưởng đến nỗ lực chống phổ biến vũ khí hạt nhân.\n",
            "\n",
            "entity:  {'text': 'Iran', 'pos': [57, 61]}\n",
            "entity index list:  [9]\n",
            "['Iran']\n",
            "[45, 49]\n",
            "Underthesea word_tokenize:  ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "My word_tokenize 1:         ['Về', 'phía', 'TQ', ',', 'Ngoại trưởng', 'Vương Nghị', 'cho', 'rằng', 'thỏa thuận', 'Iran', 'dù', 'không', 'hoàn hảo', 'nhưng', 'nếu', 'Iran', 'bị', 'hủy bỏ', 'sẽ', 'ảnh hưởng', 'đến', 'nỗ lực', 'chống', 'phổ biến', 'vũ khí', 'hạt nhân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10170\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [156, 161]}\n",
            "entity index list:  [21]\n",
            "[125, 130]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10171\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar al-Assad', 'pos': [162, 177]}\n",
            "entity index list:  [22]\n",
            "[130, 144]\n",
            "['Bashar al-Assad']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10174\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [156, 161]}\n",
            "entity index list:  [21]\n",
            "[125, 130]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10175\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar al-Assad', 'pos': [162, 177]}\n",
            "entity index list:  [22]\n",
            "[130, 144]\n",
            "['Bashar al-Assad']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10177\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [156, 161]}\n",
            "entity index list:  [21]\n",
            "[125, 130]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10178\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar al-Assad', 'pos': [162, 177]}\n",
            "entity index list:  [22]\n",
            "[130, 144]\n",
            "['Bashar al-Assad']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10179\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [156, 161]}\n",
            "entity index list:  [21]\n",
            "[125, 130]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10180\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Bashar al-Assad', 'pos': [162, 177]}\n",
            "entity index list:  [22]\n",
            "[130, 144]\n",
            "['Bashar al-Assad']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 2:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10181\n",
            "sentence:  Nếu Iran muốn thỏa thuận này được duy trì thì chính quyền Tehran phải chấp nhận không tiếp tục hỗ trợ lực lượng vũ trang Hezbollah (Lebanon ) và Tổng thống Syria Bashar al-Assad .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [156, 161]}\n",
            "entity index list:  [21]\n",
            "['Syria']\n",
            "[125, 130]\n",
            "Underthesea word_tokenize:  ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria Bashar al-Assad', '.']\n",
            "My word_tokenize 1:         ['Nếu', 'Iran', 'muốn', 'thỏa thuận', 'này', 'được', 'duy trì', 'thì', 'chính quyền', 'Tehran', 'phải', 'chấp nhận', 'không', 'tiếp tục', 'hỗ trợ lực lượng vũ trang', 'Hezbollah', '(', 'Lebanon', ')', 'và', 'Tổng thống', 'Syria', 'Bashar al-Assad', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10260\n",
            "sentence:  Câu nói của Ngọc khiến Minh như gỡ được nút thắt trong lòng, anh vui mừng, nắm lấy tay Ngọc định nói ra điều gì đó thì một giọng nói cất lên: Minh quay đầu lại nhận ra đó là An .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [87, 91]}\n",
            "entity index list:  [19]\n",
            "[68, 72]\n",
            "['Ngọc']\n",
            "My word_tokenize 1:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "My word_tokenize 2:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc', 'định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10263\n",
            "sentence:  Câu nói của Ngọc khiến Minh như gỡ được nút thắt trong lòng, anh vui mừng, nắm lấy tay Ngọc định nói ra điều gì đó thì một giọng nói cất lên: Minh quay đầu lại nhận ra đó là An .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [87, 91]}\n",
            "entity index list:  [19]\n",
            "[68, 72]\n",
            "['Ngọc']\n",
            "My word_tokenize 1:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "My word_tokenize 2:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc', 'định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10266\n",
            "sentence:  Câu nói của Ngọc khiến Minh như gỡ được nút thắt trong lòng, anh vui mừng, nắm lấy tay Ngọc định nói ra điều gì đó thì một giọng nói cất lên: Minh quay đầu lại nhận ra đó là An .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [87, 91]}\n",
            "entity index list:  [19]\n",
            "['Ngọc']\n",
            "[68, 72]\n",
            "Underthesea word_tokenize:  ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "My word_tokenize 1:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc', 'định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10267\n",
            "sentence:  Câu nói của Ngọc khiến Minh như gỡ được nút thắt trong lòng, anh vui mừng, nắm lấy tay Ngọc định nói ra điều gì đó thì một giọng nói cất lên: Minh quay đầu lại nhận ra đó là An .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [87, 91]}\n",
            "entity index list:  [19]\n",
            "['Ngọc']\n",
            "[68, 72]\n",
            "Underthesea word_tokenize:  ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "My word_tokenize 1:         ['Câu nói', 'của', 'Ngọc', 'khiến', 'Minh', 'như', 'gỡ', 'được', 'nút', 'thắt', 'trong', 'lòng', ',', 'anh', 'vui mừng', ',', 'nắm', 'lấy', 'tay', 'Ngọc', 'định', 'nói', 'ra', 'điều', 'gì', 'đó', 'thì', 'một', 'giọng', 'nói', 'cất', 'lên', ':', 'Minh', 'quay', 'đầu', 'lại', 'nhận', 'ra', 'đó', 'là', 'An', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10275\n",
            "sentence:  Minh lên tiếng chào An còn cô dường như hơi có thoáng chút giật mình khi nghe Ngọc nói anh là bạn, cô có vẻ không ưa gì anh, nên không nói gì chỉ im lặng bước qua Minh rồi đột nhiên quay lại nói: Minh hiểu bản thân anh không được đón nhận ở căn biệt thư này nên xin phép ra về.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [20, 22]}\n",
            "entity index list:  [4]\n",
            "[16, 18]\n",
            "['An']\n",
            "My word_tokenize 1:         ['Minh', 'lên', 'tiếng', 'chào An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "My word_tokenize 2:         ['Minh', 'lên', 'tiếng', 'chào', 'An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10279\n",
            "sentence:  Minh lên tiếng chào An còn cô dường như hơi có thoáng chút giật mình khi nghe Ngọc nói anh là bạn, cô có vẻ không ưa gì anh, nên không nói gì chỉ im lặng bước qua Minh rồi đột nhiên quay lại nói: Minh hiểu bản thân anh không được đón nhận ở căn biệt thư này nên xin phép ra về.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [20, 22]}\n",
            "entity index list:  [4]\n",
            "['An']\n",
            "[16, 18]\n",
            "Underthesea word_tokenize:  ['Minh', 'lên', 'tiếng', 'chào An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "My word_tokenize 1:         ['Minh', 'lên', 'tiếng', 'chào', 'An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10280\n",
            "sentence:  Minh lên tiếng chào An còn cô dường như hơi có thoáng chút giật mình khi nghe Ngọc nói anh là bạn, cô có vẻ không ưa gì anh, nên không nói gì chỉ im lặng bước qua Minh rồi đột nhiên quay lại nói: Minh hiểu bản thân anh không được đón nhận ở căn biệt thư này nên xin phép ra về.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [20, 22]}\n",
            "entity index list:  [4]\n",
            "['An']\n",
            "[16, 18]\n",
            "Underthesea word_tokenize:  ['Minh', 'lên', 'tiếng', 'chào An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "My word_tokenize 1:         ['Minh', 'lên', 'tiếng', 'chào', 'An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10281\n",
            "sentence:  Minh lên tiếng chào An còn cô dường như hơi có thoáng chút giật mình khi nghe Ngọc nói anh là bạn, cô có vẻ không ưa gì anh, nên không nói gì chỉ im lặng bước qua Minh rồi đột nhiên quay lại nói: Minh hiểu bản thân anh không được đón nhận ở căn biệt thư này nên xin phép ra về.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [20, 22]}\n",
            "entity index list:  [4]\n",
            "['An']\n",
            "[16, 18]\n",
            "Underthesea word_tokenize:  ['Minh', 'lên', 'tiếng', 'chào An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "My word_tokenize 1:         ['Minh', 'lên', 'tiếng', 'chào', 'An', 'còn', 'cô', 'dường như', 'hơi', 'có', 'thoáng', 'chút', 'giật mình', 'khi', 'nghe', 'Ngọc', 'nói', 'anh', 'là', 'bạn', ',', 'cô', 'có vẻ', 'không', 'ưa', 'gì', 'anh', ',', 'nên', 'không', 'nói', 'gì', 'chỉ', 'im lặng', 'bước', 'qua', 'Minh', 'rồi', 'đột nhiên', 'quay', 'lại', 'nói', ':', 'Minh', 'hiểu', 'bản thân', 'anh', 'không', 'được', 'đón nhận', 'ở', 'căn', 'biệt', 'thư', 'này', 'nên', 'xin', 'phép', 'ra', 'về', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10286\n",
            "sentence:  Minh trở về nhà, cũng may lần trước Ngọc gọi, anh vẫn còn giữ số điện thoại, tối ấy cả hai người lại nói chuyện với nhau rất lâu.\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [36, 40]}\n",
            "entity index list:  [9]\n",
            "[28, 32]\n",
            "['Ngọc']\n",
            "My word_tokenize 1:         ['Minh', 'trở', 'về', 'nhà', ',', 'cũng', 'may', 'lần', 'trước', 'Ngọc gọi', ',', 'anh', 'vẫn', 'còn', 'giữ', 'số', 'điện thoại', ',', 'tối', 'ấy', 'cả', 'hai', 'người', 'lại', 'nói chuyện', 'với', 'nhau', 'rất', 'lâu', '.']\n",
            "My word_tokenize 2:         ['Minh', 'trở', 'về', 'nhà', ',', 'cũng', 'may', 'lần', 'trước', 'Ngọc', 'gọi', ',', 'anh', 'vẫn', 'còn', 'giữ', 'số', 'điện thoại', ',', 'tối', 'ấy', 'cả', 'hai', 'người', 'lại', 'nói chuyện', 'với', 'nhau', 'rất', 'lâu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10299\n",
            "sentence:  An lập công ty về thời trang để cô có thể sống tại Việt Nam và tiện chăm sóc Ngọc và bố mẹ cô.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [0, 2]}\n",
            "entity index list:  [0]\n",
            "['An']\n",
            "[0, 2]\n",
            "Underthesea word_tokenize:  ['An lập', 'công ty', 'về', 'thời trang', 'để', 'cô', 'có thể', 'sống', 'tại', 'Việt Nam', 'và', 'tiện', 'chăm sóc', 'Ngọc', 'và', 'bố mẹ', 'cô', '.']\n",
            "My word_tokenize 1:         ['An', 'lập', 'công ty', 'về', 'thời trang', 'để', 'cô', 'có thể', 'sống', 'tại', 'Việt Nam', 'và', 'tiện', 'chăm sóc', 'Ngọc', 'và', 'bố mẹ', 'cô', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10300\n",
            "sentence:  An lập công ty về thời trang để cô có thể sống tại Việt Nam và tiện chăm sóc Ngọc và bố mẹ cô.\n",
            "\n",
            "entity:  {'text': 'An', 'pos': [0, 2]}\n",
            "entity index list:  [0]\n",
            "['An']\n",
            "[0, 2]\n",
            "Underthesea word_tokenize:  ['An lập', 'công ty', 'về', 'thời trang', 'để', 'cô', 'có thể', 'sống', 'tại', 'Việt Nam', 'và', 'tiện', 'chăm sóc', 'Ngọc', 'và', 'bố mẹ', 'cô', '.']\n",
            "My word_tokenize 1:         ['An', 'lập', 'công ty', 'về', 'thời trang', 'để', 'cô', 'có thể', 'sống', 'tại', 'Việt Nam', 'và', 'tiện', 'chăm sóc', 'Ngọc', 'và', 'bố mẹ', 'cô', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10314\n",
            "sentence:  Cả cô Kim nữa, Minh nên nói thế nào với cô ta, dù Ngọc không phải nhân tình nhưng chuyện ông Long đối tốt với cô chắc chắn sẽ khiến Kim khó chịu và làm hại Ngọc .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [50, 54]}\n",
            "entity index list:  [14]\n",
            "[37, 41]\n",
            "['Ngọc']\n",
            "My word_tokenize 1:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "My word_tokenize 2:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10318\n",
            "sentence:  Cả cô Kim nữa, Minh nên nói thế nào với cô ta, dù Ngọc không phải nhân tình nhưng chuyện ông Long đối tốt với cô chắc chắn sẽ khiến Kim khó chịu và làm hại Ngọc .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [50, 54]}\n",
            "entity index list:  [14]\n",
            "[37, 41]\n",
            "['Ngọc']\n",
            "My word_tokenize 1:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "My word_tokenize 2:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10322\n",
            "sentence:  Cả cô Kim nữa, Minh nên nói thế nào với cô ta, dù Ngọc không phải nhân tình nhưng chuyện ông Long đối tốt với cô chắc chắn sẽ khiến Kim khó chịu và làm hại Ngọc .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [50, 54]}\n",
            "entity index list:  [14]\n",
            "['Ngọc']\n",
            "[37, 41]\n",
            "Underthesea word_tokenize:  ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "My word_tokenize 1:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10323\n",
            "sentence:  Cả cô Kim nữa, Minh nên nói thế nào với cô ta, dù Ngọc không phải nhân tình nhưng chuyện ông Long đối tốt với cô chắc chắn sẽ khiến Kim khó chịu và làm hại Ngọc .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [50, 54]}\n",
            "entity index list:  [14]\n",
            "['Ngọc']\n",
            "[37, 41]\n",
            "Underthesea word_tokenize:  ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "My word_tokenize 1:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10324\n",
            "sentence:  Cả cô Kim nữa, Minh nên nói thế nào với cô ta, dù Ngọc không phải nhân tình nhưng chuyện ông Long đối tốt với cô chắc chắn sẽ khiến Kim khó chịu và làm hại Ngọc .\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [50, 54]}\n",
            "entity index list:  [14]\n",
            "['Ngọc']\n",
            "[37, 41]\n",
            "Underthesea word_tokenize:  ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "My word_tokenize 1:         ['Cả', 'cô', 'Kim', 'nữa', ',', 'Minh', 'nên', 'nói', 'thế nào', 'với', 'cô', 'ta', ',', 'dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'nhưng', 'chuyện', 'ông', 'Long', 'đối', 'tốt', 'với', 'cô', 'chắc chắn', 'sẽ', 'khiến', 'Kim', 'khó chịu', 'và', 'làm', 'hại', 'Ngọc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10328\n",
            "sentence:  Dù Ngọc không phải nhân tình của ông Long nhưng tại sao ông ta lại chuyển một nửa tài sản cho Ngọc ?\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [3, 7]}\n",
            "entity index list:  [1]\n",
            "['Ngọc']\n",
            "[2, 6]\n",
            "Underthesea word_tokenize:  ['Dù Ngọc', 'không', 'phải', 'nhân tình', 'của', 'ông', 'Long', 'nhưng', 'tại sao', 'ông', 'ta', 'lại', 'chuyển', 'một nửa', 'tài sản', 'cho', 'Ngọc', '?']\n",
            "My word_tokenize 1:         ['Dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'của', 'ông', 'Long', 'nhưng', 'tại sao', 'ông', 'ta', 'lại', 'chuyển', 'một nửa', 'tài sản', 'cho', 'Ngọc', '?']\n",
            "\n",
            "\n",
            "---------- sent_id:  10329\n",
            "sentence:  Dù Ngọc không phải nhân tình của ông Long nhưng tại sao ông ta lại chuyển một nửa tài sản cho Ngọc ?\n",
            "\n",
            "entity:  {'text': 'Ngọc', 'pos': [3, 7]}\n",
            "entity index list:  [1]\n",
            "['Ngọc']\n",
            "[2, 6]\n",
            "Underthesea word_tokenize:  ['Dù Ngọc', 'không', 'phải', 'nhân tình', 'của', 'ông', 'Long', 'nhưng', 'tại sao', 'ông', 'ta', 'lại', 'chuyển', 'một nửa', 'tài sản', 'cho', 'Ngọc', '?']\n",
            "My word_tokenize 1:         ['Dù', 'Ngọc', 'không', 'phải', 'nhân tình', 'của', 'ông', 'Long', 'nhưng', 'tại sao', 'ông', 'ta', 'lại', 'chuyển', 'một nửa', 'tài sản', 'cho', 'Ngọc', '?']\n",
            "\n",
            "\n",
            "---------- sent_id:  10459\n",
            "sentence:  Chiêm ngưỡng trang phục độc đáo các dân tộc thiểu số Nga Lễ hội nghệ thuật các dân tộc thiểu số toàn Nga diễn ra từ 14/9 đến hết tháng 12/2017.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [53, 56]}\n",
            "entity index list:  [5]\n",
            "['Nga']\n",
            "[42, 45]\n",
            "Underthesea word_tokenize:  ['Chiêm ngưỡng', 'trang phục', 'độc đáo', 'các', 'dân tộc thiểu số', 'Nga Lễ hội', 'nghệ thuật', 'các', 'dân tộc thiểu số', 'toàn', 'Nga', 'diễn', 'ra', 'từ', '14/9', 'đến', 'hết', 'tháng', '12/2017', '.']\n",
            "My word_tokenize 1:         ['Chiêm ngưỡng', 'trang phục', 'độc đáo', 'các', 'dân tộc thiểu số', 'Nga', 'Lễ hội', 'nghệ thuật', 'các', 'dân tộc thiểu số', 'toàn', 'Nga', 'diễn', 'ra', 'từ', '14/9', 'đến', 'hết', 'tháng', '12/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10536\n",
            "sentence:  Ảnh tư liệu Tháng 2/1946, Bác Hồ tặng cho quân và dân Nam bộ danh hiệu “Thành đồng Tổ quốc”, và tinh thần ấy vẫn luôn là kim chỉ nam, soi sáng đường cho thế hệ hôm nay trong công cuộc xây dựng, bảo vệ Tổ quốc Việt Nam xã hội chủ nghĩa.\n",
            "\n",
            "entity:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "entity index list:  [38]\n",
            "[162, 169]\n",
            "['Việt Nam']\n",
            "My word_tokenize 1:         ['Ảnh', 'tư liệu', 'Tháng', '2/1946', ',', 'Bác Hồ', 'tặng', 'cho', 'quân', 'và', 'dân', 'Nam bộ', 'danh hiệu', '“', 'Thành đồng', 'Tổ quốc', '”', ',', 'và', 'tinh thần', 'ấy', 'vẫn', 'luôn', 'là', 'kim chỉ nam', ',', 'soi', 'sáng', 'đường', 'cho', 'thế hệ', 'hôm nay', 'trong', 'công cuộc', 'xây dựng', ',', 'bảo vệ', 'Tổ quốc Việt Nam', 'xã hội chủ nghĩa', '.']\n",
            "My word_tokenize 2:         ['Ảnh', 'tư liệu', 'Tháng', '2/1946', ',', 'Bác Hồ', 'tặng', 'cho', 'quân', 'và', 'dân', 'Nam bộ', 'danh hiệu', '“', 'Thành đồng', 'Tổ quốc', '”', ',', 'và', 'tinh thần', 'ấy', 'vẫn', 'luôn', 'là', 'kim chỉ nam', ',', 'soi', 'sáng', 'đường', 'cho', 'thế hệ', 'hôm nay', 'trong', 'công cuộc', 'xây dựng', ',', 'bảo vệ', 'Tổ quốc', 'Việt Nam', 'xã hội chủ nghĩa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10537\n",
            "sentence:  Ảnh tư liệu Tháng 2/1946, Bác Hồ tặng cho quân và dân Nam bộ danh hiệu “Thành đồng Tổ quốc”, và tinh thần ấy vẫn luôn là kim chỉ nam, soi sáng đường cho thế hệ hôm nay trong công cuộc xây dựng, bảo vệ Tổ quốc Việt Nam xã hội chủ nghĩa.\n",
            "\n",
            "entity:  {'text': 'Việt Nam', 'pos': [209, 217]}\n",
            "entity index list:  [38]\n",
            "[162, 169]\n",
            "['Việt Nam']\n",
            "My word_tokenize 1:         ['Ảnh', 'tư liệu', 'Tháng', '2/1946', ',', 'Bác Hồ', 'tặng', 'cho', 'quân', 'và', 'dân', 'Nam bộ', 'danh hiệu', '“', 'Thành đồng', 'Tổ quốc', '”', ',', 'và', 'tinh thần', 'ấy', 'vẫn', 'luôn', 'là', 'kim chỉ nam', ',', 'soi', 'sáng', 'đường', 'cho', 'thế hệ', 'hôm nay', 'trong', 'công cuộc', 'xây dựng', ',', 'bảo vệ', 'Tổ quốc Việt Nam', 'xã hội chủ nghĩa', '.']\n",
            "My word_tokenize 2:         ['Ảnh', 'tư liệu', 'Tháng', '2/1946', ',', 'Bác Hồ', 'tặng', 'cho', 'quân', 'và', 'dân', 'Nam bộ', 'danh hiệu', '“', 'Thành đồng', 'Tổ quốc', '”', ',', 'và', 'tinh thần', 'ấy', 'vẫn', 'luôn', 'là', 'kim chỉ nam', ',', 'soi', 'sáng', 'đường', 'cho', 'thế hệ', 'hôm nay', 'trong', 'công cuộc', 'xây dựng', ',', 'bảo vệ', 'Tổ quốc', 'Việt Nam', 'xã hội chủ nghĩa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10576\n",
            "sentence:  Anh Nguyễn Đăng – ông bố có hai con đang học tiểu học và mẫu giáo, hiện đang sinh sống và làm việc ở Nhật Bản – cho biết, hội phụ huynh ở đây sinh ra là để các phụ huynh giúp đỡ lẫn nhau trong việc chăm sóc con cái.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Đăng', 'pos': [4, 15]}\n",
            "entity index list:  [1]\n",
            "['Nguyễn Đăng']\n",
            "[3, 13]\n",
            "Underthesea word_tokenize:  ['Anh', 'Nguyễn Đăng –', 'ông', 'bố', 'có', 'hai', 'con', 'đang', 'học', 'tiểu học', 'và', 'mẫu giáo', ',', 'hiện', 'đang', 'sinh sống', 'và', 'làm việc', 'ở', 'Nhật Bản', '–', 'cho', 'biết', ',', 'hội', 'phụ huynh', 'ở', 'đây', 'sinh', 'ra', 'là', 'để', 'các', 'phụ huynh', 'giúp đỡ', 'lẫn', 'nhau', 'trong', 'việc', 'chăm sóc', 'con cái', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Nguyễn Đăng', '–', 'ông', 'bố', 'có', 'hai', 'con', 'đang', 'học', 'tiểu học', 'và', 'mẫu giáo', ',', 'hiện', 'đang', 'sinh sống', 'và', 'làm việc', 'ở', 'Nhật Bản', '–', 'cho', 'biết', ',', 'hội', 'phụ huynh', 'ở', 'đây', 'sinh', 'ra', 'là', 'để', 'các', 'phụ huynh', 'giúp đỡ', 'lẫn', 'nhau', 'trong', 'việc', 'chăm sóc', 'con cái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10613\n",
            "sentence:  Đắm say trước khung cảnh kỳ vĩ của vịnh Vũng Rô Do được bao quanh bởi ba dãy núi cao hiểm trở, vịnh Vũng Rô của Phú Yên là nơi có khung cảnh thiên nhiên hùng vĩ khiến lòng người say đắm.\n",
            "\n",
            "entity:  {'text': 'Vũng Rô', 'pos': [40, 47]}\n",
            "entity index list:  [7]\n",
            "['Vũng Rô']\n",
            "[31, 37]\n",
            "Underthesea word_tokenize:  ['Đắm say', 'trước', 'khung cảnh', 'kỳ', 'vĩ', 'của', 'vịnh', 'Vũng Rô Do', 'được', 'bao', 'quanh', 'bởi', 'ba', 'dãy', 'núi', 'cao', 'hiểm trở', ',', 'vịnh', 'Vũng Rô', 'của', 'Phú Yên', 'là', 'nơi', 'có', 'khung cảnh', 'thiên nhiên', 'hùng vĩ', 'khiến', 'lòng', 'người', 'say đắm', '.']\n",
            "My word_tokenize 1:         ['Đắm say', 'trước', 'khung cảnh', 'kỳ', 'vĩ', 'của', 'vịnh', 'Vũng Rô', 'Do', 'được', 'bao', 'quanh', 'bởi', 'ba', 'dãy', 'núi', 'cao', 'hiểm trở', ',', 'vịnh', 'Vũng Rô', 'của', 'Phú Yên', 'là', 'nơi', 'có', 'khung cảnh', 'thiên nhiên', 'hùng vĩ', 'khiến', 'lòng', 'người', 'say đắm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10614\n",
            "sentence:  Đắm say trước khung cảnh kỳ vĩ của vịnh Vũng Rô Do được bao quanh bởi ba dãy núi cao hiểm trở, vịnh Vũng Rô của Phú Yên là nơi có khung cảnh thiên nhiên hùng vĩ khiến lòng người say đắm.\n",
            "\n",
            "entity:  {'text': 'Vũng Rô', 'pos': [40, 47]}\n",
            "entity index list:  [7]\n",
            "['Vũng Rô']\n",
            "[31, 37]\n",
            "Underthesea word_tokenize:  ['Đắm say', 'trước', 'khung cảnh', 'kỳ', 'vĩ', 'của', 'vịnh', 'Vũng Rô Do', 'được', 'bao', 'quanh', 'bởi', 'ba', 'dãy', 'núi', 'cao', 'hiểm trở', ',', 'vịnh', 'Vũng Rô', 'của', 'Phú Yên', 'là', 'nơi', 'có', 'khung cảnh', 'thiên nhiên', 'hùng vĩ', 'khiến', 'lòng', 'người', 'say đắm', '.']\n",
            "My word_tokenize 1:         ['Đắm say', 'trước', 'khung cảnh', 'kỳ', 'vĩ', 'của', 'vịnh', 'Vũng Rô', 'Do', 'được', 'bao', 'quanh', 'bởi', 'ba', 'dãy', 'núi', 'cao', 'hiểm trở', ',', 'vịnh', 'Vũng Rô', 'của', 'Phú Yên', 'là', 'nơi', 'có', 'khung cảnh', 'thiên nhiên', 'hùng vĩ', 'khiến', 'lòng', 'người', 'say đắm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10846\n",
            "sentence:  Sôi động chuẩn bị Festival thức ăn đường phố Việt tại Nga Chiều 22/9 (chiều tối 22/9 giờ Hà Nội ), tại trung tâm Thương mại Hà Nội - Mátxcơva ở thủ đô Nga sẽ khai mạc Festival thức ăn đường phố Việt Nam tại Nga lần thứ nhất (kéo dài đến hết 24/9).\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [54, 57]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[43, 46]\n",
            "Underthesea word_tokenize:  ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "My word_tokenize 1:         ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga', 'Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10847\n",
            "sentence:  Sôi động chuẩn bị Festival thức ăn đường phố Việt tại Nga Chiều 22/9 (chiều tối 22/9 giờ Hà Nội ), tại trung tâm Thương mại Hà Nội - Mátxcơva ở thủ đô Nga sẽ khai mạc Festival thức ăn đường phố Việt Nam tại Nga lần thứ nhất (kéo dài đến hết 24/9).\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [54, 57]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[43, 46]\n",
            "Underthesea word_tokenize:  ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "My word_tokenize 1:         ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga', 'Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10848\n",
            "sentence:  Sôi động chuẩn bị Festival thức ăn đường phố Việt tại Nga Chiều 22/9 (chiều tối 22/9 giờ Hà Nội ), tại trung tâm Thương mại Hà Nội - Mátxcơva ở thủ đô Nga sẽ khai mạc Festival thức ăn đường phố Việt Nam tại Nga lần thứ nhất (kéo dài đến hết 24/9).\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [54, 57]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[43, 46]\n",
            "Underthesea word_tokenize:  ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "My word_tokenize 1:         ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga', 'Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10849\n",
            "sentence:  Sôi động chuẩn bị Festival thức ăn đường phố Việt tại Nga Chiều 22/9 (chiều tối 22/9 giờ Hà Nội ), tại trung tâm Thương mại Hà Nội - Mátxcơva ở thủ đô Nga sẽ khai mạc Festival thức ăn đường phố Việt Nam tại Nga lần thứ nhất (kéo dài đến hết 24/9).\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [54, 57]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[43, 46]\n",
            "Underthesea word_tokenize:  ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "My word_tokenize 1:         ['Sôi động', 'chuẩn bị', 'Festival', 'thức ăn', 'đường phố', 'Việt', 'tại', 'Nga', 'Chiều', '22/9', '(', 'chiều tối', '22/9', 'giờ', 'Hà Nội', ')', ',', 'tại', 'trung tâm', 'Thương mại', 'Hà Nội', '-', 'Mátxcơva', 'ở', 'thủ đô', 'Nga', 'sẽ', 'khai mạc', 'Festival', 'thức ăn', 'đường phố', 'Việt Nam', 'tại', 'Nga', 'lần', 'thứ', 'nhất', '(', 'kéo dài', 'đến', 'hết', '24/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10872\n",
            "sentence:  Một số nghệ sĩ nổi tiếng được mời từ trong nước sang như ca sĩ Dương Hoàng Yến , MC Thuỳ Linh … Trong ảnh là một cô gái tham gia chuẩn bị cho Festival trong trang phục dân tộc.\n",
            "\n",
            "entity:  {'text': 'Thuỳ Linh', 'pos': [84, 93]}\n",
            "entity index list:  [15]\n",
            "[64, 72]\n",
            "['Thuỳ Linh']\n",
            "My word_tokenize 1:         ['Một số', 'nghệ sĩ', 'nổi tiếng', 'được', 'mời', 'từ', 'trong', 'nước', 'sang', 'như', 'ca sĩ', 'Dương', 'Hoàng Yến', ',', 'MC Thuỳ Linh', '…', 'Trong', 'ảnh', 'là', 'một', 'cô', 'gái', 'tham gia', 'chuẩn bị', 'cho', 'Festival', 'trong', 'trang phục', 'dân tộc', '.']\n",
            "My word_tokenize 2:         ['Một số', 'nghệ sĩ', 'nổi tiếng', 'được', 'mời', 'từ', 'trong', 'nước', 'sang', 'như', 'ca sĩ', 'Dương', 'Hoàng Yến', ',', 'MC', 'Thuỳ Linh', '…', 'Trong', 'ảnh', 'là', 'một', 'cô', 'gái', 'tham gia', 'chuẩn bị', 'cho', 'Festival', 'trong', 'trang phục', 'dân tộc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10888\n",
            "sentence:  Kết thúc hành trình 6 năm \"Your Singapore \", Tổng cục Du lịch Singapore (STB ) vừa chính thức giới thiệu nhận diện thương hiệu mới tại Việt Nam là \"Singapore - Passion Made Possible\" (tạm dịch:\n",
            "\n",
            "entity:  {'text': 'Singapore', 'pos': [32, 41]}\n",
            "entity index list:  [6]\n",
            "['Singapore']\n",
            "[25, 34]\n",
            "Underthesea word_tokenize:  ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "My word_tokenize 1:         ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your', 'Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10889\n",
            "sentence:  Kết thúc hành trình 6 năm \"Your Singapore \", Tổng cục Du lịch Singapore (STB ) vừa chính thức giới thiệu nhận diện thương hiệu mới tại Việt Nam là \"Singapore - Passion Made Possible\" (tạm dịch:\n",
            "\n",
            "entity:  {'text': 'Singapore', 'pos': [32, 41]}\n",
            "entity index list:  [6]\n",
            "['Singapore']\n",
            "[25, 34]\n",
            "Underthesea word_tokenize:  ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "My word_tokenize 1:         ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your', 'Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10890\n",
            "sentence:  Kết thúc hành trình 6 năm \"Your Singapore \", Tổng cục Du lịch Singapore (STB ) vừa chính thức giới thiệu nhận diện thương hiệu mới tại Việt Nam là \"Singapore - Passion Made Possible\" (tạm dịch:\n",
            "\n",
            "entity:  {'text': 'Singapore', 'pos': [32, 41]}\n",
            "entity index list:  [6]\n",
            "['Singapore']\n",
            "[25, 34]\n",
            "Underthesea word_tokenize:  ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "My word_tokenize 1:         ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your', 'Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10891\n",
            "sentence:  Kết thúc hành trình 6 năm \"Your Singapore \", Tổng cục Du lịch Singapore (STB ) vừa chính thức giới thiệu nhận diện thương hiệu mới tại Việt Nam là \"Singapore - Passion Made Possible\" (tạm dịch:\n",
            "\n",
            "entity:  {'text': 'Singapore', 'pos': [32, 41]}\n",
            "entity index list:  [6]\n",
            "['Singapore']\n",
            "[25, 34]\n",
            "Underthesea word_tokenize:  ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "My word_tokenize 1:         ['Kết thúc', 'hành trình', '6', 'năm', '\"', 'Your', 'Singapore', '\"', ',', 'Tổng cục', 'Du lịch', 'Singapore', '(', 'STB', ')', 'vừa', 'chính thức', 'giới thiệu', 'nhận diện', 'thương hiệu', 'mới', 'tại', 'Việt Nam', 'là', '\"', 'Singapore', '-', 'Passion Made Possible', '\"', '(', 'tạm', 'dịch', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  10920\n",
            "sentence:  Từ một làng chài ở cửa sông Rochor , giờ đây Kampong Glam là điểm đến lý tưởng cho các tín đồ thích mua sắm.\n",
            "\n",
            "entity:  {'text': 'sông Rochor', 'pos': [23, 34]}\n",
            "entity index list:  [6, 7]\n",
            "['sông', 'Rochor']\n",
            "[17, 27]\n",
            "Underthesea word_tokenize:  ['Từ', 'một', 'làng', 'chài', 'ở', 'cửa sông', 'Rochor', ',', 'giờ đây', 'Kampong Glam', 'là', 'điểm', 'đến', 'lý tưởng', 'cho', 'các', 'tín đồ', 'thích', 'mua sắm', '.']\n",
            "My word_tokenize 1:         ['Từ', 'một', 'làng', 'chài', 'ở', 'cửa', 'sông', 'Rochor', ',', 'giờ đây', 'Kampong Glam', 'là', 'điểm', 'đến', 'lý tưởng', 'cho', 'các', 'tín đồ', 'thích', 'mua sắm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10924\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Bắc Mỹ', 'pos': [56, 62]}\n",
            "entity index list:  [12, 13]\n",
            "[45, 50]\n",
            "['Bắc', 'Mỹ']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 2:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10925\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Victoria', 'pos': [63, 71]}\n",
            "entity index list:  [14]\n",
            "[50, 58]\n",
            "['Victoria']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 2:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10928\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Bắc Mỹ', 'pos': [56, 62]}\n",
            "entity index list:  [12, 13]\n",
            "['Bắc', 'Mỹ']\n",
            "[45, 50]\n",
            "Underthesea word_tokenize:  ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10929\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Bắc Mỹ', 'pos': [56, 62]}\n",
            "entity index list:  [12, 13]\n",
            "['Bắc', 'Mỹ']\n",
            "[45, 50]\n",
            "Underthesea word_tokenize:  ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10930\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Bắc Mỹ', 'pos': [56, 62]}\n",
            "entity index list:  [12, 13]\n",
            "['Bắc', 'Mỹ']\n",
            "[45, 50]\n",
            "Underthesea word_tokenize:  ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10931\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Victoria', 'pos': [63, 71]}\n",
            "entity index list:  [14]\n",
            "['Victoria']\n",
            "[50, 58]\n",
            "Underthesea word_tokenize:  ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10932\n",
            "sentence:  Một ngày trên 'đảo ngọc' Victoria - danh thắng bậc nhất Bắc Mỹ Victoria là một hòn đảo vô cùng đặc biệt, không chỉ với người dân Canada mà cả khu vực Bắc Mỹ .\n",
            "\n",
            "entity:  {'text': 'Victoria', 'pos': [63, 71]}\n",
            "entity index list:  [14]\n",
            "['Victoria']\n",
            "[50, 58]\n",
            "Underthesea word_tokenize:  ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "My word_tokenize 1:         ['Một', 'ngày', 'trên', \"'\", 'đảo', 'ngọc', \"'\", 'Victoria', '-', 'danh thắng', 'bậc', 'nhất', 'Bắc', 'Mỹ', 'Victoria', 'là', 'một', 'hòn', 'đảo', 'vô cùng', 'đặc biệt', ',', 'không chỉ', 'với', 'người', 'dân', 'Canada', 'mà', 'cả', 'khu vực', 'Bắc Mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10945\n",
            "sentence:  Giang Nguyễn /Vietnam+ ) Những cửa hiệu tạp hóa nhỏ, những quán rượu nằm ép mình trong ngõ hẹp, quán café vỉa hè, hay từng nhóm nhỏ cư dân ngồi tán gẫu khi chiều buông là những hình ảnh rất đỗi quen thuộc đối với những du khách đặt chân tới phố Tàu .\n",
            "\n",
            "entity:  {'text': 'Giang Nguyễn', 'pos': [0, 12]}\n",
            "entity index list:  [0, 1]\n",
            "['Giang', 'Nguyễn']\n",
            "[0, 11]\n",
            "Underthesea word_tokenize:  ['Giang', 'Nguyễn /', 'Vietnam', '+', ')', 'Những', 'cửa hiệu', 'tạp hóa', 'nhỏ', ',', 'những', 'quán rượu', 'nằm', 'ép', 'mình', 'trong', 'ngõ', 'hẹp', ',', 'quán', 'café', 'vỉa hè', ',', 'hay', 'từng', 'nhóm', 'nhỏ', 'cư dân', 'ngồi', 'tán gẫu', 'khi', 'chiều', 'buông', 'là', 'những', 'hình ảnh', 'rất đỗi', 'quen thuộc', 'đối với', 'những', 'du khách', 'đặt chân', 'tới', 'phố', 'Tàu', '.']\n",
            "My word_tokenize 1:         ['Giang', 'Nguyễn', '/', 'Vietnam', '+', ')', 'Những', 'cửa hiệu', 'tạp hóa', 'nhỏ', ',', 'những', 'quán rượu', 'nằm', 'ép', 'mình', 'trong', 'ngõ', 'hẹp', ',', 'quán', 'café', 'vỉa hè', ',', 'hay', 'từng', 'nhóm', 'nhỏ', 'cư dân', 'ngồi', 'tán gẫu', 'khi', 'chiều', 'buông', 'là', 'những', 'hình ảnh', 'rất đỗi', 'quen thuộc', 'đối với', 'những', 'du khách', 'đặt chân', 'tới', 'phố', 'Tàu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  10998\n",
            "sentence:  Dù việc học tập của sinh viên Triều Tiên được đánh giá cao, nhưng việc phát triển năng lực hạt nhân ngày càng cao của Triều Tiên đã gây ra mối lo ngại về sự có mặt của các nhà khoa học Triều Tiên trong các viện nghiên cứu nhạy cảm tại Trung Quốc .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [185, 195]}\n",
            "entity index list:  [30]\n",
            "[143, 152]\n",
            "['Triều Tiên']\n",
            "My word_tokenize 1:         ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "My word_tokenize 2:         ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học', 'Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11000\n",
            "sentence:  Dù việc học tập của sinh viên Triều Tiên được đánh giá cao, nhưng việc phát triển năng lực hạt nhân ngày càng cao của Triều Tiên đã gây ra mối lo ngại về sự có mặt của các nhà khoa học Triều Tiên trong các viện nghiên cứu nhạy cảm tại Trung Quốc .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [185, 195]}\n",
            "entity index list:  [30]\n",
            "[143, 152]\n",
            "['Triều Tiên']\n",
            "My word_tokenize 1:         ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "My word_tokenize 2:         ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học', 'Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11002\n",
            "sentence:  Dù việc học tập của sinh viên Triều Tiên được đánh giá cao, nhưng việc phát triển năng lực hạt nhân ngày càng cao của Triều Tiên đã gây ra mối lo ngại về sự có mặt của các nhà khoa học Triều Tiên trong các viện nghiên cứu nhạy cảm tại Trung Quốc .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [185, 195]}\n",
            "entity index list:  [30]\n",
            "['Triều Tiên']\n",
            "[143, 152]\n",
            "Underthesea word_tokenize:  ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "My word_tokenize 1:         ['Dù', 'việc', 'học tập', 'của', 'sinh viên', 'Triều Tiên', 'được', 'đánh giá', 'cao', ',', 'nhưng', 'việc', 'phát triển', 'năng lực', 'hạt nhân', 'ngày càng', 'cao', 'của', 'Triều Tiên', 'đã', 'gây', 'ra', 'mối', 'lo ngại', 'về', 'sự', 'có mặt', 'của', 'các', 'nhà khoa học', 'Triều Tiên', 'trong', 'các', 'viện', 'nghiên cứu', 'nhạy cảm', 'tại', 'Trung Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11066\n",
            "sentence:  Tuy nhiên thực tế Tây Ban Nha lại theo múi giờ Trung Âu (CET) và đồng bộ thời gian với Belgrade , thủ đô Serbia , cách Madrid hơn 2.500 km về phía Đông.\n",
            "\n",
            "entity:  {'text': 'Tây Ban Nha', 'pos': [18, 29]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Tây', 'Ban', 'Nha']\n",
            "[14, 23]\n",
            "Underthesea word_tokenize:  ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "My word_tokenize 1:         ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha', 'lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11067\n",
            "sentence:  Tuy nhiên thực tế Tây Ban Nha lại theo múi giờ Trung Âu (CET) và đồng bộ thời gian với Belgrade , thủ đô Serbia , cách Madrid hơn 2.500 km về phía Đông.\n",
            "\n",
            "entity:  {'text': 'Tây Ban Nha', 'pos': [18, 29]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Tây', 'Ban', 'Nha']\n",
            "[14, 23]\n",
            "Underthesea word_tokenize:  ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "My word_tokenize 1:         ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha', 'lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11068\n",
            "sentence:  Tuy nhiên thực tế Tây Ban Nha lại theo múi giờ Trung Âu (CET) và đồng bộ thời gian với Belgrade , thủ đô Serbia , cách Madrid hơn 2.500 km về phía Đông.\n",
            "\n",
            "entity:  {'text': 'Tây Ban Nha', 'pos': [18, 29]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Tây', 'Ban', 'Nha']\n",
            "[14, 23]\n",
            "Underthesea word_tokenize:  ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "My word_tokenize 1:         ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha', 'lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11069\n",
            "sentence:  Tuy nhiên thực tế Tây Ban Nha lại theo múi giờ Trung Âu (CET) và đồng bộ thời gian với Belgrade , thủ đô Serbia , cách Madrid hơn 2.500 km về phía Đông.\n",
            "\n",
            "entity:  {'text': 'Tây Ban Nha', 'pos': [18, 29]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Tây', 'Ban', 'Nha']\n",
            "[14, 23]\n",
            "Underthesea word_tokenize:  ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "My word_tokenize 1:         ['Tuy nhiên', 'thực tế', 'Tây', 'Ban', 'Nha', 'lại', 'theo', 'múi giờ', 'Trung Âu', '(', 'CET', ')', 'và', 'đồng bộ', 'thời gian', 'với', 'Belgrade', ',', 'thủ đô', 'Serbia', ',', 'cách', 'Madrid', 'hơn', '2.500', 'km', 'về', 'phía', 'Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11079\n",
            "sentence:  Nhưng vào năm 2016, Thủ tướng Tây Ban Nha Mariano Rajoy tuyên bố rằng chính phủ đang có kế hoạch áp dụng giờ làm việc mới, kết thúc vào lúc 6 giờ chiều thay vì 8 giờ tối.\n",
            "\n",
            "entity:  {'text': 'Tây Ban Nha', 'pos': [30, 41]}\n",
            "entity index list:  [6, 7, 8]\n",
            "['Tây', 'Ban', 'Nha']\n",
            "[24, 33]\n",
            "Underthesea word_tokenize:  ['Nhưng', 'vào', 'năm', '2016', ',', 'Thủ tướng', 'Tây', 'Ban', 'Nha Mariano Rajoy', 'tuyên bố', 'rằng', 'chính phủ', 'đang', 'có', 'kế hoạch', 'áp dụng', 'giờ', 'làm việc', 'mới', ',', 'kết thúc', 'vào', 'lúc', '6', 'giờ', 'chiều', 'thay vì', '8', 'giờ', 'tối', '.']\n",
            "My word_tokenize 1:         ['Nhưng', 'vào', 'năm', '2016', ',', 'Thủ tướng', 'Tây', 'Ban', 'Nha', 'Mariano Rajoy', 'tuyên bố', 'rằng', 'chính phủ', 'đang', 'có', 'kế hoạch', 'áp dụng', 'giờ', 'làm việc', 'mới', ',', 'kết thúc', 'vào', 'lúc', '6', 'giờ', 'chiều', 'thay vì', '8', 'giờ', 'tối', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11095\n",
            "sentence:  Sau cơn mưa chiều 22/9, mặt Hồ Tây đoạn số 223-235 (phố Trích Sài ) xuất hiện hàng trăm chiếc bao cao su nổi rải rác.\n",
            "\n",
            "entity:  {'text': 'Hồ Tây', 'pos': [28, 34]}\n",
            "entity index list:  [7]\n",
            "['Hồ Tây']\n",
            "[22, 27]\n",
            "Underthesea word_tokenize:  ['Sau', 'cơn', 'mưa', 'chiều', '22/9', ',', 'mặt', 'Hồ Tây đoạn', 'số', '223', '-', '235', '(', 'phố', 'Trích Sài', ')', 'xuất hiện', 'hàng', 'trăm', 'chiếc', 'bao cao su', 'nổi', 'rải rác', '.']\n",
            "My word_tokenize 1:         ['Sau', 'cơn', 'mưa', 'chiều', '22/9', ',', 'mặt', 'Hồ Tây', 'đoạn', 'số', '223', '-', '235', '(', 'phố', 'Trích Sài', ')', 'xuất hiện', 'hàng', 'trăm', 'chiếc', 'bao cao su', 'nổi', 'rải rác', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11175\n",
            "sentence:  Ngày ấy, những con đường Hoàng Diệu , Phan Đình Phùng kéo lên Hoàng Hoa Thám vắng vẻ quanh năm.\n",
            "\n",
            "entity:  {'text': 'Hoàng Diệu', 'pos': [25, 35]}\n",
            "entity index list:  [6]\n",
            "['Hoàng Diệu']\n",
            "[20, 29]\n",
            "Underthesea word_tokenize:  ['Ngày', 'ấy', ',', 'những', 'con', 'đường Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "My word_tokenize 1:         ['Ngày', 'ấy', ',', 'những', 'con', 'đường', 'Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "\n",
            "entity:  {'text': 'Phan Đình Phùng', 'pos': [38, 53]}\n",
            "entity index list:  [8]\n",
            "[30, 43]\n",
            "['Phan Đình Phùng']\n",
            "My word_tokenize 1:         ['Ngày', 'ấy', ',', 'những', 'con', 'đường', 'Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "My word_tokenize 2:         ['Ngày', 'ấy', ',', 'những', 'con', 'đường', 'Hoàng Diệu', ',', 'Phan Đình Phùng', 'kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11176\n",
            "sentence:  Ngày ấy, những con đường Hoàng Diệu , Phan Đình Phùng kéo lên Hoàng Hoa Thám vắng vẻ quanh năm.\n",
            "\n",
            "entity:  {'text': 'Hoàng Diệu', 'pos': [25, 35]}\n",
            "entity index list:  [6]\n",
            "['Hoàng Diệu']\n",
            "[20, 29]\n",
            "Underthesea word_tokenize:  ['Ngày', 'ấy', ',', 'những', 'con', 'đường Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "My word_tokenize 1:         ['Ngày', 'ấy', ',', 'những', 'con', 'đường', 'Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11177\n",
            "sentence:  Ngày ấy, những con đường Hoàng Diệu , Phan Đình Phùng kéo lên Hoàng Hoa Thám vắng vẻ quanh năm.\n",
            "\n",
            "entity:  {'text': 'Phan Đình Phùng', 'pos': [38, 53]}\n",
            "entity index list:  [7]\n",
            "['Phan Đình Phùng']\n",
            "[30, 43]\n",
            "Underthesea word_tokenize:  ['Ngày', 'ấy', ',', 'những', 'con', 'đường Hoàng Diệu', ',', 'Phan Đình Phùng kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "My word_tokenize 1:         ['Ngày', 'ấy', ',', 'những', 'con', 'đường Hoàng Diệu', ',', 'Phan Đình Phùng', 'kéo', 'lên', 'Hoàng Hoa Thám', 'vắng vẻ', 'quanh năm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11179\n",
            "sentence:  Giờ muốn nhìn thảm lá sấu dày dặn như thế phải tìm lên phố Phan Đình Phùng chỗ gần cổng thành Cửa Bắc .\n",
            "\n",
            "entity:  {'text': 'phố Phan Đình Phùng', 'pos': [55, 74]}\n",
            "entity index list:  [11, 12]\n",
            "['phố', 'Phan Đình Phùng']\n",
            "[42, 58]\n",
            "Underthesea word_tokenize:  ['Giờ', 'muốn', 'nhìn', 'thảm', 'lá', 'sấu', 'dày dặn', 'như thế', 'phải', 'tìm', 'lên', 'phố', 'Phan Đình Phùng chỗ', 'gần', 'cổng', 'thành', 'Cửa Bắc', '.']\n",
            "My word_tokenize 1:         ['Giờ', 'muốn', 'nhìn', 'thảm', 'lá', 'sấu', 'dày dặn', 'như thế', 'phải', 'tìm', 'lên', 'phố', 'Phan Đình Phùng', 'chỗ', 'gần', 'cổng', 'thành', 'Cửa Bắc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11195\n",
            "sentence:  Trưởng ban Quản lý di tích - danh thắng Hà Nội (Sở Văn hóa - Thể thao Hà Nội ) Nguyễn Thị Hòa cho biết:\n",
            "\n",
            "entity:  {'text': 'ban Quản lý di tích - danh thắng Hà Nội', 'pos': [7, 46]}\n",
            "entity index list:  [1, 2, 3, 4, 5, 6]\n",
            "['ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội']\n",
            "[6, 36]\n",
            "Underthesea word_tokenize:  ['Trưởng ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội', '(', 'Sở', 'Văn hóa', '-', 'Thể thao', 'Hà Nội', ')', 'Nguyễn Thị Hòa', 'cho', 'biết', ':']\n",
            "My word_tokenize 1:         ['Trưởng', 'ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội', '(', 'Sở', 'Văn hóa', '-', 'Thể thao', 'Hà Nội', ')', 'Nguyễn Thị Hòa', 'cho', 'biết', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11196\n",
            "sentence:  Trưởng ban Quản lý di tích - danh thắng Hà Nội (Sở Văn hóa - Thể thao Hà Nội ) Nguyễn Thị Hòa cho biết:\n",
            "\n",
            "entity:  {'text': 'ban Quản lý di tích - danh thắng Hà Nội', 'pos': [7, 46]}\n",
            "entity index list:  [1, 2, 3, 4, 5, 6]\n",
            "['ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội']\n",
            "[6, 36]\n",
            "Underthesea word_tokenize:  ['Trưởng ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội', '(', 'Sở', 'Văn hóa', '-', 'Thể thao', 'Hà Nội', ')', 'Nguyễn Thị Hòa', 'cho', 'biết', ':']\n",
            "My word_tokenize 1:         ['Trưởng', 'ban', 'Quản lý', 'di tích', '-', 'danh thắng', 'Hà Nội', '(', 'Sở', 'Văn hóa', '-', 'Thể thao', 'Hà Nội', ')', 'Nguyễn Thị Hòa', 'cho', 'biết', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11253\n",
            "sentence:  Trong khoa thi Tam khôi đầu tiên, thần đồng nhỏ tuổi Nguyễn Hiền đỗ Trạng nguyên và được vua Trần Thái Tông phong là “Khai quốc Trạng nguyên”, điều này được nhà sử học Ngô Sĩ Liên khẳng định trong “Đại Việt sử ký toàn thư ”.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [53, 64]}\n",
            "entity index list:  [7]\n",
            "['Nguyễn Hiền']\n",
            "[42, 52]\n",
            "Underthesea word_tokenize:  ['Trong', 'khoa thi', 'Tam khôi', 'đầu tiên', ',', 'thần đồng', 'nhỏ tuổi', 'Nguyễn Hiền đỗ', 'Trạng nguyên', 'và', 'được', 'vua', 'Trần Thái Tông', 'phong', 'là', '“', 'Khai quốc Trạng nguyên', '”', ',', 'điều', 'này', 'được', 'nhà', 'sử học', 'Ngô Sĩ', 'Liên', 'khẳng định', 'trong', '“', 'Đại Việt', 'sử ký', 'toàn thư', '”', '.']\n",
            "My word_tokenize 1:         ['Trong', 'khoa thi', 'Tam khôi', 'đầu tiên', ',', 'thần đồng', 'nhỏ tuổi', 'Nguyễn Hiền', 'đỗ', 'Trạng nguyên', 'và', 'được', 'vua', 'Trần Thái Tông', 'phong', 'là', '“', 'Khai quốc Trạng nguyên', '”', ',', 'điều', 'này', 'được', 'nhà', 'sử học', 'Ngô Sĩ', 'Liên', 'khẳng định', 'trong', '“', 'Đại Việt', 'sử ký', 'toàn thư', '”', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11254\n",
            "sentence:  Trong khoa thi Tam khôi đầu tiên, thần đồng nhỏ tuổi Nguyễn Hiền đỗ Trạng nguyên và được vua Trần Thái Tông phong là “Khai quốc Trạng nguyên”, điều này được nhà sử học Ngô Sĩ Liên khẳng định trong “Đại Việt sử ký toàn thư ”.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [53, 64]}\n",
            "entity index list:  [7]\n",
            "['Nguyễn Hiền']\n",
            "[42, 52]\n",
            "Underthesea word_tokenize:  ['Trong', 'khoa thi', 'Tam khôi', 'đầu tiên', ',', 'thần đồng', 'nhỏ tuổi', 'Nguyễn Hiền đỗ', 'Trạng nguyên', 'và', 'được', 'vua', 'Trần Thái Tông', 'phong', 'là', '“', 'Khai quốc Trạng nguyên', '”', ',', 'điều', 'này', 'được', 'nhà', 'sử học', 'Ngô Sĩ', 'Liên', 'khẳng định', 'trong', '“', 'Đại Việt', 'sử ký', 'toàn thư', '”', '.']\n",
            "My word_tokenize 1:         ['Trong', 'khoa thi', 'Tam khôi', 'đầu tiên', ',', 'thần đồng', 'nhỏ tuổi', 'Nguyễn Hiền', 'đỗ', 'Trạng nguyên', 'và', 'được', 'vua', 'Trần Thái Tông', 'phong', 'là', '“', 'Khai quốc Trạng nguyên', '”', ',', 'điều', 'này', 'được', 'nhà', 'sử học', 'Ngô Sĩ', 'Liên', 'khẳng định', 'trong', '“', 'Đại Việt', 'sử ký', 'toàn thư', '”', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11259\n",
            "sentence:  Theo các cụ cao niên ở làng Dương A , xã Nam Thắng (Nam Trực - Nam Định ) thì Nguyễn Hiền sinh năm 1234 (một số tài liệu ghi là 1235).\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [78, 89]}\n",
            "entity index list:  [16]\n",
            "[58, 68]\n",
            "['Nguyễn Hiền']\n",
            "My word_tokenize 1:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "My word_tokenize 2:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền', 'sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11262\n",
            "sentence:  Theo các cụ cao niên ở làng Dương A , xã Nam Thắng (Nam Trực - Nam Định ) thì Nguyễn Hiền sinh năm 1234 (một số tài liệu ghi là 1235).\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [78, 89]}\n",
            "entity index list:  [16]\n",
            "[58, 68]\n",
            "['Nguyễn Hiền']\n",
            "My word_tokenize 1:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "My word_tokenize 2:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền', 'sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11264\n",
            "sentence:  Theo các cụ cao niên ở làng Dương A , xã Nam Thắng (Nam Trực - Nam Định ) thì Nguyễn Hiền sinh năm 1234 (một số tài liệu ghi là 1235).\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [78, 89]}\n",
            "entity index list:  [16]\n",
            "[58, 68]\n",
            "['Nguyễn Hiền']\n",
            "My word_tokenize 1:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "My word_tokenize 2:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền', 'sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11265\n",
            "sentence:  Theo các cụ cao niên ở làng Dương A , xã Nam Thắng (Nam Trực - Nam Định ) thì Nguyễn Hiền sinh năm 1234 (một số tài liệu ghi là 1235).\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hiền', 'pos': [78, 89]}\n",
            "entity index list:  [16]\n",
            "[58, 68]\n",
            "['Nguyễn Hiền']\n",
            "My word_tokenize 1:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "My word_tokenize 2:         ['Theo', 'các', 'cụ', 'cao niên', 'ở', 'làng', 'Dương A', ',', 'xã', 'Nam Thắng', '(', 'Nam Trực', '-', 'Nam Định', ')', 'thì', 'Nguyễn Hiền', 'sinh', 'năm', '1234', '(', 'một số', 'tài liệu', 'ghi', 'là', '1235', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11274\n",
            "sentence:  Kiều Trang – Hưng Tiến\n",
            "\n",
            "entity:  {'text': 'Kiều Trang', 'pos': [0, 10]}\n",
            "entity index list:  [0]\n",
            "['Kiều Trang']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Kiều Trang –', 'Hưng Tiến']\n",
            "My word_tokenize 1:         ['Kiều Trang', '–', 'Hưng Tiến']\n",
            "\n",
            "\n",
            "---------- sent_id:  11275\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Pháp', 'pos': [80, 84]}\n",
            "entity index list:  [13]\n",
            "['Pháp']\n",
            "[63, 67]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "entity:  {'text': 'Ma Rốc', 'pos': [89, 95]}\n",
            "entity index list:  [15]\n",
            "[70, 75]\n",
            "['Ma Rốc']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 2:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11276\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Pháp', 'pos': [80, 84]}\n",
            "entity index list:  [13]\n",
            "['Pháp']\n",
            "[63, 67]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "entity:  {'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "entity index list:  [16]\n",
            "[75, 87]\n",
            "['Leïla Slimani']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 2:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11277\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Pháp', 'pos': [80, 84]}\n",
            "entity index list:  [13]\n",
            "['Pháp']\n",
            "[63, 67]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11278\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Pháp', 'pos': [80, 84]}\n",
            "entity index list:  [13]\n",
            "['Pháp']\n",
            "[63, 67]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn', 'Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11279\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Ma Rốc', 'pos': [89, 95]}\n",
            "entity index list:  [14]\n",
            "['Ma Rốc']\n",
            "[70, 75]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11280\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Ma Rốc', 'pos': [89, 95]}\n",
            "entity index list:  [14]\n",
            "['Ma Rốc']\n",
            "[70, 75]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11281\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Ma Rốc', 'pos': [89, 95]}\n",
            "entity index list:  [14]\n",
            "['Ma Rốc']\n",
            "[70, 75]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11282\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "entity index list:  [15]\n",
            "['Leïla Slimani']\n",
            "[75, 87]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11283\n",
            "sentence:  Nhân dịp phát hành bản dịch tiếng Việt cuốn sách Người lạ trong nhà của nhà văn Pháp gốc Ma Rốc Leïla Slimani , Công ty CP văn hóa và truyền thông Nhã Nam cùng Trung tâm văn hóa Pháp tổ chức tọa đàm Cuộc sống hiện đại:\n",
            "\n",
            "entity:  {'text': 'Leïla Slimani', 'pos': [96, 109]}\n",
            "entity index list:  [15]\n",
            "['Leïla Slimani']\n",
            "[75, 87]\n",
            "Underthesea word_tokenize:  ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "My word_tokenize 1:         ['Nhân dịp', 'phát hành', 'bản', 'dịch', 'tiếng', 'Việt', 'cuốn', 'sách', 'Người lạ', 'trong', 'nhà', 'của', 'nhà văn Pháp', 'gốc', 'Ma Rốc', 'Leïla Slimani', ',', 'Công ty', 'CP', 'văn hóa', 'và', 'truyền thông', 'Nhã', 'Nam', 'cùng', 'Trung tâm', 'văn hóa', 'Pháp', 'tổ chức', 'tọa đàm', 'Cuộc sống', 'hiện đại', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  11315\n",
            "sentence:  Trần Ly Ly dựng 'Huyền thoại làng chài' tại Phan Thiết Biên đạo múa Trần Ly Ly (Phó hiệu trưởng Trường Múa TP.HCM ) vừa nhận lời làm tổng đạo diễn và biên đạo cho show Huyền thoại làng chài (Fishermen Show) phục vụ khách du lịch và những người yêu nghệ thuật múa.\n",
            "\n",
            "entity:  {'text': 'Phan Thiết', 'pos': [44, 54]}\n",
            "entity index list:  [8]\n",
            "[35, 44]\n",
            "['Phan Thiết']\n",
            "My word_tokenize 1:         ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "My word_tokenize 2:         ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết', 'Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11318\n",
            "sentence:  Trần Ly Ly dựng 'Huyền thoại làng chài' tại Phan Thiết Biên đạo múa Trần Ly Ly (Phó hiệu trưởng Trường Múa TP.HCM ) vừa nhận lời làm tổng đạo diễn và biên đạo cho show Huyền thoại làng chài (Fishermen Show) phục vụ khách du lịch và những người yêu nghệ thuật múa.\n",
            "\n",
            "entity:  {'text': 'Phan Thiết', 'pos': [44, 54]}\n",
            "entity index list:  [8]\n",
            "['Phan Thiết']\n",
            "[35, 44]\n",
            "Underthesea word_tokenize:  ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "My word_tokenize 1:         ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết', 'Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11319\n",
            "sentence:  Trần Ly Ly dựng 'Huyền thoại làng chài' tại Phan Thiết Biên đạo múa Trần Ly Ly (Phó hiệu trưởng Trường Múa TP.HCM ) vừa nhận lời làm tổng đạo diễn và biên đạo cho show Huyền thoại làng chài (Fishermen Show) phục vụ khách du lịch và những người yêu nghệ thuật múa.\n",
            "\n",
            "entity:  {'text': 'Phan Thiết', 'pos': [44, 54]}\n",
            "entity index list:  [8]\n",
            "['Phan Thiết']\n",
            "[35, 44]\n",
            "Underthesea word_tokenize:  ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "My word_tokenize 1:         ['Trần Ly Ly', 'dựng', \"'\", 'Huyền thoại', 'làng', 'chài', \"'\", 'tại', 'Phan Thiết', 'Biên đạo', 'múa', 'Trần Ly Ly', '(', 'Phó hiệu trưởng', 'Trường', 'Múa', 'TP.HCM', ')', 'vừa', 'nhận lời', 'làm', 'tổng', 'đạo diễn', 'và', 'biên đạo', 'cho', 'show', 'Huyền thoại', 'làng', 'chài', '(', 'Fishermen Show', ')', 'phục vụ', 'khách', 'du lịch', 'và', 'những', 'người yêu', 'nghệ thuật', 'múa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11420\n",
            "sentence:  Ngoài việc cùng với mọi người chạy đôn, chạy đáo khắp nơi để xin giấy phép trùng tu, sửa chữa chùa Chèo và kêu gọi hỗ trợ, bà Lê Thị Thời , Trưởng ban hộ tự chùa Chèo và nhiều người dân còn không ít lần đi khắp các tỉnh quanh khu vực để tìm sư về làm trụ trì ngôi chùa này.\n",
            "\n",
            "entity:  {'text': 'ban hộ tự chùa Chèo', 'pos': [147, 166]}\n",
            "entity index list:  [29, 30, 31, 32, 33]\n",
            "[114, 129]\n",
            "['ban', 'hộ', 'tự', 'chùa', 'Chèo']\n",
            "My word_tokenize 1:         ['Ngoài', 'việc', 'cùng', 'với', 'mọi', 'người', 'chạy', 'đôn', ',', 'chạy', 'đáo', 'khắp', 'nơi', 'để', 'xin', 'giấy phép', 'trùng tu', ',', 'sửa chữa', 'chùa', 'Chèo', 'và', 'kêu gọi', 'hỗ trợ', ',', 'bà', 'Lê Thị Thời', ',', 'Trưởng ban', 'hộ', 'tự', 'chùa', 'Chèo', 'và', 'nhiều', 'người', 'dân', 'còn', 'không', 'ít', 'lần', 'đi', 'khắp', 'các', 'tỉnh', 'quanh', 'khu vực', 'để', 'tìm', 'sư', 'về', 'làm', 'trụ trì', 'ngôi', 'chùa', 'này', '.']\n",
            "My word_tokenize 2:         ['Ngoài', 'việc', 'cùng', 'với', 'mọi', 'người', 'chạy', 'đôn', ',', 'chạy', 'đáo', 'khắp', 'nơi', 'để', 'xin', 'giấy phép', 'trùng tu', ',', 'sửa chữa', 'chùa', 'Chèo', 'và', 'kêu gọi', 'hỗ trợ', ',', 'bà', 'Lê Thị Thời', ',', 'Trưởng', 'ban', 'hộ', 'tự', 'chùa', 'Chèo', 'và', 'nhiều', 'người', 'dân', 'còn', 'không', 'ít', 'lần', 'đi', 'khắp', 'các', 'tỉnh', 'quanh', 'khu vực', 'để', 'tìm', 'sư', 'về', 'làm', 'trụ trì', 'ngôi', 'chùa', 'này', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11421\n",
            "sentence:  Ngoài việc cùng với mọi người chạy đôn, chạy đáo khắp nơi để xin giấy phép trùng tu, sửa chữa chùa Chèo và kêu gọi hỗ trợ, bà Lê Thị Thời , Trưởng ban hộ tự chùa Chèo và nhiều người dân còn không ít lần đi khắp các tỉnh quanh khu vực để tìm sư về làm trụ trì ngôi chùa này.\n",
            "\n",
            "entity:  {'text': 'ban hộ tự chùa Chèo', 'pos': [147, 166]}\n",
            "entity index list:  [29, 30, 31, 32, 33]\n",
            "[114, 129]\n",
            "['ban', 'hộ', 'tự', 'chùa', 'Chèo']\n",
            "My word_tokenize 1:         ['Ngoài', 'việc', 'cùng', 'với', 'mọi', 'người', 'chạy', 'đôn', ',', 'chạy', 'đáo', 'khắp', 'nơi', 'để', 'xin', 'giấy phép', 'trùng tu', ',', 'sửa chữa', 'chùa', 'Chèo', 'và', 'kêu gọi', 'hỗ trợ', ',', 'bà', 'Lê Thị Thời', ',', 'Trưởng ban', 'hộ', 'tự', 'chùa', 'Chèo', 'và', 'nhiều', 'người', 'dân', 'còn', 'không', 'ít', 'lần', 'đi', 'khắp', 'các', 'tỉnh', 'quanh', 'khu vực', 'để', 'tìm', 'sư', 'về', 'làm', 'trụ trì', 'ngôi', 'chùa', 'này', '.']\n",
            "My word_tokenize 2:         ['Ngoài', 'việc', 'cùng', 'với', 'mọi', 'người', 'chạy', 'đôn', ',', 'chạy', 'đáo', 'khắp', 'nơi', 'để', 'xin', 'giấy phép', 'trùng tu', ',', 'sửa chữa', 'chùa', 'Chèo', 'và', 'kêu gọi', 'hỗ trợ', ',', 'bà', 'Lê Thị Thời', ',', 'Trưởng', 'ban', 'hộ', 'tự', 'chùa', 'Chèo', 'và', 'nhiều', 'người', 'dân', 'còn', 'không', 'ít', 'lần', 'đi', 'khắp', 'các', 'tỉnh', 'quanh', 'khu vực', 'để', 'tìm', 'sư', 'về', 'làm', 'trụ trì', 'ngôi', 'chùa', 'này', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11460\n",
            "sentence:  Gọi cô Linh đẳng cấp hơn cô Hà và cô Hà thì đẳng cấp hơn anh Hưng tức là ta đã đặt ra một thước đo giữa họ với nhau, nghĩa là bản thân mỗi người trong số họ chính là thứ để đối chiếu cho kẻ còn lại.\n",
            "\n",
            "entity:  {'text': 'Hưng', 'pos': [61, 65]}\n",
            "entity index list:  [14]\n",
            "[45, 49]\n",
            "['Hưng']\n",
            "My word_tokenize 1:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "My word_tokenize 2:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng', 'tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11462\n",
            "sentence:  Gọi cô Linh đẳng cấp hơn cô Hà và cô Hà thì đẳng cấp hơn anh Hưng tức là ta đã đặt ra một thước đo giữa họ với nhau, nghĩa là bản thân mỗi người trong số họ chính là thứ để đối chiếu cho kẻ còn lại.\n",
            "\n",
            "entity:  {'text': 'Hưng', 'pos': [61, 65]}\n",
            "entity index list:  [14]\n",
            "[45, 49]\n",
            "['Hưng']\n",
            "My word_tokenize 1:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "My word_tokenize 2:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng', 'tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11463\n",
            "sentence:  Gọi cô Linh đẳng cấp hơn cô Hà và cô Hà thì đẳng cấp hơn anh Hưng tức là ta đã đặt ra một thước đo giữa họ với nhau, nghĩa là bản thân mỗi người trong số họ chính là thứ để đối chiếu cho kẻ còn lại.\n",
            "\n",
            "entity:  {'text': 'Hưng', 'pos': [61, 65]}\n",
            "entity index list:  [14]\n",
            "[45, 49]\n",
            "['Hưng']\n",
            "My word_tokenize 1:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "My word_tokenize 2:         ['Gọi', 'cô', 'Linh', 'đẳng cấp', 'hơn', 'cô', 'Hà', 'và', 'cô', 'Hà', 'thì', 'đẳng cấp', 'hơn', 'anh', 'Hưng', 'tức là', 'ta', 'đã', 'đặt', 'ra', 'một', 'thước đo', 'giữa', 'họ', 'với', 'nhau', ',', 'nghĩa là', 'bản thân', 'mỗi', 'người', 'trong', 'số', 'họ', 'chính', 'là', 'thứ', 'để', 'đối chiếu', 'cho', 'kẻ', 'còn', 'lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11512\n",
            "sentence:  Hà Nội trở nên hỗn độn vì đã không Hà Nội hóa được người di cư, việc mà các đô thị khác đã Huế hoá , Đà Nẵng hóa và Sài Gòn hóa vô cùng thành công.\n",
            "\n",
            "entity:  {'text': 'Hà Nội', 'pos': [35, 41]}\n",
            "entity index list:  [6]\n",
            "[26, 31]\n",
            "['Hà Nội']\n",
            "My word_tokenize 1:         ['Hà Nội', 'trở nên', 'hỗn độn', 'vì', 'đã', 'không', 'Hà Nội hóa', 'được', 'người', 'di cư', ',', 'việc', 'mà', 'các', 'đô thị', 'khác', 'đã', 'Huế hoá', ',', 'Đà Nẵng hóa', 'và', 'Sài Gòn', 'hóa', 'vô cùng', 'thành công', '.']\n",
            "My word_tokenize 2:         ['Hà Nội', 'trở nên', 'hỗn độn', 'vì', 'đã', 'không', 'Hà Nội', 'hóa', 'được', 'người', 'di cư', ',', 'việc', 'mà', 'các', 'đô thị', 'khác', 'đã', 'Huế hoá', ',', 'Đà Nẵng hóa', 'và', 'Sài Gòn', 'hóa', 'vô cùng', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11651\n",
            "sentence:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19/1/1974.\n",
            "\n",
            "entity:  {'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "entity index list:  [32, 33]\n",
            "[162, 174]\n",
            "['chiến', 'Hoàng Sa']\n",
            "My word_tokenize 1:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "My word_tokenize 2:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải', 'chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11655\n",
            "sentence:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19/1/1974.\n",
            "\n",
            "entity:  {'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "entity index list:  [32, 33]\n",
            "[162, 174]\n",
            "['chiến', 'Hoàng Sa']\n",
            "My word_tokenize 1:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "My word_tokenize 2:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải', 'chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11658\n",
            "sentence:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19/1/1974.\n",
            "\n",
            "entity:  {'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "entity index list:  [32, 33]\n",
            "[162, 174]\n",
            "['chiến', 'Hoàng Sa']\n",
            "My word_tokenize 1:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "My word_tokenize 2:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải', 'chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11660\n",
            "sentence:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19/1/1974.\n",
            "\n",
            "entity:  {'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "entity index list:  [32, 33]\n",
            "[162, 174]\n",
            "['chiến', 'Hoàng Sa']\n",
            "My word_tokenize 1:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "My word_tokenize 2:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải', 'chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11661\n",
            "sentence:  Một số hình ảnh tư liệu về quá trình thực thi và bảo vệ chủ quyền của Việt Nam đối với hai quần đảo Hoàng Sa và Trường Sa từ những năm 1930 đến khi Trung Quốc xâm chiếm toàn bộ quần đảo Hoàng Sa bằng trận “Hải chiến Hoàng Sa ” ngày 19/1/1974.\n",
            "\n",
            "entity:  {'text': 'chiến\\xa0Hoàng Sa', 'pos': [210, 224]}\n",
            "entity index list:  [32, 33]\n",
            "[162, 174]\n",
            "['chiến', 'Hoàng Sa']\n",
            "My word_tokenize 1:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "My word_tokenize 2:         ['Một số', 'hình ảnh', 'tư liệu', 'về', 'quá trình', 'thực thi', 'và', 'bảo vệ', 'chủ quyền', 'của', 'Việt Nam', 'đối với', 'hai', 'quần đảo', 'Hoàng Sa', 'và', 'Trường Sa', 'từ', 'những', 'năm', '1930', 'đến', 'khi', 'Trung Quốc', 'xâm chiếm', 'toàn bộ', 'quần đảo', 'Hoàng Sa', 'bằng', 'trận', '“', 'Hải', 'chiến', 'Hoàng Sa', '”', 'ngày', '19/1/1974', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11853\n",
            "sentence:  Bà NGUYỄN THỊ THU HIỀN , Trưởng phòng GD&ĐT quận 9\n",
            "\n",
            "entity:  {'text': 'phòng GD&ĐT quận 9', 'pos': [32, 50]}\n",
            "entity index list:  [4, 5, 6, 7]\n",
            "[25, 40]\n",
            "['phòng', 'GD&ĐT', 'quận', '9']\n",
            "My word_tokenize 1:         ['Bà', 'NGUYỄN THỊ THU HIỀN', ',', 'Trưởng phòng', 'GD&ĐT', 'quận', '9']\n",
            "My word_tokenize 2:         ['Bà', 'NGUYỄN THỊ THU HIỀN', ',', 'Trưởng', 'phòng', 'GD&ĐT', 'quận', '9']\n",
            "\n",
            "\n",
            "---------- sent_id:  11855\n",
            "sentence:  Theo Thùy Nguyễn / Báo đời sống pháp luật\n",
            "\n",
            "entity:  {'text': 'Thùy Nguyễn', 'pos': [5, 16]}\n",
            "entity index list:  [1, 2]\n",
            "['Thùy', 'Nguyễn']\n",
            "[4, 14]\n",
            "Underthesea word_tokenize:  ['Theo', 'Thùy', 'Nguyễn /', 'Báo', 'đời sống', 'pháp luật']\n",
            "My word_tokenize 1:         ['Theo', 'Thùy', 'Nguyễn', '/', 'Báo', 'đời sống', 'pháp luật']\n",
            "\n",
            "\n",
            "---------- sent_id:  11933\n",
            "sentence:  Một cảnh trong phim ngắn của Lê Thế Thắng Một phim ngắn khác về VN thu hút cộng đồng mạng (với hơn 3 triệu lượt xem và hơn 40.000 lượt chia sẻ) là Reverie of Vietnam của nhà làm phim người Ý Oliver Astrologo , được anh đưa lên Facebook cuối năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Oliver Astrologo', 'pos': [191, 207]}\n",
            "entity index list:  [38]\n",
            "[149, 164]\n",
            "['Oliver Astrologo']\n",
            "My word_tokenize 1:         ['Một', 'cảnh', 'trong', 'phim', 'ngắn', 'của', 'Lê Thế Thắng', 'Một', 'phim', 'ngắn', 'khác', 'về', 'VN', 'thu hút', 'cộng đồng', 'mạng', '(', 'với', 'hơn', '3', 'triệu', 'lượt', 'xem', 'và', 'hơn', '40.000', 'lượt', 'chia sẻ', ')', 'là', 'Reverie', 'of Vietnam', 'của', 'nhà', 'làm', 'phim', 'người', 'Ý Oliver Astrologo', ',', 'được', 'anh', 'đưa', 'lên', 'Facebook', 'cuối', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Một', 'cảnh', 'trong', 'phim', 'ngắn', 'của', 'Lê Thế Thắng', 'Một', 'phim', 'ngắn', 'khác', 'về', 'VN', 'thu hút', 'cộng đồng', 'mạng', '(', 'với', 'hơn', '3', 'triệu', 'lượt', 'xem', 'và', 'hơn', '40.000', 'lượt', 'chia sẻ', ')', 'là', 'Reverie', 'of Vietnam', 'của', 'nhà', 'làm', 'phim', 'người', 'Ý', 'Oliver Astrologo', ',', 'được', 'anh', 'đưa', 'lên', 'Facebook', 'cuối', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  11934\n",
            "sentence:  Một cảnh trong phim ngắn của Lê Thế Thắng Một phim ngắn khác về VN thu hút cộng đồng mạng (với hơn 3 triệu lượt xem và hơn 40.000 lượt chia sẻ) là Reverie of Vietnam của nhà làm phim người Ý Oliver Astrologo , được anh đưa lên Facebook cuối năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Oliver Astrologo', 'pos': [191, 207]}\n",
            "entity index list:  [38]\n",
            "[149, 164]\n",
            "['Oliver Astrologo']\n",
            "My word_tokenize 1:         ['Một', 'cảnh', 'trong', 'phim', 'ngắn', 'của', 'Lê Thế Thắng', 'Một', 'phim', 'ngắn', 'khác', 'về', 'VN', 'thu hút', 'cộng đồng', 'mạng', '(', 'với', 'hơn', '3', 'triệu', 'lượt', 'xem', 'và', 'hơn', '40.000', 'lượt', 'chia sẻ', ')', 'là', 'Reverie', 'of Vietnam', 'của', 'nhà', 'làm', 'phim', 'người', 'Ý Oliver Astrologo', ',', 'được', 'anh', 'đưa', 'lên', 'Facebook', 'cuối', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Một', 'cảnh', 'trong', 'phim', 'ngắn', 'của', 'Lê Thế Thắng', 'Một', 'phim', 'ngắn', 'khác', 'về', 'VN', 'thu hút', 'cộng đồng', 'mạng', '(', 'với', 'hơn', '3', 'triệu', 'lượt', 'xem', 'và', 'hơn', '40.000', 'lượt', 'chia sẻ', ')', 'là', 'Reverie', 'of Vietnam', 'của', 'nhà', 'làm', 'phim', 'người', 'Ý', 'Oliver Astrologo', ',', 'được', 'anh', 'đưa', 'lên', 'Facebook', 'cuối', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12179\n",
            "sentence:  Khi vụ việc được nêu ra tại buổi họp báo Chính phủ thường kỳ đầu tháng 8/2017, ông Nguyễn Ngọc Đông – Thứ trưởng Bộ Giao thông Vận tải trả lời rằng:\n",
            "\n",
            "entity:  {'text': 'Nguyễn Ngọc Đông', 'pos': [83, 99]}\n",
            "entity index list:  [16]\n",
            "['Nguyễn Ngọc Đông']\n",
            "[65, 79]\n",
            "Underthesea word_tokenize:  ['Khi', 'vụ việc', 'được', 'nêu', 'ra', 'tại', 'buổi', 'họp báo', 'Chính phủ', 'thường', 'kỳ', 'đầu', 'tháng', '8/2017', ',', 'ông', 'Nguyễn Ngọc Đông –', 'Thứ trưởng', 'Bộ', 'Giao thông', 'Vận tải', 'trả lời', 'rằng', ':']\n",
            "My word_tokenize 1:         ['Khi', 'vụ việc', 'được', 'nêu', 'ra', 'tại', 'buổi', 'họp báo', 'Chính phủ', 'thường', 'kỳ', 'đầu', 'tháng', '8/2017', ',', 'ông', 'Nguyễn Ngọc Đông', '–', 'Thứ trưởng', 'Bộ', 'Giao thông', 'Vận tải', 'trả lời', 'rằng', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  12332\n",
            "sentence:  1.000.000 đồng; Phạm Thị Đức Hạnh (489/57/11 Huỳnh Văn Bánh , P.13 , Q.Phú Nhuận , TP.HCM ):\n",
            "\n",
            "entity:  {'text': 'Phạm Thị Đức', 'pos': [16, 28]}\n",
            "entity index list:  [3]\n",
            "['Phạm Thị Đức']\n",
            "[14, 24]\n",
            "Underthesea word_tokenize:  ['1.000.000', 'đồng', ';', 'Phạm Thị Đức Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "My word_tokenize 1:         ['1.000.000', 'đồng', ';', 'Phạm Thị Đức', 'Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  12333\n",
            "sentence:  1.000.000 đồng; Phạm Thị Đức Hạnh (489/57/11 Huỳnh Văn Bánh , P.13 , Q.Phú Nhuận , TP.HCM ):\n",
            "\n",
            "entity:  {'text': 'Phạm Thị Đức', 'pos': [16, 28]}\n",
            "entity index list:  [3]\n",
            "['Phạm Thị Đức']\n",
            "[14, 24]\n",
            "Underthesea word_tokenize:  ['1.000.000', 'đồng', ';', 'Phạm Thị Đức Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "My word_tokenize 1:         ['1.000.000', 'đồng', ';', 'Phạm Thị Đức', 'Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  12334\n",
            "sentence:  1.000.000 đồng; Phạm Thị Đức Hạnh (489/57/11 Huỳnh Văn Bánh , P.13 , Q.Phú Nhuận , TP.HCM ):\n",
            "\n",
            "entity:  {'text': 'Phạm Thị Đức', 'pos': [16, 28]}\n",
            "entity index list:  [3]\n",
            "['Phạm Thị Đức']\n",
            "[14, 24]\n",
            "Underthesea word_tokenize:  ['1.000.000', 'đồng', ';', 'Phạm Thị Đức Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "My word_tokenize 1:         ['1.000.000', 'đồng', ';', 'Phạm Thị Đức', 'Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  12335\n",
            "sentence:  1.000.000 đồng; Phạm Thị Đức Hạnh (489/57/11 Huỳnh Văn Bánh , P.13 , Q.Phú Nhuận , TP.HCM ):\n",
            "\n",
            "entity:  {'text': 'Phạm Thị Đức', 'pos': [16, 28]}\n",
            "entity index list:  [3]\n",
            "['Phạm Thị Đức']\n",
            "[14, 24]\n",
            "Underthesea word_tokenize:  ['1.000.000', 'đồng', ';', 'Phạm Thị Đức Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "My word_tokenize 1:         ['1.000.000', 'đồng', ';', 'Phạm Thị Đức', 'Hạnh', '(', '489', '/', '57/11', 'Huỳnh Văn Bánh', ',', 'P.', '13', ',', 'Q.Phú Nhuận', ',', 'TP.HCM', ')', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  12481\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "[58, 65]\n",
            "['Bộ GD-ĐT']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12482\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "[67, 89]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12488\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "[58, 65]\n",
            "['Bộ GD-ĐT']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12489\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "[67, 89]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12494\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "[58, 65]\n",
            "['Bộ GD-ĐT']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12495\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "[67, 89]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12500\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "['Bộ GD-ĐT']\n",
            "[58, 65]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [15, 16, 17]\n",
            "[67, 89]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12501\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "['Bộ GD-ĐT']\n",
            "[58, 65]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12502\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "['Bộ GD-ĐT']\n",
            "[58, 65]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12503\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "['Bộ GD-ĐT']\n",
            "[58, 65]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12504\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [76, 84]}\n",
            "entity index list:  [13]\n",
            "['Bộ GD-ĐT']\n",
            "[58, 65]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12505\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[67, 89]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12506\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[67, 89]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12507\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[67, 89]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12508\n",
            "sentence:  Bộ GD-ĐT trao 1 tỷ đồng hỗ trợ ngành giáo dục Quảng Bình , Hà Tĩnh Thay mặt Bộ GD-ĐT và Công đoàn Giáo dục Việt Nam , bà Nguyễn Thị Nghĩa (Thứ trưởng Bộ GD-ĐT ) đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [88, 115]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[67, 89]\n",
            "Underthesea word_tokenize:  ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'GD-ĐT', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'giáo dục', 'Quảng Bình', ',', 'Hà Tĩnh', 'Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'Giáo dục', 'Việt Nam', ',', 'bà', 'Nguyễn Thị Nghĩa', '(', 'Thứ trưởng', 'Bộ', 'GD-ĐT', ')', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12515\n",
            "sentence:  Mới đây, đoàn công tác của Bộ Giáo dục và Đào tạo (GD-ĐT) và Công đoàn Giáo dục Việt Nam (GDVN) do Thứ trưởng Nguyễn Thị Nghĩa làm trưởng đoàn đã đến thăm hỏi, động viên cán bộ, giáo viên, học sinh tỉnh Quảng Bình và Hà Tĩnh - 2 địa phương chịu thiệt hại nặng nề nhất trong cơn bão số 10 vừa qua.\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [61, 88]}\n",
            "entity index list:  [11, 12, 13]\n",
            "[47, 69]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "My word_tokenize 2:         ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và', 'Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12519\n",
            "sentence:  Mới đây, đoàn công tác của Bộ Giáo dục và Đào tạo (GD-ĐT) và Công đoàn Giáo dục Việt Nam (GDVN) do Thứ trưởng Nguyễn Thị Nghĩa làm trưởng đoàn đã đến thăm hỏi, động viên cán bộ, giáo viên, học sinh tỉnh Quảng Bình và Hà Tĩnh - 2 địa phương chịu thiệt hại nặng nề nhất trong cơn bão số 10 vừa qua.\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [61, 88]}\n",
            "entity index list:  [11, 12, 13]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[47, 69]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và', 'Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12520\n",
            "sentence:  Mới đây, đoàn công tác của Bộ Giáo dục và Đào tạo (GD-ĐT) và Công đoàn Giáo dục Việt Nam (GDVN) do Thứ trưởng Nguyễn Thị Nghĩa làm trưởng đoàn đã đến thăm hỏi, động viên cán bộ, giáo viên, học sinh tỉnh Quảng Bình và Hà Tĩnh - 2 địa phương chịu thiệt hại nặng nề nhất trong cơn bão số 10 vừa qua.\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [61, 88]}\n",
            "entity index list:  [11, 12, 13]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[47, 69]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và', 'Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12521\n",
            "sentence:  Mới đây, đoàn công tác của Bộ Giáo dục và Đào tạo (GD-ĐT) và Công đoàn Giáo dục Việt Nam (GDVN) do Thứ trưởng Nguyễn Thị Nghĩa làm trưởng đoàn đã đến thăm hỏi, động viên cán bộ, giáo viên, học sinh tỉnh Quảng Bình và Hà Tĩnh - 2 địa phương chịu thiệt hại nặng nề nhất trong cơn bão số 10 vừa qua.\n",
            "\n",
            "entity:  {'text': 'Công đoàn Giáo dục Việt Nam', 'pos': [61, 88]}\n",
            "entity index list:  [11, 12, 13]\n",
            "['Công đoàn', 'Giáo dục', 'Việt Nam']\n",
            "[47, 69]\n",
            "Underthesea word_tokenize:  ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "My word_tokenize 1:         ['Mới đây', ',', 'đoàn', 'công tác', 'của', 'Bộ', 'Giáo dục và Đào tạo', '(', 'GD-ĐT', ')', 'và', 'Công đoàn', 'Giáo dục', 'Việt Nam', '(', 'GDVN', ')', 'do', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'làm', 'trưởng đoàn', 'đã', 'đến', 'thăm hỏi', ',', 'động viên', 'cán bộ', ',', 'giáo viên', ',', 'học sinh', 'tỉnh', 'Quảng Bình', 'và', 'Hà Tĩnh', '-', '2', 'địa phương', 'chịu', 'thiệt hại', 'nặng nề', 'nhất', 'trong', 'cơn', 'bão', 'số', '10', 'vừa qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12549\n",
            "sentence:  Cùng ngày, đoàn công tác của Bộ GD-ĐT và Công đoàn GDVN đã đến thăm, trao quà các trường học trên địa bàn huyện Kỳ Anh , tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [29, 37]}\n",
            "entity index list:  [6]\n",
            "['Bộ GD-ĐT']\n",
            "[23, 30]\n",
            "Underthesea word_tokenize:  ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [41, 55]}\n",
            "entity index list:  [8, 9]\n",
            "[32, 44]\n",
            "['Công đoàn', 'GDVN']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT', 'và', 'Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12550\n",
            "sentence:  Cùng ngày, đoàn công tác của Bộ GD-ĐT và Công đoàn GDVN đã đến thăm, trao quà các trường học trên địa bàn huyện Kỳ Anh , tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [29, 37]}\n",
            "entity index list:  [6]\n",
            "['Bộ GD-ĐT']\n",
            "[23, 30]\n",
            "Underthesea word_tokenize:  ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12551\n",
            "sentence:  Cùng ngày, đoàn công tác của Bộ GD-ĐT và Công đoàn GDVN đã đến thăm, trao quà các trường học trên địa bàn huyện Kỳ Anh , tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [29, 37]}\n",
            "entity index list:  [6]\n",
            "['Bộ GD-ĐT']\n",
            "[23, 30]\n",
            "Underthesea word_tokenize:  ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12552\n",
            "sentence:  Cùng ngày, đoàn công tác của Bộ GD-ĐT và Công đoàn GDVN đã đến thăm, trao quà các trường học trên địa bàn huyện Kỳ Anh , tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [41, 55]}\n",
            "entity index list:  [7, 8]\n",
            "['Công đoàn', 'GDVN']\n",
            "[32, 44]\n",
            "Underthesea word_tokenize:  ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và', 'Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12553\n",
            "sentence:  Cùng ngày, đoàn công tác của Bộ GD-ĐT và Công đoàn GDVN đã đến thăm, trao quà các trường học trên địa bàn huyện Kỳ Anh , tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [41, 55]}\n",
            "entity index list:  [7, 8]\n",
            "['Công đoàn', 'GDVN']\n",
            "[32, 44]\n",
            "Underthesea word_tokenize:  ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Cùng', 'ngày', ',', 'đoàn', 'công tác', 'của', 'Bộ GD-ĐT và', 'Công đoàn', 'GDVN', 'đã', 'đến', 'thăm', ',', 'trao', 'quà', 'các', 'trường học', 'trên', 'địa bàn', 'huyện', 'Kỳ Anh', ',', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12576\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [9, 17]}\n",
            "entity index list:  [1]\n",
            "['Bộ GD-ĐT']\n",
            "[7, 14]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [21, 35]}\n",
            "entity index list:  [3, 4]\n",
            "[16, 28]\n",
            "['Công đoàn', 'GDVN']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 2:         ['Thay mặt', 'Bộ GD-ĐT', 'và', 'Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12577\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [9, 17]}\n",
            "entity index list:  [1]\n",
            "['Bộ GD-ĐT']\n",
            "[7, 14]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12578\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [9, 17]}\n",
            "entity index list:  [1]\n",
            "['Bộ GD-ĐT']\n",
            "[7, 14]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12579\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Bộ GD-ĐT', 'pos': [9, 17]}\n",
            "entity index list:  [1]\n",
            "['Bộ GD-ĐT']\n",
            "[7, 14]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT', 'và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12580\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [21, 35]}\n",
            "entity index list:  [2, 3]\n",
            "['Công đoàn', 'GDVN']\n",
            "[16, 28]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12581\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [21, 35]}\n",
            "entity index list:  [2, 3]\n",
            "['Công đoàn', 'GDVN']\n",
            "[16, 28]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12582\n",
            "sentence:  Thay mặt Bộ GD-ĐT và Công đoàn GDVN , Thứ trưởng Nguyễn Thị Nghĩa đã trao 1 tỷ đồng hỗ trợ ngành Giáo dục tỉnh Quảng Bình và tỉnh Hà Tĩnh .\n",
            "\n",
            "entity:  {'text': 'Công đoàn GDVN', 'pos': [21, 35]}\n",
            "entity index list:  [2, 3]\n",
            "['Công đoàn', 'GDVN']\n",
            "[16, 28]\n",
            "Underthesea word_tokenize:  ['Thay mặt', 'Bộ GD-ĐT và Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "My word_tokenize 1:         ['Thay mặt', 'Bộ GD-ĐT và', 'Công đoàn', 'GDVN', ',', 'Thứ trưởng', 'Nguyễn Thị Nghĩa', 'đã', 'trao', '1', 'tỷ', 'đồng', 'hỗ trợ', 'ngành', 'Giáo dục', 'tỉnh', 'Quảng Bình', 'và', 'tỉnh', 'Hà Tĩnh', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12639\n",
            "sentence:  Ngọc Vũ Cuộc sống khó khăn, đa số học sinh ở miền núi Quảng Trị đều bị thiếu cân, gầy gò ốm yếu.\n",
            "\n",
            "entity:  {'text': 'Ngọc Vũ', 'pos': [0, 7]}\n",
            "entity index list:  [0]\n",
            "['Ngọc Vũ']\n",
            "[0, 6]\n",
            "Underthesea word_tokenize:  ['Ngọc Vũ Cuộc sống', 'khó khăn', ',', 'đa số', 'học sinh', 'ở', 'miền', 'núi', 'Quảng Trị', 'đều', 'bị', 'thiếu', 'cân', ',', 'gầy gò', 'ốm yếu', '.']\n",
            "My word_tokenize 1:         ['Ngọc Vũ', 'Cuộc sống', 'khó khăn', ',', 'đa số', 'học sinh', 'ở', 'miền', 'núi', 'Quảng Trị', 'đều', 'bị', 'thiếu', 'cân', ',', 'gầy gò', 'ốm yếu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12661\n",
            "sentence:  Ngọc Vũ Lãnh đạo xã Tà Rụt cho biết, huyện thông báo nhà nước đã có dự án đầu tư xây cầu bắc qua thôn A Vương và Vực Leng nhưng chờ mãi mà chưa thấy làm, trong khi con em địa phương hàng ngày mỏi mòn chờ đợi.\n",
            "\n",
            "entity:  {'text': 'Ngọc Vũ', 'pos': [0, 7]}\n",
            "entity index list:  [0]\n",
            "['Ngọc Vũ']\n",
            "[0, 6]\n",
            "Underthesea word_tokenize:  ['Ngọc Vũ Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "My word_tokenize 1:         ['Ngọc Vũ', 'Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12662\n",
            "sentence:  Ngọc Vũ Lãnh đạo xã Tà Rụt cho biết, huyện thông báo nhà nước đã có dự án đầu tư xây cầu bắc qua thôn A Vương và Vực Leng nhưng chờ mãi mà chưa thấy làm, trong khi con em địa phương hàng ngày mỏi mòn chờ đợi.\n",
            "\n",
            "entity:  {'text': 'Ngọc Vũ', 'pos': [0, 7]}\n",
            "entity index list:  [0]\n",
            "['Ngọc Vũ']\n",
            "[0, 6]\n",
            "Underthesea word_tokenize:  ['Ngọc Vũ Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "My word_tokenize 1:         ['Ngọc Vũ', 'Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12663\n",
            "sentence:  Ngọc Vũ Lãnh đạo xã Tà Rụt cho biết, huyện thông báo nhà nước đã có dự án đầu tư xây cầu bắc qua thôn A Vương và Vực Leng nhưng chờ mãi mà chưa thấy làm, trong khi con em địa phương hàng ngày mỏi mòn chờ đợi.\n",
            "\n",
            "entity:  {'text': 'Ngọc Vũ', 'pos': [0, 7]}\n",
            "entity index list:  [0]\n",
            "['Ngọc Vũ']\n",
            "[0, 6]\n",
            "Underthesea word_tokenize:  ['Ngọc Vũ Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "My word_tokenize 1:         ['Ngọc Vũ', 'Lãnh đạo', 'xã', 'Tà Rụt', 'cho', 'biết', ',', 'huyện', 'thông báo', 'nhà nước', 'đã', 'có', 'dự án', 'đầu tư', 'xây', 'cầu', 'bắc', 'qua', 'thôn', 'A Vương', 'và', 'Vực Leng', 'nhưng', 'chờ', 'mãi', 'mà', 'chưa', 'thấy', 'làm', ',', 'trong', 'khi', 'con em', 'địa phương', 'hàng', 'ngày', 'mỏi mòn', 'chờ đợi', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12716\n",
            "sentence:  Xem dàn mỹ nữ đi thi tuyển phi công quân sự ở Nga Lần đầu tiên trong lịch sử hiện đại nước Nga , trường Hàng không Quân sự Krasnodar tiếp nhận các học viên nữ.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [46, 49]}\n",
            "entity index list:  [8]\n",
            "['Nga']\n",
            "[34, 37]\n",
            "Underthesea word_tokenize:  ['Xem', 'dàn', 'mỹ nữ', 'đi', 'thi tuyển', 'phi công', 'quân sự', 'ở', 'Nga Lần', 'đầu tiên', 'trong', 'lịch sử', 'hiện đại', 'nước', 'Nga', ',', 'trường', 'Hàng', 'không', 'Quân sự', 'Krasnodar', 'tiếp nhận', 'các', 'học viên', 'nữ', '.']\n",
            "My word_tokenize 1:         ['Xem', 'dàn', 'mỹ nữ', 'đi', 'thi tuyển', 'phi công', 'quân sự', 'ở', 'Nga', 'Lần', 'đầu tiên', 'trong', 'lịch sử', 'hiện đại', 'nước', 'Nga', ',', 'trường', 'Hàng', 'không', 'Quân sự', 'Krasnodar', 'tiếp nhận', 'các', 'học viên', 'nữ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12717\n",
            "sentence:  Xem dàn mỹ nữ đi thi tuyển phi công quân sự ở Nga Lần đầu tiên trong lịch sử hiện đại nước Nga , trường Hàng không Quân sự Krasnodar tiếp nhận các học viên nữ.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [46, 49]}\n",
            "entity index list:  [8]\n",
            "['Nga']\n",
            "[34, 37]\n",
            "Underthesea word_tokenize:  ['Xem', 'dàn', 'mỹ nữ', 'đi', 'thi tuyển', 'phi công', 'quân sự', 'ở', 'Nga Lần', 'đầu tiên', 'trong', 'lịch sử', 'hiện đại', 'nước', 'Nga', ',', 'trường', 'Hàng', 'không', 'Quân sự', 'Krasnodar', 'tiếp nhận', 'các', 'học viên', 'nữ', '.']\n",
            "My word_tokenize 1:         ['Xem', 'dàn', 'mỹ nữ', 'đi', 'thi tuyển', 'phi công', 'quân sự', 'ở', 'Nga', 'Lần', 'đầu tiên', 'trong', 'lịch sử', 'hiện đại', 'nước', 'Nga', ',', 'trường', 'Hàng', 'không', 'Quân sự', 'Krasnodar', 'tiếp nhận', 'các', 'học viên', 'nữ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12904\n",
            "sentence:  Uber nhờ cư dân London giúp đỡ Vài giờ sau khi cơ quan quản lý giao thông của thành phố London tước giấy phép của Uber , CEO Dara Khosrowshahi đăng lên twitter cá nhân kêu gọi người dân London giúp đỡ.\n",
            "\n",
            "entity:  {'text': 'Dara Khosrowshahi', 'pos': [125, 142]}\n",
            "entity index list:  [21]\n",
            "[97, 113]\n",
            "['Dara Khosrowshahi']\n",
            "My word_tokenize 1:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "My word_tokenize 2:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO', 'Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12908\n",
            "sentence:  Uber nhờ cư dân London giúp đỡ Vài giờ sau khi cơ quan quản lý giao thông của thành phố London tước giấy phép của Uber , CEO Dara Khosrowshahi đăng lên twitter cá nhân kêu gọi người dân London giúp đỡ.\n",
            "\n",
            "entity:  {'text': 'Dara Khosrowshahi', 'pos': [125, 142]}\n",
            "entity index list:  [21]\n",
            "[97, 113]\n",
            "['Dara Khosrowshahi']\n",
            "My word_tokenize 1:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "My word_tokenize 2:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO', 'Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12911\n",
            "sentence:  Uber nhờ cư dân London giúp đỡ Vài giờ sau khi cơ quan quản lý giao thông của thành phố London tước giấy phép của Uber , CEO Dara Khosrowshahi đăng lên twitter cá nhân kêu gọi người dân London giúp đỡ.\n",
            "\n",
            "entity:  {'text': 'Dara Khosrowshahi', 'pos': [125, 142]}\n",
            "entity index list:  [21]\n",
            "[97, 113]\n",
            "['Dara Khosrowshahi']\n",
            "My word_tokenize 1:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "My word_tokenize 2:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO', 'Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12913\n",
            "sentence:  Uber nhờ cư dân London giúp đỡ Vài giờ sau khi cơ quan quản lý giao thông của thành phố London tước giấy phép của Uber , CEO Dara Khosrowshahi đăng lên twitter cá nhân kêu gọi người dân London giúp đỡ.\n",
            "\n",
            "entity:  {'text': 'Dara Khosrowshahi', 'pos': [125, 142]}\n",
            "entity index list:  [21]\n",
            "[97, 113]\n",
            "['Dara Khosrowshahi']\n",
            "My word_tokenize 1:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "My word_tokenize 2:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO', 'Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12915\n",
            "sentence:  Uber nhờ cư dân London giúp đỡ Vài giờ sau khi cơ quan quản lý giao thông của thành phố London tước giấy phép của Uber , CEO Dara Khosrowshahi đăng lên twitter cá nhân kêu gọi người dân London giúp đỡ.\n",
            "\n",
            "entity:  {'text': 'Dara Khosrowshahi', 'pos': [125, 142]}\n",
            "entity index list:  [21]\n",
            "['Dara Khosrowshahi']\n",
            "[97, 113]\n",
            "Underthesea word_tokenize:  ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "My word_tokenize 1:         ['Uber', 'nhờ', 'cư dân', 'London', 'giúp đỡ', 'Vài', 'giờ', 'sau', 'khi', 'cơ quan', 'quản lý', 'giao thông', 'của', 'thành phố', 'London', 'tước', 'giấy phép', 'của', 'Uber', ',', 'CEO', 'Dara Khosrowshahi', 'đăng', 'lên', 'twitter', 'cá nhân', 'kêu gọi', 'người', 'dân', 'London', 'giúp đỡ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  12939\n",
            "sentence:  Theo K Nguyễn -Thời Đại\n",
            "\n",
            "entity:  {'text': 'K Nguyễn', 'pos': [5, 13]}\n",
            "entity index list:  [1, 2]\n",
            "['K', 'Nguyễn']\n",
            "[4, 11]\n",
            "Underthesea word_tokenize:  ['Theo', 'K', 'Nguyễn -', 'Thời Đại']\n",
            "My word_tokenize 1:         ['Theo', 'K', 'Nguyễn', '-', 'Thời Đại']\n",
            "\n",
            "\n",
            "---------- sent_id:  13003\n",
            "sentence:  Bill Gates không thích chức năng Ctrl-Alt-Del trên Windows Chức năng Ctrl-Alt-Del trên máy tính Windows luôn là một thao tác hai tay khó chịu cho người dùng, đó là lý do tại sao đồng sáng lập Microsoft Bill Gates muốn nó đơn giản hơn nữa.\n",
            "\n",
            "entity:  {'text': 'Microsoft', 'pos': [192, 201]}\n",
            "entity index list:  [30]\n",
            "[155, 164]\n",
            "['Microsoft']\n",
            "My word_tokenize 1:         ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "My word_tokenize 2:         ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft', 'Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13004\n",
            "sentence:  Bill Gates không thích chức năng Ctrl-Alt-Del trên Windows Chức năng Ctrl-Alt-Del trên máy tính Windows luôn là một thao tác hai tay khó chịu cho người dùng, đó là lý do tại sao đồng sáng lập Microsoft Bill Gates muốn nó đơn giản hơn nữa.\n",
            "\n",
            "entity:  {'text': 'Bill Gates', 'pos': [202, 212]}\n",
            "entity index list:  [31]\n",
            "[164, 173]\n",
            "['Bill Gates']\n",
            "My word_tokenize 1:         ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "My word_tokenize 2:         ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft', 'Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13005\n",
            "sentence:  Bill Gates không thích chức năng Ctrl-Alt-Del trên Windows Chức năng Ctrl-Alt-Del trên máy tính Windows luôn là một thao tác hai tay khó chịu cho người dùng, đó là lý do tại sao đồng sáng lập Microsoft Bill Gates muốn nó đơn giản hơn nữa.\n",
            "\n",
            "entity:  {'text': 'Microsoft', 'pos': [192, 201]}\n",
            "entity index list:  [30]\n",
            "['Microsoft']\n",
            "[155, 164]\n",
            "Underthesea word_tokenize:  ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "My word_tokenize 1:         ['Bill', 'Gates', 'không', 'thích', 'chức năng', 'Ctrl-Alt-Del', 'trên', 'Windows', 'Chức năng', 'Ctrl-Alt-Del', 'trên', 'máy tính', 'Windows', 'luôn', 'là', 'một', 'thao tác', 'hai', 'tay', 'khó chịu', 'cho', 'người', 'dùng', ',', 'đó', 'là', 'lý do', 'tại sao', 'đồng', 'sáng lập', 'Microsoft', 'Bill Gates', 'muốn', 'nó', 'đơn giản', 'hơn', 'nữa', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13250\n",
            "sentence:  Nhà khoa học Jessica Agarwal tới từ Viện nghiên cứu Hệ mặt trời Max Planck giải thích:\n",
            "\n",
            "entity:  {'text': 'Jessica Agarwal', 'pos': [13, 28]}\n",
            "entity index list:  [1]\n",
            "['Jessica Agarwal']\n",
            "[10, 24]\n",
            "Underthesea word_tokenize:  ['Nhà khoa học Jessica Agarwal', 'tới', 'từ', 'Viện', 'nghiên cứu', 'Hệ mặt trời', 'Max Planck', 'giải thích', ':']\n",
            "My word_tokenize 1:         ['Nhà khoa học', 'Jessica Agarwal', 'tới', 'từ', 'Viện', 'nghiên cứu', 'Hệ mặt trời', 'Max Planck', 'giải thích', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  13255\n",
            "sentence:  Điều này đồng nghĩa họ dành rất ít thời gian gặp mặt trực tiếp hoặc ra ngoài chơi với bạn bè”, Đài ABC dẫn lời bà Twenge nhận định.\n",
            "\n",
            "entity:  {'text': 'ABC', 'pos': [99, 102]}\n",
            "entity index list:  [19]\n",
            "['ABC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Điều', 'này', 'đồng nghĩa', 'họ', 'dành', 'rất', 'ít', 'thời gian', 'gặp mặt', 'trực tiếp', 'hoặc', 'ra', 'ngoài', 'chơi', 'với', 'bạn bè', '”', ',', 'Đài ABC', 'dẫn', 'lời', 'bà', 'Twenge', 'nhận định', '.']\n",
            "My word_tokenize 1:         ['Điều', 'này', 'đồng nghĩa', 'họ', 'dành', 'rất', 'ít', 'thời gian', 'gặp mặt', 'trực tiếp', 'hoặc', 'ra', 'ngoài', 'chơi', 'với', 'bạn bè', '”', ',', 'Đài', 'ABC', 'dẫn', 'lời', 'bà', 'Twenge', 'nhận định', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13261\n",
            "sentence:  “Họ nói không thật sự muốn dùng điện thoại quá nhiều, nhưng cảm thấy áp lực, buộc phải làm như vậy”, bà Twenge chia sẻ với Đài ABC .\n",
            "\n",
            "entity:  {'text': 'ABC', 'pos': [127, 130]}\n",
            "entity index list:  [26]\n",
            "[100, 103]\n",
            "['ABC']\n",
            "My word_tokenize 1:         ['“', 'Họ', 'nói', 'không', 'thật sự', 'muốn', 'dùng', 'điện thoại', 'quá', 'nhiều', ',', 'nhưng', 'cảm thấy', 'áp lực', ',', 'buộc', 'phải', 'làm', 'như vậy', '”', ',', 'bà', 'Twenge', 'chia sẻ', 'với', 'Đài ABC', '.']\n",
            "My word_tokenize 2:         ['“', 'Họ', 'nói', 'không', 'thật sự', 'muốn', 'dùng', 'điện thoại', 'quá', 'nhiều', ',', 'nhưng', 'cảm thấy', 'áp lực', ',', 'buộc', 'phải', 'làm', 'như vậy', '”', ',', 'bà', 'Twenge', 'chia sẻ', 'với', 'Đài', 'ABC', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13287\n",
            "sentence:  Đây là khẳng định của CEO Apple Tim Cook trước những ý kiến cho rằng giá bán iPhone X quá đắt.\n",
            "\n",
            "entity:  {'text': 'Apple', 'pos': [26, 31]}\n",
            "entity index list:  [5]\n",
            "['Apple']\n",
            "[20, 25]\n",
            "Underthesea word_tokenize:  ['Đây', 'là', 'khẳng định', 'của', 'CEO Apple Tim Cook', 'trước', 'những', 'ý kiến', 'cho', 'rằng', 'giá bán', 'iPhone', 'X', 'quá', 'đắt', '.']\n",
            "My word_tokenize 1:         ['Đây', 'là', 'khẳng định', 'của', 'CEO', 'Apple', 'Tim Cook', 'trước', 'những', 'ý kiến', 'cho', 'rằng', 'giá bán', 'iPhone', 'X', 'quá', 'đắt', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13288\n",
            "sentence:  Trong chương trình Good Morning America , phản hồi ý kiến \"Giá bán iPhone X quá đắt\", CEO Apple Tim Cook khẳng định mức giá khởi điểm 999 USD là hoàn toàn phù hợp với những gì thiết bị này sở hữu.\n",
            "\n",
            "entity:  {'text': 'America', 'pos': [32, 39]}\n",
            "entity index list:  [3]\n",
            "['America']\n",
            "[27, 34]\n",
            "Underthesea word_tokenize:  ['Trong', 'chương trình', 'Good Morning America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "My word_tokenize 1:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "\n",
            "entity:  {'text': 'Apple', 'pos': [90, 95]}\n",
            "entity index list:  [16]\n",
            "[72, 77]\n",
            "['Apple']\n",
            "My word_tokenize 1:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "My word_tokenize 2:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO', 'Apple', 'Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13289\n",
            "sentence:  Trong chương trình Good Morning America , phản hồi ý kiến \"Giá bán iPhone X quá đắt\", CEO Apple Tim Cook khẳng định mức giá khởi điểm 999 USD là hoàn toàn phù hợp với những gì thiết bị này sở hữu.\n",
            "\n",
            "entity:  {'text': 'America', 'pos': [32, 39]}\n",
            "entity index list:  [3]\n",
            "['America']\n",
            "[27, 34]\n",
            "Underthesea word_tokenize:  ['Trong', 'chương trình', 'Good Morning America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "My word_tokenize 1:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "\n",
            "entity:  {'text': 'Tim Cook', 'pos': [96, 104]}\n",
            "entity index list:  [16]\n",
            "[77, 84]\n",
            "['Tim Cook']\n",
            "My word_tokenize 1:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "My word_tokenize 2:         ['Trong', 'chương trình', 'Good Morning', 'America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple', 'Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  13290\n",
            "sentence:  Trong chương trình Good Morning America , phản hồi ý kiến \"Giá bán iPhone X quá đắt\", CEO Apple Tim Cook khẳng định mức giá khởi điểm 999 USD là hoàn toàn phù hợp với những gì thiết bị này sở hữu.\n",
            "\n",
            "entity:  {'text': 'Apple', 'pos': [90, 95]}\n",
            "entity index list:  [15]\n",
            "['Apple']\n",
            "[72, 77]\n",
            "Underthesea word_tokenize:  ['Trong', 'chương trình', 'Good Morning America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO Apple Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "My word_tokenize 1:         ['Trong', 'chương trình', 'Good Morning America', ',', 'phản hồi', 'ý kiến', '\"', 'Giá bán', 'iPhone', 'X', 'quá', 'đắt', '\"', ',', 'CEO', 'Apple', 'Tim Cook', 'khẳng định', 'mức', 'giá', 'khởi điểm', '999', 'USD', 'là', 'hoàn toàn', 'phù hợp', 'với', 'những', 'gì', 'thiết bị', 'này', 'sở hữu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15026\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15027\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [10]\n",
            "[57, 67]\n",
            "['Chris Bosse']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 2:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15028\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15029\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15030\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15031\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15032\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Alessandra Cianchetta', 'pos': [4, 25]}\n",
            "entity index list:  [1]\n",
            "['Alessandra Cianchetta']\n",
            "[3, 23]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS', 'Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15033\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "[57, 67]\n",
            "['Chris Bosse']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 2:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15039\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "['Chris Bosse']\n",
            "[57, 67]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15040\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "['Chris Bosse']\n",
            "[57, 67]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15041\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "['Chris Bosse']\n",
            "[57, 67]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15042\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "['Chris Bosse']\n",
            "[57, 67]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15043\n",
            "sentence:  KTS Alessandra Cianchetta – Giám đốc điều hành Cty kiến trúc AWP ; KTS Chris Bosse – Giám đốc Cty LAVA ; KTS Hoàng Thúc Hào -Kiến trúc sư trưởng văn phòng kiến trúc 1+1>2; KTS Nguyễn Hoàng Mạnh – Đồng sáng lập, CEO và Kiến trúc sư chủ trì của Cty TNHH Tư vấn Kiến trúc & Xây dựng MIA Design Studio ...\n",
            "\n",
            "entity:  {'text': 'Chris Bosse', 'pos': [71, 82]}\n",
            "entity index list:  [9]\n",
            "['Chris Bosse']\n",
            "[57, 67]\n",
            "Underthesea word_tokenize:  ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "My word_tokenize 1:         ['KTS Alessandra Cianchetta', '–', 'Giám đốc', 'điều hành', 'Cty', 'kiến trúc', 'AWP', ';', 'KTS', 'Chris Bosse', '–', 'Giám đốc', 'Cty LAVA', ';', 'KTS', 'Hoàng Thúc', 'Hào', '-', 'Kiến trúc sư trưởng', 'văn phòng', 'kiến trúc', '1', '+', '1', '>', '2', ';', 'KTS', 'Nguyễn Hoàng Mạnh', '–', 'Đồng', 'sáng lập', ',', 'CEO', 'và', 'Kiến trúc sư', 'chủ trì', 'của', 'Cty TNHH', 'Tư vấn', 'Kiến trúc', '&', 'Xây dựng', 'MIA Design Studio', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  15266\n",
            "sentence:  Theo quan điểm của PGS, TS Lê Hành - Chủ tịch Hội phẫu thuật thẩm mỹ TP Hồ Chí Minh - Trưởng ban Vận động thành lập Hội phẫu thuật tạo hình thẩm mỹ Việt Nam , có ba tiêu chí xuất phát từ bệnh nhân, bác sĩ và cơ sở phẫu thuật thẩm mỹ.\n",
            "\n",
            "entity:  {'text': 'Hội phẫu thuật tạo hình thẩm mỹ Việt Nam', 'pos': [116, 156]}\n",
            "entity index list:  [18, 19, 20, 21, 22]\n",
            "[89, 121]\n",
            "['Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Theo', 'quan điểm', 'của', 'PGS', ',', 'TS', 'Lê Hành', '-', 'Chủ tịch', 'Hội', 'phẫu thuật', 'thẩm mỹ', 'TP', 'Hồ Chí Minh', '-', 'Trưởng ban', 'Vận động', 'thành lập Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam', ',', 'có', 'ba', 'tiêu chí', 'xuất phát', 'từ', 'bệnh nhân', ',', 'bác sĩ', 'và', 'cơ sở', 'phẫu thuật', 'thẩm mỹ', '.']\n",
            "My word_tokenize 2:         ['Theo', 'quan điểm', 'của', 'PGS', ',', 'TS', 'Lê Hành', '-', 'Chủ tịch', 'Hội', 'phẫu thuật', 'thẩm mỹ', 'TP', 'Hồ Chí Minh', '-', 'Trưởng ban', 'Vận động', 'thành lập', 'Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam', ',', 'có', 'ba', 'tiêu chí', 'xuất phát', 'từ', 'bệnh nhân', ',', 'bác sĩ', 'và', 'cơ sở', 'phẫu thuật', 'thẩm mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15267\n",
            "sentence:  Theo quan điểm của PGS, TS Lê Hành - Chủ tịch Hội phẫu thuật thẩm mỹ TP Hồ Chí Minh - Trưởng ban Vận động thành lập Hội phẫu thuật tạo hình thẩm mỹ Việt Nam , có ba tiêu chí xuất phát từ bệnh nhân, bác sĩ và cơ sở phẫu thuật thẩm mỹ.\n",
            "\n",
            "entity:  {'text': 'Hội phẫu thuật tạo hình thẩm mỹ Việt Nam', 'pos': [116, 156]}\n",
            "entity index list:  [18, 19, 20, 21, 22]\n",
            "[89, 121]\n",
            "['Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam']\n",
            "My word_tokenize 1:         ['Theo', 'quan điểm', 'của', 'PGS', ',', 'TS', 'Lê Hành', '-', 'Chủ tịch', 'Hội', 'phẫu thuật', 'thẩm mỹ', 'TP', 'Hồ Chí Minh', '-', 'Trưởng ban', 'Vận động', 'thành lập Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam', ',', 'có', 'ba', 'tiêu chí', 'xuất phát', 'từ', 'bệnh nhân', ',', 'bác sĩ', 'và', 'cơ sở', 'phẫu thuật', 'thẩm mỹ', '.']\n",
            "My word_tokenize 2:         ['Theo', 'quan điểm', 'của', 'PGS', ',', 'TS', 'Lê Hành', '-', 'Chủ tịch', 'Hội', 'phẫu thuật', 'thẩm mỹ', 'TP', 'Hồ Chí Minh', '-', 'Trưởng ban', 'Vận động', 'thành lập', 'Hội', 'phẫu thuật', 'tạo hình', 'thẩm mỹ', 'Việt Nam', ',', 'có', 'ba', 'tiêu chí', 'xuất phát', 'từ', 'bệnh nhân', ',', 'bác sĩ', 'và', 'cơ sở', 'phẫu thuật', 'thẩm mỹ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15292\n",
            "sentence:  10.000 người đi tránh núi lửa phun trào ở thiên đường du lịch Bali Gần 10.000 người dân sống quanh núi lửa Agung ở Bali , Indonesia đã được sơ tán trong lúc nguy cơ về một đợt phun trào ngày càng cao.\n",
            "\n",
            "entity:  {'text': 'Bali', 'pos': [62, 66]}\n",
            "entity index list:  [10]\n",
            "['Bali']\n",
            "[49, 53]\n",
            "Underthesea word_tokenize:  ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "My word_tokenize 1:         ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali', 'Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15293\n",
            "sentence:  10.000 người đi tránh núi lửa phun trào ở thiên đường du lịch Bali Gần 10.000 người dân sống quanh núi lửa Agung ở Bali , Indonesia đã được sơ tán trong lúc nguy cơ về một đợt phun trào ngày càng cao.\n",
            "\n",
            "entity:  {'text': 'Bali', 'pos': [62, 66]}\n",
            "entity index list:  [10]\n",
            "['Bali']\n",
            "[49, 53]\n",
            "Underthesea word_tokenize:  ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "My word_tokenize 1:         ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali', 'Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15294\n",
            "sentence:  10.000 người đi tránh núi lửa phun trào ở thiên đường du lịch Bali Gần 10.000 người dân sống quanh núi lửa Agung ở Bali , Indonesia đã được sơ tán trong lúc nguy cơ về một đợt phun trào ngày càng cao.\n",
            "\n",
            "entity:  {'text': 'Bali', 'pos': [62, 66]}\n",
            "entity index list:  [10]\n",
            "['Bali']\n",
            "[49, 53]\n",
            "Underthesea word_tokenize:  ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "My word_tokenize 1:         ['10.000', 'người', 'đi', 'tránh', 'núi lửa', 'phun', 'trào', 'ở', 'thiên đường', 'du lịch', 'Bali', 'Gần', '10.000', 'người', 'dân', 'sống', 'quanh', 'núi lửa', 'Agung', 'ở', 'Bali', ',', 'Indonesia', 'đã', 'được', 'sơ tán', 'trong', 'lúc', 'nguy cơ', 'về', 'một', 'đợt', 'phun trào', 'ngày càng', 'cao', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15304\n",
            "sentence:  Khi dung nham tìm được đường đúng, nó sẽ tạo ra một trận động đất, rồi dâng trào lên bề mặt\", đài ABC (Australia ) dẫn lời ông Syahbana , người đứng đầu cơ quan ứng phó núi lửa đông Indonesia , cho biết.\n",
            "\n",
            "entity:  {'text': 'ABC', 'pos': [98, 101]}\n",
            "entity index list:  [23]\n",
            "['ABC']\n",
            "[76, 79]\n",
            "Underthesea word_tokenize:  ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "My word_tokenize 1:         ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài', 'ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15305\n",
            "sentence:  Khi dung nham tìm được đường đúng, nó sẽ tạo ra một trận động đất, rồi dâng trào lên bề mặt\", đài ABC (Australia ) dẫn lời ông Syahbana , người đứng đầu cơ quan ứng phó núi lửa đông Indonesia , cho biết.\n",
            "\n",
            "entity:  {'text': 'ABC', 'pos': [98, 101]}\n",
            "entity index list:  [23]\n",
            "['ABC']\n",
            "[76, 79]\n",
            "Underthesea word_tokenize:  ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "My word_tokenize 1:         ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài', 'ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15306\n",
            "sentence:  Khi dung nham tìm được đường đúng, nó sẽ tạo ra một trận động đất, rồi dâng trào lên bề mặt\", đài ABC (Australia ) dẫn lời ông Syahbana , người đứng đầu cơ quan ứng phó núi lửa đông Indonesia , cho biết.\n",
            "\n",
            "entity:  {'text': 'ABC', 'pos': [98, 101]}\n",
            "entity index list:  [23]\n",
            "['ABC']\n",
            "[76, 79]\n",
            "Underthesea word_tokenize:  ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "My word_tokenize 1:         ['Khi', 'dung nham', 'tìm', 'được', 'đường', 'đúng', ',', 'nó', 'sẽ', 'tạo', 'ra', 'một', 'trận', 'động đất', ',', 'rồi', 'dâng', 'trào', 'lên', 'bề mặt', '\"', ',', 'đài', 'ABC', '(', 'Australia', ')', 'dẫn', 'lời', 'ông', 'Syahbana', ',', 'người', 'đứng', 'đầu', 'cơ quan', 'ứng phó', 'núi', 'lửa', 'đông', 'Indonesia', ',', 'cho', 'biết', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15315\n",
            "sentence:  Hiệp hội các nhà sản xuất Ô tô Nhật Bản (JAMA ) sẽ tổ chức Triển lãm Ô tô Tokyo (Tokyo Motor Show ) 2017 trong 10 ngày, từ 27/10 - 5/11/2017 tại Trung tâm Triển lãm Tokyo Tokyo Big Sight với chủ đề “Beyond The Mortor – Hơn cả một trải nghiệm xe hơi\".\n",
            "\n",
            "entity:  {'text': 'Trung tâm Triển lãm Tokyo', 'pos': [145, 170]}\n",
            "entity index list:  [26, 27, 28]\n",
            "[112, 133]\n",
            "['Trung tâm', 'Triển lãm', 'Tokyo']\n",
            "My word_tokenize 1:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "My word_tokenize 2:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo', 'Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15316\n",
            "sentence:  Hiệp hội các nhà sản xuất Ô tô Nhật Bản (JAMA ) sẽ tổ chức Triển lãm Ô tô Tokyo (Tokyo Motor Show ) 2017 trong 10 ngày, từ 27/10 - 5/11/2017 tại Trung tâm Triển lãm Tokyo Tokyo Big Sight với chủ đề “Beyond The Mortor – Hơn cả một trải nghiệm xe hơi\".\n",
            "\n",
            "entity:  {'text': 'Tokyo Big Sight', 'pos': [171, 186]}\n",
            "entity index list:  [29]\n",
            "[133, 146]\n",
            "['Tokyo Big Sight']\n",
            "My word_tokenize 1:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "My word_tokenize 2:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo', 'Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15317\n",
            "sentence:  Hiệp hội các nhà sản xuất Ô tô Nhật Bản (JAMA ) sẽ tổ chức Triển lãm Ô tô Tokyo (Tokyo Motor Show ) 2017 trong 10 ngày, từ 27/10 - 5/11/2017 tại Trung tâm Triển lãm Tokyo Tokyo Big Sight với chủ đề “Beyond The Mortor – Hơn cả một trải nghiệm xe hơi\".\n",
            "\n",
            "entity:  {'text': 'Trung tâm Triển lãm Tokyo', 'pos': [145, 170]}\n",
            "entity index list:  [26, 27, 28]\n",
            "[112, 133]\n",
            "['Trung tâm', 'Triển lãm', 'Tokyo']\n",
            "My word_tokenize 1:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "My word_tokenize 2:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo', 'Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15318\n",
            "sentence:  Hiệp hội các nhà sản xuất Ô tô Nhật Bản (JAMA ) sẽ tổ chức Triển lãm Ô tô Tokyo (Tokyo Motor Show ) 2017 trong 10 ngày, từ 27/10 - 5/11/2017 tại Trung tâm Triển lãm Tokyo Tokyo Big Sight với chủ đề “Beyond The Mortor – Hơn cả một trải nghiệm xe hơi\".\n",
            "\n",
            "entity:  {'text': 'Tokyo Big Sight', 'pos': [171, 186]}\n",
            "entity index list:  [29]\n",
            "[133, 146]\n",
            "['Tokyo Big Sight']\n",
            "My word_tokenize 1:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "My word_tokenize 2:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo', 'Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15319\n",
            "sentence:  Hiệp hội các nhà sản xuất Ô tô Nhật Bản (JAMA ) sẽ tổ chức Triển lãm Ô tô Tokyo (Tokyo Motor Show ) 2017 trong 10 ngày, từ 27/10 - 5/11/2017 tại Trung tâm Triển lãm Tokyo Tokyo Big Sight với chủ đề “Beyond The Mortor – Hơn cả một trải nghiệm xe hơi\".\n",
            "\n",
            "entity:  {'text': 'Trung tâm Triển lãm Tokyo', 'pos': [145, 170]}\n",
            "entity index list:  [26, 27, 28]\n",
            "['Trung tâm', 'Triển lãm', 'Tokyo']\n",
            "[112, 133]\n",
            "Underthesea word_tokenize:  ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "My word_tokenize 1:         ['Hiệp hội', 'các', 'nhà sản xuất', 'Ô tô', 'Nhật Bản', '(', 'JAMA', ')', 'sẽ', 'tổ chức', 'Triển lãm', 'Ô tô', 'Tokyo', '(', 'Tokyo Motor Show', ')', '2017', 'trong', '10', 'ngày', ',', 'từ', '27/10', '-', '5/11/2017', 'tại', 'Trung tâm', 'Triển lãm', 'Tokyo', 'Tokyo Big Sight', 'với', 'chủ đề', '“', 'Beyond The Mortor –', 'Hơn cả', 'một', 'trải nghiệm', 'xe hơi', '\"', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15342\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [86, 97]}\n",
            "entity index list:  [13]\n",
            "[68, 77]\n",
            "['Lee Won Hee']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15343\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [105, 113]}\n",
            "entity index list:  [15]\n",
            "[82, 89]\n",
            "['Yu Jiyun']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15346\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [86, 97]}\n",
            "entity index list:  [13]\n",
            "[68, 77]\n",
            "['Lee Won Hee']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15347\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [105, 113]}\n",
            "entity index list:  [15]\n",
            "[82, 89]\n",
            "['Yu Jiyun']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15349\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [86, 97]}\n",
            "entity index list:  [13]\n",
            "[68, 77]\n",
            "['Lee Won Hee']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15350\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [105, 113]}\n",
            "entity index list:  [15]\n",
            "[82, 89]\n",
            "['Yu Jiyun']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15352\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [86, 97]}\n",
            "entity index list:  [13]\n",
            "['Lee Won Hee']\n",
            "[68, 77]\n",
            "Underthesea word_tokenize:  ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [105, 113]}\n",
            "entity index list:  [16]\n",
            "[82, 89]\n",
            "['Yu Jiyun']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 2:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15353\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [86, 97]}\n",
            "entity index list:  [13]\n",
            "['Lee Won Hee']\n",
            "[68, 77]\n",
            "Underthesea word_tokenize:  ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15354\n",
            "sentence:  ông Nguyễn Anh Tuấn – Viện trưởng Viện Nghiên cứu Phát triển (Tổng cục Du lịch ); TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc ;…\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [105, 113]}\n",
            "entity index list:  [15]\n",
            "['Yu Jiyun']\n",
            "[82, 89]\n",
            "Underthesea word_tokenize:  ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "My word_tokenize 1:         ['ông', 'Nguyễn Anh Tuấn', '–', 'Viện trưởng', 'Viện', 'Nghiên cứu', 'Phát triển', '(', 'Tổng cục', 'Du lịch', ')', ';', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', ';', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  15360\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [37, 48]}\n",
            "entity index list:  [6]\n",
            "['Lee Won Hee']\n",
            "[29, 38]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [56, 64]}\n",
            "entity index list:  [9]\n",
            "[43, 50]\n",
            "['Yu Jiyun']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 2:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15361\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [37, 48]}\n",
            "entity index list:  [6]\n",
            "['Lee Won Hee']\n",
            "[29, 38]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15362\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [37, 48]}\n",
            "entity index list:  [6]\n",
            "['Lee Won Hee']\n",
            "[29, 38]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15363\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Lee Won Hee', 'pos': [37, 48]}\n",
            "entity index list:  [6]\n",
            "['Lee Won Hee']\n",
            "[29, 38]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS.', 'Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15364\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [56, 64]}\n",
            "entity index list:  [8]\n",
            "['Yu Jiyun']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15365\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [56, 64]}\n",
            "entity index list:  [8]\n",
            "['Yu Jiyun']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15366\n",
            "sentence:  Toàn cảnh hội thảo Tại hội thảo, TS. Lee Won Hee và TS. Yu Jiyun - Viện Nghiên cứu Văn hóa và Du lịch Hàn Quốc cũng đã trình bày tham luận về đặc điểm, kinh nghiệm phát triển của làn sóng du lịch Hàn Quốc và những định hướng chính sách trong phát triển du lịch dựa vào các chương trình nghệ thuật tổng hợp tại Hàn Quốc .\n",
            "\n",
            "entity:  {'text': 'Yu Jiyun', 'pos': [56, 64]}\n",
            "entity index list:  [8]\n",
            "['Yu Jiyun']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS. Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "My word_tokenize 1:         ['Toàn cảnh', 'hội thảo', 'Tại', 'hội thảo', ',', 'TS. Lee Won Hee', 'và', 'TS.', 'Yu Jiyun', '-', 'Viện', 'Nghiên cứu Văn hóa', 'và', 'Du lịch', 'Hàn Quốc', 'cũng', 'đã', 'trình bày', 'tham luận', 'về', 'đặc điểm', ',', 'kinh nghiệm', 'phát triển', 'của', 'làn sóng', 'du lịch', 'Hàn Quốc', 'và', 'những', 'định hướng', 'chính sách', 'trong', 'phát triển', 'du lịch', 'dựa', 'vào', 'các', 'chương trình', 'nghệ thuật', 'tổng hợp', 'tại', 'Hàn Quốc', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15480\n",
            "sentence:  Ảnh: Pháp luật TP.HCM Trả lời Pháp luật TP.HCM  về trường hợp này, ông Nguyễn Vinh Hiển , Hiệu trưởng Trường Tiểu học Trương Văn Thành , cho biết ông chưa gặp bà Hương trước đó mà chỉ gặp một người khác có đến trình bày về trường hợp của em Ngọc Hân vào ngày thứ Ba vừa rồi (tức ngày 19/9).\n",
            "\n",
            "entity:  {'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "entity index list:  [5, 6, 7]\n",
            "[21, 38]\n",
            "['lời', 'Pháp luật', 'TP.HCM']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "My word_tokenize 2:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả', 'lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15485\n",
            "sentence:  Ảnh: Pháp luật TP.HCM Trả lời Pháp luật TP.HCM  về trường hợp này, ông Nguyễn Vinh Hiển , Hiệu trưởng Trường Tiểu học Trương Văn Thành , cho biết ông chưa gặp bà Hương trước đó mà chỉ gặp một người khác có đến trình bày về trường hợp của em Ngọc Hân vào ngày thứ Ba vừa rồi (tức ngày 19/9).\n",
            "\n",
            "entity:  {'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "entity index list:  [5, 6, 7]\n",
            "['lời', 'Pháp luật', 'TP.HCM']\n",
            "[21, 38]\n",
            "Underthesea word_tokenize:  ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả', 'lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15486\n",
            "sentence:  Ảnh: Pháp luật TP.HCM Trả lời Pháp luật TP.HCM  về trường hợp này, ông Nguyễn Vinh Hiển , Hiệu trưởng Trường Tiểu học Trương Văn Thành , cho biết ông chưa gặp bà Hương trước đó mà chỉ gặp một người khác có đến trình bày về trường hợp của em Ngọc Hân vào ngày thứ Ba vừa rồi (tức ngày 19/9).\n",
            "\n",
            "entity:  {'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "entity index list:  [5, 6, 7]\n",
            "['lời', 'Pháp luật', 'TP.HCM']\n",
            "[21, 38]\n",
            "Underthesea word_tokenize:  ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả', 'lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15487\n",
            "sentence:  Ảnh: Pháp luật TP.HCM Trả lời Pháp luật TP.HCM  về trường hợp này, ông Nguyễn Vinh Hiển , Hiệu trưởng Trường Tiểu học Trương Văn Thành , cho biết ông chưa gặp bà Hương trước đó mà chỉ gặp một người khác có đến trình bày về trường hợp của em Ngọc Hân vào ngày thứ Ba vừa rồi (tức ngày 19/9).\n",
            "\n",
            "entity:  {'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "entity index list:  [5, 6, 7]\n",
            "['lời', 'Pháp luật', 'TP.HCM']\n",
            "[21, 38]\n",
            "Underthesea word_tokenize:  ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả', 'lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15488\n",
            "sentence:  Ảnh: Pháp luật TP.HCM Trả lời Pháp luật TP.HCM  về trường hợp này, ông Nguyễn Vinh Hiển , Hiệu trưởng Trường Tiểu học Trương Văn Thành , cho biết ông chưa gặp bà Hương trước đó mà chỉ gặp một người khác có đến trình bày về trường hợp của em Ngọc Hân vào ngày thứ Ba vừa rồi (tức ngày 19/9).\n",
            "\n",
            "entity:  {'text': 'lời\\xa0Pháp luật TP.HCM', 'pos': [26, 46]}\n",
            "entity index list:  [5, 6, 7]\n",
            "['lời', 'Pháp luật', 'TP.HCM']\n",
            "[21, 38]\n",
            "Underthesea word_tokenize:  ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'Pháp luật', 'TP.HCM', 'Trả', 'lời', 'Pháp luật', 'TP.HCM', 'về', 'trường hợp', 'này', ',', 'ông', 'Nguyễn Vinh Hiển', ',', 'Hiệu trưởng', 'Trường', 'Tiểu học', 'Trương Văn Thành', ',', 'cho', 'biết', 'ông', 'chưa', 'gặp', 'bà', 'Hương', 'trước', 'đó', 'mà', 'chỉ', 'gặp', 'một', 'người', 'khác', 'có', 'đến', 'trình bày', 'về', 'trường hợp', 'của', 'em', 'Ngọc Hân', 'vào', 'ngày', 'thứ Ba', 'vừa rồi', '(', 'tức', 'ngày', '19/9', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15497\n",
            "sentence:  Ảnh: VTC Bé Hân cho biết: “Không được đi học cháu rất buồn.\n",
            "\n",
            "entity:  {'text': 'Hân', 'pos': [12, 15]}\n",
            "entity index list:  [4]\n",
            "[9, 12]\n",
            "['Hân']\n",
            "My word_tokenize 1:         ['Ảnh', ':', 'VTC', 'Bé Hân', 'cho', 'biết', ':', '“', 'Không', 'được', 'đi', 'học', 'cháu', 'rất', 'buồn', '.']\n",
            "My word_tokenize 2:         ['Ảnh', ':', 'VTC', 'Bé', 'Hân', 'cho', 'biết', ':', '“', 'Không', 'được', 'đi', 'học', 'cháu', 'rất', 'buồn', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15617\n",
            "sentence:  EVN Nghệ An thành lập vào tháng 12/2013, là 1 trong 17 CLB thành viên của mạng lưới TNV Bảo vệ động vật hoang dã được điều phối bởi Trung tâm giáo dục thiên nhiên (ENV ).\n",
            "\n",
            "entity:  {'text': 'EVN Nghệ An', 'pos': [0, 11]}\n",
            "entity index list:  [0, 1]\n",
            "['EVN', 'Nghệ An']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['EVN', 'Nghệ An thành lập', 'vào', 'tháng', '12/2013', ',', 'là', '1', 'trong', '17', 'CLB', 'thành viên', 'của', 'mạng lưới', 'TNV', 'Bảo vệ', 'động vật', 'hoang dã', 'được', 'điều phối', 'bởi', 'Trung tâm', 'giáo dục', 'thiên nhiên', '(', 'ENV', ')', '.']\n",
            "My word_tokenize 1:         ['EVN', 'Nghệ An', 'thành lập', 'vào', 'tháng', '12/2013', ',', 'là', '1', 'trong', '17', 'CLB', 'thành viên', 'của', 'mạng lưới', 'TNV', 'Bảo vệ', 'động vật', 'hoang dã', 'được', 'điều phối', 'bởi', 'Trung tâm', 'giáo dục', 'thiên nhiên', '(', 'ENV', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15618\n",
            "sentence:  EVN Nghệ An thành lập vào tháng 12/2013, là 1 trong 17 CLB thành viên của mạng lưới TNV Bảo vệ động vật hoang dã được điều phối bởi Trung tâm giáo dục thiên nhiên (ENV ).\n",
            "\n",
            "entity:  {'text': 'EVN Nghệ An', 'pos': [0, 11]}\n",
            "entity index list:  [0, 1]\n",
            "['EVN', 'Nghệ An']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['EVN', 'Nghệ An thành lập', 'vào', 'tháng', '12/2013', ',', 'là', '1', 'trong', '17', 'CLB', 'thành viên', 'của', 'mạng lưới', 'TNV', 'Bảo vệ', 'động vật', 'hoang dã', 'được', 'điều phối', 'bởi', 'Trung tâm', 'giáo dục', 'thiên nhiên', '(', 'ENV', ')', '.']\n",
            "My word_tokenize 1:         ['EVN', 'Nghệ An', 'thành lập', 'vào', 'tháng', '12/2013', ',', 'là', '1', 'trong', '17', 'CLB', 'thành viên', 'của', 'mạng lưới', 'TNV', 'Bảo vệ', 'động vật', 'hoang dã', 'được', 'điều phối', 'bởi', 'Trung tâm', 'giáo dục', 'thiên nhiên', '(', 'ENV', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15650\n",
            "sentence:  Thế nhưng theo TS. Susanne Ekstedt , nhà nghiên cứu thuộc khoa thực phẩm và sinh học tại Viện nghiên cứu kỹ thuật SP (Gothenburg , Thụy Điển ), chúng ta đã rã đông sai cách.\n",
            "\n",
            "entity:  {'text': 'Susanne Ekstedt', 'pos': [19, 34]}\n",
            "entity index list:  [4]\n",
            "['Susanne Ekstedt']\n",
            "[15, 29]\n",
            "Underthesea word_tokenize:  ['Thế', 'nhưng', 'theo', 'TS. Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "My word_tokenize 1:         ['Thế', 'nhưng', 'theo', 'TS.', 'Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15651\n",
            "sentence:  Thế nhưng theo TS. Susanne Ekstedt , nhà nghiên cứu thuộc khoa thực phẩm và sinh học tại Viện nghiên cứu kỹ thuật SP (Gothenburg , Thụy Điển ), chúng ta đã rã đông sai cách.\n",
            "\n",
            "entity:  {'text': 'Susanne Ekstedt', 'pos': [19, 34]}\n",
            "entity index list:  [4]\n",
            "['Susanne Ekstedt']\n",
            "[15, 29]\n",
            "Underthesea word_tokenize:  ['Thế', 'nhưng', 'theo', 'TS. Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "My word_tokenize 1:         ['Thế', 'nhưng', 'theo', 'TS.', 'Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  15652\n",
            "sentence:  Thế nhưng theo TS. Susanne Ekstedt , nhà nghiên cứu thuộc khoa thực phẩm và sinh học tại Viện nghiên cứu kỹ thuật SP (Gothenburg , Thụy Điển ), chúng ta đã rã đông sai cách.\n",
            "\n",
            "entity:  {'text': 'Susanne Ekstedt', 'pos': [19, 34]}\n",
            "entity index list:  [4]\n",
            "['Susanne Ekstedt']\n",
            "[15, 29]\n",
            "Underthesea word_tokenize:  ['Thế', 'nhưng', 'theo', 'TS. Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "My word_tokenize 1:         ['Thế', 'nhưng', 'theo', 'TS.', 'Susanne Ekstedt', ',', 'nhà nghiên cứu', 'thuộc', 'khoa', 'thực phẩm', 'và', 'sinh học', 'tại', 'Viện', 'nghiên cứu', 'kỹ thuật', 'SP', '(', 'Gothenburg', ',', 'Thụy Điển', ')', ',', 'chúng ta', 'đã', 'rã', 'đông', 'sai', 'cách', '.']\n",
            "Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoKdd-zY66Jc"
      },
      "source": [
        "##### Create train input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xfu-7oPFyIA"
      },
      "source": [
        "###### max len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzFYaBbn5N80",
        "outputId": "a36abc05-c575-4168-d207-4732aa52ccd0"
      },
      "source": [
        "print(jtrain_data_v3[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc_id': '23351113', 'sent_id': 1, 'sentence': 'Ảnh minh họa Thứ trưởng Bộ GD&ĐT Nguyễn Thị Nghĩa đã có ý kiến về vấn đề này.', 'spos': [311, 388], 'entity_1': {'text': 'Bộ GD&ĐT', 'pos': [24, 32]}, 'entity_2': {'text': 'Nguyễn Thị Nghĩa', 'pos': [33, 49]}, 'label': 'AFFILIATION_TO', 'new_sentence': 'Ảnh minh họa Thứ trưởng Bộ GD&ĐT Nguyễn Thị Nghĩa đã có ý kiến về vấn đề này.', 'new_entity_1': {'text': 'Bộ GD&ĐT', 'pos': [24, 32], 'wtk_index_lst': [3, 4], 'pos_no_space': [19, 26]}, 'new_entity_2': {'text': 'Nguyễn Thị Nghĩa', 'pos': [33, 49], 'wtk_index_lst': [5], 'pos_no_space': [26, 40]}, 'word_tokenize_lst': ['Ảnh', 'minh họa', 'Thứ trưởng', 'Bộ', 'GD&ĐT', 'Nguyễn Thị Nghĩa', 'đã', 'có', 'ý kiến', 'về', 'vấn đề', 'này', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOCfi8DmzHDO",
        "outputId": "7650a424-07df-4206-9a9d-123504dd130e"
      },
      "source": [
        "pb_sent_maxlen = 0\n",
        "xlmr_sent_maxlen = 0\n",
        "\n",
        "pb_sent_len_lst = []\n",
        "xlmr_sent_len_lst = []\n",
        "\n",
        "for sentif in jtrain_data_v3:\n",
        "\n",
        "    assert (sentif['new_sentence'] == unicodedata.normalize(\"NFC\", sentif['new_sentence'])), str('sentence not seem to be normalized.')\n",
        "    assert (''.join(sentif['new_sentence'].split()) == u''.join([tk.replace(\" \", \"\") for tk in sentif['word_tokenize_lst']])), \\\n",
        "    str('word_tokenize_lst not match new_sentence.')\n",
        "\n",
        "    # phobert\n",
        "    pb_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "    pb_sent_tokenize = pb_tokenizer.tokenize(pb_sent)\n",
        "\n",
        "    pb_sent_maxlen = max(pb_sent_maxlen, len(pb_sent_tokenize))\n",
        "\n",
        "    pb_sent_len_lst.append(len(pb_sent_tokenize))\n",
        "\n",
        "    # xlmr\n",
        "    xlmr_sent = u\" \".join(copy.deepcopy(sentif['word_tokenize_lst']))\n",
        "    xlmr_sent_tokenize = xlmr_tokenizer.tokenize(xlmr_sent)\n",
        "\n",
        "    xlmr_sent_maxlen = max(xlmr_sent_maxlen, len(xlmr_sent_tokenize))\n",
        "    xlmr_sent_len_lst.append(len(xlmr_sent_tokenize))\n",
        "\n",
        "\n",
        "print('pb_sent_maxlen: ', pb_sent_maxlen)\n",
        "print('xlmr_sent_maxlen: ', xlmr_sent_maxlen)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pb_sent_maxlen:  168\n",
            "xlmr_sent_maxlen:  235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEdxfgcBARDM",
        "outputId": "766932aa-6e0f-40e4-8f03-19508ab3321e"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import Counter \n",
        "\n",
        "# phobert\n",
        "print('--phobert')\n",
        "print(pd.Series(pb_sent_len_lst).describe())\n",
        "most_common_len = Counter(pb_sent_len_lst).most_common(1)[0]\n",
        "print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n",
        "# xlmr\n",
        "print('\\n--XLM-RoBERTa')\n",
        "print(pd.Series(xlmr_sent_len_lst).describe())\n",
        "most_common_len = Counter(xlmr_sent_len_lst).most_common(1)[0]\n",
        "print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--phobert\n",
            "count    15666.000000\n",
            "mean        55.106473\n",
            "std         35.205998\n",
            "min          2.000000\n",
            "25%         31.000000\n",
            "50%         44.000000\n",
            "75%         63.000000\n",
            "max        168.000000\n",
            "dtype: float64\n",
            "most common sentence len:  140  appear  1653  times.\n",
            "\n",
            "--XLM-RoBERTa\n",
            "count    15666.000000\n",
            "mean        81.328801\n",
            "std         56.527934\n",
            "min          4.000000\n",
            "25%         45.000000\n",
            "50%         64.000000\n",
            "75%         93.000000\n",
            "max        235.000000\n",
            "dtype: float64\n",
            "most common sentence len:  223  appear  1653  times.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuL9lddpF3eS"
      },
      "source": [
        "###### create input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho30-2avoKm4",
        "outputId": "e4cb3a05-f539-498d-c24b-a5043dcea6b8"
      },
      "source": [
        "for sentif in jtrain_data_v3:\n",
        "    if 'Hotspur' in sentif['new_sentence']:\n",
        "        print(sentif)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc_id': '23351556', 'sent_id': 1726, 'sentence': 'Tottenham Hotspur 21:00 Burnley ?', 'spos': [3153, 3186], 'entity_1': {'text': 'Tottenham Hotspur', 'pos': [0, 17]}, 'entity_2': {'text': 'Burnley', 'pos': [24, 31]}, 'label': 'OTHERS', 'new_sentence': 'Tottenham Hotspur 21:00 Burnley ?', 'new_entity_1': {'text': 'Tottenham Hotspur', 'pos': [0, 17], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 16]}, 'new_entity_2': {'text': 'Burnley', 'pos': [24, 31], 'wtk_index_lst': [5], 'pos_no_space': [21, 28]}, 'word_tokenize_lst': ['Tottenham', 'Hotspur', '21', ':', '00', 'Burnley', '?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4Lb-dzlCpWp",
        "outputId": "b09821c9-3903-4f11-cee2-608b71ed3555"
      },
      "source": [
        "'''\n",
        "# thêm token vào phobert để tránh bị <unk> token, token này sẽ có embedding được khởi tạo một cái random\n",
        "# https://github.com/huggingface/transformers/issues/1413\n",
        "# https://huggingface.co/transformers/internal/tokenization_utils.html?highlight=add_token\n",
        "\n",
        "print(len(pb_tokenizer))\n",
        "\n",
        "add_Hotspur_to_pb = pb_tokenizer.add_tokens([unicodedata.normalize(\"NFC\", 'Hotspur')])\n",
        "print('We have added', add_Hotspur_to_pb, 'tokens')\n",
        "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
        "\n",
        "print(len(pb_tokenizer))\n",
        "\n",
        "pb_model.resize_token_embeddings(len(pb_tokenizer))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# thêm token vào phobert để tránh bị <unk> token, token này sẽ có embedding được khởi tạo một cái random\\n# https://github.com/huggingface/transformers/issues/1413\\n# https://huggingface.co/transformers/internal/tokenization_utils.html?highlight=add_token\\n\\nprint(len(pb_tokenizer))\\n\\nadd_Hotspur_to_pb = pb_tokenizer.add_tokens([unicodedata.normalize(\"NFC\", \\'Hotspur\\')])\\nprint(\\'We have added\\', add_Hotspur_to_pb, \\'tokens\\')\\n# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\\n\\nprint(len(pb_tokenizer))\\n\\npb_model.resize_token_embeddings(len(pb_tokenizer))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpJ2RKTg65ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9220b4a1-f7f4-490b-e49f-58b0a69fa400"
      },
      "source": [
        "if flags['use_phobert'] == True:\n",
        "    train_pb_input_ids = []\n",
        "    train_pb_attention_masks = []\n",
        "    train_pb_entity_1_eids = []\n",
        "    train_pb_entity_2_eids = []\n",
        "    #train_pb_labels = []\n",
        "\n",
        "if flags['use_xlmr'] == True:\n",
        "    train_xlmr_input_ids = []\n",
        "    train_xlmr_attention_masks = []\n",
        "    train_xlmr_entity_1_eids = []\n",
        "    train_xlmr_entity_2_eids = []\n",
        "    #train_xlmr_labels = []\n",
        "\n",
        "train_labels = []\n",
        "\n",
        "# Do entity_eids của các entity trong các câu không cùng chiều dài nên ta cần chuyển về cùng chiều dài thì mới biến thành tensor được\n",
        "# để chuyển về cùng chiều dài ta sẽ pad các eids ngắn hơn bằng -2.\n",
        "# vì eids phải >= 1 nên để số < 0 sẽ không sợ nhầm và ta chỉ thêm vào bên phải. \n",
        "# >= 1 vì lúc tìm eids đã tính <s> nên đã +1 sẵn nên min = 1\n",
        "# giả sử 1 entity_eids chỉ có chiều dài max là 30\n",
        "pad_ent_eid = -2\n",
        "max_len_ent_eid = 30\n",
        "\n",
        "assert (pad_ent_eid < 0), str('pad_ent_eid must < 0')\n",
        "\n",
        "jtrain_data_use = copy.deepcopy(jtrain_data_v3)\n",
        "\n",
        "for isentif, sentif in enumerate(jtrain_data_use):\n",
        "    \n",
        "    # cau nay chua 1 tu khong co trong vocab cua phobert. ta se bo cau nay di cho don gian\n",
        "    if sentif['sent_id'] == 1726:\n",
        "        print('-----SKIP 1726-----')\n",
        "        continue\n",
        "    \n",
        "    if flags['use_xlmr'] == True:\n",
        "        # xlmr\n",
        "        # xlmr biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n",
        "                # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n",
        "                # tương tự với ½ thành 1⁄2\n",
        "\n",
        "        # Lưu ý: XLM-R có một số kí tự như … bị biến thành ..., ½ thành 1⁄2 dẫn tới việc check, kiểm tra so sánh chuỗi bị khác\n",
        "        # và dù trong câu lẫn word_tokenize_lst có kí tự \\ufeff nhưng khi XLM-R lại loại bỏ khi toknenize nên kí tự cũng bị thay đổi vị trí\n",
        "        # các vấn đề này được fix trong hàm: get_entity_word_piece_index()\n",
        "\n",
        "        #xlmr_input_sent = sentif['new_sentence']\n",
        "        xlmr_input_sent = u\" \".join(sentif['word_tokenize_lst'])\n",
        "\n",
        "        xlmr_encode_dict = xlmr_tokenizer(xlmr_input_sent, add_special_tokens=True, padding='max_length', max_length=256)\n",
        "\n",
        "        xlmr_tokenize_lst = xlmr_tokenizer.tokenize(xlmr_input_sent)\n",
        "        assert ((len(xlmr_tokenize_lst) + 2) <= 256), str('len xlmr_tokenize_lst > 256')\n",
        "\n",
        "        xlmr_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'train')\n",
        "        xlmr_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'train')\n",
        "        \n",
        "        # pad\n",
        "        assert ((len(xlmr_entity_1_eids) <= max_len_ent_eid) and (len(xlmr_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n",
        "\n",
        "        xlmr_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_1_eids))\n",
        "        xlmr_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_2_eids))\n",
        "\n",
        "\n",
        "        if isentif < 10:\n",
        "            print('\\n')\n",
        "            print(xlmr_tokenize_lst)\n",
        "            print(sentif['new_entity_1']['text'])\n",
        "            print(xlmr_entity_1_eids)\n",
        "            print(sentif['new_entity_2']['text'])\n",
        "            print(xlmr_entity_2_eids)\n",
        "        \n",
        "\n",
        "        train_xlmr_input_ids.append(copy.deepcopy(xlmr_encode_dict['input_ids']))\n",
        "        train_xlmr_attention_masks.append(copy.deepcopy(xlmr_encode_dict['attention_mask']))\n",
        "        train_xlmr_entity_1_eids.append(copy.deepcopy(xlmr_entity_1_eids))\n",
        "        train_xlmr_entity_2_eids.append(copy.deepcopy(xlmr_entity_2_eids))\n",
        "        #train_xlmr_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "    \n",
        "\n",
        "\n",
        "    if flags['use_phobert'] == True:\n",
        "        # phobert\n",
        "        # lưu ý: phải để phobert ở bên dưới xlmr để những thay đổi bên dưới chỉ ảnh hưởng tới phobert chứ không ảnh hưởng tới XLM-R\n",
        "        # trong các câu chứa các cụm dưới, chả hiểu sao trong phobert '’' khi đứng 1 mình thì encode là 1 wpi bthg \n",
        "        # nhưng đứng trong cụm dưới dưới thì lại thành <unk>\n",
        "        # ta sẽ đổi ’ thành ' thì sẽ k bị lỗi nữa\n",
        "        if ('N’Golo Kante' in sentif['word_tokenize_lst']) or ('Hay’at Tahrir al-Sham' in sentif['word_tokenize_lst']) or ('O’Henry' in sentif['word_tokenize_lst']):\n",
        "            assert (sentif['new_sentence'].count('’') == 1), str('count ’ in new_sentence not equal 1.')\n",
        "\n",
        "            for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n",
        "                if '’' in wtk_item:\n",
        "                    sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "                    break\n",
        "            \n",
        "\n",
        "            sentif['new_sentence'] = sentif['new_sentence'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "            sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "            sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "\n",
        "\n",
        "        \n",
        "        pb_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "\n",
        "        pb_encode_dict = pb_tokenizer(pb_input_sent, add_special_tokens=True, padding='max_length', max_length=192)\n",
        "\n",
        "        pb_tokenize_lst = pb_tokenizer.tokenize(pb_input_sent)\n",
        "        assert ((len(pb_tokenize_lst) + 2) <= 192), str('len pb_tokenize_lst > 192')\n",
        "\n",
        "        pb_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'train')\n",
        "        pb_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'train')\n",
        "\n",
        "        # pad\n",
        "        assert ((len(pb_entity_1_eids) <= max_len_ent_eid) and (len(pb_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n",
        "\n",
        "        pb_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_1_eids))\n",
        "        pb_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_2_eids))\n",
        "        \n",
        "\n",
        "\n",
        "        if isentif < 10:\n",
        "            print('\\n')\n",
        "            print(pb_tokenize_lst)\n",
        "            print(sentif['new_entity_1']['text'])\n",
        "            print(pb_entity_1_eids)\n",
        "            print(sentif['new_entity_2']['text'])\n",
        "            print(pb_entity_2_eids)\n",
        "        \n",
        "\n",
        "\n",
        "        train_pb_input_ids.append(copy.deepcopy(pb_encode_dict['input_ids']))\n",
        "        train_pb_attention_masks.append(copy.deepcopy(pb_encode_dict['attention_mask']))\n",
        "        train_pb_entity_1_eids.append(copy.deepcopy(pb_entity_1_eids))\n",
        "        train_pb_entity_2_eids.append(copy.deepcopy(pb_entity_2_eids))\n",
        "        #train_pb_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "\n",
        "\n",
        "    train_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "['▁Ảnh', '▁minh', '▁họa', '▁Thứ', '▁trưởng', '▁Bộ', '▁GD', '&', 'ĐT', '▁Nguyễn', '▁Thị', '▁Ngh', 'ĩ', 'a', '▁đã', '▁có', '▁ý', '▁kiến', '▁về', '▁vấn', '▁đề', '▁này', '▁', '.']\n",
            "Bộ GD&ĐT\n",
            "[6, 7, 8, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Nguyễn Thị Nghĩa\n",
            "[10, 11, 12, 13, 14, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Ảnh', 'minh_@@', 'họ@@', 'a', 'Thứ_trưởng', 'Bộ', 'GD@@', '&@@', 'ĐT', 'Nguyễn_Thị_Nghĩa', 'đã', 'có', 'ý_kiến', 'về', 'vấn_đề', 'này', '.']\n",
            "Bộ GD&ĐT\n",
            "[6, 7, 8, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Nguyễn Thị Nghĩa\n",
            "[10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Ông', '▁Nguyễn', '▁T', 'ùng', '▁Lâm', '▁S', 'ắ', 'p', '▁tới', '▁', ',', '▁Bộ', '▁GD', '&', 'ĐT', '▁sẽ', '▁tăng', '▁cường', '▁thanh', '▁', ',', '▁kiểm', '▁tra', '▁để', '▁có', '▁biện', '▁pháp', '▁chấn', '▁chỉnh', '▁việc', '▁thực', '▁hiện', '▁quy', '▁định', '▁Điều', '▁lệ', '▁của', '▁Ban', '▁đại', '▁diện', '▁cha', '▁mẹ', '▁học', '▁sinh', '▁', '.']\n",
            "Nguyễn Tùng Lâm\n",
            "[2, 3, 4, 5, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Bộ GD&ĐT\n",
            "[12, 13, 14, 15, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Ông', 'Nguyễn_Tùng_Lâm', 'Sắp', 'tới', ',', 'Bộ_@@', 'GD@@', '&@@', 'ĐT', 'sẽ', 'tăng_cường', 'thanh', ',', 'kiểm_tra', 'để', 'có', 'biện_pháp', 'chấn_chỉnh', 'việc', 'thực_hiện', 'quy_định', 'Điều_lệ', 'của', 'Ban', 'đại_diện', 'cha_mẹ', 'học_sinh', '.']\n",
            "Nguyễn Tùng Lâm\n",
            "[2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Bộ GD&ĐT\n",
            "[6, 7, 8, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁', 'Cũng', '▁theo', '▁Thứ', '▁trưởng', '▁Nguyễn', '▁Thị', '▁Ngh', 'ĩ', 'a', '▁', ',', '▁trước', '▁những', '▁biến', '▁tướng', '▁như', '▁hiện', '▁tại', '▁', ',', '▁Bộ', '▁GD', '&', 'ĐT', '▁nghiên', '▁cứu', '▁có', '▁thể', '▁bỏ', '▁quy', '▁định', '▁này', '▁để', '▁tránh', '▁hiện', '▁tượng', '▁l', 'ách', '▁luật', '▁', '.']\n",
            "Nguyễn Thị Nghĩa\n",
            "[6, 7, 8, 9, 10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Bộ GD&ĐT\n",
            "[22, 23, 24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Cũng', 'theo', 'Thứ_trưởng', 'Nguyễn_Thị_Nghĩa', ',', 'trước', 'những', 'biến_tướng', 'như', 'hiện_tại', ',', 'Bộ_@@', 'GD@@', '&@@', 'ĐT', 'nghiên_cứu', 'có_thể', 'bỏ', 'quy_định', 'này', 'để', 'tránh', 'hiện_tượng', 'lách', 'luật', '.']\n",
            "Nguyễn Thị Nghĩa\n",
            "[4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Bộ GD&ĐT\n",
            "[12, 13, 14, 15, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Liên', '▁quan', '▁đến', '▁vấn', '▁đề', '▁lãnh', '▁đạo', '▁ngành', '▁Giáo', '▁dục', '▁trao', '▁đổi', '▁', ',', '▁thầy', '▁Nguyễn', '▁Văn', '▁Định', '▁–', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Phú', '▁Đ', 'iền', '▁', ',', '▁Đồng', '▁Th', 'áp', '▁–', '▁chia', '▁sẻ', '▁:']\n",
            "Nguyễn Văn Định\n",
            "[16, 17, 18, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Trường THPT Phú Điền\n",
            "[22, 23, 24, 25, 26, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Liên_quan', 'đến', 'vấn_đề', 'lãnh_đạo', 'ngành', 'Giáo_dục', 'trao_đổi', ',', 'thầy', 'Nguyễn_Văn_@@', 'Định', '–', 'Hiệu_trưởng', 'Trường', 'THPT', 'Phú_@@', 'Điền', ',', 'Đồng_Tháp', '–', 'chia_sẻ', ':']\n",
            "Nguyễn Văn Định\n",
            "[10, 11, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Trường THPT Phú Điền\n",
            "[14, 15, 16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Liên', '▁quan', '▁đến', '▁vấn', '▁đề', '▁lãnh', '▁đạo', '▁ngành', '▁Giáo', '▁dục', '▁trao', '▁đổi', '▁', ',', '▁thầy', '▁Nguyễn', '▁Văn', '▁Định', '▁–', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Phú', '▁Đ', 'iền', '▁', ',', '▁Đồng', '▁Th', 'áp', '▁–', '▁chia', '▁sẻ', '▁:']\n",
            "Nguyễn Văn Định\n",
            "[16, 17, 18, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Đồng Tháp\n",
            "[29, 30, 31, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Liên_quan', 'đến', 'vấn_đề', 'lãnh_đạo', 'ngành', 'Giáo_dục', 'trao_đổi', ',', 'thầy', 'Nguyễn_Văn_@@', 'Định', '–', 'Hiệu_trưởng', 'Trường', 'THPT', 'Phú_@@', 'Điền', ',', 'Đồng_Tháp', '–', 'chia_sẻ', ':']\n",
            "Nguyễn Văn Định\n",
            "[10, 11, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Đồng Tháp\n",
            "[19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Liên', '▁quan', '▁đến', '▁vấn', '▁đề', '▁lãnh', '▁đạo', '▁ngành', '▁Giáo', '▁dục', '▁trao', '▁đổi', '▁', ',', '▁thầy', '▁Nguyễn', '▁Văn', '▁Định', '▁–', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Phú', '▁Đ', 'iền', '▁', ',', '▁Đồng', '▁Th', 'áp', '▁–', '▁chia', '▁sẻ', '▁:']\n",
            "Trường THPT Phú Điền\n",
            "[22, 23, 24, 25, 26, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Đồng Tháp\n",
            "[29, 30, 31, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Liên_quan', 'đến', 'vấn_đề', 'lãnh_đạo', 'ngành', 'Giáo_dục', 'trao_đổi', ',', 'thầy', 'Nguyễn_Văn_@@', 'Định', '–', 'Hiệu_trưởng', 'Trường', 'THPT', 'Phú_@@', 'Điền', ',', 'Đồng_Tháp', '–', 'chia_sẻ', ':']\n",
            "Trường THPT Phú Điền\n",
            "[14, 15, 16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Đồng Tháp\n",
            "[19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Nhận', '▁định', '▁ý', '▁tưởng', '▁của', '▁Bộ', '▁GD', '&', 'ĐT', '▁bỏ', '▁quyền', '▁được', '▁thu', '▁tiền', '▁của', '▁Ban', '▁đại', '▁diện', '▁cha', '▁mẹ', '▁học', '▁sinh', '▁vào', '▁thời', '▁điểm', '▁hiện', '▁nay', '▁là', '▁khá', '▁phù', '▁hợp', '▁', ',', '▁thầy', '▁Nguyễn', '▁Văn', '▁Định', '▁đưa', '▁lý', '▁do', '▁:']\n",
            "Bộ GD&ĐT\n",
            "[6, 7, 8, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Nguyễn Văn Định\n",
            "[35, 36, 37, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Nhận_định', 'ý_tưởng', 'của', 'Bộ_@@', 'GD@@', '&@@', 'ĐT', 'bỏ', 'quyền', 'được', 'thu', 'tiền', 'của', 'Ban', 'đại_diện', 'cha_mẹ', 'học_sinh', 'vào', 'thời_điểm', 'hiện_nay', 'là', 'khá', 'phù_hợp', ',', 'thầy', 'Nguyễn_Văn_@@', 'Định', 'đưa', 'lý_do', ':']\n",
            "Bộ GD&ĐT\n",
            "[4, 5, 6, 7, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Nguyễn Văn Định\n",
            "[26, 27, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁', 'Cũng', '▁về', '▁câu', '▁chuyện', '▁lạ', 'm', '▁thu', '▁liên', '▁quan', '▁đến', '▁Ban', '▁đại', '▁diện', '▁cha', '▁mẹ', '▁học', '▁sinh', '▁', ',', '▁TS', '▁Nguyễn', '▁T', 'ùng', '▁Lâm', '▁–', '▁Chủ', '▁tịch', '▁Hội', '▁Tâm', '▁lý', '▁giáo', '▁dục', '▁Hà', '▁Nội', '▁', ',', '▁nguyên', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Đinh', '▁Tiên', '▁Hoàng', '▁(', '▁Hà', '▁Nội', '▁)', '▁–', '▁cho', '▁rằng', '▁:']\n",
            "Nguyễn Tùng Lâm\n",
            "[22, 23, 24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Hội Tâm lý giáo dục Hà Nội\n",
            "[29, 30, 31, 32, 33, 34, 35, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Cũng', 'về', 'câu_chuyện', 'lạm_thu', 'liên_quan', 'đến', 'Ban', 'đại_diện', 'cha_mẹ', 'học_sinh', ',', 'TS', 'Nguyễn_Tùng_Lâm', '–', 'Chủ_tịch', 'Hội', 'Tâm_lý', 'giáo_dục', 'Hà_Nội', ',', 'nguyên', 'Hiệu_trưởng', 'Trường', 'THPT', 'Đinh_Tiên_Hoàng', '(', 'Hà_Nội', ')', '–', 'cho', 'rằng', ':']\n",
            "Nguyễn Tùng Lâm\n",
            "[13, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Hội Tâm lý giáo dục Hà Nội\n",
            "[16, 17, 18, 19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁', 'Cũng', '▁về', '▁câu', '▁chuyện', '▁lạ', 'm', '▁thu', '▁liên', '▁quan', '▁đến', '▁Ban', '▁đại', '▁diện', '▁cha', '▁mẹ', '▁học', '▁sinh', '▁', ',', '▁TS', '▁Nguyễn', '▁T', 'ùng', '▁Lâm', '▁–', '▁Chủ', '▁tịch', '▁Hội', '▁Tâm', '▁lý', '▁giáo', '▁dục', '▁Hà', '▁Nội', '▁', ',', '▁nguyên', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Đinh', '▁Tiên', '▁Hoàng', '▁(', '▁Hà', '▁Nội', '▁)', '▁–', '▁cho', '▁rằng', '▁:']\n",
            "Nguyễn Tùng Lâm\n",
            "[22, 23, 24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Trường THPT Đinh Tiên Hoàng\n",
            "[41, 42, 43, 44, 45, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Cũng', 'về', 'câu_chuyện', 'lạm_thu', 'liên_quan', 'đến', 'Ban', 'đại_diện', 'cha_mẹ', 'học_sinh', ',', 'TS', 'Nguyễn_Tùng_Lâm', '–', 'Chủ_tịch', 'Hội', 'Tâm_lý', 'giáo_dục', 'Hà_Nội', ',', 'nguyên', 'Hiệu_trưởng', 'Trường', 'THPT', 'Đinh_Tiên_Hoàng', '(', 'Hà_Nội', ')', '–', 'cho', 'rằng', ':']\n",
            "Nguyễn Tùng Lâm\n",
            "[13, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Trường THPT Đinh Tiên Hoàng\n",
            "[23, 24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁', 'Cũng', '▁về', '▁câu', '▁chuyện', '▁lạ', 'm', '▁thu', '▁liên', '▁quan', '▁đến', '▁Ban', '▁đại', '▁diện', '▁cha', '▁mẹ', '▁học', '▁sinh', '▁', ',', '▁TS', '▁Nguyễn', '▁T', 'ùng', '▁Lâm', '▁–', '▁Chủ', '▁tịch', '▁Hội', '▁Tâm', '▁lý', '▁giáo', '▁dục', '▁Hà', '▁Nội', '▁', ',', '▁nguyên', '▁Hiệu', '▁trưởng', '▁Trường', '▁THPT', '▁Đinh', '▁Tiên', '▁Hoàng', '▁(', '▁Hà', '▁Nội', '▁)', '▁–', '▁cho', '▁rằng', '▁:']\n",
            "Nguyễn Tùng Lâm\n",
            "[22, 23, 24, 25, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Hà Nội\n",
            "[47, 48, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Cũng', 'về', 'câu_chuyện', 'lạm_thu', 'liên_quan', 'đến', 'Ban', 'đại_diện', 'cha_mẹ', 'học_sinh', ',', 'TS', 'Nguyễn_Tùng_Lâm', '–', 'Chủ_tịch', 'Hội', 'Tâm_lý', 'giáo_dục', 'Hà_Nội', ',', 'nguyên', 'Hiệu_trưởng', 'Trường', 'THPT', 'Đinh_Tiên_Hoàng', '(', 'Hà_Nội', ')', '–', 'cho', 'rằng', ':']\n",
            "Nguyễn Tùng Lâm\n",
            "[13, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Hà Nội\n",
            "[27, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "-----SKIP 1726-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-yzwOtCqi13",
        "outputId": "71fb7e29-0371-4e8f-be8e-ed8c537743d0"
      },
      "source": [
        "# convert to tensor\n",
        "\n",
        "pad_eid = -2\n",
        "\n",
        "if flags['use_phobert'] == True:\n",
        "    train_pb_input_ids = torch.tensor(train_pb_input_ids)\n",
        "    train_pb_attention_masks = torch.tensor(train_pb_attention_masks)\n",
        "    train_pb_entity_1_eids = torch.tensor(train_pb_entity_1_eids)\n",
        "    train_pb_entity_2_eids = torch.tensor(train_pb_entity_2_eids)\n",
        "    #train_pb_labels = torch.tensor(train_pb_labels)\n",
        "\n",
        "\n",
        "if flags['use_xlmr'] == True:\n",
        "    train_xlmr_input_ids = torch.tensor(train_xlmr_input_ids)\n",
        "    train_xlmr_attention_masks = torch.tensor(train_xlmr_attention_masks)\n",
        "    train_xlmr_entity_1_eids = torch.tensor(train_xlmr_entity_1_eids)\n",
        "    train_xlmr_entity_2_eids = torch.tensor(train_xlmr_entity_2_eids)\n",
        "    #train_xlmr_labels = torch.tensor(train_xlmr_labels)\n",
        "\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "\n",
        "print('DONE')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQnGMcvkDajP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6fd734-75f0-4727-9d59-0794d8c7e8b3"
      },
      "source": [
        "'''\n",
        "if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, \\\n",
        "                                  train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, \\\n",
        "                                  train_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, train_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "    train_dataset = TensorDataset(train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, train_labels)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\\n    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids,                                   train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids,                                   train_labels)\\n\\nelif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\\n    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, train_labels)\\n\\nelif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\\n    train_dataset = TensorDataset(train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, train_labels)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYAF_MORQfQi"
      },
      "source": [
        "#train_dataloader = DataLoader(train_dataset, batch_size=flags['batch_size'], shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBh9YcvMeghQ"
      },
      "source": [
        "### dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFWd_-BreghQ"
      },
      "source": [
        "##### Add entity index and word_tokenize to traindata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFcVY6keghQ",
        "outputId": "067cdbd8-86da-4c47-bf76-08fa733350ca"
      },
      "source": [
        "# sẽ in ra việc những câu mà underthesea word_tokenize bị thay đổi cho đúng với entity_text\n",
        "jdev_data_v3 = copy.deepcopy(add_word_tokenize_and_entity_index(jdev_data_v2, 'dev', print_output=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4714\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [115, 138]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[95, 114]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [23]\n",
            "[143, 152]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4715\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [115, 138]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[95, 114]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [185, 210]}\n",
            "entity index list:  [24, 25, 26]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4716\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [115, 138]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[95, 114]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4717\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [115, 138]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[95, 114]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4718\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [115, 138]}\n",
            "entity index list:  [14, 15, 16]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[95, 114]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4719\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [22]\n",
            "[143, 152]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4720\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [185, 210]}\n",
            "entity index list:  [23, 24, 25]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4724\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[143, 152]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4725\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[143, 152]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4726\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[143, 152]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4727\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [175, 184]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[143, 152]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4728\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [185, 210]}\n",
            "entity index list:  [23, 24, 25]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "[152, 173]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4729\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [185, 210]}\n",
            "entity index list:  [23, 24, 25]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "[152, 173]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4730\n",
            "sentence:  Nguyễn Việt Hà (nguyên Giám đốc Oceanbank chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên Giám đốc Oceanbank Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên Giám đốc Oceanbank Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên Giám đốc Oceanbank chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [185, 210]}\n",
            "entity index list:  [23, 24, 25]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "[152, 173]\n",
            "Underthesea word_tokenize:  ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Nguyễn Việt Hà', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'Giám đốc', 'Oceanbank Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'Giám đốc', 'Oceanbank', 'chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  4886\n",
            "sentence:  Năm 2015 đánh dấu sự chuyển mình trong âm nhạc khi Soobin Hoàng Sơn quyết định Nam tiến để phát triển niềm đam mê của mình.\n",
            "\n",
            "entity:  {'text': 'Nam', 'pos': [79, 82]}\n",
            "entity index list:  [11]\n",
            "[63, 66]\n",
            "['Nam']\n",
            "My word_tokenize 1:         ['Năm', '2015', 'đánh dấu', 'sự', 'chuyển mình', 'trong', 'âm nhạc', 'khi', 'Soobin', 'Hoàng Sơn', 'quyết định', 'Nam tiến', 'để', 'phát triển', 'niềm', 'đam mê', 'của', 'mình', '.']\n",
            "My word_tokenize 2:         ['Năm', '2015', 'đánh dấu', 'sự', 'chuyển mình', 'trong', 'âm nhạc', 'khi', 'Soobin', 'Hoàng Sơn', 'quyết định', 'Nam', 'tiến', 'để', 'phát triển', 'niềm', 'đam mê', 'của', 'mình', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5081\n",
            "sentence:  Thủ tướng New Zealand Bill English (trái) trong chiến dịch vận động tranh cử ở Wellington ngày 15/9.\n",
            "\n",
            "entity:  {'text': 'New Zealand', 'pos': [10, 21]}\n",
            "entity index list:  [1]\n",
            "['New Zealand']\n",
            "[8, 18]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'New Zealand Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'New Zealand', 'Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5082\n",
            "sentence:  Thủ tướng New Zealand Bill English (trái) trong chiến dịch vận động tranh cử ở Wellington ngày 15/9.\n",
            "\n",
            "entity:  {'text': 'New Zealand', 'pos': [10, 21]}\n",
            "entity index list:  [1]\n",
            "['New Zealand']\n",
            "[8, 18]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'New Zealand Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'New Zealand', 'Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5083\n",
            "sentence:  Thủ tướng New Zealand Bill English (trái) trong chiến dịch vận động tranh cử ở Wellington ngày 15/9.\n",
            "\n",
            "entity:  {'text': 'Bill English', 'pos': [22, 34]}\n",
            "entity index list:  [2]\n",
            "['Bill English']\n",
            "[18, 29]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'New Zealand Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'New Zealand', 'Bill English', '(', 'trái', ')', 'trong', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Wellington', 'ngày', '15/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5086\n",
            "sentence:  AFP /TTXVN Bộ phận Dự báo bầu cử của báo New Zealand Herald , chuyên phân tích dữ liệu từ tất cả các cuộc thăm dò chính tiến hành cả năm qua và dự báo kết quả các cuộc bầu cử từ năm 1999, dự đoán đảng Quốc gia sẽ giành được 56 ghế trong Quốc hội nhiệm kỳ mới, trong khi Liên minh Công đảng -đảng Xanh sẽ giành được 54 ghế.\n",
            "\n",
            "entity:  {'text': 'Công đảng', 'pos': [280, 289]}\n",
            "entity index list:  [48]\n",
            "[216, 224]\n",
            "['Công đảng']\n",
            "My word_tokenize 1:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "My word_tokenize 2:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh', 'Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5089\n",
            "sentence:  AFP /TTXVN Bộ phận Dự báo bầu cử của báo New Zealand Herald , chuyên phân tích dữ liệu từ tất cả các cuộc thăm dò chính tiến hành cả năm qua và dự báo kết quả các cuộc bầu cử từ năm 1999, dự đoán đảng Quốc gia sẽ giành được 56 ghế trong Quốc hội nhiệm kỳ mới, trong khi Liên minh Công đảng -đảng Xanh sẽ giành được 54 ghế.\n",
            "\n",
            "entity:  {'text': 'Công đảng', 'pos': [280, 289]}\n",
            "entity index list:  [48]\n",
            "[216, 224]\n",
            "['Công đảng']\n",
            "My word_tokenize 1:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "My word_tokenize 2:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh', 'Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5091\n",
            "sentence:  AFP /TTXVN Bộ phận Dự báo bầu cử của báo New Zealand Herald , chuyên phân tích dữ liệu từ tất cả các cuộc thăm dò chính tiến hành cả năm qua và dự báo kết quả các cuộc bầu cử từ năm 1999, dự đoán đảng Quốc gia sẽ giành được 56 ghế trong Quốc hội nhiệm kỳ mới, trong khi Liên minh Công đảng -đảng Xanh sẽ giành được 54 ghế.\n",
            "\n",
            "entity:  {'text': 'Công đảng', 'pos': [280, 289]}\n",
            "entity index list:  [48]\n",
            "[216, 224]\n",
            "['Công đảng']\n",
            "My word_tokenize 1:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "My word_tokenize 2:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh', 'Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5093\n",
            "sentence:  AFP /TTXVN Bộ phận Dự báo bầu cử của báo New Zealand Herald , chuyên phân tích dữ liệu từ tất cả các cuộc thăm dò chính tiến hành cả năm qua và dự báo kết quả các cuộc bầu cử từ năm 1999, dự đoán đảng Quốc gia sẽ giành được 56 ghế trong Quốc hội nhiệm kỳ mới, trong khi Liên minh Công đảng -đảng Xanh sẽ giành được 54 ghế.\n",
            "\n",
            "entity:  {'text': 'Công đảng', 'pos': [280, 289]}\n",
            "entity index list:  [48]\n",
            "['Công đảng']\n",
            "[216, 224]\n",
            "Underthesea word_tokenize:  ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "My word_tokenize 1:         ['AFP', '/', 'TTXVN', 'Bộ phận', 'Dự báo', 'bầu cử', 'của', 'báo', 'New Zealand Herald', ',', 'chuyên', 'phân tích', 'dữ liệu', 'từ', 'tất cả', 'các', 'cuộc', 'thăm dò', 'chính', 'tiến hành', 'cả', 'năm', 'qua', 'và', 'dự báo', 'kết quả', 'các', 'cuộc', 'bầu cử', 'từ', 'năm', '1999', ',', 'dự đoán', 'đảng Quốc gia', 'sẽ', 'giành', 'được', '56', 'ghế', 'trong', 'Quốc hội', 'nhiệm kỳ', 'mới', ',', 'trong', 'khi', 'Liên minh', 'Công đảng', '-', 'đảng Xanh', 'sẽ', 'giành', 'được', '54', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5141\n",
            "sentence:  Hiện các đối tượng cùng tang vật đã được Đội CSGT số 2 bàn giao cho cơ quan Cảnh sát điều tra Công an TP.Thanh Hóa để tiếp tục xử lý.\n",
            "\n",
            "entity:  {'text': 'Công an TP.Thanh Hóa', 'pos': [94, 114]}\n",
            "entity index list:  [16, 17]\n",
            "[72, 89]\n",
            "['Công an', 'TP.Thanh Hóa']\n",
            "My word_tokenize 1:         ['Hiện', 'các', 'đối tượng', 'cùng', 'tang vật', 'đã', 'được', 'Đội', 'CSGT', 'số', '2', 'bàn giao', 'cho', 'cơ quan', 'Cảnh sát', 'điều tra', 'Công an', 'TP.Thanh Hóa để', 'tiếp tục', 'xử lý', '.']\n",
            "My word_tokenize 2:         ['Hiện', 'các', 'đối tượng', 'cùng', 'tang vật', 'đã', 'được', 'Đội', 'CSGT', 'số', '2', 'bàn giao', 'cho', 'cơ quan', 'Cảnh sát', 'điều tra', 'Công an', 'TP.Thanh Hóa', 'để', 'tiếp tục', 'xử lý', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5158\n",
            "sentence:  Sáng nay (22/9), tại Bali (Indonesia ) đã diễn ra Lễ bốc thăm chia bảng giải Futsal HDBank vô địch Đông Nam Á 2017.\n",
            "\n",
            "entity:  {'text': 'HDBank', 'pos': [84, 90]}\n",
            "entity index list:  [21]\n",
            "[67, 73]\n",
            "['HDBank']\n",
            "My word_tokenize 1:         ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "My word_tokenize 2:         ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal', 'HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5160\n",
            "sentence:  Sáng nay (22/9), tại Bali (Indonesia ) đã diễn ra Lễ bốc thăm chia bảng giải Futsal HDBank vô địch Đông Nam Á 2017.\n",
            "\n",
            "entity:  {'text': 'HDBank', 'pos': [84, 90]}\n",
            "entity index list:  [21]\n",
            "[67, 73]\n",
            "['HDBank']\n",
            "My word_tokenize 1:         ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "My word_tokenize 2:         ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal', 'HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5162\n",
            "sentence:  Sáng nay (22/9), tại Bali (Indonesia ) đã diễn ra Lễ bốc thăm chia bảng giải Futsal HDBank vô địch Đông Nam Á 2017.\n",
            "\n",
            "entity:  {'text': 'HDBank', 'pos': [84, 90]}\n",
            "entity index list:  [21]\n",
            "['HDBank']\n",
            "[67, 73]\n",
            "Underthesea word_tokenize:  ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "My word_tokenize 1:         ['Sáng', 'nay', '(', '22/9', ')', ',', 'tại', 'Bali', '(', 'Indonesia', ')', 'đã', 'diễn', 'ra', 'Lễ', 'bốc', 'thăm', 'chia', 'bảng', 'giải', 'Futsal', 'HDBank', 'vô địch', 'Đông Nam Á', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5201\n",
            "sentence:  U.16 Việt Nam đại thắng U.16 Mông Cổ 9-0 Được đánh giá cao hơn đối thủ nên U.16 Việt Nam không mấy khó khăn để giành chiến thắng áp đảo trước đội chủ nhà Mông Cổ .\n",
            "\n",
            "entity:  {'text': 'U.16 Mông Cổ', 'pos': [24, 36]}\n",
            "entity index list:  [4, 5, 6]\n",
            "[19, 29]\n",
            "['U.', '16', 'Mông Cổ']\n",
            "My word_tokenize 1:         ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ 9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "My word_tokenize 2:         ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ', '9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5204\n",
            "sentence:  U.16 Việt Nam đại thắng U.16 Mông Cổ 9-0 Được đánh giá cao hơn đối thủ nên U.16 Việt Nam không mấy khó khăn để giành chiến thắng áp đảo trước đội chủ nhà Mông Cổ .\n",
            "\n",
            "entity:  {'text': 'U.16 Mông Cổ', 'pos': [24, 36]}\n",
            "entity index list:  [4, 5, 6]\n",
            "['U.', '16', 'Mông Cổ']\n",
            "[19, 29]\n",
            "Underthesea word_tokenize:  ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ 9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "My word_tokenize 1:         ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ', '9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5205\n",
            "sentence:  U.16 Việt Nam đại thắng U.16 Mông Cổ 9-0 Được đánh giá cao hơn đối thủ nên U.16 Việt Nam không mấy khó khăn để giành chiến thắng áp đảo trước đội chủ nhà Mông Cổ .\n",
            "\n",
            "entity:  {'text': 'U.16 Mông Cổ', 'pos': [24, 36]}\n",
            "entity index list:  [4, 5, 6]\n",
            "['U.', '16', 'Mông Cổ']\n",
            "[19, 29]\n",
            "Underthesea word_tokenize:  ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ 9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "My word_tokenize 1:         ['U.', '16', 'Việt Nam', 'đại thắng', 'U.', '16', 'Mông Cổ', '9-0 Được', 'đánh giá', 'cao', 'hơn', 'đối thủ', 'nên', 'U.', '16', 'Việt Nam', 'không', 'mấy', 'khó khăn', 'để', 'giành', 'chiến thắng', 'áp đảo', 'trước', 'đội', 'chủ', 'nhà', 'Mông Cổ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5306\n",
            "sentence:  Người mẫu Brazil sở hữu thân hình xinh như ngọc Fabiana Semprebom sinh ngày 26/05/1984 tại Londrina , Parana , Brazil .\n",
            "\n",
            "entity:  {'text': 'Fabiana Semprebom', 'pos': [48, 65]}\n",
            "entity index list:  [7]\n",
            "[38, 54]\n",
            "['Fabiana Semprebom']\n",
            "My word_tokenize 1:         ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "My word_tokenize 2:         ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom', 'sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5310\n",
            "sentence:  Người mẫu Brazil sở hữu thân hình xinh như ngọc Fabiana Semprebom sinh ngày 26/05/1984 tại Londrina , Parana , Brazil .\n",
            "\n",
            "entity:  {'text': 'Fabiana Semprebom', 'pos': [48, 65]}\n",
            "entity index list:  [7]\n",
            "['Fabiana Semprebom']\n",
            "[38, 54]\n",
            "Underthesea word_tokenize:  ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "My word_tokenize 1:         ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom', 'sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5311\n",
            "sentence:  Người mẫu Brazil sở hữu thân hình xinh như ngọc Fabiana Semprebom sinh ngày 26/05/1984 tại Londrina , Parana , Brazil .\n",
            "\n",
            "entity:  {'text': 'Fabiana Semprebom', 'pos': [48, 65]}\n",
            "entity index list:  [7]\n",
            "['Fabiana Semprebom']\n",
            "[38, 54]\n",
            "Underthesea word_tokenize:  ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "My word_tokenize 1:         ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom', 'sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5312\n",
            "sentence:  Người mẫu Brazil sở hữu thân hình xinh như ngọc Fabiana Semprebom sinh ngày 26/05/1984 tại Londrina , Parana , Brazil .\n",
            "\n",
            "entity:  {'text': 'Fabiana Semprebom', 'pos': [48, 65]}\n",
            "entity index list:  [7]\n",
            "['Fabiana Semprebom']\n",
            "[38, 54]\n",
            "Underthesea word_tokenize:  ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "My word_tokenize 1:         ['Người mẫu', 'Brazil', 'sở hữu', 'thân hình', 'xinh', 'như', 'ngọc', 'Fabiana Semprebom', 'sinh', 'ngày', '26/05/1984', 'tại', 'Londrina', ',', 'Parana', ',', 'Brazil', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5351\n",
            "sentence:  Nhà lãnh đạo Kim Jong-un thị sát Viện dưỡng lão mới được xây dựng ở Bình Nhưỡng .\n",
            "\n",
            "entity:  {'text': 'Kim Jong-un', 'pos': [13, 24]}\n",
            "entity index list:  [2]\n",
            "['Kim Jong-un']\n",
            "[10, 20]\n",
            "Underthesea word_tokenize:  ['Nhà', 'lãnh đạo', 'Kim Jong-un thị sát', 'Viện', 'dưỡng lão', 'mới', 'được', 'xây dựng', 'ở', 'Bình', 'Nhưỡng', '.']\n",
            "My word_tokenize 1:         ['Nhà', 'lãnh đạo', 'Kim Jong-un', 'thị sát', 'Viện', 'dưỡng lão', 'mới', 'được', 'xây dựng', 'ở', 'Bình', 'Nhưỡng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5352\n",
            "sentence:  Nhà lãnh đạo Kim Jong-un thị sát Viện dưỡng lão mới được xây dựng ở Bình Nhưỡng .\n",
            "\n",
            "entity:  {'text': 'Kim Jong-un', 'pos': [13, 24]}\n",
            "entity index list:  [2]\n",
            "['Kim Jong-un']\n",
            "[10, 20]\n",
            "Underthesea word_tokenize:  ['Nhà', 'lãnh đạo', 'Kim Jong-un thị sát', 'Viện', 'dưỡng lão', 'mới', 'được', 'xây dựng', 'ở', 'Bình', 'Nhưỡng', '.']\n",
            "My word_tokenize 1:         ['Nhà', 'lãnh đạo', 'Kim Jong-un', 'thị sát', 'Viện', 'dưỡng lão', 'mới', 'được', 'xây dựng', 'ở', 'Bình', 'Nhưỡng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5358\n",
            "sentence:  Lãnh đạo Kim Jong-un vẫy chào các phi công của quân đội Triều Tiên trên núi Paektu phủ đầy tuyết trắng.\n",
            "\n",
            "entity:  {'text': 'Kim Jong-un', 'pos': [9, 20]}\n",
            "entity index list:  [1]\n",
            "['Kim Jong-un']\n",
            "[7, 17]\n",
            "Underthesea word_tokenize:  ['Lãnh đạo', 'Kim Jong-un vẫy', 'chào', 'các', 'phi công', 'của', 'quân đội', 'Triều Tiên', 'trên', 'núi', 'Paektu', 'phủ', 'đầy', 'tuyết', 'trắng', '.']\n",
            "My word_tokenize 1:         ['Lãnh đạo', 'Kim Jong-un', 'vẫy', 'chào', 'các', 'phi công', 'của', 'quân đội', 'Triều Tiên', 'trên', 'núi', 'Paektu', 'phủ', 'đầy', 'tuyết', 'trắng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5359\n",
            "sentence:  Lãnh đạo Kim Jong-un vẫy chào các phi công của quân đội Triều Tiên trên núi Paektu phủ đầy tuyết trắng.\n",
            "\n",
            "entity:  {'text': 'Kim Jong-un', 'pos': [9, 20]}\n",
            "entity index list:  [1]\n",
            "['Kim Jong-un']\n",
            "[7, 17]\n",
            "Underthesea word_tokenize:  ['Lãnh đạo', 'Kim Jong-un vẫy', 'chào', 'các', 'phi công', 'của', 'quân đội', 'Triều Tiên', 'trên', 'núi', 'Paektu', 'phủ', 'đầy', 'tuyết', 'trắng', '.']\n",
            "My word_tokenize 1:         ['Lãnh đạo', 'Kim Jong-un', 'vẫy', 'chào', 'các', 'phi công', 'của', 'quân đội', 'Triều Tiên', 'trên', 'núi', 'Paektu', 'phủ', 'đầy', 'tuyết', 'trắng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5379\n",
            "sentence:  Chẳng hạn, khi khách hàng sử dụng số di động của mạng Viettel hiện nay là 098w460xxx, 097w460xxx, 096w460xx mà muốn chuyển sang mạng của VinaPhone sẽ được giữ nguyên 098w460xxx, 097w460xxx, 096w460xx.\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [54, 61]}\n",
            "entity index list:  [9]\n",
            "['Viettel']\n",
            "[42, 49]\n",
            "Underthesea word_tokenize:  ['Chẳng hạn', ',', 'khi', 'khách hàng', 'sử dụng', 'số', 'di động', 'của', 'mạng Viettel', 'hiện nay', 'là', '098', 'w460xxx', ',', '097', 'w460xxx', ',', '096', 'w460xx', 'mà', 'muốn', 'chuyển', 'sang', 'mạng', 'của', 'VinaPhone', 'sẽ', 'được', 'giữ', 'nguyên', '098', 'w460xxx', ',', '097', 'w460xxx', ',', '096', 'w460xx', '.']\n",
            "My word_tokenize 1:         ['Chẳng hạn', ',', 'khi', 'khách hàng', 'sử dụng', 'số', 'di động', 'của', 'mạng', 'Viettel', 'hiện nay', 'là', '098', 'w460xxx', ',', '097', 'w460xxx', ',', '096', 'w460xx', 'mà', 'muốn', 'chuyển', 'sang', 'mạng', 'của', 'VinaPhone', 'sẽ', 'được', 'giữ', 'nguyên', '098', 'w460xxx', ',', '097', 'w460xxx', ',', '096', 'w460xx', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5380\n",
            "sentence:  Thuê bao của mạng MobiFone đang sử dụng là 090w460xxx, 093w460xxx muốn chuyển sang mạng Viettel thì được giữ nguyên tất cả các số là 090w460xxx, 093w460xxx.\n",
            "\n",
            "entity:  {'text': 'MobiFone', 'pos': [18, 26]}\n",
            "entity index list:  [3]\n",
            "['MobiFone']\n",
            "[14, 22]\n",
            "Underthesea word_tokenize:  ['Thuê bao', 'của', 'mạng MobiFone', 'đang', 'sử dụng', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', 'muốn', 'chuyển', 'sang', 'mạng Viettel', 'thì', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', '.']\n",
            "My word_tokenize 1:         ['Thuê bao', 'của', 'mạng', 'MobiFone', 'đang', 'sử dụng', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', 'muốn', 'chuyển', 'sang', 'mạng Viettel', 'thì', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', '.']\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [88, 95]}\n",
            "entity index list:  [16]\n",
            "[73, 80]\n",
            "['Viettel']\n",
            "My word_tokenize 1:         ['Thuê bao', 'của', 'mạng', 'MobiFone', 'đang', 'sử dụng', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', 'muốn', 'chuyển', 'sang', 'mạng Viettel', 'thì', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', '.']\n",
            "My word_tokenize 2:         ['Thuê bao', 'của', 'mạng', 'MobiFone', 'đang', 'sử dụng', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', 'muốn', 'chuyển', 'sang', 'mạng', 'Viettel', 'thì', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', 'là', '090', 'w460xxx', ',', '093', 'w460xxx', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5381\n",
            "sentence:  Hoặc thuê bao VinaPhone là 091w460xxx, 094w460xxxx muốn chuyển sang mạng Viettel sẽ được giữ nguyên tất cả các số 091w460xxx, 094w460xxxx.\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [73, 80]}\n",
            "entity index list:  [13]\n",
            "[62, 69]\n",
            "['Viettel']\n",
            "My word_tokenize 1:         ['Hoặc', 'thuê bao', 'VinaPhone', 'là', '091', 'w460xxx', ',', '094', 'w460xxxx', 'muốn', 'chuyển', 'sang', 'mạng Viettel', 'sẽ', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', '091', 'w460xxx', ',', '094', 'w460xxxx', '.']\n",
            "My word_tokenize 2:         ['Hoặc', 'thuê bao', 'VinaPhone', 'là', '091', 'w460xxx', ',', '094', 'w460xxxx', 'muốn', 'chuyển', 'sang', 'mạng', 'Viettel', 'sẽ', 'được', 'giữ', 'nguyên', 'tất cả', 'các', 'số', '091', 'w460xxx', ',', '094', 'w460xxxx', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5382\n",
            "sentence:  Ví dụ khi đó không còn định danh đầu số 098, 097, 096 là của mạng Viettel ; 091, 094 là của VinaPhone và 093, 090 thuộc sở hữu của MobiFone .\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [66, 73]}\n",
            "entity index list:  [16]\n",
            "['Viettel']\n",
            "[50, 57]\n",
            "Underthesea word_tokenize:  ['Ví dụ', 'khi', 'đó', 'không', 'còn', 'định danh', 'đầu', 'số', '098', ',', '097', ',', '096', 'là', 'của', 'mạng Viettel', ';', '091', ',', '094', 'là', 'của', 'VinaPhone', 'và', '093', ',', '090', 'thuộc', 'sở hữu', 'của', 'MobiFone', '.']\n",
            "My word_tokenize 1:         ['Ví dụ', 'khi', 'đó', 'không', 'còn', 'định danh', 'đầu', 'số', '098', ',', '097', ',', '096', 'là', 'của', 'mạng', 'Viettel', ';', '091', ',', '094', 'là', 'của', 'VinaPhone', 'và', '093', ',', '090', 'thuộc', 'sở hữu', 'của', 'MobiFone', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5383\n",
            "sentence:  Ví dụ khi đó không còn định danh đầu số 098, 097, 096 là của mạng Viettel ; 091, 094 là của VinaPhone và 093, 090 thuộc sở hữu của MobiFone .\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [66, 73]}\n",
            "entity index list:  [16]\n",
            "['Viettel']\n",
            "[50, 57]\n",
            "Underthesea word_tokenize:  ['Ví dụ', 'khi', 'đó', 'không', 'còn', 'định danh', 'đầu', 'số', '098', ',', '097', ',', '096', 'là', 'của', 'mạng Viettel', ';', '091', ',', '094', 'là', 'của', 'VinaPhone', 'và', '093', ',', '090', 'thuộc', 'sở hữu', 'của', 'MobiFone', '.']\n",
            "My word_tokenize 1:         ['Ví dụ', 'khi', 'đó', 'không', 'còn', 'định danh', 'đầu', 'số', '098', ',', '097', ',', '096', 'là', 'của', 'mạng', 'Viettel', ';', '091', ',', '094', 'là', 'của', 'VinaPhone', 'và', '093', ',', '090', 'thuộc', 'sở hữu', 'của', 'MobiFone', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5404\n",
            "sentence:  Không khởi tố hình sự vụ giám đốc doanh nghiệp hành hung bác sĩ NGHỆ AN - Cơ quan CSĐT CA tỉnh Nghệ An vừa có kết luận:\n",
            "\n",
            "entity:  {'text': 'CA tỉnh Nghệ An', 'pos': [87, 102]}\n",
            "entity index list:  [11, 12, 13]\n",
            "[67, 79]\n",
            "['CA', 'tỉnh', 'Nghệ An']\n",
            "My word_tokenize 1:         ['Không', 'khởi tố', 'hình sự vụ', 'giám đốc', 'doanh nghiệp', 'hành hung', 'bác sĩ', 'NGHỆ AN', '-', 'Cơ quan', 'CSĐT CA', 'tỉnh', 'Nghệ An', 'vừa', 'có', 'kết luận', ':']\n",
            "My word_tokenize 2:         ['Không', 'khởi tố', 'hình sự vụ', 'giám đốc', 'doanh nghiệp', 'hành hung', 'bác sĩ', 'NGHỆ AN', '-', 'Cơ quan', 'CSĐT', 'CA', 'tỉnh', 'Nghệ An', 'vừa', 'có', 'kết luận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  5405\n",
            "sentence:  NGHỆ AN - Cơ quan CSĐT CA tỉnh Nghệ An vừa có kết luận:\n",
            "\n",
            "entity:  {'text': 'CA tỉnh Nghệ An', 'pos': [23, 38]}\n",
            "entity index list:  [4, 5, 6]\n",
            "[17, 29]\n",
            "['CA', 'tỉnh', 'Nghệ An']\n",
            "My word_tokenize 1:         ['NGHỆ AN', '-', 'Cơ quan', 'CSĐT CA', 'tỉnh', 'Nghệ An', 'vừa', 'có', 'kết luận', ':']\n",
            "My word_tokenize 2:         ['NGHỆ AN', '-', 'Cơ quan', 'CSĐT', 'CA', 'tỉnh', 'Nghệ An', 'vừa', 'có', 'kết luận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  5452\n",
            "sentence:  Hiện cơ quan CSĐT CA tỉnh Nghệ An đã chuyển toàn bộ hồ sơ vụ việc đến CATP Vinh để xử lý vi phạm hành chính đối với ông Nguyễn Đình Hoàng Thắng và ông Nguyễn Xuân Huân .\n",
            "\n",
            "entity:  {'text': 'CA tỉnh Nghệ An', 'pos': [18, 33]}\n",
            "entity index list:  [3, 4, 5]\n",
            "['CA', 'tỉnh', 'Nghệ An']\n",
            "[14, 26]\n",
            "Underthesea word_tokenize:  ['Hiện', 'cơ quan', 'CSĐT CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "My word_tokenize 1:         ['Hiện', 'cơ quan', 'CSĐT', 'CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5453\n",
            "sentence:  Hiện cơ quan CSĐT CA tỉnh Nghệ An đã chuyển toàn bộ hồ sơ vụ việc đến CATP Vinh để xử lý vi phạm hành chính đối với ông Nguyễn Đình Hoàng Thắng và ông Nguyễn Xuân Huân .\n",
            "\n",
            "entity:  {'text': 'CA tỉnh Nghệ An', 'pos': [18, 33]}\n",
            "entity index list:  [3, 4, 5]\n",
            "['CA', 'tỉnh', 'Nghệ An']\n",
            "[14, 26]\n",
            "Underthesea word_tokenize:  ['Hiện', 'cơ quan', 'CSĐT CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "My word_tokenize 1:         ['Hiện', 'cơ quan', 'CSĐT', 'CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5454\n",
            "sentence:  Hiện cơ quan CSĐT CA tỉnh Nghệ An đã chuyển toàn bộ hồ sơ vụ việc đến CATP Vinh để xử lý vi phạm hành chính đối với ông Nguyễn Đình Hoàng Thắng và ông Nguyễn Xuân Huân .\n",
            "\n",
            "entity:  {'text': 'CA tỉnh Nghệ An', 'pos': [18, 33]}\n",
            "entity index list:  [3, 4, 5]\n",
            "['CA', 'tỉnh', 'Nghệ An']\n",
            "[14, 26]\n",
            "Underthesea word_tokenize:  ['Hiện', 'cơ quan', 'CSĐT CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "My word_tokenize 1:         ['Hiện', 'cơ quan', 'CSĐT', 'CA', 'tỉnh', 'Nghệ An', 'đã', 'chuyển', 'toàn bộ', 'hồ sơ', 'vụ việc', 'đến', 'CATP Vinh', 'để', 'xử lý', 'vi phạm', 'hành chính', 'đối với', 'ông', 'Nguyễn Đình Hoàng Thắng', 'và', 'ông', 'Nguyễn Xuân Huân', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5486\n",
            "sentence:  Chủ tịch nước mong muốn, cùng với việc tổ chức các hoạt động kỷ niệm 50 năm thành lập, quá trình hội nhập cũng như nỗ lực xây dựng cộng đồng chung và bản sắc chung của ASEAN , Hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ các quốc gia cũng như Hiệp hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ quốc tế và Uỷ ban Chữ thập Đỏ quốc tế cần quan tâm, đóng góp vào việc xây dựng Cộng đồng ASEAN với 3 trụ cột chính là Cộng đồng Chính trị-An ninh, Cộng đồng Kinh tế và Cộng đồng Văn hóa Xã hội.\n",
            "\n",
            "entity:  {'text': 'ASEAN', 'pos': [368, 373]}\n",
            "entity index list:  [55]\n",
            "[284, 289]\n",
            "['ASEAN']\n",
            "My word_tokenize 1:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "My word_tokenize 2:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng', 'ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5488\n",
            "sentence:  Chủ tịch nước mong muốn, cùng với việc tổ chức các hoạt động kỷ niệm 50 năm thành lập, quá trình hội nhập cũng như nỗ lực xây dựng cộng đồng chung và bản sắc chung của ASEAN , Hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ các quốc gia cũng như Hiệp hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ quốc tế và Uỷ ban Chữ thập Đỏ quốc tế cần quan tâm, đóng góp vào việc xây dựng Cộng đồng ASEAN với 3 trụ cột chính là Cộng đồng Chính trị-An ninh, Cộng đồng Kinh tế và Cộng đồng Văn hóa Xã hội.\n",
            "\n",
            "entity:  {'text': 'ASEAN', 'pos': [368, 373]}\n",
            "entity index list:  [55]\n",
            "[284, 289]\n",
            "['ASEAN']\n",
            "My word_tokenize 1:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "My word_tokenize 2:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng', 'ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5489\n",
            "sentence:  Chủ tịch nước mong muốn, cùng với việc tổ chức các hoạt động kỷ niệm 50 năm thành lập, quá trình hội nhập cũng như nỗ lực xây dựng cộng đồng chung và bản sắc chung của ASEAN , Hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ các quốc gia cũng như Hiệp hội Chữ thập Đỏ và Trăng lưỡi liềm Đỏ quốc tế và Uỷ ban Chữ thập Đỏ quốc tế cần quan tâm, đóng góp vào việc xây dựng Cộng đồng ASEAN với 3 trụ cột chính là Cộng đồng Chính trị-An ninh, Cộng đồng Kinh tế và Cộng đồng Văn hóa Xã hội.\n",
            "\n",
            "entity:  {'text': 'ASEAN', 'pos': [368, 373]}\n",
            "entity index list:  [55]\n",
            "[284, 289]\n",
            "['ASEAN']\n",
            "My word_tokenize 1:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "My word_tokenize 2:         ['Chủ tịch', 'nước', 'mong muốn', ',', 'cùng', 'với', 'việc', 'tổ chức', 'các', 'hoạt động', 'kỷ niệm', '50', 'năm', 'thành lập', ',', 'quá trình', 'hội nhập', 'cũng', 'như', 'nỗ lực', 'xây dựng', 'cộng đồng', 'chung', 'và', 'bản sắc', 'chung', 'của', 'ASEAN', ',', 'Hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'các', 'quốc gia', 'cũng', 'như', 'Hiệp hội', 'Chữ thập Đỏ', 'và', 'Trăng lưỡi liềm', 'Đỏ', 'quốc tế', 'và', 'Uỷ ban Chữ thập Đỏ', 'quốc tế', 'cần', 'quan tâm', ',', 'đóng góp', 'vào', 'việc', 'xây dựng', 'Cộng đồng', 'ASEAN', 'với', '3', 'trụ cột', 'chính', 'là', 'Cộng đồng', 'Chính', 'trị-An ninh', ',', 'Cộng đồng', 'Kinh tế', 'và', 'Cộng đồng Văn hóa', 'Xã hội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5495\n",
            "sentence:  Bộ TT&TT yêu cầu chỉnh đốn hoạt động báo chí tại Gia Lai Bộ TT&TT đề nghị thành lập đoàn kiểm tra rà soát lại hoạt động báo chí của văn phòng đại diện, phóng viên thường trú ở Gia Lai .\n",
            "\n",
            "entity:  {'text': 'Gia Lai', 'pos': [49, 56]}\n",
            "entity index list:  [7]\n",
            "[38, 44]\n",
            "['Gia Lai']\n",
            "My word_tokenize 1:         ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "My word_tokenize 2:         ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại', 'Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5498\n",
            "sentence:  Bộ TT&TT yêu cầu chỉnh đốn hoạt động báo chí tại Gia Lai Bộ TT&TT đề nghị thành lập đoàn kiểm tra rà soát lại hoạt động báo chí của văn phòng đại diện, phóng viên thường trú ở Gia Lai .\n",
            "\n",
            "entity:  {'text': 'Gia Lai', 'pos': [49, 56]}\n",
            "entity index list:  [7]\n",
            "['Gia Lai']\n",
            "[38, 44]\n",
            "Underthesea word_tokenize:  ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại', 'Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5499\n",
            "sentence:  Bộ TT&TT yêu cầu chỉnh đốn hoạt động báo chí tại Gia Lai Bộ TT&TT đề nghị thành lập đoàn kiểm tra rà soát lại hoạt động báo chí của văn phòng đại diện, phóng viên thường trú ở Gia Lai .\n",
            "\n",
            "entity:  {'text': 'Gia Lai', 'pos': [49, 56]}\n",
            "entity index list:  [7]\n",
            "['Gia Lai']\n",
            "[38, 44]\n",
            "Underthesea word_tokenize:  ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "My word_tokenize 1:         ['Bộ', 'TT&TT', 'yêu cầu', 'chỉnh đốn', 'hoạt động', 'báo chí', 'tại', 'Gia Lai', 'Bộ', 'TT&TT', 'đề nghị', 'thành lập', 'đoàn', 'kiểm tra', 'rà soát', 'lại', 'hoạt động', 'báo chí', 'của', 'văn phòng', 'đại diện', ',', 'phóng viên', 'thường trú', 'ở', 'Gia Lai', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5568\n",
            "sentence:  Bìa cuốn sách “Please, Let Me Go” (Làm ơn hãy để tôi đi) của Caitlin Spencer Spencer nhớ rõ \"khách hàng\" đầu tiên.\n",
            "\n",
            "entity:  {'text': 'Caitlin Spencer', 'pos': [61, 76]}\n",
            "entity index list:  [16]\n",
            "['Caitlin Spencer']\n",
            "[47, 61]\n",
            "Underthesea word_tokenize:  ['Bìa', 'cuốn', 'sách', '“', 'Please', ',', 'Let Me Go', '”', '(', 'Làm ơn', 'hãy', 'để', 'tôi', 'đi', ')', 'của', 'Caitlin Spencer Spencer', 'nhớ', 'rõ', '\"', 'khách hàng', '\"', 'đầu tiên', '.']\n",
            "My word_tokenize 1:         ['Bìa', 'cuốn', 'sách', '“', 'Please', ',', 'Let Me Go', '”', '(', 'Làm ơn', 'hãy', 'để', 'tôi', 'đi', ')', 'của', 'Caitlin Spencer', 'Spencer', 'nhớ', 'rõ', '\"', 'khách hàng', '\"', 'đầu tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5768\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'miền Đông', 'pos': [71, 80]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 62]\n",
            "['miền', 'Đông']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 2:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5769\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'Ukraine', 'pos': [81, 88]}\n",
            "entity index list:  [16]\n",
            "[62, 69]\n",
            "['Ukraine']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 2:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5772\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'miền Đông', 'pos': [71, 80]}\n",
            "entity index list:  [14, 15]\n",
            "[54, 62]\n",
            "['miền', 'Đông']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 2:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5773\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'Ukraine', 'pos': [81, 88]}\n",
            "entity index list:  [16]\n",
            "[62, 69]\n",
            "['Ukraine']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 2:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5776\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'miền Đông', 'pos': [71, 80]}\n",
            "entity index list:  [14, 15]\n",
            "['miền', 'Đông']\n",
            "[54, 62]\n",
            "Underthesea word_tokenize:  ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5777\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'miền Đông', 'pos': [71, 80]}\n",
            "entity index list:  [14, 15]\n",
            "['miền', 'Đông']\n",
            "[54, 62]\n",
            "Underthesea word_tokenize:  ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5778\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'miền Đông', 'pos': [71, 80]}\n",
            "entity index list:  [14, 15]\n",
            "['miền', 'Đông']\n",
            "[54, 62]\n",
            "Underthesea word_tokenize:  ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5779\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'Ukraine', 'pos': [81, 88]}\n",
            "entity index list:  [16]\n",
            "['Ukraine']\n",
            "[62, 69]\n",
            "Underthesea word_tokenize:  ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5780\n",
            "sentence:  Sự trỗi dậy của Nga qua vụ sáp nhập thần tốc Crimea và cuộc xung đột ở miền Đông Ukraine , cuộc khủng hoảng kinh tế tại Hy Lạp và tương lai của khu vực đồng tiền chung EU .\n",
            "\n",
            "entity:  {'text': 'Ukraine', 'pos': [81, 88]}\n",
            "entity index list:  [16]\n",
            "['Ukraine']\n",
            "[62, 69]\n",
            "Underthesea word_tokenize:  ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "My word_tokenize 1:         ['Sự', 'trỗi', 'dậy', 'của', 'Nga', 'qua', 'vụ', 'sáp nhập', 'thần tốc', 'Crimea', 'và', 'cuộc', 'xung đột', 'ở', 'miền', 'Đông', 'Ukraine', ',', 'cuộc', 'khủng hoảng kinh tế', 'tại', 'Hy Lạp', 'và', 'tương lai', 'của', 'khu vực', 'đồng tiền', 'chung', 'EU', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5817\n",
            "sentence:  Bà Merkel gặp Tổng thống Nga Vladimir Putin vào năm 2002.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [25, 28]}\n",
            "entity index list:  [4]\n",
            "[20, 23]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga', 'Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5818\n",
            "sentence:  Bà Merkel gặp Tổng thống Nga Vladimir Putin vào năm 2002.\n",
            "\n",
            "entity:  {'text': 'Vladimir Putin', 'pos': [29, 43]}\n",
            "entity index list:  [5]\n",
            "[23, 36]\n",
            "['Vladimir Putin']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga', 'Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5819\n",
            "sentence:  Bà Merkel gặp Tổng thống Nga Vladimir Putin vào năm 2002.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [25, 28]}\n",
            "entity index list:  [4]\n",
            "['Nga']\n",
            "[20, 23]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'gặp', 'Tổng thống', 'Nga', 'Vladimir Putin', 'vào', 'năm', '2002', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5821\n",
            "sentence:  Những năm đầu tiên của Merkel trong vai trò lãnh đạo đảng CDU không hề dễ dàng.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [58, 61]}\n",
            "entity index list:  [9]\n",
            "[46, 49]\n",
            "['CDU']\n",
            "My word_tokenize 1:         ['Những', 'năm', 'đầu tiên', 'của', 'Merkel', 'trong', 'vai trò', 'lãnh đạo', 'đảng CDU', 'không', 'hề', 'dễ dàng', '.']\n",
            "My word_tokenize 2:         ['Những', 'năm', 'đầu tiên', 'của', 'Merkel', 'trong', 'vai trò', 'lãnh đạo', 'đảng', 'CDU', 'không', 'hề', 'dễ dàng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5850\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [36, 38]}\n",
            "entity index list:  [5]\n",
            "[29, 31]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5851\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Obama', 'pos': [39, 44]}\n",
            "entity index list:  [6]\n",
            "[31, 36]\n",
            "['Obama']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 2:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5854\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [36, 38]}\n",
            "entity index list:  [5]\n",
            "['Mỹ']\n",
            "[29, 31]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5855\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [36, 38]}\n",
            "entity index list:  [5]\n",
            "['Mỹ']\n",
            "[29, 31]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5856\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [36, 38]}\n",
            "entity index list:  [5]\n",
            "['Mỹ']\n",
            "[29, 31]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5857\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Obama', 'pos': [39, 44]}\n",
            "entity index list:  [6]\n",
            "['Obama']\n",
            "[31, 36]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5858\n",
            "sentence:  Bà Merkel trò chuyện với Tổng thống Mỹ Obama bên lề hội nghị thượng đỉnh G7 ở Đức , tháng 6/2015.\n",
            "\n",
            "entity:  {'text': 'Obama', 'pos': [39, 44]}\n",
            "entity index list:  [6]\n",
            "['Obama']\n",
            "[31, 36]\n",
            "Underthesea word_tokenize:  ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "My word_tokenize 1:         ['Bà', 'Merkel', 'trò chuyện', 'với', 'Tổng thống', 'Mỹ', 'Obama', 'bên', 'lề', 'hội nghị', 'thượng đỉnh', 'G7', 'ở', 'Đức', ',', 'tháng', '6/2015', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5898\n",
            "sentence:  Để làm rõ hành vi của đối tượng Long , PV Báo ANTĐ đã có buổi trao đổi cụ thể với Luật sư Trương Anh Tú – Văn phòng Luật sư Trương Anh Tú , Đoàn Luật sư Hà Nội .\n",
            "\n",
            "entity:  {'text': 'Báo ANTĐ', 'pos': [42, 50]}\n",
            "entity index list:  [9]\n",
            "[31, 38]\n",
            "['Báo ANTĐ']\n",
            "My word_tokenize 1:         ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "My word_tokenize 2:         ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV', 'Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5902\n",
            "sentence:  Để làm rõ hành vi của đối tượng Long , PV Báo ANTĐ đã có buổi trao đổi cụ thể với Luật sư Trương Anh Tú – Văn phòng Luật sư Trương Anh Tú , Đoàn Luật sư Hà Nội .\n",
            "\n",
            "entity:  {'text': 'Báo ANTĐ', 'pos': [42, 50]}\n",
            "entity index list:  [9]\n",
            "['Báo ANTĐ']\n",
            "[31, 38]\n",
            "Underthesea word_tokenize:  ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "My word_tokenize 1:         ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV', 'Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5903\n",
            "sentence:  Để làm rõ hành vi của đối tượng Long , PV Báo ANTĐ đã có buổi trao đổi cụ thể với Luật sư Trương Anh Tú – Văn phòng Luật sư Trương Anh Tú , Đoàn Luật sư Hà Nội .\n",
            "\n",
            "entity:  {'text': 'Báo ANTĐ', 'pos': [42, 50]}\n",
            "entity index list:  [9]\n",
            "['Báo ANTĐ']\n",
            "[31, 38]\n",
            "Underthesea word_tokenize:  ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "My word_tokenize 1:         ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV', 'Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  5904\n",
            "sentence:  Để làm rõ hành vi của đối tượng Long , PV Báo ANTĐ đã có buổi trao đổi cụ thể với Luật sư Trương Anh Tú – Văn phòng Luật sư Trương Anh Tú , Đoàn Luật sư Hà Nội .\n",
            "\n",
            "entity:  {'text': 'Báo ANTĐ', 'pos': [42, 50]}\n",
            "entity index list:  [9]\n",
            "['Báo ANTĐ']\n",
            "[31, 38]\n",
            "Underthesea word_tokenize:  ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "My word_tokenize 1:         ['Để', 'làm', 'rõ', 'hành vi', 'của', 'đối tượng', 'Long', ',', 'PV', 'Báo ANTĐ', 'đã', 'có', 'buổi', 'trao đổi', 'cụ thể', 'với', 'Luật sư', 'Trương Anh Tú', '–', 'Văn phòng', 'Luật sư', 'Trương Anh Tú', ',', 'Đoàn', 'Luật sư', 'Hà Nội', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6017\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "[95, 103]\n",
            "['Al-Qaeda']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6018\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6023\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "[95, 103]\n",
            "['Al-Qaeda']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6024\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6028\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "[95, 103]\n",
            "['Al-Qaeda']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6029\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6032\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "[95, 103]\n",
            "['Al-Qaeda']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6033\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6035\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "[95, 103]\n",
            "['Al-Qaeda']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6036\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6038\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "['Al-Qaeda']\n",
            "[95, 103]\n",
            "Underthesea word_tokenize:  ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "[103, 108]\n",
            "['Syria']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 2:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6039\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Al-Qaeda', 'pos': [121, 129]}\n",
            "entity index list:  [21]\n",
            "['Al-Qaeda']\n",
            "[95, 103]\n",
            "Underthesea word_tokenize:  ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6040\n",
            "sentence:  Hôm nay tình thế Deir Ezzor , Nga có quá nhiều lợi thế, trong khi Mỹ chỉ còn lại SDF và lực lượng Hay’at Tahrir Al-Sham (Al-Qaeda Syria –HTS ) thì không thể làm nên trò trống gì...\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [130, 135]}\n",
            "entity index list:  [22]\n",
            "['Syria']\n",
            "[103, 108]\n",
            "Underthesea word_tokenize:  ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda Syria –', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "My word_tokenize 1:         ['Hôm nay', 'tình thế', 'Deir Ezzor', ',', 'Nga', 'có', 'quá', 'nhiều', 'lợi thế', ',', 'trong', 'khi', 'Mỹ', 'chỉ', 'còn', 'lại', 'SDF', 'và', 'lực lượng', 'Hay’at Tahrir Al-Sham', '(', 'Al-Qaeda', 'Syria', '–', 'HTS', ')', 'thì', 'không thể', 'làm nên', 'trò trống', 'gì', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  6050\n",
            "sentence:  Trên bàn cờ tàn Syria đã hết bóng dáng của Saudi , Qatar ...cùng hàng chục tổ chức cái gọi là lực lượng nổi dậy, phiến quân “ôn hòa” đã được “đóng băng” trong 4 “vùng giảm leo thang” thì chiến dịch giải phóng Deir Ezzor là trận cuối loại bỏ IS , kết thúc chiến tranh bằng một giải pháp chính trị hòa bình cho Syria .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [16, 21]}\n",
            "entity index list:  [3]\n",
            "['Syria']\n",
            "[12, 17]\n",
            "Underthesea word_tokenize:  ['Trên', 'bàn cờ', 'tàn Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "My word_tokenize 1:         ['Trên', 'bàn cờ', 'tàn', 'Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6051\n",
            "sentence:  Trên bàn cờ tàn Syria đã hết bóng dáng của Saudi , Qatar ...cùng hàng chục tổ chức cái gọi là lực lượng nổi dậy, phiến quân “ôn hòa” đã được “đóng băng” trong 4 “vùng giảm leo thang” thì chiến dịch giải phóng Deir Ezzor là trận cuối loại bỏ IS , kết thúc chiến tranh bằng một giải pháp chính trị hòa bình cho Syria .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [16, 21]}\n",
            "entity index list:  [3]\n",
            "['Syria']\n",
            "[12, 17]\n",
            "Underthesea word_tokenize:  ['Trên', 'bàn cờ', 'tàn Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "My word_tokenize 1:         ['Trên', 'bàn cờ', 'tàn', 'Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6052\n",
            "sentence:  Trên bàn cờ tàn Syria đã hết bóng dáng của Saudi , Qatar ...cùng hàng chục tổ chức cái gọi là lực lượng nổi dậy, phiến quân “ôn hòa” đã được “đóng băng” trong 4 “vùng giảm leo thang” thì chiến dịch giải phóng Deir Ezzor là trận cuối loại bỏ IS , kết thúc chiến tranh bằng một giải pháp chính trị hòa bình cho Syria .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [16, 21]}\n",
            "entity index list:  [3]\n",
            "['Syria']\n",
            "[12, 17]\n",
            "Underthesea word_tokenize:  ['Trên', 'bàn cờ', 'tàn Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "My word_tokenize 1:         ['Trên', 'bàn cờ', 'tàn', 'Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6053\n",
            "sentence:  Trên bàn cờ tàn Syria đã hết bóng dáng của Saudi , Qatar ...cùng hàng chục tổ chức cái gọi là lực lượng nổi dậy, phiến quân “ôn hòa” đã được “đóng băng” trong 4 “vùng giảm leo thang” thì chiến dịch giải phóng Deir Ezzor là trận cuối loại bỏ IS , kết thúc chiến tranh bằng một giải pháp chính trị hòa bình cho Syria .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [16, 21]}\n",
            "entity index list:  [3]\n",
            "['Syria']\n",
            "[12, 17]\n",
            "Underthesea word_tokenize:  ['Trên', 'bàn cờ', 'tàn Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "My word_tokenize 1:         ['Trên', 'bàn cờ', 'tàn', 'Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6054\n",
            "sentence:  Trên bàn cờ tàn Syria đã hết bóng dáng của Saudi , Qatar ...cùng hàng chục tổ chức cái gọi là lực lượng nổi dậy, phiến quân “ôn hòa” đã được “đóng băng” trong 4 “vùng giảm leo thang” thì chiến dịch giải phóng Deir Ezzor là trận cuối loại bỏ IS , kết thúc chiến tranh bằng một giải pháp chính trị hòa bình cho Syria .\n",
            "\n",
            "entity:  {'text': 'Syria', 'pos': [16, 21]}\n",
            "entity index list:  [3]\n",
            "['Syria']\n",
            "[12, 17]\n",
            "Underthesea word_tokenize:  ['Trên', 'bàn cờ', 'tàn Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "My word_tokenize 1:         ['Trên', 'bàn cờ', 'tàn', 'Syria', 'đã', 'hết', 'bóng dáng', 'của', 'Saudi', ',', 'Qatar', '...', 'cùng', 'hàng', 'chục', 'tổ chức', 'cái', 'gọi', 'là', 'lực lượng', 'nổi', 'dậy', ',', 'phiến quân', '“', 'ôn hòa', '”', 'đã', 'được', '“', 'đóng băng', '”', 'trong', '4', '“', 'vùng', 'giảm', 'leo thang', '”', 'thì', 'chiến dịch', 'giải phóng', 'Deir Ezzor', 'là', 'trận', 'cuối', 'loại bỏ', 'IS', ',', 'kết thúc', 'chiến tranh', 'bằng', 'một', 'giải pháp', 'chính trị', 'hòa bình', 'cho', 'Syria', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6069\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "[27, 30]\n",
            "['VKS']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 2:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6070\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [40, 43]}\n",
            "entity index list:  [10]\n",
            "[30, 33]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 2:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6075\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "['VKS']\n",
            "[27, 30]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6076\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "['VKS']\n",
            "[27, 30]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6077\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "['VKS']\n",
            "[27, 30]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6078\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "['VKS']\n",
            "[27, 30]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6079\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [36, 39]}\n",
            "entity index list:  [9]\n",
            "['VKS']\n",
            "[27, 30]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6080\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [40, 43]}\n",
            "entity index list:  [10]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6081\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [40, 43]}\n",
            "entity index list:  [10]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6082\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [40, 43]}\n",
            "entity index list:  [10]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6083\n",
            "sentence:  1, Nhận thấy SAA dưới sự hỗ trợ của VKS Nga phá vây thành công tại Deir Ezzor , đánh chiếm xong dãy cao điểm Thardah , nguy cơ Deir Ezzor thất thủ chỉ là vấn đề thời gian, Mỹ lập tức điều động lực lượng…\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [40, 43]}\n",
            "entity index list:  [10]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "My word_tokenize 1:         ['1', ',', 'Nhận', 'thấy', 'SAA', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'phá vây', 'thành công', 'tại', 'Deir Ezzor', ',', 'đánh', 'chiếm', 'xong', 'dãy', 'cao điểm', 'Thardah', ',', 'nguy cơ', 'Deir Ezzor', 'thất thủ chỉ', 'là', 'vấn đề', 'thời gian', ',', 'Mỹ', 'lập tức', 'điều động lực lượng', '…']\n",
            "\n",
            "\n",
            "---------- sent_id:  6131\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [56, 59]}\n",
            "entity index list:  [12]\n",
            "[42, 45]\n",
            "['VKS']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 2:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6132\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [60, 63]}\n",
            "entity index list:  [13]\n",
            "[45, 48]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 2:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6134\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [56, 59]}\n",
            "entity index list:  [12]\n",
            "[42, 45]\n",
            "['VKS']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 2:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6135\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [60, 63]}\n",
            "entity index list:  [13]\n",
            "[45, 48]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 2:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6137\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [56, 59]}\n",
            "entity index list:  [12]\n",
            "['VKS']\n",
            "[42, 45]\n",
            "Underthesea word_tokenize:  ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6138\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'VKS', 'pos': [56, 59]}\n",
            "entity index list:  [12]\n",
            "['VKS']\n",
            "[42, 45]\n",
            "Underthesea word_tokenize:  ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6139\n",
            "sentence:  2, Đội đặc nhiệm SAA cùng cố vấn Nga dưới sự hỗ trợ của VKS Nga đã vượt sông Euphrates đánh chiếm đầu cầu thành công.\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [60, 63]}\n",
            "entity index list:  [13]\n",
            "['Nga']\n",
            "[45, 48]\n",
            "Underthesea word_tokenize:  ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "My word_tokenize 1:         ['2', ',', 'Đội', 'đặc nhiệm', 'SAA', 'cùng', 'cố vấn', 'Nga', 'dưới', 'sự', 'hỗ trợ', 'của', 'VKS', 'Nga', 'đã', 'vượt', 'sông', 'Euphrates', 'đánh', 'chiếm', 'đầu', 'cầu', 'thành công', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6142\n",
            "sentence:  Đầu tiên, SDF xả đập thượng nguồn Euphrates gây dòng chảy mạnh gây khó cho SAA vượt sông.\n",
            "\n",
            "entity:  {'text': 'SDF', 'pos': [10, 13]}\n",
            "entity index list:  [2]\n",
            "['SDF']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Đầu tiên', ',', 'SDF xả', 'đập', 'thượng nguồn', 'Euphrates', 'gây', 'dòng chảy', 'mạnh', 'gây', 'khó', 'cho', 'SAA', 'vượt', 'sông', '.']\n",
            "My word_tokenize 1:         ['Đầu tiên', ',', 'SDF', 'xả', 'đập', 'thượng nguồn', 'Euphrates', 'gây', 'dòng chảy', 'mạnh', 'gây', 'khó', 'cho', 'SAA', 'vượt', 'sông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6143\n",
            "sentence:  Đầu tiên, SDF xả đập thượng nguồn Euphrates gây dòng chảy mạnh gây khó cho SAA vượt sông.\n",
            "\n",
            "entity:  {'text': 'SDF', 'pos': [10, 13]}\n",
            "entity index list:  [2]\n",
            "['SDF']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Đầu tiên', ',', 'SDF xả', 'đập', 'thượng nguồn', 'Euphrates', 'gây', 'dòng chảy', 'mạnh', 'gây', 'khó', 'cho', 'SAA', 'vượt', 'sông', '.']\n",
            "My word_tokenize 1:         ['Đầu tiên', ',', 'SDF', 'xả', 'đập', 'thượng nguồn', 'Euphrates', 'gây', 'dòng chảy', 'mạnh', 'gây', 'khó', 'cho', 'SAA', 'vượt', 'sông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6151\n",
            "sentence:  3, Mỹ sử dụng lực lượng Al Qeada , HTS tại Idlid mở mặt trận Bắc Hama (trong đó có một đòn độc:\n",
            "\n",
            "entity:  {'text': 'Hama', 'pos': [65, 69]}\n",
            "entity index list:  [13]\n",
            "[49, 53]\n",
            "['Hama']\n",
            "My word_tokenize 1:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "My word_tokenize 2:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc', 'Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6154\n",
            "sentence:  3, Mỹ sử dụng lực lượng Al Qeada , HTS tại Idlid mở mặt trận Bắc Hama (trong đó có một đòn độc:\n",
            "\n",
            "entity:  {'text': 'Hama', 'pos': [65, 69]}\n",
            "entity index list:  [13]\n",
            "[49, 53]\n",
            "['Hama']\n",
            "My word_tokenize 1:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "My word_tokenize 2:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc', 'Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6156\n",
            "sentence:  3, Mỹ sử dụng lực lượng Al Qeada , HTS tại Idlid mở mặt trận Bắc Hama (trong đó có một đòn độc:\n",
            "\n",
            "entity:  {'text': 'Hama', 'pos': [65, 69]}\n",
            "entity index list:  [13]\n",
            "[49, 53]\n",
            "['Hama']\n",
            "My word_tokenize 1:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "My word_tokenize 2:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc', 'Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6157\n",
            "sentence:  3, Mỹ sử dụng lực lượng Al Qeada , HTS tại Idlid mở mặt trận Bắc Hama (trong đó có một đòn độc:\n",
            "\n",
            "entity:  {'text': 'Hama', 'pos': [65, 69]}\n",
            "entity index list:  [13]\n",
            "[49, 53]\n",
            "['Hama']\n",
            "My word_tokenize 1:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "My word_tokenize 2:         ['3', ',', 'Mỹ', 'sử dụng', 'lực lượng', 'Al Qeada', ',', 'HTS', 'tại', 'Idlid', 'mở', 'mặt trận', 'Bắc', 'Hama', '(', 'trong', 'đó', 'có', 'một', 'đòn', 'độc', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6163\n",
            "sentence:  Việc sư đoàn cơ giới số 4 của SAA tràn qua sông phát triển tốt hướng Bắc và Đông Euphrates bất chấp lời cảnh báo vô lý của SDF là một chuyện, quan trọng hơn là họ kịp thời chặt đứt ý đồ phát triển về phía Đông và chiếm Al Bukaman của SDF nhằm tranh thêm một “mẫu bánh” Deir Ezzor .\n",
            "\n",
            "entity:  {'text': 'Euphrates', 'pos': [81, 90]}\n",
            "entity index list:  [16]\n",
            "[62, 71]\n",
            "['Euphrates']\n",
            "My word_tokenize 1:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "My word_tokenize 2:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông', 'Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6168\n",
            "sentence:  Việc sư đoàn cơ giới số 4 của SAA tràn qua sông phát triển tốt hướng Bắc và Đông Euphrates bất chấp lời cảnh báo vô lý của SDF là một chuyện, quan trọng hơn là họ kịp thời chặt đứt ý đồ phát triển về phía Đông và chiếm Al Bukaman của SDF nhằm tranh thêm một “mẫu bánh” Deir Ezzor .\n",
            "\n",
            "entity:  {'text': 'Euphrates', 'pos': [81, 90]}\n",
            "entity index list:  [16]\n",
            "['Euphrates']\n",
            "[62, 71]\n",
            "Underthesea word_tokenize:  ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "My word_tokenize 1:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông', 'Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6169\n",
            "sentence:  Việc sư đoàn cơ giới số 4 của SAA tràn qua sông phát triển tốt hướng Bắc và Đông Euphrates bất chấp lời cảnh báo vô lý của SDF là một chuyện, quan trọng hơn là họ kịp thời chặt đứt ý đồ phát triển về phía Đông và chiếm Al Bukaman của SDF nhằm tranh thêm một “mẫu bánh” Deir Ezzor .\n",
            "\n",
            "entity:  {'text': 'Euphrates', 'pos': [81, 90]}\n",
            "entity index list:  [16]\n",
            "['Euphrates']\n",
            "[62, 71]\n",
            "Underthesea word_tokenize:  ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "My word_tokenize 1:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông', 'Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6170\n",
            "sentence:  Việc sư đoàn cơ giới số 4 của SAA tràn qua sông phát triển tốt hướng Bắc và Đông Euphrates bất chấp lời cảnh báo vô lý của SDF là một chuyện, quan trọng hơn là họ kịp thời chặt đứt ý đồ phát triển về phía Đông và chiếm Al Bukaman của SDF nhằm tranh thêm một “mẫu bánh” Deir Ezzor .\n",
            "\n",
            "entity:  {'text': 'Euphrates', 'pos': [81, 90]}\n",
            "entity index list:  [16]\n",
            "['Euphrates']\n",
            "[62, 71]\n",
            "Underthesea word_tokenize:  ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "My word_tokenize 1:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông', 'Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6171\n",
            "sentence:  Việc sư đoàn cơ giới số 4 của SAA tràn qua sông phát triển tốt hướng Bắc và Đông Euphrates bất chấp lời cảnh báo vô lý của SDF là một chuyện, quan trọng hơn là họ kịp thời chặt đứt ý đồ phát triển về phía Đông và chiếm Al Bukaman của SDF nhằm tranh thêm một “mẫu bánh” Deir Ezzor .\n",
            "\n",
            "entity:  {'text': 'Euphrates', 'pos': [81, 90]}\n",
            "entity index list:  [16]\n",
            "['Euphrates']\n",
            "[62, 71]\n",
            "Underthesea word_tokenize:  ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "My word_tokenize 1:         ['Việc', 'sư đoàn', 'cơ giới', 'số', '4', 'của', 'SAA', 'tràn', 'qua', 'sông', 'phát triển', 'tốt', 'hướng', 'Bắc', 'và', 'Đông', 'Euphrates', 'bất chấp', 'lời', 'cảnh báo', 'vô lý', 'của', 'SDF', 'là', 'một', 'chuyện', ',', 'quan trọng', 'hơn', 'là', 'họ', 'kịp thời', 'chặt', 'đứt', 'ý đồ', 'phát triển', 'về', 'phía', 'Đông', 'và', 'chiếm', 'Al Bukaman', 'của', 'SDF', 'nhằm', 'tranh', 'thêm', 'một', '“', 'mẫu', 'bánh', '”', 'Deir Ezzor', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6226\n",
            "sentence:  Man City , MU và Chelsea đua Ngoại hạng Anh :\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [17, 24]}\n",
            "entity index list:  [4]\n",
            "[12, 19]\n",
            "['Chelsea']\n",
            "My word_tokenize 1:         ['Man City', ',', 'MU', 'và', 'Chelsea đua', 'Ngoại hạng', 'Anh', ':']\n",
            "My word_tokenize 2:         ['Man City', ',', 'MU', 'và', 'Chelsea', 'đua', 'Ngoại hạng', 'Anh', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6228\n",
            "sentence:  Man City , MU và Chelsea đua Ngoại hạng Anh :\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [17, 24]}\n",
            "entity index list:  [4]\n",
            "[12, 19]\n",
            "['Chelsea']\n",
            "My word_tokenize 1:         ['Man City', ',', 'MU', 'và', 'Chelsea đua', 'Ngoại hạng', 'Anh', ':']\n",
            "My word_tokenize 2:         ['Man City', ',', 'MU', 'và', 'Chelsea', 'đua', 'Ngoại hạng', 'Anh', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6230\n",
            "sentence:  Man City , MU và Chelsea đua Ngoại hạng Anh :\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [17, 24]}\n",
            "entity index list:  [4]\n",
            "['Chelsea']\n",
            "[12, 19]\n",
            "Underthesea word_tokenize:  ['Man City', ',', 'MU', 'và', 'Chelsea đua', 'Ngoại hạng', 'Anh', ':']\n",
            "My word_tokenize 1:         ['Man City', ',', 'MU', 'và', 'Chelsea', 'đua', 'Ngoại hạng', 'Anh', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6252\n",
            "sentence:  Man xanh “đốt” 215 triệu bảng cho 7 tân binh, nhà ĐKVĐ Chelsea “phá két” 192 triệu bảng (tiêu biểu có tiền đạo Morata 70 triệu bảng) trong khi MU “chỉ” tăng cường 3 tân binh nhưng 2 trong số đó cực chất, Matic và Lukaku .\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [55, 62]}\n",
            "entity index list:  [14]\n",
            "[43, 50]\n",
            "['Chelsea']\n",
            "My word_tokenize 1:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "My word_tokenize 2:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ', 'Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6257\n",
            "sentence:  Man xanh “đốt” 215 triệu bảng cho 7 tân binh, nhà ĐKVĐ Chelsea “phá két” 192 triệu bảng (tiêu biểu có tiền đạo Morata 70 triệu bảng) trong khi MU “chỉ” tăng cường 3 tân binh nhưng 2 trong số đó cực chất, Matic và Lukaku .\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [55, 62]}\n",
            "entity index list:  [14]\n",
            "['Chelsea']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "My word_tokenize 1:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ', 'Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6258\n",
            "sentence:  Man xanh “đốt” 215 triệu bảng cho 7 tân binh, nhà ĐKVĐ Chelsea “phá két” 192 triệu bảng (tiêu biểu có tiền đạo Morata 70 triệu bảng) trong khi MU “chỉ” tăng cường 3 tân binh nhưng 2 trong số đó cực chất, Matic và Lukaku .\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [55, 62]}\n",
            "entity index list:  [14]\n",
            "['Chelsea']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "My word_tokenize 1:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ', 'Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6259\n",
            "sentence:  Man xanh “đốt” 215 triệu bảng cho 7 tân binh, nhà ĐKVĐ Chelsea “phá két” 192 triệu bảng (tiêu biểu có tiền đạo Morata 70 triệu bảng) trong khi MU “chỉ” tăng cường 3 tân binh nhưng 2 trong số đó cực chất, Matic và Lukaku .\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [55, 62]}\n",
            "entity index list:  [14]\n",
            "['Chelsea']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "My word_tokenize 1:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ', 'Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6260\n",
            "sentence:  Man xanh “đốt” 215 triệu bảng cho 7 tân binh, nhà ĐKVĐ Chelsea “phá két” 192 triệu bảng (tiêu biểu có tiền đạo Morata 70 triệu bảng) trong khi MU “chỉ” tăng cường 3 tân binh nhưng 2 trong số đó cực chất, Matic và Lukaku .\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [55, 62]}\n",
            "entity index list:  [14]\n",
            "['Chelsea']\n",
            "[43, 50]\n",
            "Underthesea word_tokenize:  ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "My word_tokenize 1:         ['Man', 'xanh', '“', 'đốt', '”', '215', 'triệu', 'bảng', 'cho', '7', 'tân binh', ',', 'nhà', 'ĐKVĐ', 'Chelsea', '“', 'phá', 'két', '”', '192', 'triệu', 'bảng', '(', 'tiêu biểu', 'có', 'tiền đạo', 'Morata', '70', 'triệu', 'bảng', ')', 'trong', 'khi', 'MU', '“', 'chỉ', '”', 'tăng cường', '3', 'tân binh', 'nhưng', '2', 'trong', 'số', 'đó', 'cực', 'chất', ',', 'Matic', 'và', 'Lukaku', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6292\n",
            "sentence:  Tuyến giữa, ông sở hữu Toure , Fernando , Delph , Gundogan (mới chấn thương).\n",
            "\n",
            "entity:  {'text': 'Toure', 'pos': [23, 28]}\n",
            "entity index list:  [5]\n",
            "['Toure']\n",
            "[18, 23]\n",
            "Underthesea word_tokenize:  ['Tuyến', 'giữa', ',', 'ông', 'sở hữu Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "My word_tokenize 1:         ['Tuyến', 'giữa', ',', 'ông', 'sở hữu', 'Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6293\n",
            "sentence:  Tuyến giữa, ông sở hữu Toure , Fernando , Delph , Gundogan (mới chấn thương).\n",
            "\n",
            "entity:  {'text': 'Toure', 'pos': [23, 28]}\n",
            "entity index list:  [5]\n",
            "['Toure']\n",
            "[18, 23]\n",
            "Underthesea word_tokenize:  ['Tuyến', 'giữa', ',', 'ông', 'sở hữu Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "My word_tokenize 1:         ['Tuyến', 'giữa', ',', 'ông', 'sở hữu', 'Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6294\n",
            "sentence:  Tuyến giữa, ông sở hữu Toure , Fernando , Delph , Gundogan (mới chấn thương).\n",
            "\n",
            "entity:  {'text': 'Toure', 'pos': [23, 28]}\n",
            "entity index list:  [5]\n",
            "['Toure']\n",
            "[18, 23]\n",
            "Underthesea word_tokenize:  ['Tuyến', 'giữa', ',', 'ông', 'sở hữu Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "My word_tokenize 1:         ['Tuyến', 'giữa', ',', 'ông', 'sở hữu', 'Toure', ',', 'Fernando', ',', 'Delph', ',', 'Gundogan', '(', 'mới', 'chấn thương', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6313\n",
            "sentence:  Trong khung gỗ, họ có Sergio Romero - người gác đền số 1 của ĐT Argentina , từng góp công lớn vào chức vô địch Europa League mùa trước.\n",
            "\n",
            "entity:  {'text': 'Argentina', 'pos': [64, 73]}\n",
            "entity index list:  [15]\n",
            "[49, 58]\n",
            "['Argentina']\n",
            "My word_tokenize 1:         ['Trong', 'khung', 'gỗ', ',', 'họ', 'có', 'Sergio Romero', '-', 'người', 'gác', 'đền', 'số', '1', 'của', 'ĐT Argentina', ',', 'từng', 'góp', 'công', 'lớn', 'vào', 'chức', 'vô địch', 'Europa League', 'mùa', 'trước', '.']\n",
            "My word_tokenize 2:         ['Trong', 'khung', 'gỗ', ',', 'họ', 'có', 'Sergio Romero', '-', 'người', 'gác', 'đền', 'số', '1', 'của', 'ĐT', 'Argentina', ',', 'từng', 'góp', 'công', 'lớn', 'vào', 'chức', 'vô địch', 'Europa League', 'mùa', 'trước', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6468\n",
            "sentence:  'Bao Thanh Thiên ' Kim Siêu Quần khỏe mạnh trở lại sau ca mổ khối u não Sau ca đại phẫu hồi năm ngoái, sức khỏe của 'Bao Thanh Thiên ' Kim Siêu Quần đã bình phục trở lại.\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [1, 16]}\n",
            "entity index list:  [1, 2]\n",
            "['Bao', 'Thanh Thiên']\n",
            "[1, 14]\n",
            "Underthesea word_tokenize:  [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6469\n",
            "sentence:  'Bao Thanh Thiên ' Kim Siêu Quần khỏe mạnh trở lại sau ca mổ khối u não Sau ca đại phẫu hồi năm ngoái, sức khỏe của 'Bao Thanh Thiên ' Kim Siêu Quần đã bình phục trở lại.\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [1, 16]}\n",
            "entity index list:  [1, 2]\n",
            "['Bao', 'Thanh Thiên']\n",
            "[1, 14]\n",
            "Underthesea word_tokenize:  [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [117, 132]}\n",
            "entity index list:  [20, 21]\n",
            "[90, 103]\n",
            "['Bao', 'Thanh Thiên']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 2:         [\"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6470\n",
            "sentence:  'Bao Thanh Thiên ' Kim Siêu Quần khỏe mạnh trở lại sau ca mổ khối u não Sau ca đại phẫu hồi năm ngoái, sức khỏe của 'Bao Thanh Thiên ' Kim Siêu Quần đã bình phục trở lại.\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [1, 16]}\n",
            "entity index list:  [1, 2]\n",
            "['Bao', 'Thanh Thiên']\n",
            "[1, 14]\n",
            "Underthesea word_tokenize:  [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6471\n",
            "sentence:  'Bao Thanh Thiên ' Kim Siêu Quần khỏe mạnh trở lại sau ca mổ khối u não Sau ca đại phẫu hồi năm ngoái, sức khỏe của 'Bao Thanh Thiên ' Kim Siêu Quần đã bình phục trở lại.\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [117, 132]}\n",
            "entity index list:  [19, 20]\n",
            "[90, 103]\n",
            "['Bao', 'Thanh Thiên']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 2:         [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6473\n",
            "sentence:  'Bao Thanh Thiên ' Kim Siêu Quần khỏe mạnh trở lại sau ca mổ khối u não Sau ca đại phẫu hồi năm ngoái, sức khỏe của 'Bao Thanh Thiên ' Kim Siêu Quần đã bình phục trở lại.\n",
            "\n",
            "entity:  {'text': 'Bao Thanh Thiên', 'pos': [117, 132]}\n",
            "entity index list:  [19, 20]\n",
            "['Bao', 'Thanh Thiên']\n",
            "[90, 103]\n",
            "Underthesea word_tokenize:  [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "My word_tokenize 1:         [\"'\", 'Bao', \"Thanh Thiên '\", 'Kim', 'Siêu Quần', 'khỏe mạnh', 'trở lại', 'sau', 'ca mổ', 'khối u', 'não Sau', 'ca', 'đại phẫu', 'hồi', 'năm ngoái', ',', 'sức khỏe', 'của', \"'\", 'Bao', 'Thanh Thiên', \"'\", 'Kim', 'Siêu Quần', 'đã', 'bình phục', 'trở lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6485\n",
            "sentence:  Trung tá Huỳnh Trung Phong – Trưởng Phòng CSGT Đường bộ - Đường sắt Công an TP.HCM đã có những trả lời cụ thể về vụ việc CSGT bị tố nhận hối lộ ở khu vực sân bay Tân Sơn Nhất thời gian qua.\n",
            "\n",
            "entity:  {'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [36, 67]}\n",
            "entity index list:  [4, 5, 6, 7, 8]\n",
            "[29, 54]\n",
            "['Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 2:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng', 'Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6487\n",
            "sentence:  Trung tá Huỳnh Trung Phong – Trưởng Phòng CSGT Đường bộ - Đường sắt Công an TP.HCM đã có những trả lời cụ thể về vụ việc CSGT bị tố nhận hối lộ ở khu vực sân bay Tân Sơn Nhất thời gian qua.\n",
            "\n",
            "entity:  {'text': 'sân bay Tân Sơn Nhất', 'pos': [154, 174]}\n",
            "entity index list:  [24, 25, 26]\n",
            "[118, 134]\n",
            "['sân bay', 'Tân Sơn', 'Nhất']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 2:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất', 'thời gian', 'qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6488\n",
            "sentence:  Trung tá Huỳnh Trung Phong – Trưởng Phòng CSGT Đường bộ - Đường sắt Công an TP.HCM đã có những trả lời cụ thể về vụ việc CSGT bị tố nhận hối lộ ở khu vực sân bay Tân Sơn Nhất thời gian qua.\n",
            "\n",
            "entity:  {'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [36, 67]}\n",
            "entity index list:  [4, 5, 6, 7, 8]\n",
            "['Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt']\n",
            "[29, 54]\n",
            "Underthesea word_tokenize:  ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng', 'Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6489\n",
            "sentence:  Trung tá Huỳnh Trung Phong – Trưởng Phòng CSGT Đường bộ - Đường sắt Công an TP.HCM đã có những trả lời cụ thể về vụ việc CSGT bị tố nhận hối lộ ở khu vực sân bay Tân Sơn Nhất thời gian qua.\n",
            "\n",
            "entity:  {'text': 'Phòng CSGT Đường bộ - Đường sắt', 'pos': [36, 67]}\n",
            "entity index list:  [4, 5, 6, 7, 8]\n",
            "['Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt']\n",
            "[29, 54]\n",
            "Underthesea word_tokenize:  ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng', 'Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "\n",
            "entity:  {'text': 'sân bay Tân Sơn Nhất', 'pos': [154, 174]}\n",
            "entity index list:  [25, 26, 27]\n",
            "[118, 134]\n",
            "['sân bay', 'Tân Sơn', 'Nhất']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng', 'Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 2:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng', 'Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất', 'thời gian', 'qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6490\n",
            "sentence:  Trung tá Huỳnh Trung Phong – Trưởng Phòng CSGT Đường bộ - Đường sắt Công an TP.HCM đã có những trả lời cụ thể về vụ việc CSGT bị tố nhận hối lộ ở khu vực sân bay Tân Sơn Nhất thời gian qua.\n",
            "\n",
            "entity:  {'text': 'sân bay Tân Sơn Nhất', 'pos': [154, 174]}\n",
            "entity index list:  [24, 25, 26]\n",
            "[118, 134]\n",
            "['sân bay', 'Tân Sơn', 'Nhất']\n",
            "My word_tokenize 1:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất thời gian', 'qua', '.']\n",
            "My word_tokenize 2:         ['Trung tá', 'Huỳnh Trung Phong', '–', 'Trưởng Phòng', 'CSGT', 'Đường bộ', '-', 'Đường sắt', 'Công an', 'TP.HCM', 'đã', 'có', 'những', 'trả lời', 'cụ thể', 'về', 'vụ việc', 'CSGT', 'bị', 'tố', 'nhận', 'hối lộ', 'ở', 'khu vực', 'sân bay', 'Tân Sơn', 'Nhất', 'thời gian', 'qua', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6496\n",
            "sentence:  Nếp Nếp - Vũ Trần Đức Hải , Đũi Nam Cao - Duy Nguyễn và SilkyVietnam .\n",
            "\n",
            "entity:  {'text': 'Duy Nguyễn', 'pos': [42, 52]}\n",
            "entity index list:  [8]\n",
            "[30, 39]\n",
            "['Duy Nguyễn']\n",
            "My word_tokenize 1:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn và', 'SilkyVietnam', '.']\n",
            "My word_tokenize 2:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn', 'và', 'SilkyVietnam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6499\n",
            "sentence:  Nếp Nếp - Vũ Trần Đức Hải , Đũi Nam Cao - Duy Nguyễn và SilkyVietnam .\n",
            "\n",
            "entity:  {'text': 'Duy Nguyễn', 'pos': [42, 52]}\n",
            "entity index list:  [8]\n",
            "[30, 39]\n",
            "['Duy Nguyễn']\n",
            "My word_tokenize 1:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn và', 'SilkyVietnam', '.']\n",
            "My word_tokenize 2:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn', 'và', 'SilkyVietnam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6501\n",
            "sentence:  Nếp Nếp - Vũ Trần Đức Hải , Đũi Nam Cao - Duy Nguyễn và SilkyVietnam .\n",
            "\n",
            "entity:  {'text': 'Duy Nguyễn', 'pos': [42, 52]}\n",
            "entity index list:  [8]\n",
            "[30, 39]\n",
            "['Duy Nguyễn']\n",
            "My word_tokenize 1:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn và', 'SilkyVietnam', '.']\n",
            "My word_tokenize 2:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn', 'và', 'SilkyVietnam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6503\n",
            "sentence:  Nếp Nếp - Vũ Trần Đức Hải , Đũi Nam Cao - Duy Nguyễn và SilkyVietnam .\n",
            "\n",
            "entity:  {'text': 'Duy Nguyễn', 'pos': [42, 52]}\n",
            "entity index list:  [8]\n",
            "['Duy Nguyễn']\n",
            "[30, 39]\n",
            "Underthesea word_tokenize:  ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn và', 'SilkyVietnam', '.']\n",
            "My word_tokenize 1:         ['Nếp', 'Nếp', '-', 'Vũ Trần Đức Hải', ',', 'Đũi', 'Nam Cao', '-', 'Duy Nguyễn', 'và', 'SilkyVietnam', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6625\n",
            "sentence:  Nga phủ nhận liên quan tới quảng cáo Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không dính líu tới những quảng cáo trên mạng xã hội Facebook có thể đã làm ảnh hưởng tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [62, 64]}\n",
            "entity index list:  [8]\n",
            "[49, 51]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6626\n",
            "sentence:  Nga phủ nhận liên quan tới quảng cáo Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không dính líu tới những quảng cáo trên mạng xã hội Facebook có thể đã làm ảnh hưởng tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [65, 77]}\n",
            "entity index list:  [9]\n",
            "[51, 62]\n",
            "['Điện Kremlin']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 2:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6628\n",
            "sentence:  Nga phủ nhận liên quan tới quảng cáo Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không dính líu tới những quảng cáo trên mạng xã hội Facebook có thể đã làm ảnh hưởng tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [62, 64]}\n",
            "entity index list:  [8]\n",
            "['Mỹ']\n",
            "[49, 51]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6629\n",
            "sentence:  Nga phủ nhận liên quan tới quảng cáo Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không dính líu tới những quảng cáo trên mạng xã hội Facebook có thể đã làm ảnh hưởng tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [62, 64]}\n",
            "entity index list:  [8]\n",
            "['Mỹ']\n",
            "[49, 51]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6630\n",
            "sentence:  Nga phủ nhận liên quan tới quảng cáo Facebook tác động bầu cử Mỹ Điện Kremlin ngày 22/9 tuyên bố không dính líu tới những quảng cáo trên mạng xã hội Facebook có thể đã làm ảnh hưởng tới cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Điện Kremlin', 'pos': [65, 77]}\n",
            "entity index list:  [9]\n",
            "['Điện Kremlin']\n",
            "[51, 62]\n",
            "Underthesea word_tokenize:  ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Nga', 'phủ nhận', 'liên quan', 'tới', 'quảng cáo', 'Facebook', 'tác động', 'bầu cử', 'Mỹ', 'Điện Kremlin', 'ngày', '22/9', 'tuyên bố', 'không', 'dính líu', 'tới', 'những', 'quảng cáo', 'trên', 'mạng', 'xã hội', 'Facebook', 'có thể', 'đã', 'làm', 'ảnh hưởng', 'tới', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6634\n",
            "sentence:  Hôm 21/9, ông chủ Facebook Mark Zuckerberg thông báo, công ty sẽ chuyển tới Quốc hội Mỹ các chi tiết về những quảng cáo liên quan tới Nga kích động căng thẳng trong thời gian diễn ra cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [27, 42]}\n",
            "entity index list:  [6]\n",
            "['Mark Zuckerberg']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook', 'Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6635\n",
            "sentence:  Hôm 21/9, ông chủ Facebook Mark Zuckerberg thông báo, công ty sẽ chuyển tới Quốc hội Mỹ các chi tiết về những quảng cáo liên quan tới Nga kích động căng thẳng trong thời gian diễn ra cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [27, 42]}\n",
            "entity index list:  [6]\n",
            "['Mark Zuckerberg']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook', 'Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6636\n",
            "sentence:  Hôm 21/9, ông chủ Facebook Mark Zuckerberg thông báo, công ty sẽ chuyển tới Quốc hội Mỹ các chi tiết về những quảng cáo liên quan tới Nga kích động căng thẳng trong thời gian diễn ra cuộc bầu cử tổng thống Mỹ hồi năm ngoái.\n",
            "\n",
            "entity:  {'text': 'Mark Zuckerberg', 'pos': [27, 42]}\n",
            "entity index list:  [6]\n",
            "['Mark Zuckerberg']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "My word_tokenize 1:         ['Hôm', '21/9', ',', 'ông', 'chủ', 'Facebook', 'Mark Zuckerberg', 'thông báo', ',', 'công ty', 'sẽ', 'chuyển', 'tới', 'Quốc hội', 'Mỹ', 'các', 'chi tiết', 'về', 'những', 'quảng cáo', 'liên quan', 'tới', 'Nga', 'kích động', 'căng thẳng', 'trong', 'thời gian', 'diễn', 'ra', 'cuộc', 'bầu cử', 'tổng thống', 'Mỹ', 'hồi', 'năm ngoái', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6678\n",
            "sentence:  Marcus Rashford đang thi đấu thăng hoa và được kỳ vọng là trụ cột của hàng công ĐT Anh trong tương lai.\n",
            "\n",
            "entity:  {'text': 'Anh', 'pos': [83, 86]}\n",
            "entity index list:  [14]\n",
            "[65, 68]\n",
            "['Anh']\n",
            "My word_tokenize 1:         ['Marcus', 'Rashford', 'đang', 'thi đấu', 'thăng hoa', 'và', 'được', 'kỳ vọng', 'là', 'trụ cột', 'của', 'hàng', 'công', 'ĐT Anh', 'trong', 'tương lai', '.']\n",
            "My word_tokenize 2:         ['Marcus', 'Rashford', 'đang', 'thi đấu', 'thăng hoa', 'và', 'được', 'kỳ vọng', 'là', 'trụ cột', 'của', 'hàng', 'công', 'ĐT', 'Anh', 'trong', 'tương lai', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6698\n",
            "sentence:  Phát biểu của Zouma đã khiến cho các CĐV Chelsea buồn lòng.\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [41, 48]}\n",
            "entity index list:  [8]\n",
            "[32, 39]\n",
            "['Chelsea']\n",
            "My word_tokenize 1:         ['Phát biểu', 'của', 'Zouma', 'đã', 'khiến', 'cho', 'các', 'CĐV Chelsea', 'buồn lòng', '.']\n",
            "My word_tokenize 2:         ['Phát biểu', 'của', 'Zouma', 'đã', 'khiến', 'cho', 'các', 'CĐV', 'Chelsea', 'buồn lòng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  6733\n",
            "sentence:  Bên cạnh đó, Costa cũng gửi thông điệp tới các CĐV Chelsea :\n",
            "\n",
            "entity:  {'text': 'Chelsea', 'pos': [51, 58]}\n",
            "entity index list:  [10]\n",
            "[40, 47]\n",
            "['Chelsea']\n",
            "My word_tokenize 1:         ['Bên cạnh', 'đó', ',', 'Costa', 'cũng', 'gửi', 'thông điệp', 'tới', 'các', 'CĐV Chelsea', ':']\n",
            "My word_tokenize 2:         ['Bên cạnh', 'đó', ',', 'Costa', 'cũng', 'gửi', 'thông điệp', 'tới', 'các', 'CĐV', 'Chelsea', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  6772\n",
            "sentence:  Hoàng Thùy , Mâu Thủy 'bị loại từ vòng gửi xe' của Hoa Hậu Hoàn Vũ Việt Nam 2017 ?\n",
            "\n",
            "entity:  {'text': 'Mâu Thủy', 'pos': [13, 21]}\n",
            "entity index list:  [3]\n",
            "[10, 17]\n",
            "['Mâu Thủy']\n",
            "My word_tokenize 1:         ['Hoàng', 'Thùy', ',', \"Mâu Thủy '\", 'bị', 'loại', 'từ', 'vòng', 'gửi', 'xe', \"'\", 'của', 'Hoa Hậu', 'Hoàn Vũ', 'Việt Nam', '2017', '?']\n",
            "My word_tokenize 2:         ['Hoàng', 'Thùy', ',', 'Mâu Thủy', \"'\", 'bị', 'loại', 'từ', 'vòng', 'gửi', 'xe', \"'\", 'của', 'Hoa Hậu', 'Hoàn Vũ', 'Việt Nam', '2017', '?']\n",
            "\n",
            "\n",
            "---------- sent_id:  6773\n",
            "sentence:  Họ vẫn tin rằng những khoản tiền chi thêm cho khách hàng là nằm trong chương trình chăm sóc khách hàng của ngân hàng, nhằm \"níu chân\" người gửi tiền, và tiền chi là của ông chủ bỏ ra (Hà Văn Thắm - Chủ tịch HĐQT Oceanbank khi đó).\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [212, 221]}\n",
            "entity index list:  [43]\n",
            "[166, 175]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Họ', 'vẫn', 'tin', 'rằng', 'những', 'khoản', 'tiền', 'chi', 'thêm', 'cho', 'khách hàng', 'là', 'nằm', 'trong', 'chương trình', 'chăm sóc', 'khách hàng', 'của', 'ngân hàng', ',', 'nhằm', '\"', 'níu', 'chân', '\"', 'người', 'gửi', 'tiền', ',', 'và', 'tiền', 'chi', 'là', 'của', 'ông', 'chủ', 'bỏ', 'ra', '(', 'Hà Văn Thắm', '-', 'Chủ tịch', 'HĐQT Oceanbank', 'khi', 'đó', ')', '.']\n",
            "My word_tokenize 2:         ['Họ', 'vẫn', 'tin', 'rằng', 'những', 'khoản', 'tiền', 'chi', 'thêm', 'cho', 'khách hàng', 'là', 'nằm', 'trong', 'chương trình', 'chăm sóc', 'khách hàng', 'của', 'ngân hàng', ',', 'nhằm', '\"', 'níu', 'chân', '\"', 'người', 'gửi', 'tiền', ',', 'và', 'tiền', 'chi', 'là', 'của', 'ông', 'chủ', 'bỏ', 'ra', '(', 'Hà Văn Thắm', '-', 'Chủ tịch', 'HĐQT', 'Oceanbank', 'khi', 'đó', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7032\n",
            "sentence:  Ông là bác sĩ riêng của hoàng đế La Mã Marcus Aurelius .\n",
            "\n",
            "entity:  {'text': 'La Mã', 'pos': [33, 38]}\n",
            "entity index list:  [6]\n",
            "['La Mã']\n",
            "[25, 29]\n",
            "Underthesea word_tokenize:  ['Ông', 'là', 'bác sĩ', 'riêng', 'của', 'hoàng đế', 'La Mã Marcus Aurelius', '.']\n",
            "My word_tokenize 1:         ['Ông', 'là', 'bác sĩ', 'riêng', 'của', 'hoàng đế', 'La Mã', 'Marcus Aurelius', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7104\n",
            "sentence:  Tối nay 22-9, hai kình ngư Nguyễn Thị Ánh Viên và Nguyễn Hữu Kim Sơn kỳ vọng sẽ mang về thêm những HCV tiếp theo cho đoàn.\n",
            "\n",
            "entity:  {'text': 'Nguyễn Hữu Kim Sơn', 'pos': [50, 68]}\n",
            "entity index list:  [8]\n",
            "[39, 54]\n",
            "['Nguyễn Hữu Kim Sơn']\n",
            "My word_tokenize 1:         ['Tối', 'nay', '22-9', ',', 'hai', 'kình ngư', 'Nguyễn Thị Ánh Viên', 'và', 'Nguyễn Hữu Kim Sơn kỳ vọng', 'sẽ', 'mang', 'về', 'thêm', 'những', 'HCV', 'tiếp theo', 'cho', 'đoàn', '.']\n",
            "My word_tokenize 2:         ['Tối', 'nay', '22-9', ',', 'hai', 'kình ngư', 'Nguyễn Thị Ánh Viên', 'và', 'Nguyễn Hữu Kim Sơn', 'kỳ vọng', 'sẽ', 'mang', 'về', 'thêm', 'những', 'HCV', 'tiếp theo', 'cho', 'đoàn', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7123\n",
            "sentence:  TS. David Nguyễn Vũ Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư khởi nghiệp tại Singapore .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7124\n",
            "sentence:  TS. David Nguyễn Vũ Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư khởi nghiệp tại Singapore .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7126\n",
            "sentence:  David Nguyễn Vũ Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư khởi nghiệp tại Singapore .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [0, 15]}\n",
            "entity index list:  [0, 1]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[0, 13]\n",
            "Underthesea word_tokenize:  ['David', 'Nguyễn Vũ Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "My word_tokenize 1:         ['David', 'Nguyễn Vũ', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7127\n",
            "sentence:  David Nguyễn Vũ Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư khởi nghiệp tại Singapore .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [0, 15]}\n",
            "entity index list:  [0, 1]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[0, 13]\n",
            "Underthesea word_tokenize:  ['David', 'Nguyễn Vũ Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "My word_tokenize 1:         ['David', 'Nguyễn Vũ', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'khởi nghiệp', 'tại', 'Singapore', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7129\n",
            "sentence:  TS. David Nguyễn Vũ - Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư tại Singapore cho các doanh nghiệp và nhà đầu tư Việt quan tâm.\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ -', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', '-', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7130\n",
            "sentence:  TS. David Nguyễn Vũ - Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư tại Singapore cho các doanh nghiệp và nhà đầu tư Việt quan tâm.\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ -', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', '-', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7131\n",
            "sentence:  TS. David Nguyễn Vũ - Chủ Tịch Hiệp Hội người Việt Nam tại Singapore đã có những chia sẻ hữu ích về môi trường đầu tư tại Singapore cho các doanh nghiệp và nhà đầu tư Việt quan tâm.\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ -', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', '-', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', 'đã', 'có', 'những', 'chia sẻ', 'hữu ích', 'về', 'môi trường', 'đầu tư', 'tại', 'Singapore', 'cho', 'các', 'doanh nghiệp', 'và', 'nhà đầu tư', 'Việt', 'quan tâm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7135\n",
            "sentence:  TS. David Nguyễn Vũ hiện là Chủ Tịch Hiệp Hội người Việt Nam tại Singapore (VAS ), đồng thời cũng là giám đốc Singapore (VietCham Singapore ).\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7136\n",
            "sentence:  TS. David Nguyễn Vũ hiện là Chủ Tịch Hiệp Hội người Việt Nam tại Singapore (VAS ), đồng thời cũng là giám đốc Singapore (VietCham Singapore ).\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7137\n",
            "sentence:  TS. David Nguyễn Vũ hiện là Chủ Tịch Hiệp Hội người Việt Nam tại Singapore (VAS ), đồng thời cũng là giám đốc Singapore (VietCham Singapore ).\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7138\n",
            "sentence:  TS. David Nguyễn Vũ hiện là Chủ Tịch Hiệp Hội người Việt Nam tại Singapore (VAS ), đồng thời cũng là giám đốc Singapore (VietCham Singapore ).\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [4, 19]}\n",
            "entity index list:  [1, 2]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[3, 16]\n",
            "Underthesea word_tokenize:  ['TS.', 'David', 'Nguyễn Vũ hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "My word_tokenize 1:         ['TS.', 'David', 'Nguyễn Vũ', 'hiện', 'là', 'Chủ Tịch', 'Hiệp Hội', 'người', 'Việt Nam', 'tại', 'Singapore', '(', 'VAS', ')', ',', 'đồng thời', 'cũng', 'là', 'giám đốc', 'Singapore', '(', 'VietCham Singapore', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7151\n",
            "sentence:  David Nguyễn Vũ hoàn thành chương trình Tiến sĩ tại Université du Maine – Pháp .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [0, 15]}\n",
            "entity index list:  [0, 1]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[0, 13]\n",
            "Underthesea word_tokenize:  ['David', 'Nguyễn Vũ hoàn thành', 'chương trình', 'Tiến sĩ', 'tại', 'Université du Maine', '–', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['David', 'Nguyễn Vũ', 'hoàn thành', 'chương trình', 'Tiến sĩ', 'tại', 'Université du Maine', '–', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7152\n",
            "sentence:  David Nguyễn Vũ hoàn thành chương trình Tiến sĩ tại Université du Maine – Pháp .\n",
            "\n",
            "entity:  {'text': 'David Nguyễn Vũ', 'pos': [0, 15]}\n",
            "entity index list:  [0, 1]\n",
            "['David', 'Nguyễn Vũ']\n",
            "[0, 13]\n",
            "Underthesea word_tokenize:  ['David', 'Nguyễn Vũ hoàn thành', 'chương trình', 'Tiến sĩ', 'tại', 'Université du Maine', '–', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['David', 'Nguyễn Vũ', 'hoàn thành', 'chương trình', 'Tiến sĩ', 'tại', 'Université du Maine', '–', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7264\n",
            "sentence:  Bất chấp lời bênh vực trên, các báo ở Argentina cho biết Tevez thường xuyên bị các CĐV Shenhua la ó, chỉ trích.\n",
            "\n",
            "entity:  {'text': 'Shenhua', 'pos': [87, 94]}\n",
            "entity index list:  [16]\n",
            "[69, 76]\n",
            "['Shenhua']\n",
            "My word_tokenize 1:         ['Bất chấp', 'lời', 'bênh vực', 'trên', ',', 'các', 'báo', 'ở', 'Argentina', 'cho', 'biết', 'Tevez', 'thường xuyên', 'bị', 'các', 'CĐV Shenhua', 'la ó', ',', 'chỉ trích', '.']\n",
            "My word_tokenize 2:         ['Bất chấp', 'lời', 'bênh vực', 'trên', ',', 'các', 'báo', 'ở', 'Argentina', 'cho', 'biết', 'Tevez', 'thường xuyên', 'bị', 'các', 'CĐV', 'Shenhua', 'la ó', ',', 'chỉ trích', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7265\n",
            "sentence:  Bất chấp lời bênh vực trên, các báo ở Argentina cho biết Tevez thường xuyên bị các CĐV Shenhua la ó, chỉ trích.\n",
            "\n",
            "entity:  {'text': 'Shenhua', 'pos': [87, 94]}\n",
            "entity index list:  [16]\n",
            "[69, 76]\n",
            "['Shenhua']\n",
            "My word_tokenize 1:         ['Bất chấp', 'lời', 'bênh vực', 'trên', ',', 'các', 'báo', 'ở', 'Argentina', 'cho', 'biết', 'Tevez', 'thường xuyên', 'bị', 'các', 'CĐV Shenhua', 'la ó', ',', 'chỉ trích', '.']\n",
            "My word_tokenize 2:         ['Bất chấp', 'lời', 'bênh vực', 'trên', ',', 'các', 'báo', 'ở', 'Argentina', 'cho', 'biết', 'Tevez', 'thường xuyên', 'bị', 'các', 'CĐV', 'Shenhua', 'la ó', ',', 'chỉ trích', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7357\n",
            "sentence:  Ngày nay, ngoài tiềm năng du lịch, vịnh Đà Nẵng còn có vị thế chiến lược quan trọng trong lĩnh vực kinh tế thương mại và quân sự của miền Trung và cả đất nước do đây là một vùng biển sâu kín gió, án ngữ cửa sông Hàn và gần các tuyến hàng hải quốc tế qua Biển Đông .\n",
            "\n",
            "entity:  {'text': 'sông Hàn', 'pos': [207, 215]}\n",
            "entity index list:  [36, 37]\n",
            "[160, 167]\n",
            "['sông', 'Hàn']\n",
            "My word_tokenize 1:         ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "My word_tokenize 2:         ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa', 'sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7359\n",
            "sentence:  Ngày nay, ngoài tiềm năng du lịch, vịnh Đà Nẵng còn có vị thế chiến lược quan trọng trong lĩnh vực kinh tế thương mại và quân sự của miền Trung và cả đất nước do đây là một vùng biển sâu kín gió, án ngữ cửa sông Hàn và gần các tuyến hàng hải quốc tế qua Biển Đông .\n",
            "\n",
            "entity:  {'text': 'sông Hàn', 'pos': [207, 215]}\n",
            "entity index list:  [36, 37]\n",
            "[160, 167]\n",
            "['sông', 'Hàn']\n",
            "My word_tokenize 1:         ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "My word_tokenize 2:         ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa', 'sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7361\n",
            "sentence:  Ngày nay, ngoài tiềm năng du lịch, vịnh Đà Nẵng còn có vị thế chiến lược quan trọng trong lĩnh vực kinh tế thương mại và quân sự của miền Trung và cả đất nước do đây là một vùng biển sâu kín gió, án ngữ cửa sông Hàn và gần các tuyến hàng hải quốc tế qua Biển Đông .\n",
            "\n",
            "entity:  {'text': 'sông Hàn', 'pos': [207, 215]}\n",
            "entity index list:  [36, 37]\n",
            "['sông', 'Hàn']\n",
            "[160, 167]\n",
            "Underthesea word_tokenize:  ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "My word_tokenize 1:         ['Ngày nay', ',', 'ngoài', 'tiềm năng', 'du lịch', ',', 'vịnh', 'Đà Nẵng', 'còn', 'có', 'vị', 'thế', 'chiến lược', 'quan trọng', 'trong', 'lĩnh vực', 'kinh tế', 'thương mại', 'và', 'quân sự', 'của', 'miền', 'Trung', 'và', 'cả', 'đất nước', 'do', 'đây', 'là', 'một', 'vùng biển', 'sâu kín', 'gió', ',', 'án ngữ', 'cửa', 'sông', 'Hàn', 'và', 'gần', 'các', 'tuyến', 'hàng hải', 'quốc tế', 'qua', 'Biển Đông', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7385\n",
            "sentence:  \"Nhiều lần liên lạc với bà Phượng nhưng không được vì quá bí bách, chúng tôi cùng ký đơn thư tố cáo sự việc lên TAND huỵện, Công an huyện Nông Sơn và Công an tỉnh Quảng Nam \", một nạn nhân cho hay.\n",
            "\n",
            "entity:  {'text': 'Công an huyện Nông Sơn', 'pos': [124, 146]}\n",
            "entity index list:  [25, 26, 27]\n",
            "[97, 115]\n",
            "['Công an', 'huyện', 'Nông Sơn']\n",
            "My word_tokenize 1:         ['\"', 'Nhiều', 'lần', 'liên lạc', 'với', 'bà', 'Phượng', 'nhưng', 'không', 'được', 'vì', 'quá', 'bí bách', ',', 'chúng tôi', 'cùng', 'ký', 'đơn', 'thư', 'tố cáo', 'sự việc', 'lên', 'TAND', 'huỵện', ',', 'Công an', 'huyện', 'Nông Sơn và', 'Công an', 'tỉnh', 'Quảng Nam', '\"', ',', 'một', 'nạn nhân', 'cho', 'hay', '.']\n",
            "My word_tokenize 2:         ['\"', 'Nhiều', 'lần', 'liên lạc', 'với', 'bà', 'Phượng', 'nhưng', 'không', 'được', 'vì', 'quá', 'bí bách', ',', 'chúng tôi', 'cùng', 'ký', 'đơn', 'thư', 'tố cáo', 'sự việc', 'lên', 'TAND', 'huỵện', ',', 'Công an', 'huyện', 'Nông Sơn', 'và', 'Công an', 'tỉnh', 'Quảng Nam', '\"', ',', 'một', 'nạn nhân', 'cho', 'hay', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7387\n",
            "sentence:  \"Nhiều lần liên lạc với bà Phượng nhưng không được vì quá bí bách, chúng tôi cùng ký đơn thư tố cáo sự việc lên TAND huỵện, Công an huyện Nông Sơn và Công an tỉnh Quảng Nam \", một nạn nhân cho hay.\n",
            "\n",
            "entity:  {'text': 'Công an huyện Nông Sơn', 'pos': [124, 146]}\n",
            "entity index list:  [25, 26, 27]\n",
            "['Công an', 'huyện', 'Nông Sơn']\n",
            "[97, 115]\n",
            "Underthesea word_tokenize:  ['\"', 'Nhiều', 'lần', 'liên lạc', 'với', 'bà', 'Phượng', 'nhưng', 'không', 'được', 'vì', 'quá', 'bí bách', ',', 'chúng tôi', 'cùng', 'ký', 'đơn', 'thư', 'tố cáo', 'sự việc', 'lên', 'TAND', 'huỵện', ',', 'Công an', 'huyện', 'Nông Sơn và', 'Công an', 'tỉnh', 'Quảng Nam', '\"', ',', 'một', 'nạn nhân', 'cho', 'hay', '.']\n",
            "My word_tokenize 1:         ['\"', 'Nhiều', 'lần', 'liên lạc', 'với', 'bà', 'Phượng', 'nhưng', 'không', 'được', 'vì', 'quá', 'bí bách', ',', 'chúng tôi', 'cùng', 'ký', 'đơn', 'thư', 'tố cáo', 'sự việc', 'lên', 'TAND', 'huỵện', ',', 'Công an', 'huyện', 'Nông Sơn', 'và', 'Công an', 'tỉnh', 'Quảng Nam', '\"', ',', 'một', 'nạn nhân', 'cho', 'hay', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7407\n",
            "sentence:  Vũ Ngọc Nhạ  sinh năm 1928 tại Thái Bình , từ nhỏ ông đã sống tại quê mẹ ở Giáo xứ Phát Diệm , Ninh Bình .\n",
            "\n",
            "entity:  {'text': 'Vũ Ngọc Nhạ', 'pos': [0, 11]}\n",
            "entity index list:  [0]\n",
            "['Vũ Ngọc Nhạ']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Vũ Ngọc Nhạ sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "My word_tokenize 1:         ['Vũ Ngọc Nhạ', 'sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7408\n",
            "sentence:  Vũ Ngọc Nhạ  sinh năm 1928 tại Thái Bình , từ nhỏ ông đã sống tại quê mẹ ở Giáo xứ Phát Diệm , Ninh Bình .\n",
            "\n",
            "entity:  {'text': 'Vũ Ngọc Nhạ', 'pos': [0, 11]}\n",
            "entity index list:  [0]\n",
            "['Vũ Ngọc Nhạ']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Vũ Ngọc Nhạ sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "My word_tokenize 1:         ['Vũ Ngọc Nhạ', 'sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7409\n",
            "sentence:  Vũ Ngọc Nhạ  sinh năm 1928 tại Thái Bình , từ nhỏ ông đã sống tại quê mẹ ở Giáo xứ Phát Diệm , Ninh Bình .\n",
            "\n",
            "entity:  {'text': 'Vũ Ngọc Nhạ', 'pos': [0, 11]}\n",
            "entity index list:  [0]\n",
            "['Vũ Ngọc Nhạ']\n",
            "[0, 9]\n",
            "Underthesea word_tokenize:  ['Vũ Ngọc Nhạ sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "My word_tokenize 1:         ['Vũ Ngọc Nhạ', 'sinh', 'năm', '1928', 'tại', 'Thái Bình', ',', 'từ', 'nhỏ', 'ông', 'đã', 'sống', 'tại', 'quê', 'mẹ', 'ở', 'Giáo xứ', 'Phát Diệm', ',', 'Ninh Bình', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7501\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Colombo', 'pos': [9, 16]}\n",
            "entity index list:  [1]\n",
            "[8, 15]\n",
            "['Colombo']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7502\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [17, 30]}\n",
            "entity index list:  [2, 3, 4]\n",
            "[15, 26]\n",
            "['Vasco', 'da', 'Gama']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7503\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Henry', 'pos': [31, 36]}\n",
            "entity index list:  [4]\n",
            "[26, 31]\n",
            "['Henry']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo Vasco', 'da', 'Gama', 'Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7504\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Ferdinand Magellan', 'pos': [37, 55]}\n",
            "entity index list:  [4]\n",
            "[31, 48]\n",
            "['Ferdinand Magellan']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7505\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Colombo', 'pos': [9, 16]}\n",
            "entity index list:  [1]\n",
            "['Colombo']\n",
            "[8, 15]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [17, 30]}\n",
            "entity index list:  [2, 3, 4]\n",
            "[15, 26]\n",
            "['Vasco', 'da', 'Gama']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7506\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Colombo', 'pos': [9, 16]}\n",
            "entity index list:  [1]\n",
            "['Colombo']\n",
            "[8, 15]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Henry', 'pos': [31, 36]}\n",
            "entity index list:  [5]\n",
            "[26, 31]\n",
            "['Henry']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7507\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Colombo', 'pos': [9, 16]}\n",
            "entity index list:  [1]\n",
            "['Colombo']\n",
            "[8, 15]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Ferdinand Magellan', 'pos': [37, 55]}\n",
            "entity index list:  [5]\n",
            "[31, 48]\n",
            "['Ferdinand Magellan']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7508\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [17, 30]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[15, 26]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Henry', 'pos': [31, 36]}\n",
            "entity index list:  [5]\n",
            "[26, 31]\n",
            "['Henry']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7509\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [17, 30]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[15, 26]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Ferdinand Magellan', 'pos': [37, 55]}\n",
            "entity index list:  [6]\n",
            "[31, 48]\n",
            "['Ferdinand Magellan']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Magellan', 'Colombo', 'Vasco', 'da', 'Gama', 'Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7510\n",
            "sentence:  Magellan Colombo Vasco da Gama Henry Ferdinand Magellan (1480-1521) là người đầu tiên trên thế giới thực hiện chuyến đi vòng quanh thế giới.\n",
            "\n",
            "entity:  {'text': 'Henry', 'pos': [31, 36]}\n",
            "entity index list:  [4]\n",
            "['Henry']\n",
            "[26, 31]\n",
            "Underthesea word_tokenize:  ['Magellan', 'Colombo Vasco', 'da', 'Gama Henry Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Magellan', 'Colombo Vasco', 'da', 'Gama', 'Henry', 'Ferdinand Magellan', '(', '1480', '-', '1521', ')', 'là', 'người', 'đầu tiên', 'trên', 'thế giới', 'thực hiện', 'chuyến', 'đi', 'vòng quanh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7534\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Bắc Băng Dương', 'pos': [0, 14]}\n",
            "entity index list:  [0]\n",
            "['Bắc Băng Dương']\n",
            "[0, 12]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "entity:  {'text': 'Ấn Độ Dương', 'pos': [15, 26]}\n",
            "entity index list:  [1, 2]\n",
            "[12, 21]\n",
            "['Ấn Độ', 'Dương']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 2:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7535\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Bắc Băng Dương', 'pos': [0, 14]}\n",
            "entity index list:  [0]\n",
            "['Bắc Băng Dương']\n",
            "[0, 12]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "entity:  {'text': 'Đại Tây Dương', 'pos': [27, 40]}\n",
            "entity index list:  [3]\n",
            "[21, 32]\n",
            "['Đại Tây Dương']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 2:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7536\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Bắc Băng Dương', 'pos': [0, 14]}\n",
            "entity index list:  [0]\n",
            "['Bắc Băng Dương']\n",
            "[0, 12]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7537\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Bắc Băng Dương', 'pos': [0, 14]}\n",
            "entity index list:  [0]\n",
            "['Bắc Băng Dương']\n",
            "[0, 12]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7538\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Bắc Băng Dương', 'pos': [0, 14]}\n",
            "entity index list:  [0]\n",
            "['Bắc Băng Dương']\n",
            "[0, 12]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7539\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Ấn Độ Dương', 'pos': [15, 26]}\n",
            "entity index list:  [1, 2]\n",
            "['Ấn Độ', 'Dương']\n",
            "[12, 21]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7540\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Ấn Độ Dương', 'pos': [15, 26]}\n",
            "entity index list:  [1, 2]\n",
            "['Ấn Độ', 'Dương']\n",
            "[12, 21]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7541\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Ấn Độ Dương', 'pos': [15, 26]}\n",
            "entity index list:  [1, 2]\n",
            "['Ấn Độ', 'Dương']\n",
            "[12, 21]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7542\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Ấn Độ Dương', 'pos': [15, 26]}\n",
            "entity index list:  [1, 2]\n",
            "['Ấn Độ', 'Dương']\n",
            "[12, 21]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương', 'Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7543\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Đại Tây Dương', 'pos': [27, 40]}\n",
            "entity index list:  [2]\n",
            "['Đại Tây Dương']\n",
            "[21, 32]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7544\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Đại Tây Dương', 'pos': [27, 40]}\n",
            "entity index list:  [2]\n",
            "['Đại Tây Dương']\n",
            "[21, 32]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7545\n",
            "sentence:  Bắc Băng Dương Ấn Độ Dương Đại Tây Dương Thái Bình Dương Thái Bình Dương chính là đại dương lớn được Magellan đặt tên.\n",
            "\n",
            "entity:  {'text': 'Đại Tây Dương', 'pos': [27, 40]}\n",
            "entity index list:  [2]\n",
            "['Đại Tây Dương']\n",
            "[21, 32]\n",
            "Underthesea word_tokenize:  ['Bắc Băng Dương Ấn Độ', 'Dương Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "My word_tokenize 1:         ['Bắc Băng Dương Ấn Độ', 'Dương', 'Đại Tây Dương', 'Thái Bình Dương', 'Thái Bình Dương', 'chính', 'là', 'đại dương', 'lớn', 'được', 'Magellan', 'đặt', 'tên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7549\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [9, 22]}\n",
            "entity index list:  [1, 2, 3]\n",
            "[8, 19]\n",
            "['Vasco', 'da', 'Gama']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 2:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7550\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Henry Wiliams', 'pos': [23, 36]}\n",
            "entity index list:  [4]\n",
            "[19, 31]\n",
            "['Henry Wiliams']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 2:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7554\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [9, 22]}\n",
            "entity index list:  [1, 2, 3]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[8, 19]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7555\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [9, 22]}\n",
            "entity index list:  [1, 2, 3]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[8, 19]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7556\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [9, 22]}\n",
            "entity index list:  [1, 2, 3]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[8, 19]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7557\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Vasco da Gama', 'pos': [9, 22]}\n",
            "entity index list:  [1, 2, 3]\n",
            "['Vasco', 'da', 'Gama']\n",
            "[8, 19]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7558\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Henry Wiliams', 'pos': [23, 36]}\n",
            "entity index list:  [4]\n",
            "['Henry Wiliams']\n",
            "[19, 31]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7559\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Henry Wiliams', 'pos': [23, 36]}\n",
            "entity index list:  [4]\n",
            "['Henry Wiliams']\n",
            "[19, 31]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7560\n",
            "sentence:  Colombus Vasco da Gama Henry Wiliams Sáng sớm 12/10/1492, trên cuộc hành trình đi tìm Ấn Ðộ bằng đường biển, nhà hàng hải Christopher Columbus đã khám phá ra Châu Mỹ , miền đất chưa ai biết đến.\n",
            "\n",
            "entity:  {'text': 'Henry Wiliams', 'pos': [23, 36]}\n",
            "entity index list:  [4]\n",
            "['Henry Wiliams']\n",
            "[19, 31]\n",
            "Underthesea word_tokenize:  ['Colombus', 'Vasco', 'da', 'Gama Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "My word_tokenize 1:         ['Colombus', 'Vasco', 'da', 'Gama', 'Henry Wiliams', 'Sáng sớm', '12/10/1492', ',', 'trên', 'cuộc', 'hành trình', 'đi', 'tìm', 'Ấn Ðộ', 'bằng', 'đường biển', ',', 'nhà hàng hải', 'Christopher Columbus', 'đã', 'khám phá', 'ra', 'Châu Mỹ', ',', 'miền', 'đất', 'chưa', 'ai', 'biết', 'đến', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7566\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "[12, 20]\n",
            "['Bồ Đào', 'Nha']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7567\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Columbus', 'pos': [26, 34]}\n",
            "entity index list:  [5]\n",
            "[20, 28]\n",
            "['Columbus']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7571\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "[12, 20]\n",
            "['Bồ Đào', 'Nha']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7572\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Columbus', 'pos': [26, 34]}\n",
            "entity index list:  [5]\n",
            "[20, 28]\n",
            "['Columbus']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7575\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "[12, 20]\n",
            "['Bồ Đào', 'Nha']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7576\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Columbus', 'pos': [26, 34]}\n",
            "entity index list:  [5]\n",
            "[20, 28]\n",
            "['Columbus']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 2:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7579\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "['Bồ Đào', 'Nha']\n",
            "[12, 20]\n",
            "Underthesea word_tokenize:  ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7580\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "['Bồ Đào', 'Nha']\n",
            "[12, 20]\n",
            "Underthesea word_tokenize:  ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7581\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Bồ Đào Nha', 'pos': [15, 25]}\n",
            "entity index list:  [3, 4]\n",
            "['Bồ Đào', 'Nha']\n",
            "[12, 20]\n",
            "Underthesea word_tokenize:  ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7582\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Columbus', 'pos': [26, 34]}\n",
            "entity index list:  [5]\n",
            "['Columbus']\n",
            "[20, 28]\n",
            "Underthesea word_tokenize:  ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7583\n",
            "sentence:  Anh Đức Italia Bồ Đào Nha Columbus là nhà hàng hải nổi tiếng, ông sinh ra ở Italia , nhưng sau đó gia nhập vào hải quân của Tây Ban Nha .\n",
            "\n",
            "entity:  {'text': 'Columbus', 'pos': [26, 34]}\n",
            "entity index list:  [5]\n",
            "['Columbus']\n",
            "[20, 28]\n",
            "Underthesea word_tokenize:  ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "My word_tokenize 1:         ['Anh', 'Đức', 'Italia', 'Bồ Đào', 'Nha', 'Columbus', 'là', 'nhà hàng hải', 'nổi tiếng', ',', 'ông', 'sinh', 'ra', 'ở', 'Italia', ',', 'nhưng', 'sau', 'đó', 'gia nhập', 'vào', 'hải quân', 'của', 'Tây', 'Ban Nha', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7606\n",
            "sentence:  Thắng đậm chủ nhà 9-0, U16 Việt Nam sẽ quyết chiến Australia Tạo ra thế trận vượt trội, U16 Việt Nam dễ dàng đánh bại chủ nhà Mông Cổ với tỷ số 9-0.\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [51, 60]}\n",
            "entity index list:  [10]\n",
            "[40, 49]\n",
            "['Australia']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia', 'Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7609\n",
            "sentence:  Thắng đậm chủ nhà 9-0, U16 Việt Nam sẽ quyết chiến Australia Tạo ra thế trận vượt trội, U16 Việt Nam dễ dàng đánh bại chủ nhà Mông Cổ với tỷ số 9-0.\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [51, 60]}\n",
            "entity index list:  [10]\n",
            "['Australia']\n",
            "[40, 49]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia', 'Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7610\n",
            "sentence:  Thắng đậm chủ nhà 9-0, U16 Việt Nam sẽ quyết chiến Australia Tạo ra thế trận vượt trội, U16 Việt Nam dễ dàng đánh bại chủ nhà Mông Cổ với tỷ số 9-0.\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [51, 60]}\n",
            "entity index list:  [10]\n",
            "['Australia']\n",
            "[40, 49]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'chủ', 'nhà', '9-0', ',', 'U16', 'Việt Nam', 'sẽ', 'quyết chiến', 'Australia', 'Tạo', 'ra', 'thế trận', 'vượt trội', ',', 'U16', 'Việt Nam', 'dễ dàng', 'đánh bại', 'chủ', 'nhà', 'Mông Cổ', 'với', 'tỷ số', '9-0', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7613\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7614\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7615\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7616\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7617\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7618\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7619\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7620\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7621\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7622\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7623\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7624\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': 'U16 Mông Cổ', 'pos': [16, 27]}\n",
            "entity index list:  [6, 7]\n",
            "['U16', 'Mông Cổ']\n",
            "[13, 22]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7625\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7626\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7627\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7628\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7629\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7630\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7631\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7632\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7633\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7634\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7635\n",
            "sentence:  *15h ngày 22/9: U16 Mông Cổ  0-9 U16 Việt Nam (sân MFF Football Centre , Ulan Bator ) U16 Việt Nam : Nguyên Hoàng 13', Thanh Trung 24' (pen), Chí Bảo 50', 61', 65', 88', Minh Đan 53', Quốc Hoàng 57', Thanh Hậu 76' Trước đội chủ nhà U16 Mông Cổ quá yếu, U16 Việt Nam không gặp nhiều khó khăn để giành chiến thắng rất đậm.\n",
            "\n",
            "entity:  {'text': '0-9\\xa0U16 Việt Nam', 'pos': [29, 45]}\n",
            "entity index list:  [8, 9, 10]\n",
            "['0-9', 'U16', 'Việt Nam']\n",
            "[22, 35]\n",
            "Underthesea word_tokenize:  ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ 0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "My word_tokenize 1:         ['*', '15', 'h', 'ngày', '22/9', ':', 'U16', 'Mông Cổ', '0-9', 'U16', 'Việt Nam', '(', 'sân', 'MFF Football Centre', ',', 'Ulan Bator', ')', 'U16', 'Việt Nam', ':', 'Nguyên', 'Hoàng', '13', \"'\", ',', 'Thanh Trung', '24', \"'\", '(', 'pen', ')', ',', 'Chí Bảo', '50', \"'\", ',', '61', \"'\", ',', '65', \"'\", ',', '88', \"'\", ',', 'Minh Đan', '53', \"'\", ',', 'Quốc Hoàng', '57', \"'\", ',', 'Thanh Hậu', '76', \"'\", 'Trước', 'đội', 'chủ', 'nhà', 'U16 Mông Cổ', 'quá', 'yếu', ',', 'U16', 'Việt Nam', 'không', 'gặp', 'nhiều', 'khó khăn', 'để', 'giành', 'chiến thắng', 'rất', 'đậm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7728\n",
            "sentence:  Sau pha phối hợp trung lộ rất hay, Nguyên Hoàng phá bấy việt vị thoát xuống, vượt qua cả thủ thành U16 Mông Cổ trước khi dễ dàng đệm lòng vào lưới trống.\n",
            "\n",
            "entity:  {'text': 'Nguyên Hoàng', 'pos': [35, 47]}\n",
            "entity index list:  [7, 8]\n",
            "['Nguyên', 'Hoàng']\n",
            "[27, 38]\n",
            "Underthesea word_tokenize:  ['Sau', 'pha', 'phối hợp', 'trung lộ', 'rất', 'hay', ',', 'Nguyên', 'Hoàng phá', 'bấy', 'việt vị', 'thoát', 'xuống', ',', 'vượt', 'qua', 'cả', 'thủ thành', 'U16 Mông Cổ', 'trước', 'khi', 'dễ dàng', 'đệm', 'lòng', 'vào', 'lưới', 'trống', '.']\n",
            "My word_tokenize 1:         ['Sau', 'pha', 'phối hợp', 'trung lộ', 'rất', 'hay', ',', 'Nguyên', 'Hoàng', 'phá', 'bấy', 'việt vị', 'thoát', 'xuống', ',', 'vượt', 'qua', 'cả', 'thủ thành', 'U16 Mông Cổ', 'trước', 'khi', 'dễ dàng', 'đệm', 'lòng', 'vào', 'lưới', 'trống', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7766\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Đức', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['Đức']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7767\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Đức', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['Đức']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7768\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Đức', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['Đức']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7769\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Đức', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['Đức']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7770\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Angela Merkel', 'pos': [14, 27]}\n",
            "entity index list:  [2]\n",
            "['Angela Merkel']\n",
            "[11, 23]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7771\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Angela Merkel', 'pos': [14, 27]}\n",
            "entity index list:  [2]\n",
            "['Angela Merkel']\n",
            "[11, 23]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7772\n",
            "sentence:  Thủ tướng Đức Angela Merkel trong một chiến dịch vận động tranh cử ở Kappeln , miền bắc Đức ngày 20/9.\n",
            "\n",
            "entity:  {'text': 'Angela Merkel', 'pos': [14, 27]}\n",
            "entity index list:  [2]\n",
            "['Angela Merkel']\n",
            "[11, 23]\n",
            "Underthesea word_tokenize:  ['Thủ tướng', 'Đức Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "My word_tokenize 1:         ['Thủ tướng', 'Đức', 'Angela Merkel', 'trong', 'một', 'chiến dịch', 'vận động', 'tranh cử', 'ở', 'Kappeln', ',', 'miền', 'bắc', 'Đức', 'ngày', '20/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7804\n",
            "sentence:  Nhìn vào tương quan lực lượng trên chính trường Đức , có thể thấy việc liên đảng CDU /CSU của đương kim Thủ tướng Angela Merkel tiếp tục giành sự ủng hộ cao là điều dễ hiểu.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [81, 84]}\n",
            "entity index list:  [12]\n",
            "[64, 67]\n",
            "['CDU']\n",
            "My word_tokenize 1:         ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "My word_tokenize 2:         ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng', 'CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7807\n",
            "sentence:  Nhìn vào tương quan lực lượng trên chính trường Đức , có thể thấy việc liên đảng CDU /CSU của đương kim Thủ tướng Angela Merkel tiếp tục giành sự ủng hộ cao là điều dễ hiểu.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [81, 84]}\n",
            "entity index list:  [12]\n",
            "['CDU']\n",
            "[64, 67]\n",
            "Underthesea word_tokenize:  ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "My word_tokenize 1:         ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng', 'CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7808\n",
            "sentence:  Nhìn vào tương quan lực lượng trên chính trường Đức , có thể thấy việc liên đảng CDU /CSU của đương kim Thủ tướng Angela Merkel tiếp tục giành sự ủng hộ cao là điều dễ hiểu.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [81, 84]}\n",
            "entity index list:  [12]\n",
            "['CDU']\n",
            "[64, 67]\n",
            "Underthesea word_tokenize:  ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "My word_tokenize 1:         ['Nhìn', 'vào', 'tương quan lực lượng', 'trên', 'chính trường', 'Đức', ',', 'có thể', 'thấy', 'việc', 'liên', 'đảng', 'CDU', '/', 'CSU', 'của', 'đương kim', 'Thủ tướng', 'Angela Merkel', 'tiếp tục', 'giành', 'sự', 'ủng hộ', 'cao', 'là', 'điều', 'dễ', 'hiểu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7930\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "[257, 259]\n",
            "['EU']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 2:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7939\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "[257, 259]\n",
            "['EU']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 2:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7947\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "[257, 259]\n",
            "['EU']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 2:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7955\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7956\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7957\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7958\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7959\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7960\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  7961\n",
            "sentence:  Đặc biệt, khả năng đảng Sự lựa chọn vì nước Đức (AfD ), một đảng theo đường lối dân túy và có tư tưởng bài ngoại, lọt vào quốc hội năm nay, cũng đang là vấn đề gây lo ngại, nhất là trong bối cảnh chủ nghĩa dân túy đang có nguy cơ trỗi dậy ở châu Âu , với sự xuất hiện của các đảng theo đường lối dân túy và chủ nghĩa dân tộc, phản đối EU và việc sử dụng đồng tiền chung châu Âu , như đảng “Vì tự do” (PVV ) trước cuộc bầu cử quốc hội Hà Lan , hay đảng Mặt trận Quốc gia (FN ) trong cuộc bầu cử tổng thống Pháp .\n",
            "\n",
            "entity:  {'text': 'EU', 'pos': [335, 337]}\n",
            "entity index list:  [64]\n",
            "['EU']\n",
            "[257, 259]\n",
            "Underthesea word_tokenize:  ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "My word_tokenize 1:         ['Đặc biệt', ',', 'khả năng', 'đảng', 'Sự', 'lựa chọn', 'vì', 'nước', 'Đức', '(', 'AfD', ')', ',', 'một', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'có', 'tư tưởng', 'bài', 'ngoại', ',', 'lọt', 'vào', 'quốc hội', 'năm', 'nay', ',', 'cũng', 'đang', 'là', 'vấn đề', 'gây', 'lo ngại', ',', 'nhất là', 'trong', 'bối cảnh', 'chủ nghĩa', 'dân túy', 'đang', 'có', 'nguy cơ', 'trỗi', 'dậy', 'ở', 'châu Âu', ',', 'với', 'sự', 'xuất hiện', 'của', 'các', 'đảng', 'theo', 'đường lối', 'dân túy', 'và', 'chủ nghĩa', 'dân tộc', ',', 'phản đối', 'EU', 'và', 'việc', 'sử dụng', 'đồng tiền', 'chung', 'châu Âu', ',', 'như', 'đảng', '“', 'Vì', 'tự do', '”', '(', 'PVV', ')', 'trước', 'cuộc', 'bầu cử', 'quốc hội', 'Hà Lan', ',', 'hay', 'đảng', 'Mặt trận', 'Quốc gia', '(', 'FN', ')', 'trong', 'cuộc', 'bầu cử', 'tổng thống', 'Pháp', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8007\n",
            "sentence:  Liên minh CDU /CSU và FDP có thể lôi kéo thêm đảng Xanh , nếu đảng này có ghế.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['CDU']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Liên minh CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "My word_tokenize 1:         ['Liên minh', 'CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8008\n",
            "sentence:  Liên minh CDU /CSU và FDP có thể lôi kéo thêm đảng Xanh , nếu đảng này có ghế.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['CDU']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Liên minh CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "My word_tokenize 1:         ['Liên minh', 'CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8009\n",
            "sentence:  Liên minh CDU /CSU và FDP có thể lôi kéo thêm đảng Xanh , nếu đảng này có ghế.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [10, 13]}\n",
            "entity index list:  [1]\n",
            "['CDU']\n",
            "[8, 11]\n",
            "Underthesea word_tokenize:  ['Liên minh CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "My word_tokenize 1:         ['Liên minh', 'CDU', '/', 'CSU', 'và', 'FDP', 'có thể', 'lôi kéo', 'thêm', 'đảng Xanh', ',', 'nếu', 'đảng', 'này', 'có', 'ghế', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8014\n",
            "sentence:  Trong trường hợp liên đảng CDU /CSU không có khả năng thành lập một chính phủ, hoàn toàn có thể xảy ra kịch bản SPD , nếu làm tốt hơn kỳ vọng trong cuộc bầu cử tới, sẽ đứng ra tập hợp một chính phủ đa số tại Quốc hội với sự ủng hộ của các đảng nhỏ.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [27, 30]}\n",
            "entity index list:  [4]\n",
            "['CDU']\n",
            "[22, 25]\n",
            "Underthesea word_tokenize:  ['Trong', 'trường hợp', 'liên', 'đảng CDU', '/', 'CSU', 'không', 'có', 'khả năng', 'thành lập', 'một', 'chính phủ', ',', 'hoàn toàn', 'có thể', 'xảy', 'ra', 'kịch bản', 'SPD', ',', 'nếu', 'làm', 'tốt', 'hơn', 'kỳ vọng', 'trong', 'cuộc', 'bầu cử', 'tới', ',', 'sẽ', 'đứng', 'ra', 'tập hợp', 'một', 'chính phủ', 'đa số', 'tại', 'Quốc hội', 'với', 'sự', 'ủng hộ', 'của', 'các', 'đảng', 'nhỏ', '.']\n",
            "My word_tokenize 1:         ['Trong', 'trường hợp', 'liên', 'đảng', 'CDU', '/', 'CSU', 'không', 'có', 'khả năng', 'thành lập', 'một', 'chính phủ', ',', 'hoàn toàn', 'có thể', 'xảy', 'ra', 'kịch bản', 'SPD', ',', 'nếu', 'làm', 'tốt', 'hơn', 'kỳ vọng', 'trong', 'cuộc', 'bầu cử', 'tới', ',', 'sẽ', 'đứng', 'ra', 'tập hợp', 'một', 'chính phủ', 'đa số', 'tại', 'Quốc hội', 'với', 'sự', 'ủng hộ', 'của', 'các', 'đảng', 'nhỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8015\n",
            "sentence:  Trong trường hợp liên đảng CDU /CSU không có khả năng thành lập một chính phủ, hoàn toàn có thể xảy ra kịch bản SPD , nếu làm tốt hơn kỳ vọng trong cuộc bầu cử tới, sẽ đứng ra tập hợp một chính phủ đa số tại Quốc hội với sự ủng hộ của các đảng nhỏ.\n",
            "\n",
            "entity:  {'text': 'CDU', 'pos': [27, 30]}\n",
            "entity index list:  [4]\n",
            "['CDU']\n",
            "[22, 25]\n",
            "Underthesea word_tokenize:  ['Trong', 'trường hợp', 'liên', 'đảng CDU', '/', 'CSU', 'không', 'có', 'khả năng', 'thành lập', 'một', 'chính phủ', ',', 'hoàn toàn', 'có thể', 'xảy', 'ra', 'kịch bản', 'SPD', ',', 'nếu', 'làm', 'tốt', 'hơn', 'kỳ vọng', 'trong', 'cuộc', 'bầu cử', 'tới', ',', 'sẽ', 'đứng', 'ra', 'tập hợp', 'một', 'chính phủ', 'đa số', 'tại', 'Quốc hội', 'với', 'sự', 'ủng hộ', 'của', 'các', 'đảng', 'nhỏ', '.']\n",
            "My word_tokenize 1:         ['Trong', 'trường hợp', 'liên', 'đảng', 'CDU', '/', 'CSU', 'không', 'có', 'khả năng', 'thành lập', 'một', 'chính phủ', ',', 'hoàn toàn', 'có thể', 'xảy', 'ra', 'kịch bản', 'SPD', ',', 'nếu', 'làm', 'tốt', 'hơn', 'kỳ vọng', 'trong', 'cuộc', 'bầu cử', 'tới', ',', 'sẽ', 'đứng', 'ra', 'tập hợp', 'một', 'chính phủ', 'đa số', 'tại', 'Quốc hội', 'với', 'sự', 'ủng hộ', 'của', 'các', 'đảng', 'nhỏ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8102\n",
            "sentence:  Sự có mặt của cầu thủ nhập tịch này đã giúp Quảng Nam tạo ra những cơ hội liên tiếp về khung thành Văn Phong .\n",
            "\n",
            "entity:  {'text': 'Văn Phong', 'pos': [99, 108]}\n",
            "entity index list:  [16]\n",
            "[76, 84]\n",
            "['Văn Phong']\n",
            "My word_tokenize 1:         ['Sự', 'có mặt', 'của', 'cầu thủ', 'nhập tịch', 'này', 'đã', 'giúp', 'Quảng Nam', 'tạo', 'ra', 'những', 'cơ hội', 'liên tiếp', 'về', 'khung thành Văn Phong', '.']\n",
            "My word_tokenize 2:         ['Sự', 'có mặt', 'của', 'cầu thủ', 'nhập tịch', 'này', 'đã', 'giúp', 'Quảng Nam', 'tạo', 'ra', 'những', 'cơ hội', 'liên tiếp', 'về', 'khung thành', 'Văn Phong', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8301\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "[21, 30]\n",
            "['Triều', 'Tiên']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 2:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8302\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [39, 42]}\n",
            "entity index list:  [7]\n",
            "[30, 33]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 2:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8306\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "[21, 30]\n",
            "['Triều', 'Tiên']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 2:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8307\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [39, 42]}\n",
            "entity index list:  [7]\n",
            "[30, 33]\n",
            "['Nga']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 2:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8311\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "['Triều', 'Tiên']\n",
            "[21, 30]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8312\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "['Triều', 'Tiên']\n",
            "[21, 30]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8313\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "['Triều', 'Tiên']\n",
            "[21, 30]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8314\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Triều Tiên', 'pos': [28, 38]}\n",
            "entity index list:  [5, 6]\n",
            "['Triều', 'Tiên']\n",
            "[21, 30]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8315\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [39, 42]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8316\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [39, 42]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8317\n",
            "sentence:  Nga tiếp tục cảnh báo Mỹ về Triều Tiên Nga tiếp tục cảnh báo Mỹ về Triều Tiên , liên quan đến thỏa thuận hạt nhân với Iran .\n",
            "\n",
            "entity:  {'text': 'Nga', 'pos': [39, 42]}\n",
            "entity index list:  [7]\n",
            "['Nga']\n",
            "[30, 33]\n",
            "Underthesea word_tokenize:  ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "My word_tokenize 1:         ['Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều', 'Tiên', 'Nga', 'tiếp tục', 'cảnh báo', 'Mỹ', 'về', 'Triều Tiên', ',', 'liên quan', 'đến', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8321\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "[11, 22]\n",
            "['Liên Hợp Quốc']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8322\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Vasily Nebenzya', 'pos': [29, 44]}\n",
            "entity index list:  [4]\n",
            "[22, 36]\n",
            "['Vasily Nebenzya']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 2:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8327\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "['Liên Hợp Quốc']\n",
            "[11, 22]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8328\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "['Liên Hợp Quốc']\n",
            "[11, 22]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8329\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "['Liên Hợp Quốc']\n",
            "[11, 22]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8330\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "['Liên Hợp Quốc']\n",
            "[11, 22]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8331\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Liên Hợp Quốc', 'pos': [15, 28]}\n",
            "entity index list:  [3]\n",
            "['Liên Hợp Quốc']\n",
            "[11, 22]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8332\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Vasily Nebenzya', 'pos': [29, 44]}\n",
            "entity index list:  [4]\n",
            "['Vasily Nebenzya']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8333\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Vasily Nebenzya', 'pos': [29, 44]}\n",
            "entity index list:  [4]\n",
            "['Vasily Nebenzya']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8334\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Vasily Nebenzya', 'pos': [29, 44]}\n",
            "entity index list:  [4]\n",
            "['Vasily Nebenzya']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8335\n",
            "sentence:  Đại sứ Nga tại Liên Hợp Quốc Vasily Nebenzya cảnh báo rằng nếu Mỹ đơn phương hủy bỏ thỏa thuận hạt nhân với Iran thì đây sẽ là tín hiệu sai lầm mà Washington muốn gửi đến Triều Tiên .\n",
            "\n",
            "entity:  {'text': 'Vasily Nebenzya', 'pos': [29, 44]}\n",
            "entity index list:  [4]\n",
            "['Vasily Nebenzya']\n",
            "[22, 36]\n",
            "Underthesea word_tokenize:  ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "My word_tokenize 1:         ['Đại sứ', 'Nga', 'tại', 'Liên Hợp Quốc', 'Vasily Nebenzya', 'cảnh báo', 'rằng', 'nếu', 'Mỹ', 'đơn phương', 'hủy bỏ', 'thỏa thuận', 'hạt nhân', 'với', 'Iran', 'thì', 'đây', 'sẽ', 'là', 'tín hiệu', 'sai lầm', 'mà', 'Washington', 'muốn', 'gửi', 'đến', 'Triều Tiên', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8359\n",
            "sentence:  Cuộc họp có sự tham dự của Ngoại trưởng Hoa Kỳ Rex Tillerson và bộ trưởng ngoại giao của nhiều nước khác.\n",
            "\n",
            "entity:  {'text': 'Hoa Kỳ', 'pos': [40, 46]}\n",
            "entity index list:  [6]\n",
            "['Hoa Kỳ']\n",
            "[31, 36]\n",
            "Underthesea word_tokenize:  ['Cuộc họp', 'có', 'sự', 'tham dự', 'của', 'Ngoại trưởng', 'Hoa Kỳ Rex Tillerson', 'và', 'bộ trưởng', 'ngoại giao', 'của', 'nhiều', 'nước', 'khác', '.']\n",
            "My word_tokenize 1:         ['Cuộc họp', 'có', 'sự', 'tham dự', 'của', 'Ngoại trưởng', 'Hoa Kỳ', 'Rex Tillerson', 'và', 'bộ trưởng', 'ngoại giao', 'của', 'nhiều', 'nước', 'khác', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8386\n",
            "sentence:  (Ngoisao.net) Trong một sự kiện mới đây tại Hà Nội , Hoa hậu Jennifer Phạm gây bất ngờ khi vừa làm MC vừa trổ tài ca hát, khoe vũ đạo bốc lửa trên sân khấu.\n",
            "\n",
            "entity:  {'text': 'Jennifer Phạm', 'pos': [61, 74]}\n",
            "entity index list:  [13, 14]\n",
            "[48, 60]\n",
            "['Jennifer', 'Phạm']\n",
            "My word_tokenize 1:         ['(', 'Ngoisao', '.', 'net', ')', 'Trong', 'một', 'sự kiện', 'mới đây', 'tại', 'Hà Nội', ',', 'Hoa hậu', 'Jennifer', 'Phạm gây', 'bất ngờ', 'khi', 'vừa', 'làm', 'MC', 'vừa', 'trổ tài', 'ca hát', ',', 'khoe', 'vũ đạo', 'bốc lửa', 'trên', 'sân khấu', '.']\n",
            "My word_tokenize 2:         ['(', 'Ngoisao', '.', 'net', ')', 'Trong', 'một', 'sự kiện', 'mới đây', 'tại', 'Hà Nội', ',', 'Hoa hậu', 'Jennifer', 'Phạm', 'gây', 'bất ngờ', 'khi', 'vừa', 'làm', 'MC', 'vừa', 'trổ tài', 'ca hát', ',', 'khoe', 'vũ đạo', 'bốc lửa', 'trên', 'sân khấu', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8387\n",
            "sentence:  (VOV ) Siêu mẫu nội y Alessandra Ambrosio diện đồ hở bạo tham dự tiệc từ thiện gây quỹ phòng chống căn bệnh AIDS tối 21/9.\n",
            "\n",
            "entity:  {'text': 'Alessandra Ambrosio', 'pos': [22, 41]}\n",
            "entity index list:  [7]\n",
            "[16, 34]\n",
            "['Alessandra Ambrosio']\n",
            "My word_tokenize 1:         ['(', 'VOV', ')', 'Siêu', 'mẫu', 'nội', 'y Alessandra Ambrosio', 'diện', 'đồ', 'hở', 'bạo', 'tham dự', 'tiệc', 'từ thiện', 'gây', 'quỹ', 'phòng chống', 'căn bệnh', 'AIDS', 'tối', '21/9', '.']\n",
            "My word_tokenize 2:         ['(', 'VOV', ')', 'Siêu', 'mẫu', 'nội', 'y', 'Alessandra Ambrosio', 'diện', 'đồ', 'hở', 'bạo', 'tham dự', 'tiệc', 'từ thiện', 'gây', 'quỹ', 'phòng chống', 'căn bệnh', 'AIDS', 'tối', '21/9', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8402\n",
            "sentence:  Hành trình khám phá hương vị hoàn hảo không đổi vươt thời gian của Heineken Nhằm thỏa mãn nhu cầu hiểu rõ hơn về câu chuyện thương hiệu của người tiêu dùng, nhãn hàng Heineken giới thiệu đến người hâm mộ tại Việt Nam một chuỗi câu chuyện đầy cảm hứng xoay quanh những giá trị hoàn hảo của thương hiệu bia lừng danh thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [67, 75]}\n",
            "entity index list:  [8]\n",
            "['Heineken']\n",
            "[53, 61]\n",
            "Underthesea word_tokenize:  ['Hành trình', 'khám phá', 'hương vị', 'hoàn hảo', 'không đổi', 'vươt', 'thời gian', 'của', 'Heineken Nhằm', 'thỏa mãn', 'nhu cầu', 'hiểu', 'rõ', 'hơn', 'về', 'câu chuyện', 'thương hiệu', 'của', 'người', 'tiêu dùng', ',', 'nhãn', 'hàng', 'Heineken', 'giới thiệu', 'đến', 'người', 'hâm mộ', 'tại', 'Việt Nam', 'một', 'chuỗi', 'câu chuyện', 'đầy', 'cảm hứng', 'xoay', 'quanh', 'những', 'giá trị', 'hoàn hảo', 'của', 'thương hiệu', 'bia', 'lừng danh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Hành trình', 'khám phá', 'hương vị', 'hoàn hảo', 'không đổi', 'vươt', 'thời gian', 'của', 'Heineken', 'Nhằm', 'thỏa mãn', 'nhu cầu', 'hiểu', 'rõ', 'hơn', 'về', 'câu chuyện', 'thương hiệu', 'của', 'người', 'tiêu dùng', ',', 'nhãn', 'hàng', 'Heineken', 'giới thiệu', 'đến', 'người', 'hâm mộ', 'tại', 'Việt Nam', 'một', 'chuỗi', 'câu chuyện', 'đầy', 'cảm hứng', 'xoay', 'quanh', 'những', 'giá trị', 'hoàn hảo', 'của', 'thương hiệu', 'bia', 'lừng danh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8403\n",
            "sentence:  Hành trình khám phá hương vị hoàn hảo không đổi vươt thời gian của Heineken Nhằm thỏa mãn nhu cầu hiểu rõ hơn về câu chuyện thương hiệu của người tiêu dùng, nhãn hàng Heineken giới thiệu đến người hâm mộ tại Việt Nam một chuỗi câu chuyện đầy cảm hứng xoay quanh những giá trị hoàn hảo của thương hiệu bia lừng danh thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [67, 75]}\n",
            "entity index list:  [8]\n",
            "['Heineken']\n",
            "[53, 61]\n",
            "Underthesea word_tokenize:  ['Hành trình', 'khám phá', 'hương vị', 'hoàn hảo', 'không đổi', 'vươt', 'thời gian', 'của', 'Heineken Nhằm', 'thỏa mãn', 'nhu cầu', 'hiểu', 'rõ', 'hơn', 'về', 'câu chuyện', 'thương hiệu', 'của', 'người', 'tiêu dùng', ',', 'nhãn', 'hàng', 'Heineken', 'giới thiệu', 'đến', 'người', 'hâm mộ', 'tại', 'Việt Nam', 'một', 'chuỗi', 'câu chuyện', 'đầy', 'cảm hứng', 'xoay', 'quanh', 'những', 'giá trị', 'hoàn hảo', 'của', 'thương hiệu', 'bia', 'lừng danh', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Hành trình', 'khám phá', 'hương vị', 'hoàn hảo', 'không đổi', 'vươt', 'thời gian', 'của', 'Heineken', 'Nhằm', 'thỏa mãn', 'nhu cầu', 'hiểu', 'rõ', 'hơn', 'về', 'câu chuyện', 'thương hiệu', 'của', 'người', 'tiêu dùng', ',', 'nhãn', 'hàng', 'Heineken', 'giới thiệu', 'đến', 'người', 'hâm mộ', 'tại', 'Việt Nam', 'một', 'chuỗi', 'câu chuyện', 'đầy', 'cảm hứng', 'xoay', 'quanh', 'những', 'giá trị', 'hoàn hảo', 'của', 'thương hiệu', 'bia', 'lừng danh', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8409\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [62, 70]}\n",
            "entity index list:  [11]\n",
            "['Heineken']\n",
            "[48, 56]\n",
            "Underthesea word_tokenize:  ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8410\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [62, 70]}\n",
            "entity index list:  [11]\n",
            "['Heineken']\n",
            "[48, 56]\n",
            "Underthesea word_tokenize:  ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8411\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [62, 70]}\n",
            "entity index list:  [11]\n",
            "['Heineken']\n",
            "[48, 56]\n",
            "Underthesea word_tokenize:  ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8412\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [62, 70]}\n",
            "entity index list:  [11]\n",
            "['Heineken']\n",
            "[48, 56]\n",
            "Underthesea word_tokenize:  ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [292, 300]}\n",
            "entity index list:  [45]\n",
            "[229, 237]\n",
            "['Heineken']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia', 'Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia', 'Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8415\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [292, 300]}\n",
            "entity index list:  [44]\n",
            "[229, 237]\n",
            "['Heineken']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia', 'Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8417\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [292, 300]}\n",
            "entity index list:  [44]\n",
            "[229, 237]\n",
            "['Heineken']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia', 'Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8418\n",
            "sentence:  Là người nắm giữ công thức và nghệ thuật tạo nên hương vị bia Heineken hoàn hảo được yêu thích trên khắp 192 quốc gia, Willem van Waesberghe – chuyên gia ủ bia toàn cầu của Heineken sẽ lần đầu tiên bật mí cho người hâm mộ Việt Nam những bí mật làm nên những giá trị hoàn hảo của hương vị bia Heineken chinh phục cả thế giới.\n",
            "\n",
            "entity:  {'text': 'Heineken', 'pos': [292, 300]}\n",
            "entity index list:  [44]\n",
            "[229, 237]\n",
            "['Heineken']\n",
            "My word_tokenize 1:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "My word_tokenize 2:         ['Là', 'người', 'nắm', 'giữ', 'công thức', 'và', 'nghệ thuật', 'tạo', 'nên', 'hương vị', 'bia Heineken', 'hoàn hảo', 'được', 'yêu thích', 'trên', 'khắp', '192', 'quốc gia', ',', 'Willem van Waesberghe', '–', 'chuyên gia', 'ủ', 'bia', 'toàn cầu', 'của', 'Heineken', 'sẽ', 'lần', 'đầu tiên', 'bật mí', 'cho', 'người', 'hâm mộ', 'Việt Nam', 'những', 'bí mật', 'làm nên', 'những', 'giá trị', 'hoàn hảo', 'của', 'hương vị', 'bia', 'Heineken', 'chinh phục', 'cả', 'thế giới', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8441\n",
            "sentence:  Trong phần luận tội, đại điện VKSND huyện Long Hồ nêu quan điểm và cho rằng, bị cáo Long thực hiện hành vi Giết người nhưng nửa chừng đã dừng lại.\n",
            "\n",
            "entity:  {'text': 'VKSND huyện Long Hồ', 'pos': [30, 49]}\n",
            "entity index list:  [6, 7, 8]\n",
            "['VKSND', 'huyện', 'Long Hồ']\n",
            "[24, 40]\n",
            "Underthesea word_tokenize:  ['Trong', 'phần', 'luận tội', ',', 'đại', 'điện', 'VKSND', 'huyện', 'Long Hồ nêu', 'quan điểm', 'và', 'cho', 'rằng', ',', 'bị cáo', 'Long', 'thực hiện', 'hành vi', 'Giết người', 'nhưng', 'nửa chừng', 'đã', 'dừng', 'lại', '.']\n",
            "My word_tokenize 1:         ['Trong', 'phần', 'luận tội', ',', 'đại', 'điện', 'VKSND', 'huyện', 'Long Hồ', 'nêu', 'quan điểm', 'và', 'cho', 'rằng', ',', 'bị cáo', 'Long', 'thực hiện', 'hành vi', 'Giết người', 'nhưng', 'nửa chừng', 'đã', 'dừng', 'lại', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8510\n",
            "sentence:  Cuối 2016, TAND huyện Diễn Châu tuyên bị cáo Điều 30 tháng tù về tội nhận Hối lộ, Lê Văn Ánh 15 tháng tù với vai trò đồng phạm.\n",
            "\n",
            "entity:  {'text': 'TAND huyện Diễn Châu', 'pos': [11, 31]}\n",
            "entity index list:  [3, 4, 5]\n",
            "['TAND', 'huyện', 'Diễn Châu']\n",
            "[9, 26]\n",
            "Underthesea word_tokenize:  ['Cuối', '2016', ',', 'TAND', 'huyện', 'Diễn Châu tuyên', 'bị cáo', 'Điều', '30', 'tháng', 'tù', 'về', 'tội', 'nhận', 'Hối lộ', ',', 'Lê Văn Ánh', '15', 'tháng', 'tù', 'với', 'vai trò', 'đồng phạm', '.']\n",
            "My word_tokenize 1:         ['Cuối', '2016', ',', 'TAND', 'huyện', 'Diễn Châu', 'tuyên', 'bị cáo', 'Điều', '30', 'tháng', 'tù', 'về', 'tội', 'nhận', 'Hối lộ', ',', 'Lê Văn Ánh', '15', 'tháng', 'tù', 'với', 'vai trò', 'đồng phạm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8511\n",
            "sentence:  Cuối 2016, TAND huyện Diễn Châu tuyên bị cáo Điều 30 tháng tù về tội nhận Hối lộ, Lê Văn Ánh 15 tháng tù với vai trò đồng phạm.\n",
            "\n",
            "entity:  {'text': 'TAND huyện Diễn Châu', 'pos': [11, 31]}\n",
            "entity index list:  [3, 4, 5]\n",
            "['TAND', 'huyện', 'Diễn Châu']\n",
            "[9, 26]\n",
            "Underthesea word_tokenize:  ['Cuối', '2016', ',', 'TAND', 'huyện', 'Diễn Châu tuyên', 'bị cáo', 'Điều', '30', 'tháng', 'tù', 'về', 'tội', 'nhận', 'Hối lộ', ',', 'Lê Văn Ánh', '15', 'tháng', 'tù', 'với', 'vai trò', 'đồng phạm', '.']\n",
            "My word_tokenize 1:         ['Cuối', '2016', ',', 'TAND', 'huyện', 'Diễn Châu', 'tuyên', 'bị cáo', 'Điều', '30', 'tháng', 'tù', 'về', 'tội', 'nhận', 'Hối lộ', ',', 'Lê Văn Ánh', '15', 'tháng', 'tù', 'với', 'vai trò', 'đồng phạm', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8535\n",
            "sentence:  Thế rồi, cơ duyên biết đến bài thuốc của lương y Triệu Thị Bình (Bản Yên Sơn – Ba Vì – Hà Nội ) đã cứu rỗi cuộc đời bà, bà được hồi sinh lần thứ hai trong đời...\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [49, 63]}\n",
            "entity index list:  [9]\n",
            "['Triệu Thị Bình']\n",
            "[38, 50]\n",
            "Underthesea word_tokenize:  ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "My word_tokenize 1:         ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  8536\n",
            "sentence:  Thế rồi, cơ duyên biết đến bài thuốc của lương y Triệu Thị Bình (Bản Yên Sơn – Ba Vì – Hà Nội ) đã cứu rỗi cuộc đời bà, bà được hồi sinh lần thứ hai trong đời...\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [49, 63]}\n",
            "entity index list:  [9]\n",
            "['Triệu Thị Bình']\n",
            "[38, 50]\n",
            "Underthesea word_tokenize:  ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "My word_tokenize 1:         ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  8537\n",
            "sentence:  Thế rồi, cơ duyên biết đến bài thuốc của lương y Triệu Thị Bình (Bản Yên Sơn – Ba Vì – Hà Nội ) đã cứu rỗi cuộc đời bà, bà được hồi sinh lần thứ hai trong đời...\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [49, 63]}\n",
            "entity index list:  [9]\n",
            "['Triệu Thị Bình']\n",
            "[38, 50]\n",
            "Underthesea word_tokenize:  ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "My word_tokenize 1:         ['Thế', 'rồi', ',', 'cơ duyên', 'biết', 'đến', 'bài thuốc', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'Ba Vì', '–', 'Hà Nội', ')', 'đã', 'cứu rỗi', 'cuộc đời', 'bà', ',', 'bà', 'được', 'hồi sinh', 'lần', 'thứ', 'hai', 'trong', 'đời', '...']\n",
            "\n",
            "\n",
            "---------- sent_id:  8548\n",
            "sentence:  Đang tuyệt vọng vì chưa biết chữa trị căn bệnh viêm khớp như thế nào thì bà Tản đọc được trên Khoẻ 365 có nhiều bệnh nhân bị viêm đa khớp, các bệnh về xương khớp đã chữa khỏi bệnh nhờ bài thuốc thảo dược của lương y Triệu Thị Bình (Bản Yên Sơn – xã Ba Vì – huyện Ba Vì – Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [216, 230]}\n",
            "entity index list:  [42]\n",
            "[168, 180]\n",
            "['Triệu Thị Bình']\n",
            "My word_tokenize 1:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8553\n",
            "sentence:  Đang tuyệt vọng vì chưa biết chữa trị căn bệnh viêm khớp như thế nào thì bà Tản đọc được trên Khoẻ 365 có nhiều bệnh nhân bị viêm đa khớp, các bệnh về xương khớp đã chữa khỏi bệnh nhờ bài thuốc thảo dược của lương y Triệu Thị Bình (Bản Yên Sơn – xã Ba Vì – huyện Ba Vì – Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [216, 230]}\n",
            "entity index list:  [42]\n",
            "['Triệu Thị Bình']\n",
            "[168, 180]\n",
            "Underthesea word_tokenize:  ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8554\n",
            "sentence:  Đang tuyệt vọng vì chưa biết chữa trị căn bệnh viêm khớp như thế nào thì bà Tản đọc được trên Khoẻ 365 có nhiều bệnh nhân bị viêm đa khớp, các bệnh về xương khớp đã chữa khỏi bệnh nhờ bài thuốc thảo dược của lương y Triệu Thị Bình (Bản Yên Sơn – xã Ba Vì – huyện Ba Vì – Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [216, 230]}\n",
            "entity index list:  [42]\n",
            "['Triệu Thị Bình']\n",
            "[168, 180]\n",
            "Underthesea word_tokenize:  ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8555\n",
            "sentence:  Đang tuyệt vọng vì chưa biết chữa trị căn bệnh viêm khớp như thế nào thì bà Tản đọc được trên Khoẻ 365 có nhiều bệnh nhân bị viêm đa khớp, các bệnh về xương khớp đã chữa khỏi bệnh nhờ bài thuốc thảo dược của lương y Triệu Thị Bình (Bản Yên Sơn – xã Ba Vì – huyện Ba Vì – Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [216, 230]}\n",
            "entity index list:  [42]\n",
            "['Triệu Thị Bình']\n",
            "[168, 180]\n",
            "Underthesea word_tokenize:  ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8556\n",
            "sentence:  Đang tuyệt vọng vì chưa biết chữa trị căn bệnh viêm khớp như thế nào thì bà Tản đọc được trên Khoẻ 365 có nhiều bệnh nhân bị viêm đa khớp, các bệnh về xương khớp đã chữa khỏi bệnh nhờ bài thuốc thảo dược của lương y Triệu Thị Bình (Bản Yên Sơn – xã Ba Vì – huyện Ba Vì – Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Triệu Thị Bình', 'pos': [216, 230]}\n",
            "entity index list:  [42]\n",
            "['Triệu Thị Bình']\n",
            "[168, 180]\n",
            "Underthesea word_tokenize:  ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['Đang', 'tuyệt vọng', 'vì', 'chưa', 'biết', 'chữa trị', 'căn bệnh', 'viêm', 'khớp', 'như', 'thế nào', 'thì', 'bà', 'Tản', 'đọc', 'được', 'trên', 'Khoẻ', '365', 'có', 'nhiều', 'bệnh nhân', 'bị', 'viêm', 'đa khớp', ',', 'các', 'bệnh', 'về', 'xương', 'khớp', 'đã', 'chữa', 'khỏi', 'bệnh', 'nhờ', 'bài', 'thuốc', 'thảo', 'dược', 'của', 'lương y', 'Triệu Thị Bình', '(', 'Bản Yên Sơn', '–', 'xã', 'Ba Vì', '–', 'huyện', 'Ba Vì', '–', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8563\n",
            "sentence:  Ngay sau khi được lương y Bình tư vấn, bà Tản quyết định lấy thuốc uống thử.\n",
            "\n",
            "entity:  {'text': 'Bình', 'pos': [26, 30]}\n",
            "entity index list:  [5]\n",
            "['Bình']\n",
            "[20, 24]\n",
            "Underthesea word_tokenize:  ['Ngay', 'sau', 'khi', 'được', 'lương y Bình', 'tư vấn', ',', 'bà', 'Tản', 'quyết định', 'lấy', 'thuốc', 'uống', 'thử', '.']\n",
            "My word_tokenize 1:         ['Ngay', 'sau', 'khi', 'được', 'lương y', 'Bình', 'tư vấn', ',', 'bà', 'Tản', 'quyết định', 'lấy', 'thuốc', 'uống', 'thử', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8568\n",
            "sentence:  “Tôi xin xảm ơn lương y Bình , nhờ gặp thầy gặp thuốc mà tôi đã khỏi bệnh khớp, tôi sẽ giới thiệu cho mấy bà bạn dùng sản phẩm này”, bà Tản chia sẻ.\n",
            "\n",
            "entity:  {'text': 'Bình', 'pos': [24, 28]}\n",
            "entity index list:  [6]\n",
            "['Bình']\n",
            "[18, 22]\n",
            "Underthesea word_tokenize:  ['“', 'Tôi', 'xin', 'xảm', 'ơn', 'lương y Bình', ',', 'nhờ', 'gặp', 'thầy', 'gặp', 'thuốc', 'mà', 'tôi', 'đã', 'khỏi', 'bệnh', 'khớp', ',', 'tôi', 'sẽ', 'giới thiệu', 'cho', 'mấy', 'bà', 'bạn', 'dùng', 'sản phẩm', 'này', '”', ',', 'bà', 'Tản', 'chia sẻ', '.']\n",
            "My word_tokenize 1:         ['“', 'Tôi', 'xin', 'xảm', 'ơn', 'lương y', 'Bình', ',', 'nhờ', 'gặp', 'thầy', 'gặp', 'thuốc', 'mà', 'tôi', 'đã', 'khỏi', 'bệnh', 'khớp', ',', 'tôi', 'sẽ', 'giới thiệu', 'cho', 'mấy', 'bà', 'bạn', 'dùng', 'sản phẩm', 'này', '”', ',', 'bà', 'Tản', 'chia sẻ', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8575\n",
            "sentence:  Sự vụ cổ phần hóa Hãng phim truyện Việt Nam sẽ không xôn xao dư luận đến vậy nếu người mua nó không phải là Tổng công ty vận tải thủy VIVASO và nơi Hãng phim tọa lạc không phải là gần 5 ngàn rưỡi mét vuông sát Hồ Tây .\n",
            "\n",
            "entity:  {'text': 'Hãng phim truyện Việt Nam', 'pos': [18, 43]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Hãng', 'phim truyện', 'Việt Nam']\n",
            "[13, 34]\n",
            "Underthesea word_tokenize:  ['Sự vụ', 'cổ phần hóa Hãng', 'phim truyện', 'Việt Nam', 'sẽ', 'không', 'xôn xao', 'dư luận', 'đến', 'vậy', 'nếu', 'người', 'mua', 'nó', 'không', 'phải', 'là', 'Tổng công ty', 'vận tải', 'thủy VIVASO', 'và', 'nơi', 'Hãng', 'phim', 'tọa lạc', 'không', 'phải', 'là', 'gần', '5', 'ngàn', 'rưỡi', 'mét vuông', 'sát', 'Hồ Tây', '.']\n",
            "My word_tokenize 1:         ['Sự vụ', 'cổ phần hóa', 'Hãng', 'phim truyện', 'Việt Nam', 'sẽ', 'không', 'xôn xao', 'dư luận', 'đến', 'vậy', 'nếu', 'người', 'mua', 'nó', 'không', 'phải', 'là', 'Tổng công ty', 'vận tải', 'thủy VIVASO', 'và', 'nơi', 'Hãng', 'phim', 'tọa lạc', 'không', 'phải', 'là', 'gần', '5', 'ngàn', 'rưỡi', 'mét vuông', 'sát', 'Hồ Tây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8576\n",
            "sentence:  Sự vụ cổ phần hóa Hãng phim truyện Việt Nam sẽ không xôn xao dư luận đến vậy nếu người mua nó không phải là Tổng công ty vận tải thủy VIVASO và nơi Hãng phim tọa lạc không phải là gần 5 ngàn rưỡi mét vuông sát Hồ Tây .\n",
            "\n",
            "entity:  {'text': 'Hãng phim truyện Việt Nam', 'pos': [18, 43]}\n",
            "entity index list:  [2, 3, 4]\n",
            "['Hãng', 'phim truyện', 'Việt Nam']\n",
            "[13, 34]\n",
            "Underthesea word_tokenize:  ['Sự vụ', 'cổ phần hóa Hãng', 'phim truyện', 'Việt Nam', 'sẽ', 'không', 'xôn xao', 'dư luận', 'đến', 'vậy', 'nếu', 'người', 'mua', 'nó', 'không', 'phải', 'là', 'Tổng công ty', 'vận tải', 'thủy VIVASO', 'và', 'nơi', 'Hãng', 'phim', 'tọa lạc', 'không', 'phải', 'là', 'gần', '5', 'ngàn', 'rưỡi', 'mét vuông', 'sát', 'Hồ Tây', '.']\n",
            "My word_tokenize 1:         ['Sự vụ', 'cổ phần hóa', 'Hãng', 'phim truyện', 'Việt Nam', 'sẽ', 'không', 'xôn xao', 'dư luận', 'đến', 'vậy', 'nếu', 'người', 'mua', 'nó', 'không', 'phải', 'là', 'Tổng công ty', 'vận tải', 'thủy VIVASO', 'và', 'nơi', 'Hãng', 'phim', 'tọa lạc', 'không', 'phải', 'là', 'gần', '5', 'ngàn', 'rưỡi', 'mét vuông', 'sát', 'Hồ Tây', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8635\n",
            "sentence:  Hiện, đội CSGT số 2 đã bàn giao các đối tượng cùng tang vật liên quan cho cơ quan Cảnh sát điều tra Công an TP.Thanh Hóa để xử lý theo đúng quy định pháp luật.\n",
            "\n",
            "entity:  {'text': 'Công an TP.Thanh Hóa', 'pos': [100, 120]}\n",
            "entity index list:  [17, 18]\n",
            "[77, 94]\n",
            "['Công an', 'TP.Thanh Hóa']\n",
            "My word_tokenize 1:         ['Hiện', ',', 'đội', 'CSGT', 'số', '2', 'đã', 'bàn giao', 'các', 'đối tượng', 'cùng', 'tang vật', 'liên quan', 'cho', 'cơ quan', 'Cảnh sát', 'điều tra', 'Công an', 'TP.Thanh Hóa để', 'xử lý', 'theo', 'đúng', 'quy định', 'pháp luật', '.']\n",
            "My word_tokenize 2:         ['Hiện', ',', 'đội', 'CSGT', 'số', '2', 'đã', 'bàn giao', 'các', 'đối tượng', 'cùng', 'tang vật', 'liên quan', 'cho', 'cơ quan', 'Cảnh sát', 'điều tra', 'Công an', 'TP.Thanh Hóa', 'để', 'xử lý', 'theo', 'đúng', 'quy định', 'pháp luật', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8667\n",
            "sentence:  Tôi có chút bồi hồi khi ông đồng ý cho Jenny tự học tại nhà để theo đuổi con đường Thời Trang hay cổ vũ Dan theo nghiệp nhà văn.\n",
            "\n",
            "entity:  {'text': 'Dan', 'pos': [104, 107]}\n",
            "entity index list:  [20]\n",
            "[79, 82]\n",
            "['Dan']\n",
            "My word_tokenize 1:         ['Tôi', 'có', 'chút', 'bồi hồi', 'khi', 'ông', 'đồng ý', 'cho', 'Jenny', 'tự', 'học', 'tại', 'nhà', 'để', 'theo đuổi', 'con', 'đường', 'Thời Trang', 'hay', 'cổ vũ Dan', 'theo', 'nghiệp', 'nhà văn', '.']\n",
            "My word_tokenize 2:         ['Tôi', 'có', 'chút', 'bồi hồi', 'khi', 'ông', 'đồng ý', 'cho', 'Jenny', 'tự', 'học', 'tại', 'nhà', 'để', 'theo đuổi', 'con', 'đường', 'Thời Trang', 'hay', 'cổ vũ', 'Dan', 'theo', 'nghiệp', 'nhà văn', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8669\n",
            "sentence:  Chẳng hạn như, nếu một thuê bao Viettel có số điện thoại 01678912345 sẽ được chuyển thành thuê bao 10 số có dạng 0338912345 nếu nhà mạng Viettel chọn đấu giá đầu số 033 để đưa về sử dụng.\n",
            "\n",
            "entity:  {'text': 'Viettel', 'pos': [137, 144]}\n",
            "entity index list:  [24]\n",
            "[110, 117]\n",
            "['Viettel']\n",
            "My word_tokenize 1:         ['Chẳng hạn', 'như', ',', 'nếu', 'một', 'thuê bao', 'Viettel', 'có', 'số', 'điện thoại', '01678912345', 'sẽ', 'được', 'chuyển', 'thành', 'thuê bao', '10', 'số', 'có', 'dạng', '0338912345', 'nếu', 'nhà', 'mạng Viettel chọn', 'đấu giá', 'đầu', 'số', '033', 'để', 'đưa', 'về', 'sử dụng', '.']\n",
            "My word_tokenize 2:         ['Chẳng hạn', 'như', ',', 'nếu', 'một', 'thuê bao', 'Viettel', 'có', 'số', 'điện thoại', '01678912345', 'sẽ', 'được', 'chuyển', 'thành', 'thuê bao', '10', 'số', 'có', 'dạng', '0338912345', 'nếu', 'nhà', 'mạng', 'Viettel', 'chọn', 'đấu giá', 'đầu', 'số', '033', 'để', 'đưa', 'về', 'sử dụng', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8670\n",
            "sentence:  Chia sẻ với PV, anh T (Chủ cửa hàng sim số đẹp trên phố Kim Mã – Ba Đình – Hà Nội ) cho hay:\n",
            "\n",
            "entity:  {'text': 'phố Kim Mã', 'pos': [52, 62]}\n",
            "entity index list:  [13, 14]\n",
            "[39, 47]\n",
            "['phố', 'Kim Mã']\n",
            "My word_tokenize 1:         ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã –', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "My word_tokenize 2:         ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã', '–', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  8673\n",
            "sentence:  Chia sẻ với PV, anh T (Chủ cửa hàng sim số đẹp trên phố Kim Mã – Ba Đình – Hà Nội ) cho hay:\n",
            "\n",
            "entity:  {'text': 'phố Kim Mã', 'pos': [52, 62]}\n",
            "entity index list:  [13, 14]\n",
            "['phố', 'Kim Mã']\n",
            "[39, 47]\n",
            "Underthesea word_tokenize:  ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã –', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "My word_tokenize 1:         ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã', '–', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  8674\n",
            "sentence:  Chia sẻ với PV, anh T (Chủ cửa hàng sim số đẹp trên phố Kim Mã – Ba Đình – Hà Nội ) cho hay:\n",
            "\n",
            "entity:  {'text': 'phố Kim Mã', 'pos': [52, 62]}\n",
            "entity index list:  [13, 14]\n",
            "['phố', 'Kim Mã']\n",
            "[39, 47]\n",
            "Underthesea word_tokenize:  ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã –', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "My word_tokenize 1:         ['Chia sẻ', 'với', 'PV', ',', 'anh', 'T', '(', 'Chủ', 'cửa hàng', 'sim', 'số', 'đẹp', 'trên', 'phố', 'Kim Mã', '–', 'Ba Đình', '–', 'Hà Nội', ')', 'cho', 'hay', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  8764\n",
            "sentence:  Phương Thanh , Tiến Đoàn làm giám khảo chung kết Người mẫu thể hình Việt Nam 2017 Ca sĩ Phương Thanh , nam vương Tiến Đoàn , HH Đại Dương Đặng Thu Thảo , ca sĩ Nguyên Vũ .... sẽ là những thành viên trong ban giám khảo chính của vòng thi chung kết Vietnam Fitness Model 2017 .\n",
            "\n",
            "entity:  {'text': 'Nguyên Vũ', 'pos': [160, 169]}\n",
            "entity index list:  [22]\n",
            "[124, 132]\n",
            "['Nguyên Vũ']\n",
            "My word_tokenize 1:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ ....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "My word_tokenize 2:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ', '....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8768\n",
            "sentence:  Phương Thanh , Tiến Đoàn làm giám khảo chung kết Người mẫu thể hình Việt Nam 2017 Ca sĩ Phương Thanh , nam vương Tiến Đoàn , HH Đại Dương Đặng Thu Thảo , ca sĩ Nguyên Vũ .... sẽ là những thành viên trong ban giám khảo chính của vòng thi chung kết Vietnam Fitness Model 2017 .\n",
            "\n",
            "entity:  {'text': 'Nguyên Vũ', 'pos': [160, 169]}\n",
            "entity index list:  [22]\n",
            "[124, 132]\n",
            "['Nguyên Vũ']\n",
            "My word_tokenize 1:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ ....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "My word_tokenize 2:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ', '....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8771\n",
            "sentence:  Phương Thanh , Tiến Đoàn làm giám khảo chung kết Người mẫu thể hình Việt Nam 2017 Ca sĩ Phương Thanh , nam vương Tiến Đoàn , HH Đại Dương Đặng Thu Thảo , ca sĩ Nguyên Vũ .... sẽ là những thành viên trong ban giám khảo chính của vòng thi chung kết Vietnam Fitness Model 2017 .\n",
            "\n",
            "entity:  {'text': 'Nguyên Vũ', 'pos': [160, 169]}\n",
            "entity index list:  [22]\n",
            "[124, 132]\n",
            "['Nguyên Vũ']\n",
            "My word_tokenize 1:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ ....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "My word_tokenize 2:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ', '....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8773\n",
            "sentence:  Phương Thanh , Tiến Đoàn làm giám khảo chung kết Người mẫu thể hình Việt Nam 2017 Ca sĩ Phương Thanh , nam vương Tiến Đoàn , HH Đại Dương Đặng Thu Thảo , ca sĩ Nguyên Vũ .... sẽ là những thành viên trong ban giám khảo chính của vòng thi chung kết Vietnam Fitness Model 2017 .\n",
            "\n",
            "entity:  {'text': 'Nguyên Vũ', 'pos': [160, 169]}\n",
            "entity index list:  [22]\n",
            "[124, 132]\n",
            "['Nguyên Vũ']\n",
            "My word_tokenize 1:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ ....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "My word_tokenize 2:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ', '....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8774\n",
            "sentence:  Phương Thanh , Tiến Đoàn làm giám khảo chung kết Người mẫu thể hình Việt Nam 2017 Ca sĩ Phương Thanh , nam vương Tiến Đoàn , HH Đại Dương Đặng Thu Thảo , ca sĩ Nguyên Vũ .... sẽ là những thành viên trong ban giám khảo chính của vòng thi chung kết Vietnam Fitness Model 2017 .\n",
            "\n",
            "entity:  {'text': 'Nguyên Vũ', 'pos': [160, 169]}\n",
            "entity index list:  [22]\n",
            "[124, 132]\n",
            "['Nguyên Vũ']\n",
            "My word_tokenize 1:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ ....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "My word_tokenize 2:         ['Phương Thanh', ',', 'Tiến Đoàn', 'làm', 'giám khảo', 'chung kết', 'Người mẫu', 'thể hình', 'Việt Nam', '2017', 'Ca sĩ', 'Phương Thanh', ',', 'nam', 'vương', 'Tiến Đoàn', ',', 'HH', 'Đại Dương', 'Đặng Thu Thảo', ',', 'ca sĩ', 'Nguyên Vũ', '....', 'sẽ', 'là', 'những', 'thành viên', 'trong', 'ban', 'giám khảo', 'chính', 'của', 'vòng', 'thi', 'chung kết', 'Vietnam Fitness Model', '2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8831\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8832\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [37]\n",
            "[173, 178]\n",
            "['Libya']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 2:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8833\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8834\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8835\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [36]\n",
            "[173, 178]\n",
            "['Libya']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 2:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8838\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [36]\n",
            "['Libya']\n",
            "[173, 178]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8839\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Vụ đắm tàu xảy ra ngoài khơi thị trấn Sabratha , phía Bắc thủ đô Tripoli .\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [36]\n",
            "['Libya']\n",
            "[173, 178]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Vụ', 'đắm', 'tàu', 'xảy', 'ra', 'ngoài', 'khơi', 'thị trấn', 'Sabratha', ',', 'phía', 'Bắc', 'thủ đô', 'Tripoli', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8848\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Minh Thu\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "\n",
            "---------- sent_id:  8849\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Minh Thu\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [37]\n",
            "[173, 178]\n",
            "['Libya']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 2:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "\n",
            "---------- sent_id:  8850\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Minh Thu\n",
            "\n",
            "entity:  {'text': 'Châu Phi', 'pos': [104, 112]}\n",
            "entity index list:  [18, 19]\n",
            "['Châu', 'Phi']\n",
            "[81, 88]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi', 'thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "\n",
            "---------- sent_id:  8851\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Minh Thu\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [36]\n",
            "[173, 178]\n",
            "['Libya']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 2:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "\n",
            "---------- sent_id:  8853\n",
            "sentence:  Xác người di cư được tập trung sau những vụ lật thuyền thương tâm Những người di cư đến từ các quốc gia Châu Phi thường đi trên thuyền cao su và bất chấp nguy hiểm Người di cư được tàu hải quân Italia giải cứu ngoài khơi Libya Có những đợt di cư lên tới hàng trăm người Những người may mắn không thiệt mạng trên biển nhưng tương lai cũng mờ mịt không kém Suy nhược sau chuyến vượt biển tìm vùng đất đổi đời Đau đớn vì mất người thân trên biển Minh Thu\n",
            "\n",
            "entity:  {'text': 'Libya', 'pos': [221, 226]}\n",
            "entity index list:  [36]\n",
            "['Libya']\n",
            "[173, 178]\n",
            "Underthesea word_tokenize:  ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "My word_tokenize 1:         ['Xác', 'người', 'di cư', 'được', 'tập trung', 'sau', 'những', 'vụ', 'lật', 'thuyền', 'thương tâm', 'Những', 'người', 'di cư', 'đến', 'từ', 'các', 'quốc gia', 'Châu', 'Phi thường', 'đi', 'trên', 'thuyền', 'cao su', 'và', 'bất chấp', 'nguy hiểm', 'Người', 'di cư', 'được', 'tàu', 'hải quân', 'Italia', 'giải cứu', 'ngoài', 'khơi', 'Libya', 'Có', 'những', 'đợt', 'di cư', 'lên', 'tới', 'hàng', 'trăm', 'người', 'Những', 'người', 'may mắn', 'không', 'thiệt mạng', 'trên', 'biển', 'nhưng', 'tương lai', 'cũng', 'mờ mịt', 'không', 'kém', 'Suy nhược', 'sau', 'chuyến', 'vượt', 'biển', 'tìm', 'vùng đất', 'đổi đời', 'Đau đớn', 'vì', 'mất', 'người thân', 'trên', 'biển', 'Minh', 'Thu']\n",
            "\n",
            "\n",
            "---------- sent_id:  8868\n",
            "sentence:  Đối tượng bán dâm là Vi Thị O. trú tại xã Thạch Giám , huyện Tương Dương .\n",
            "\n",
            "entity:  {'text': 'Vi Thị O.', 'pos': [21, 30]}\n",
            "entity index list:  [3]\n",
            "['Vi Thị O.']\n",
            "[16, 23]\n",
            "Underthesea word_tokenize:  ['Đối tượng', 'bán dâm', 'là', 'Vi Thị O. trú', 'tại', 'xã', 'Thạch Giám', ',', 'huyện', 'Tương Dương', '.']\n",
            "My word_tokenize 1:         ['Đối tượng', 'bán dâm', 'là', 'Vi Thị O.', 'trú', 'tại', 'xã', 'Thạch Giám', ',', 'huyện', 'Tương Dương', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8869\n",
            "sentence:  Đối tượng bán dâm là Vi Thị O. trú tại xã Thạch Giám , huyện Tương Dương .\n",
            "\n",
            "entity:  {'text': 'Vi Thị O.', 'pos': [21, 30]}\n",
            "entity index list:  [3]\n",
            "['Vi Thị O.']\n",
            "[16, 23]\n",
            "Underthesea word_tokenize:  ['Đối tượng', 'bán dâm', 'là', 'Vi Thị O. trú', 'tại', 'xã', 'Thạch Giám', ',', 'huyện', 'Tương Dương', '.']\n",
            "My word_tokenize 1:         ['Đối tượng', 'bán dâm', 'là', 'Vi Thị O.', 'trú', 'tại', 'xã', 'Thạch Giám', ',', 'huyện', 'Tương Dương', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8884\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "[109, 128]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8886\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8890\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "[109, 128]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8892\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8895\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "[109, 128]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8897\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8900\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[109, 128]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8901\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[109, 128]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [29, 30, 31]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8902\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[109, 128]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8903\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Đông Đô', 'pos': [138, 161]}\n",
            "entity index list:  [20, 21, 22]\n",
            "['Phòng', 'giao dịch', 'Đông Đô']\n",
            "[109, 128]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8904\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "[152, 173]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 2:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8907\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "[152, 173]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8908\n",
            "sentence:  VKS đột ngột đề nghị miễn hình phạt đối với các bị cáo Nguyễn Việt Hà (nguyên GĐ Chi nhánh Thái Bình ), Nguyễn Phan Trung Kiên (nguyên GĐ Phòng giao dịch Đông Đô ), Nguyễn Thị Loan (nguyên GĐ Phòng giao dịch Trung Yên ) và Trần Anh Thiết (nguyên GĐ Chi nhánh Hà Nội ).\n",
            "\n",
            "entity:  {'text': 'Phòng giao dịch Trung Yên', 'pos': [192, 217]}\n",
            "entity index list:  [28, 29, 30]\n",
            "['Phòng', 'giao dịch', 'Trung Yên']\n",
            "[152, 173]\n",
            "Underthesea word_tokenize:  ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "My word_tokenize 1:         ['VKS', 'đột ngột', 'đề nghị', 'miễn', 'hình phạt', 'đối với', 'các', 'bị cáo', 'Nguyễn Việt Hà', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Thái Bình', ')', ',', 'Nguyễn Phan Trung Kiên', '(', 'nguyên', 'GĐ Phòng', 'giao dịch', 'Đông Đô', ')', ',', 'Nguyễn Thị Loan', '(', 'nguyên', 'GĐ', 'Phòng', 'giao dịch', 'Trung Yên', ')', 'và', 'Trần Anh Thiết', '(', 'nguyên', 'GĐ', 'Chi nhánh', 'Hà Nội', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8910\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "[77, 80]\n",
            "['BSC']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 2:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8912\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "[104, 113]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 2:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8919\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8920\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [23]\n",
            "[104, 113]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 2:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8921\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8922\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8923\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8924\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8925\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8926\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'BSC', 'pos': [99, 102]}\n",
            "entity index list:  [16]\n",
            "['BSC']\n",
            "[77, 80]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ', 'BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8927\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "[104, 113]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 2:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8934\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8935\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8936\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8937\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8938\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  8939\n",
            "sentence:  Đại diện VKS cũng đề nghị áp dụng thêm tình tiết giảm nhẹ cho các bị cáo Phạm Hoàng Giang (cựu TGĐ BSC ), Lê Thị Thu Thủy (cựu Phó TGĐ Oceanbank ), Vũ Thị Thùy Dương (nguyên Trưởng ban kế toán), Hứa Thị Phấn (nguyên Chủ tịch HĐQT công ty Phú Mỹ ) Áp dụng thêm hình phạt là án treo đối với Phạm Hồng Tứ (nguyên Chủ tịch HĐQT công ty BSC ), đề nghị xử phạt bị cáo Tứ mức án từ 30-36 tháng tù treo.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [135, 144]}\n",
            "entity index list:  [22]\n",
            "['Oceanbank']\n",
            "[104, 113]\n",
            "Underthesea word_tokenize:  ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "My word_tokenize 1:         ['Đại diện', 'VKS', 'cũng', 'đề nghị', 'áp dụng', 'thêm', 'tình tiết', 'giảm', 'nhẹ', 'cho', 'các', 'bị cáo', 'Phạm Hoàng Giang', '(', 'cựu', 'TGĐ BSC', ')', ',', 'Lê Thị Thu Thủy', '(', 'cựu', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Vũ Thị Thùy Dương', '(', 'nguyên', 'Trưởng ban', 'kế toán', ')', ',', 'Hứa Thị Phấn', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'Phú Mỹ', ')', 'Áp dụng', 'thêm', 'hình phạt', 'là', 'án treo', 'đối với', 'Phạm Hồng Tứ', '(', 'nguyên', 'Chủ tịch', 'HĐQT', 'công ty', 'BSC', ')', ',', 'đề nghị', 'xử phạt', 'bị cáo', 'Tứ', 'mức', 'án', 'từ', '30-36', 'tháng', 'tù treo', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9021\n",
            "sentence:  Các bị cáo Nguyễn Văn Hoàn (nguyên Phó TGĐ Oceanbank ), Phạm Hoàng Giang (nguyên TGĐ công ty BSC cũng được đại diện VKS đề nghị HĐXX giảm nhẹ hình phạt.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [43, 52]}\n",
            "entity index list:  [6]\n",
            "[34, 43]\n",
            "['Oceanbank']\n",
            "My word_tokenize 1:         ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "My word_tokenize 2:         ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9024\n",
            "sentence:  Các bị cáo Nguyễn Văn Hoàn (nguyên Phó TGĐ Oceanbank ), Phạm Hoàng Giang (nguyên TGĐ công ty BSC cũng được đại diện VKS đề nghị HĐXX giảm nhẹ hình phạt.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [43, 52]}\n",
            "entity index list:  [6]\n",
            "['Oceanbank']\n",
            "[34, 43]\n",
            "Underthesea word_tokenize:  ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "My word_tokenize 1:         ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9025\n",
            "sentence:  Các bị cáo Nguyễn Văn Hoàn (nguyên Phó TGĐ Oceanbank ), Phạm Hoàng Giang (nguyên TGĐ công ty BSC cũng được đại diện VKS đề nghị HĐXX giảm nhẹ hình phạt.\n",
            "\n",
            "entity:  {'text': 'Oceanbank', 'pos': [43, 52]}\n",
            "entity index list:  [6]\n",
            "['Oceanbank']\n",
            "[34, 43]\n",
            "Underthesea word_tokenize:  ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "My word_tokenize 1:         ['Các', 'bị cáo', 'Nguyễn Văn Hoàn', '(', 'nguyên', 'Phó TGĐ', 'Oceanbank', ')', ',', 'Phạm Hoàng Giang', '(', 'nguyên', 'TGĐ', 'công ty', 'BSC', 'cũng', 'được', 'đại diện', 'VKS', 'đề nghị', 'HĐXX', 'giảm', 'nhẹ', 'hình phạt', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9078\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [55, 64]}\n",
            "entity index list:  [8]\n",
            "[43, 52]\n",
            "['Australia']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9079\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Mông Cổ', 'pos': [75, 82]}\n",
            "entity index list:  [10]\n",
            "[60, 66]\n",
            "['Mông Cổ']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ', '9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9082\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [55, 64]}\n",
            "entity index list:  [8]\n",
            "[43, 52]\n",
            "['Australia']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9083\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Mông Cổ', 'pos': [75, 82]}\n",
            "entity index list:  [10]\n",
            "[60, 66]\n",
            "['Mông Cổ']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ', '9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9086\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [55, 64]}\n",
            "entity index list:  [8]\n",
            "['Australia']\n",
            "[43, 52]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "entity:  {'text': 'Mông Cổ', 'pos': [75, 82]}\n",
            "entity index list:  [11]\n",
            "[60, 66]\n",
            "['Mông Cổ']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 2:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ', '9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9087\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [55, 64]}\n",
            "entity index list:  [8]\n",
            "['Australia']\n",
            "[43, 52]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9088\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Australia', 'pos': [55, 64]}\n",
            "entity index list:  [8]\n",
            "['Australia']\n",
            "[43, 52]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia', 'Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9089\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Mông Cổ', 'pos': [75, 82]}\n",
            "entity index list:  [10]\n",
            "['Mông Cổ']\n",
            "[60, 66]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ', '9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9090\n",
            "sentence:  Thắng đậm Mông Cổ , U16 Việt Nam sẵn sàng nghênh chiến Australia Thắng đậm Mông Cổ 9-0, U16 Việt Nam đã có bước chạy đà hoàn hảo trước trận gặp U16 Australia .\n",
            "\n",
            "entity:  {'text': 'Mông Cổ', 'pos': [75, 82]}\n",
            "entity index list:  [10]\n",
            "['Mông Cổ']\n",
            "[60, 66]\n",
            "Underthesea word_tokenize:  ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ 9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "My word_tokenize 1:         ['Thắng', 'đậm', 'Mông Cổ', ',', 'U16', 'Việt Nam', 'sẵn sàng', 'nghênh chiến', 'Australia Thắng', 'đậm', 'Mông Cổ', '9-0', ',', 'U16', 'Việt Nam', 'đã', 'có', 'bước', 'chạy đà', 'hoàn hảo', 'trước', 'trận', 'gặp', 'U16 Australia', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9103\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "[118, 126]\n",
            "['Vivienne']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9104\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [35]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9108\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "[118, 126]\n",
            "['Vivienne']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9109\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [35]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9112\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "[118, 126]\n",
            "['Vivienne']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9113\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [35]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9115\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "[118, 126]\n",
            "['Vivienne']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9116\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [35]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9117\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "[118, 126]\n",
            "['Vivienne']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9118\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [35]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9119\n",
            "sentence:  Angelian Jolie và 6 đứa con cùng các cộng sự giới thiệu phim tại Liên hoan phim Toronto Với 6 đứa con - Maddox , 16, Pax , 13, Zahara , 12, Shiloh , 11, Vivienne and Knox , 9 - cùng đi, ngôi sao màn bạc 42 tuổi này đã xuất hiện trước công chúng trong buổi giới thiệu phim ‘First They Killed My Father’ (tạm dịch ‘Đầu tiên họ đã giết cha tôi’).\n",
            "\n",
            "entity:  {'text': 'Vivienne', 'pos': [153, 161]}\n",
            "entity index list:  [34]\n",
            "['Vivienne']\n",
            "[118, 126]\n",
            "Underthesea word_tokenize:  ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "entity:  {'text': 'Knox', 'pos': [166, 170]}\n",
            "entity index list:  [36]\n",
            "[129, 133]\n",
            "['Knox']\n",
            "My word_tokenize 1:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "My word_tokenize 2:         ['Angelian Jolie', 'và', '6', 'đứa', 'con', 'cùng', 'các', 'cộng sự', 'giới thiệu', 'phim', 'tại', 'Liên hoan phim', 'Toronto', 'Với', '6', 'đứa', 'con', '-', 'Maddox', ',', '16', ',', 'Pax', ',', '13', ',', 'Zahara', ',', '12', ',', 'Shiloh', ',', '11', ',', 'Vivienne', 'and', 'Knox', ',', '9', '-', 'cùng', 'đi', ',', 'ngôi sao', 'màn bạc', '42', 'tuổi', 'này', 'đã', 'xuất hiện', 'trước', 'công chúng', 'trong', 'buổi', 'giới thiệu', 'phim', '‘', 'First They Killed My Father ’', '(', 'tạm', 'dịch', '‘', 'Đầu tiên', 'họ', 'đã', 'giết', 'cha', 'tôi', '’', ')', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9132\n",
            "sentence:  (Xem thêm) Ông Timothy Franz Geithner , Chủ tịch Công ty Quản lý quỹ Warburg Pincus , nguyên Bộ trưởng Tài chính Mỹ , nguyên Chủ tịch Ngân hàng Dự trữ Liên bang New York (Fed New York ) vừa có chuyến thăm Ngân hàng Nhà nước Việt Nam ngày 20/9/2017.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [113, 115]}\n",
            "entity index list:  [16]\n",
            "[91, 93]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "My word_tokenize 2:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính', 'Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9136\n",
            "sentence:  (Xem thêm) Ông Timothy Franz Geithner , Chủ tịch Công ty Quản lý quỹ Warburg Pincus , nguyên Bộ trưởng Tài chính Mỹ , nguyên Chủ tịch Ngân hàng Dự trữ Liên bang New York (Fed New York ) vừa có chuyến thăm Ngân hàng Nhà nước Việt Nam ngày 20/9/2017.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [113, 115]}\n",
            "entity index list:  [16]\n",
            "[91, 93]\n",
            "['Mỹ']\n",
            "My word_tokenize 1:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "My word_tokenize 2:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính', 'Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9140\n",
            "sentence:  (Xem thêm) Ông Timothy Franz Geithner , Chủ tịch Công ty Quản lý quỹ Warburg Pincus , nguyên Bộ trưởng Tài chính Mỹ , nguyên Chủ tịch Ngân hàng Dự trữ Liên bang New York (Fed New York ) vừa có chuyến thăm Ngân hàng Nhà nước Việt Nam ngày 20/9/2017.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [113, 115]}\n",
            "entity index list:  [16]\n",
            "['Mỹ']\n",
            "[91, 93]\n",
            "Underthesea word_tokenize:  ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "My word_tokenize 1:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính', 'Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9141\n",
            "sentence:  (Xem thêm) Ông Timothy Franz Geithner , Chủ tịch Công ty Quản lý quỹ Warburg Pincus , nguyên Bộ trưởng Tài chính Mỹ , nguyên Chủ tịch Ngân hàng Dự trữ Liên bang New York (Fed New York ) vừa có chuyến thăm Ngân hàng Nhà nước Việt Nam ngày 20/9/2017.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [113, 115]}\n",
            "entity index list:  [16]\n",
            "['Mỹ']\n",
            "[91, 93]\n",
            "Underthesea word_tokenize:  ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "My word_tokenize 1:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính', 'Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9142\n",
            "sentence:  (Xem thêm) Ông Timothy Franz Geithner , Chủ tịch Công ty Quản lý quỹ Warburg Pincus , nguyên Bộ trưởng Tài chính Mỹ , nguyên Chủ tịch Ngân hàng Dự trữ Liên bang New York (Fed New York ) vừa có chuyến thăm Ngân hàng Nhà nước Việt Nam ngày 20/9/2017.\n",
            "\n",
            "entity:  {'text': 'Mỹ', 'pos': [113, 115]}\n",
            "entity index list:  [16]\n",
            "['Mỹ']\n",
            "[91, 93]\n",
            "Underthesea word_tokenize:  ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "My word_tokenize 1:         ['(', 'Xem', 'thêm', ')', 'Ông', 'Timothy Franz Geithner', ',', 'Chủ tịch', 'Công ty', 'Quản lý', 'quỹ', 'Warburg Pincus', ',', 'nguyên', 'Bộ trưởng', 'Tài chính', 'Mỹ', ',', 'nguyên', 'Chủ tịch', 'Ngân hàng', 'Dự trữ', 'Liên bang', 'New York', '(', 'Fed New York', ')', 'vừa', 'có', 'chuyến', 'thăm', 'Ngân hàng', 'Nhà nước', 'Việt Nam', 'ngày', '20/9/2017', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9163\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "[82, 103]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9167\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9171\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "[82, 103]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9175\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9178\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "[82, 103]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9182\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9184\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "[82, 103]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9188\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9190\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[82, 103]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9191\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[82, 103]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9192\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[82, 103]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9193\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[82, 103]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [47, 48, 49, 50]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9194\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [107, 132]}\n",
            "entity index list:  [18, 19, 20, 21]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[82, 103]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9197\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9200\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9202\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "[217, 238]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9204\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa được hưởng trợ cấp thương binh Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam Chiều 22/9, Phó Giám đốc Sở LĐ-TB-XH Bình Định , ông Phan Đình Hòa , xác nhận:\n",
            "\n",
            "entity:  {'text': 'đốc\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [278, 303]}\n",
            "entity index list:  [46, 47, 48, 49]\n",
            "['đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[217, 238]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'được', 'hưởng', 'trợ cấp', 'thương binh', 'Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', 'Chiều', '22/9', ',', 'Phó', 'Giám', 'đốc', 'Sở', 'LĐ-TB-XH', 'Bình Định', ',', 'ông', 'Phan Đình Hòa', ',', 'xác nhận', ':']\n",
            "\n",
            "\n",
            "---------- sent_id:  9216\n",
            "sentence:  Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam ) xảy ra vào tháng 3/1988.\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [48, 73]}\n",
            "entity index list:  [10, 11, 12, 13]\n",
            "[36, 57]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "My word_tokenize 2:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9220\n",
            "sentence:  Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam ) xảy ra vào tháng 3/1988.\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [48, 73]}\n",
            "entity index list:  [10, 11, 12, 13]\n",
            "[36, 57]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "My word_tokenize 2:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9224\n",
            "sentence:  Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam ) xảy ra vào tháng 3/1988.\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [48, 73]}\n",
            "entity index list:  [10, 11, 12, 13]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[36, 57]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9225\n",
            "sentence:  Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam ) xảy ra vào tháng 3/1988.\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [48, 73]}\n",
            "entity index list:  [10, 11, 12, 13]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[36, 57]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9226\n",
            "sentence:  Trước đó, cựu binh Gạc Ma Lê Văn Thoa đã có đơn gửi Sở LĐ-TB-XH Bình Định đề nghị giám định lại vết thương còn sót của ông trong trận hải chiến bảo vệ đảo Gạc Ma (thuộc Quần đảo Trường Sa -Việt Nam ) xảy ra vào tháng 3/1988.\n",
            "\n",
            "entity:  {'text': 'gửi\\xa0Sở LĐ-TB-XH Bình Định', 'pos': [48, 73]}\n",
            "entity index list:  [10, 11, 12, 13]\n",
            "['gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định']\n",
            "[36, 57]\n",
            "Underthesea word_tokenize:  ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "My word_tokenize 1:         ['Trước', 'đó', ',', 'cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'đã', 'có', 'đơn', 'gửi', 'Sở', 'LĐ-TB-XH', 'Bình Định', 'đề nghị', 'giám định', 'lại', 'vết thương', 'còn', 'sót', 'của', 'ông', 'trong', 'trận', 'hải chiến', 'bảo vệ', 'đảo', 'Gạc Ma', '(', 'thuộc', 'Quần đảo', 'Trường Sa', '-', 'Việt Nam', ')', 'xảy', 'ra', 'vào', 'tháng', '3/1988', '.']\n",
            "\n",
            "\n",
            "---------- sent_id:  9233\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa ĐÌNH THUNG\n",
            "\n",
            "entity:  {'text': 'Lê Văn Thoa', 'pos': [16, 27]}\n",
            "entity index list:  [3]\n",
            "[12, 21]\n",
            "['Lê Văn Thoa']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa ĐÌNH THUNG']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'ĐÌNH THUNG']\n",
            "\n",
            "\n",
            "---------- sent_id:  9234\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa ĐÌNH THUNG\n",
            "\n",
            "entity:  {'text': 'ĐÌNH THUNG', 'pos': [28, 38]}\n",
            "entity index list:  [4]\n",
            "[21, 30]\n",
            "['ĐÌNH THUNG']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa ĐÌNH THUNG']\n",
            "My word_tokenize 2:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'ĐÌNH THUNG']\n",
            "\n",
            "\n",
            "---------- sent_id:  9235\n",
            "sentence:  Cựu binh Gạc Ma Lê Văn Thoa ĐÌNH THUNG\n",
            "\n",
            "entity:  {'text': 'Lê Văn Thoa', 'pos': [16, 27]}\n",
            "entity index list:  [3]\n",
            "['Lê Văn Thoa']\n",
            "[12, 21]\n",
            "Underthesea word_tokenize:  ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa ĐÌNH THUNG']\n",
            "My word_tokenize 1:         ['Cựu binh', 'Gạc', 'Ma', 'Lê Văn Thoa', 'ĐÌNH THUNG']\n",
            "Done adding new_word_tokenize_lst and entity eids in new_word_tokenize_lst to jdata.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRaOZpRFeghS"
      },
      "source": [
        "##### Create dev input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1fwk7ckeghS"
      },
      "source": [
        "###### max len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISJI3L6deghS",
        "outputId": "3498a39e-a20d-4ac9-8ae4-aeb86218856f"
      },
      "source": [
        "print(jdev_data_v3[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'doc_id': '23351996', 'sent_id': 1, 'sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'spos': [0, 127], 'entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12]}, 'entity_2': {'text': 'Mông Cổ', 'pos': [36, 43]}, 'label': 'OTHERS', 'new_sentence': \"U16 Việt Nam dội 'mưa gôn' vào lưới Mông Cổ Không nằm ngoài dự đoán, U16 Việt Nam đã có chiến thắng dễ dàng trước U16 Mông Cổ .\", 'new_entity_1': {'text': 'U16 Việt Nam', 'pos': [0, 12], 'wtk_index_lst': [0, 1], 'pos_no_space': [0, 10]}, 'new_entity_2': {'text': 'Mông Cổ', 'pos': [36, 43], 'wtk_index_lst': [9], 'pos_no_space': [28, 34]}, 'word_tokenize_lst': ['U16', 'Việt Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông Cổ', 'Không', 'nằm', 'ngoài', 'dự đoán', ',', 'U16', 'Việt Nam', 'đã', 'có', 'chiến thắng', 'dễ dàng', 'trước', 'U16', 'Mông Cổ', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuIRTYOGeghS",
        "outputId": "5a526a69-f713-4f24-dbf3-88361fff31c5"
      },
      "source": [
        "pb_sent_maxlen = 0\n",
        "xlmr_sent_maxlen = 0\n",
        "\n",
        "pb_sent_len_lst = []\n",
        "xlmr_sent_len_lst = []\n",
        "\n",
        "for sentif in jdev_data_v3:\n",
        "\n",
        "    assert (sentif['new_sentence'] == unicodedata.normalize(\"NFC\", sentif['new_sentence'])), str('sentence not seem to be normalized.')\n",
        "    assert (''.join(sentif['new_sentence'].split()) == u''.join([tk.replace(\" \", \"\") for tk in sentif['word_tokenize_lst']])), \\\n",
        "    str('word_tokenize_lst not match new_sentence.')\n",
        "\n",
        "    # phobert\n",
        "    pb_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "    pb_sent_tokenize = pb_tokenizer.tokenize(pb_sent)\n",
        "\n",
        "    pb_sent_maxlen = max(pb_sent_maxlen, len(pb_sent_tokenize))\n",
        "\n",
        "    pb_sent_len_lst.append(len(pb_sent_tokenize))\n",
        "\n",
        "    # xlmr\n",
        "    xlmr_sent = u\" \".join(copy.deepcopy(sentif['word_tokenize_lst']))\n",
        "    xlmr_sent_tokenize = xlmr_tokenizer.tokenize(xlmr_sent)\n",
        "\n",
        "    xlmr_sent_maxlen = max(xlmr_sent_maxlen, len(xlmr_sent_tokenize))\n",
        "    xlmr_sent_len_lst.append(len(xlmr_sent_tokenize))\n",
        "\n",
        "\n",
        "print('pb_sent_maxlen: ', pb_sent_maxlen)\n",
        "print('xlmr_sent_maxlen: ', xlmr_sent_maxlen)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pb_sent_maxlen:  141\n",
            "xlmr_sent_maxlen:  218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR-somgSeghS",
        "outputId": "1feea71c-939f-4115-c784-3a28b5dda169"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import Counter \n",
        "\n",
        "# phobert\n",
        "print('--phobert')\n",
        "print(pd.Series(pb_sent_len_lst).describe())\n",
        "most_common_len = Counter(pb_sent_len_lst).most_common(1)[0]\n",
        "print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n",
        "# xlmr\n",
        "print('\\n--XLM-RoBERTa')\n",
        "print(pd.Series(xlmr_sent_len_lst).describe())\n",
        "most_common_len = Counter(xlmr_sent_len_lst).most_common(1)[0]\n",
        "print('most common sentence len: ', most_common_len[0] , ' appear ' , most_common_len[1], ' times.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--phobert\n",
            "count    9235.000000\n",
            "mean       47.118029\n",
            "std        21.856274\n",
            "min         3.000000\n",
            "25%        31.000000\n",
            "50%        43.000000\n",
            "75%        60.000000\n",
            "max       141.000000\n",
            "dtype: float64\n",
            "most common sentence len:  34  appear  263  times.\n",
            "\n",
            "--XLM-RoBERTa\n",
            "count    9235.000000\n",
            "mean       68.191770\n",
            "std        32.705261\n",
            "min         4.000000\n",
            "25%        45.000000\n",
            "50%        62.000000\n",
            "75%        85.000000\n",
            "max       218.000000\n",
            "dtype: float64\n",
            "most common sentence len:  46  appear  288  times.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM60o1G9eghS"
      },
      "source": [
        "###### create input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnZc9k7EpeYc"
      },
      "source": [
        "for sentif in jdev_data_v3:\n",
        "    if 'Hotspur' in sentif['new_sentence']:\n",
        "        print(sentif)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYQNbaB0eghT",
        "outputId": "e34e06a9-9bfe-40c5-f9cb-8d3284bdeea8"
      },
      "source": [
        "'''\n",
        "# thêm token vào phobert để tránh bị <unk> token, token này sẽ có embedding được khởi tạo một cái random\n",
        "# https://github.com/huggingface/transformers/issues/1413\n",
        "# https://huggingface.co/transformers/internal/tokenization_utils.html?highlight=add_token\n",
        "\n",
        "print(len(pb_tokenizer))\n",
        "\n",
        "add_Hotspur_to_pb = pb_tokenizer.add_tokens([unicodedata.normalize(\"NFC\", 'Hotspur')])\n",
        "print('We have added', add_Hotspur_to_pb, 'tokens')\n",
        "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
        "\n",
        "print(len(pb_tokenizer))\n",
        "\n",
        "pb_model.resize_token_embeddings(len(pb_tokenizer))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# thêm token vào phobert để tránh bị <unk> token, token này sẽ có embedding được khởi tạo một cái random\\n# https://github.com/huggingface/transformers/issues/1413\\n# https://huggingface.co/transformers/internal/tokenization_utils.html?highlight=add_token\\n\\nprint(len(pb_tokenizer))\\n\\nadd_Hotspur_to_pb = pb_tokenizer.add_tokens([unicodedata.normalize(\"NFC\", \\'Hotspur\\')])\\nprint(\\'We have added\\', add_Hotspur_to_pb, \\'tokens\\')\\n# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\\n\\nprint(len(pb_tokenizer))\\n\\npb_model.resize_token_embeddings(len(pb_tokenizer))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqw4QV_UeghT",
        "outputId": "f7da3cdd-8342-499f-8b36-f1de99d2a1e0"
      },
      "source": [
        "if flags['use_phobert'] == True:\n",
        "    dev_pb_input_ids = []\n",
        "    dev_pb_attention_masks = []\n",
        "    dev_pb_entity_1_eids = []\n",
        "    dev_pb_entity_2_eids = []\n",
        "    #dev_pb_labels = []\n",
        "\n",
        "if flags['use_xlmr'] == True:\n",
        "    dev_xlmr_input_ids = []\n",
        "    dev_xlmr_attention_masks = []\n",
        "    dev_xlmr_entity_1_eids = []\n",
        "    dev_xlmr_entity_2_eids = []\n",
        "    #dev_xlmr_labels = []\n",
        "\n",
        "dev_labels = []\n",
        "\n",
        "# Do entity_eids của các entity trong các câu không cùng chiều dài nên ta cần chuyển về cùng chiều dài thì mới biến thành tensor được\n",
        "# để chuyển về cùng chiều dài ta sẽ pad các eids ngắn hơn bằng -2.\n",
        "# vì eids phải >= 1 nên để số < 0 sẽ không sợ nhầm và ta chỉ thêm vào bên phải. \n",
        "# >= 1 vì lúc tìm eids đã tính <s> nên đã +1 sẵn nên min = 1\n",
        "# giả sử 1 entity_eids chỉ có chiều dài max là 30\n",
        "pad_ent_eid = -2\n",
        "max_len_ent_eid = 30\n",
        "\n",
        "assert (pad_ent_eid < 0), str('pad_ent_eid must < 0')\n",
        "\n",
        "jdev_data_use = copy.deepcopy(jdev_data_v3)\n",
        "\n",
        "for isentif, sentif in enumerate(jdev_data_use):\n",
        "\n",
        "    if flags['use_xlmr'] == True:\n",
        "        # xlmr\n",
        "        # xlmr biến … thành ... khi tokenize nên cần sửa lại wpi_start_pos, wpi_end_pos\n",
        "                # và với cái wpi này thì chấp nhận sent_non_space[wpi_start_pos:wpi_end_pos] != clean_wpi\n",
        "                # tương tự với ½ thành 1⁄2\n",
        "\n",
        "        # Lưu ý: XLM-R có một số kí tự như … bị biến thành ..., ½ thành 1⁄2 dẫn tới việc check, kiểm tra so sánh chuỗi bị khác\n",
        "        # và dù trong câu lẫn word_tokenize_lst có kí tự \\ufeff nhưng khi XLM-R lại loại bỏ khi toknenize nên kí tự cũng bị thay đổi vị trí\n",
        "        # các vấn đề này được fix trong hàm: get_entity_word_piece_index()\n",
        "\n",
        "        #xlmr_input_sent = sentif['new_sentence']\n",
        "        xlmr_input_sent = u\" \".join(sentif['word_tokenize_lst'])\n",
        "\n",
        "        xlmr_encode_dict = xlmr_tokenizer(xlmr_input_sent, add_special_tokens=True, padding='max_length', max_length=224)\n",
        "\n",
        "        xlmr_tokenize_lst = xlmr_tokenizer.tokenize(xlmr_input_sent)\n",
        "        assert ((len(xlmr_tokenize_lst) + 2) <= 224), str('len xlmr_tokenize_lst > 224')\n",
        "\n",
        "\n",
        "        xlmr_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'dev')\n",
        "        xlmr_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], xlmr_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'xlmr', xlmr_encode_dict['input_ids'], 'dev')\n",
        "        \n",
        "        # pad\n",
        "        assert ((len(xlmr_entity_1_eids) <= max_len_ent_eid) and (len(xlmr_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n",
        "\n",
        "        xlmr_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_1_eids))\n",
        "        xlmr_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(xlmr_entity_2_eids))\n",
        "\n",
        "\n",
        "        if isentif < 10:\n",
        "            print('\\n')\n",
        "            print(xlmr_tokenize_lst)\n",
        "            print(sentif['new_entity_1']['text'])\n",
        "            print(xlmr_entity_1_eids)\n",
        "            print(sentif['new_entity_2']['text'])\n",
        "            print(xlmr_entity_2_eids)\n",
        "        \n",
        "\n",
        "        dev_xlmr_input_ids.append(copy.deepcopy(xlmr_encode_dict['input_ids']))\n",
        "        dev_xlmr_attention_masks.append(copy.deepcopy(xlmr_encode_dict['attention_mask']))\n",
        "        dev_xlmr_entity_1_eids.append(copy.deepcopy(xlmr_entity_1_eids))\n",
        "        dev_xlmr_entity_2_eids.append(copy.deepcopy(xlmr_entity_2_eids))\n",
        "        #dev_xlmr_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "    \n",
        "\n",
        "\n",
        "    if flags['use_phobert'] == True:\n",
        "        # phobert\n",
        "        # lưu ý: phải để phobert ở bên dưới xlmr để những thay đổi bên dưới chỉ ảnh hưởng tới phobert chứ không ảnh hưởng tới XLM-R\n",
        "        # trong các câu chứa các cụm dưới, chả hiểu sao trong phobert '’' khi đứng 1 mình thì encode là 1 wpi bthg \n",
        "        # nhưng đứng trong cụm dưới dưới thì lại thành <unk>\n",
        "        # ta sẽ đổi ’ thành ' thì sẽ k bị lỗi nữa\n",
        "        \n",
        "        if ('Cư M’gar' in sentif['word_tokenize_lst']) or ('L’Oreal' in sentif['word_tokenize_lst']) or ('Hay’at Tahrir Al-Sham' in sentif['word_tokenize_lst']) \\\n",
        "        or ('Đắk R’Lấp' in sentif['word_tokenize_lst']) or ('Let’s Việt' in sentif['word_tokenize_lst']) or ('H’M' in sentif['word_tokenize_lst']) \\\n",
        "        or ('H’A Byă' in sentif['word_tokenize_lst']):\n",
        "            \n",
        "\n",
        "            for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n",
        "                if '’' in wtk_item:\n",
        "                    sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "                    \n",
        "\n",
        "            sentif['new_sentence'] = sentif['new_sentence'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "            sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "            sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('’', unicodedata.normalize(\"NFC\", \"\\'\"))\n",
        "\n",
        "        \n",
        "        if ('Eugène Schueller' in sentif['new_sentence']):\n",
        "            \n",
        "\n",
        "            for iwtk_item, wtk_item in enumerate(sentif['word_tokenize_lst']):\n",
        "                if 'Eugène Schueller' in wtk_item:\n",
        "                    sentif['word_tokenize_lst'][iwtk_item] = sentif['word_tokenize_lst'][iwtk_item].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n",
        "                    \n",
        "\n",
        "            sentif['new_sentence'] = sentif['new_sentence'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n",
        "            sentif['new_entity_1']['text'] = sentif['new_entity_1']['text'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n",
        "            sentif['new_entity_2']['text'] = sentif['new_entity_2']['text'].replace('Eugène Schueller', unicodedata.normalize(\"NFC\", \"Eugene Schueller\"))\n",
        "        \n",
        "\n",
        "        \n",
        "        pb_input_sent = u\" \".join([tk.replace(\" \", \"_\") for tk in sentif['word_tokenize_lst']])\n",
        "\n",
        "        pb_encode_dict = pb_tokenizer(pb_input_sent, add_special_tokens=True, padding='max_length', max_length=160)\n",
        "\n",
        "        pb_tokenize_lst = pb_tokenizer.tokenize(pb_input_sent)\n",
        "        assert ((len(pb_tokenize_lst) + 2) <= 160), str('len pb_tokenize_lst > 160')\n",
        "\n",
        "        pb_entity_1_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_1'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'dev')\n",
        "        pb_entity_2_eids = get_entity_word_piece_index(sentif['sent_id'], pb_tokenize_lst, sentif['new_entity_2'], sentif['new_sentence'], 'phobert', pb_encode_dict['input_ids'], 'dev')\n",
        "\n",
        "        # pad\n",
        "        assert ((len(pb_entity_1_eids) <= max_len_ent_eid) and (len(pb_entity_2_eids) <= max_len_ent_eid)), str('max_len_ent_eid must > ' + str(max_len_ent_eid))\n",
        "\n",
        "        pb_entity_1_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_1_eids))\n",
        "        pb_entity_2_eids += [pad_ent_eid] * (max_len_ent_eid - len(pb_entity_2_eids))\n",
        "        \n",
        "\n",
        "\n",
        "        if isentif < 10:\n",
        "            print('\\n')\n",
        "            print(pb_tokenize_lst)\n",
        "            print(sentif['new_entity_1']['text'])\n",
        "            print(pb_entity_1_eids)\n",
        "            print(sentif['new_entity_2']['text'])\n",
        "            print(pb_entity_2_eids)\n",
        "        \n",
        "\n",
        "\n",
        "        dev_pb_input_ids.append(copy.deepcopy(pb_encode_dict['input_ids']))\n",
        "        dev_pb_attention_masks.append(copy.deepcopy(pb_encode_dict['attention_mask']))\n",
        "        dev_pb_entity_1_eids.append(copy.deepcopy(pb_entity_1_eids))\n",
        "        dev_pb_entity_2_eids.append(copy.deepcopy(pb_entity_2_eids))\n",
        "        #dev_pb_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "\n",
        "\n",
        "    dev_labels.append(copy.deepcopy(encode_label(sentif['label'])))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, 3, 4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Mông Cổ\n",
            "[14, 15, 16, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "Mông Cổ\n",
            "[10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, 3, 4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[24, 25, 26, 27, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, 3, 4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[35, 36, 37, 38, 39, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[23, 24, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "Mông Cổ\n",
            "[14, 15, 16, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[24, 25, 26, 27, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "Mông Cổ\n",
            "[10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "Mông Cổ\n",
            "[14, 15, 16, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[35, 36, 37, 38, 39, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "Mông Cổ\n",
            "[10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[23, 24, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁d', 'ội', \"▁'\", '▁mưa', '▁g', 'ôn', \"▁'\", '▁vào', '▁lưới', '▁M', 'ông', '▁Cổ', '▁Không', '▁nằm', '▁ngoài', '▁dự', '▁đoán', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁đã', '▁có', '▁chiến', '▁thắng', '▁dễ', '▁dàng', '▁trước', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[24, 25, 26, 27, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[35, 36, 37, 38, 39, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'dội', \"'\", 'mưa', 'gôn', \"'\", 'vào', 'lưới', 'Mông_Cổ', 'Không', 'nằm', 'ngoài', 'dự_đoán', ',', 'U16', 'Việt_Nam', 'đã', 'có', 'chiến_thắng', 'dễ_dàng', 'trước', 'U16', 'Mông_Cổ', '.']\n",
            "U16 Việt Nam\n",
            "[16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[23, 24, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Như', '▁vậy', '▁tại', '▁bảng', '▁I', '▁vòng', '▁loại', '▁U', '16', '▁châu', '▁Á', '▁2018', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁và', '▁U', '16', '▁Australia', '▁tạm', '▁bằng', '▁điểm', '▁nhau', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[15, 16, 17, 18, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Australia\n",
            "[20, 21, 22, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Như_vậy', 'tại', 'bảng', 'I', 'vòng', 'loại', 'U16', 'châu_Á', '2018', ',', 'U16', 'Việt_Nam', 'và', 'U@@', '16@@', '_@@', 'Australia', 'tạm', 'bằng', 'điểm', 'nhau', '.']\n",
            "U16 Việt Nam\n",
            "[11, 12, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Australia\n",
            "[14, 15, 16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁U', '16', '▁Việt', '▁Nam', '▁thắng', '▁dễ', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, 3, 4, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[7, 8, 9, 10, 11, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['U16', 'Việt_Nam', 'thắng', 'dễ', 'U16', 'Mông_Cổ', '.']\n",
            "U16 Việt Nam\n",
            "[1, 2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Mông Cổ\n",
            "[5, 6, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Trong', '▁trận', '▁ra', '▁quân', '▁tại', '▁bảng', '▁I', '▁vòng', '▁loại', '▁U', '16', '▁châu', '▁Á', '▁2018', '▁gặp', '▁U', '16', '▁Campuchia', '▁', ',', '▁dù', '▁bị', '▁gỡ', '▁hòa', '▁1-1', '▁và', '▁bị', '▁mất', '▁người', '▁ở', '▁phút', '▁20', '▁', ',', '▁nhưng', '▁U', '16', '▁Việt', '▁Nam', '▁vẫn', '▁chơi', '▁xuất', '▁sắc', '▁để', '▁có', '▁chiến', '▁thắng', '▁chung', '▁cuộc', '▁5', '-2', '▁', '.']\n",
            "U16 Campuchia\n",
            "[16, 17, 18, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[36, 37, 38, 39, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Trong', 'trận', 'ra_quân', 'tại', 'bảng', 'I', 'vòng', 'loại', 'U16', 'châu_Á', '2018', 'gặp', 'U@@', '16@@', '_Cam@@', 'pu@@', 'chia', ',', 'dù', 'bị', 'gỡ', 'hò@@', 'a_@@', '1-1', 'và', 'bị', 'mất', 'người', 'ở', 'phút', '20', ',', 'nhưng', 'U16', 'Việt_Nam', 'vẫn', 'chơi', 'xuất_sắc', 'để', 'có', 'chiến_thắng', 'chung_cuộc', '5-2', '.']\n",
            "U16 Campuchia\n",
            "[13, 14, 15, 16, 17, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[34, 35, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['▁Bước', '▁vào', '▁trận', '▁thứ', '▁2', '▁gặp', '▁chủ', '▁nhà', '▁U', '16', '▁M', 'ông', '▁Cổ', '▁', ',', '▁U', '16', '▁Việt', '▁Nam', '▁tràn', '▁đầy', '▁tự', '▁tin', '▁hướng', '▁tới', '▁một', '▁chiến', '▁thắng', '▁đậm', '▁nhằm', '▁tạo', '▁đà', '▁tâm', '▁lý', '▁trước', '▁cuộc', '▁quyết', '▁đấu', '▁với', '▁U', '16', '▁Australia', '▁vào', '▁chiều', '▁ngày', '▁24', '/9', '▁tới', '▁', '.']\n",
            "U16 Mông Cổ\n",
            "[9, 10, 11, 12, 13, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[16, 17, 18, 19, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "\n",
            "\n",
            "['Bước', 'vào', 'trận', 'thứ', '2', 'gặp', 'chủ', 'nhà', 'U@@', '16@@', '_M@@', 'ông_@@', 'Cổ', ',', 'U16', 'Việt_Nam', 'tràn_đầy', 'tự_tin', 'hướng', 'tới', 'một', 'chiến_thắng', 'đậm', 'nhằm', 'tạo', 'đà', 'tâm_lý', 'trước', 'cuộc', 'quyết_đấu', 'với', 'U@@', '16@@', '_@@', 'Australia', 'vào', 'chiều', 'ngày', '24/9', 'tới', '.']\n",
            "U16 Mông Cổ\n",
            "[9, 10, 11, 12, 13, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
            "U16 Việt Nam\n",
            "[15, 16, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf8INnaweghT",
        "outputId": "d3028850-20fa-42b4-e0cf-c616a3d9f659"
      },
      "source": [
        "# convert to tensor\n",
        "\n",
        "pad_eid = -2\n",
        "\n",
        "if flags['use_phobert'] == True:\n",
        "    dev_pb_input_ids = torch.tensor(dev_pb_input_ids)\n",
        "    dev_pb_attention_masks = torch.tensor(dev_pb_attention_masks)\n",
        "    dev_pb_entity_1_eids = torch.tensor(dev_pb_entity_1_eids)\n",
        "    dev_pb_entity_2_eids = torch.tensor(dev_pb_entity_2_eids)\n",
        "    #dev_pb_labels = torch.tensor(dev_pb_labels)\n",
        "\n",
        "\n",
        "if flags['use_xlmr'] == True:\n",
        "    dev_xlmr_input_ids = torch.tensor(dev_xlmr_input_ids)\n",
        "    dev_xlmr_attention_masks = torch.tensor(dev_xlmr_attention_masks)\n",
        "    dev_xlmr_entity_1_eids = torch.tensor(dev_xlmr_entity_1_eids)\n",
        "    dev_xlmr_entity_2_eids = torch.tensor(dev_xlmr_entity_2_eids)\n",
        "    #dev_xlmr_labels = torch.tensor(dev_xlmr_labels)\n",
        "\n",
        "\n",
        "dev_labels = torch.tensor(dev_labels)\n",
        "\n",
        "print('DONE')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrvMixGGeghT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c17bd95-05e5-4235-d529-6d55c49ff1fb"
      },
      "source": [
        "'''\n",
        "if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, \\\n",
        "                                  dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids, \\\n",
        "                                  dev_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, dev_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "    dev_dataset = TensorDataset(dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids, dev_labels)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\\n    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids,                                   dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids,                                   dev_labels)\\n\\nelif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\\n    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, dev_labels)\\n\\nelif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\\n    dev_dataset = TensorDataset(dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids, dev_labels)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCQUsFTLeghT"
      },
      "source": [
        "#dev_dataloader = DataLoader(dev_dataset, batch_size=flags['batch_size'], shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2w44XoqKy_P"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4BFfO0cVk1"
      },
      "source": [
        "class BERTModel(nn.Module):\n",
        "    def __init__(self, model_type, entity_handle_type, emb_layer_lst, emb_layer_handle_type):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model_type = model_type\n",
        "\n",
        "        if self.model_type == 'phobert_base':\n",
        "            print('Using ', self.model_type, '.')\n",
        "            self.bert_model = AutoModel.from_pretrained(\"vinai/phobert-base\", output_hidden_states=True)\n",
        "\n",
        "        elif self.model_type == 'phobert_large':\n",
        "            print('Using ', self.model_type, '.')\n",
        "            self.bert_model = AutoModel.from_pretrained(\"vinai/phobert-large\", output_hidden_states=True)\n",
        "            \n",
        "        elif self.model_type == 'xlmr_base':\n",
        "            print('Using ', self.model_type, '.')\n",
        "            self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-base', output_hidden_states=True)\n",
        "\n",
        "        elif self.model_type == 'xlmr_large':\n",
        "            print('Using ', self.model_type, '.')\n",
        "            self.bert_model = XLMRobertaModel.from_pretrained('xlm-roberta-large', output_hidden_states=True)\n",
        "        \n",
        "        else:\n",
        "            assert False, str('Unkown model name: ' + self.model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n",
        "\n",
        "\n",
        "        self.entity_handle_type = entity_handle_type\n",
        "        self.emb_layer_lst = emb_layer_lst\n",
        "        self.emb_layer_handle_type = emb_layer_handle_type\n",
        "\n",
        "        # dùng để kiểm tra 1 phần xem code có chạy ổn không\n",
        "        self.sent_emb_len, self.wpi_emb_len = self.calculate_len_embedding()\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, b_input_ids, b_attention_mask, b_entity_1_eids, b_entity_2_eids):\n",
        "\n",
        "        outputs = self.bert_model(b_input_ids, b_attention_mask)\n",
        "        \n",
        "        # num_layer (13) * batch_size * max_sent_len * emb_size\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "        b_sent_final_embedding = self.get_sent_final_vector(hidden_states, b_entity_1_eids, b_entity_2_eids)\n",
        "\n",
        "        return b_sent_final_embedding\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "    hàm dưới sẽ duyệt từng cặp enitty trong 1 câu\n",
        "    sau đó tìm vector đại diện cho từng entity trong cặp này -> 2 vector embedding đại diện cho 2 entity\n",
        "    từ 2 vector này ta sẽ kết hợp lại theo luật dưới, rồi concat lại với nhau\n",
        "    [h_s,h_t,h_s*h_t,h_s+h_t,|h_s-h_t|]\n",
        "    cuối cùng sẽ thu được 1 vector duy nhất đại diện cho câu, và vector này có thể dùng cho lớp linear,... để phân loại\n",
        "\n",
        "    Lưu ý: hàm này sẽ trả về batch vector đại diện cho batch câu\n",
        "    '''\n",
        "    def get_sent_final_vector(self, hidden_states, b_entity_1_eids, b_entity_2_eids):\n",
        "\n",
        "        assert (len(b_entity_1_eids) == len(b_entity_2_eids)), str('len(b_entity_1_eids) != len(b_entity_2_eids)')\n",
        "            \n",
        "        sent_final_embedding_lst = []\n",
        "\n",
        "        for isent in range(len(b_entity_1_eids)):   # từng câu 1 trong batch\n",
        "\n",
        "            \n",
        "            entity_1_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_1_eids[isent], isent)\n",
        "            entity_2_final_vector = self.get_entity_embedding_vector(hidden_states, b_entity_2_eids[isent], isent)\n",
        "\n",
        "            assert (entity_1_final_vector.size() == entity_2_final_vector.size()), str('entity_1_final_vector size != entity_2_final_vector size')\n",
        "\n",
        "            # not implement custom emb stack yet \n",
        "            entity_sum_vector = torch.add(entity_1_final_vector, entity_2_final_vector)\n",
        "            entity_mul_vector = torch.mul(entity_1_final_vector, entity_2_final_vector)\n",
        "            entity_abs_sub_vector = torch.abs(torch.sub(entity_1_final_vector, entity_2_final_vector))\n",
        "\n",
        "            # [h_s,h_t,h_s*h_t,h_s+h_t,|h_s-h_t|]\n",
        "            sent_final_vector = torch.cat((entity_1_final_vector, entity_2_final_vector, entity_mul_vector, entity_sum_vector, entity_abs_sub_vector))\n",
        "\n",
        "            assert (len(sent_final_vector.size()) == 1), str('sent_final_vector is not a vector')\n",
        "\n",
        "            assert (sent_final_vector.size()[0] == self.sent_emb_len), str('sent_emb_len is not: ' + str(self.sent_emb_len))\n",
        "\n",
        "\n",
        "            sent_final_embedding_lst.append(sent_final_vector)\n",
        "\n",
        "\n",
        "        assert (len(sent_final_embedding_lst) == len(b_entity_1_eids)), str(self.model_type + ': len batch sent embedding not qual batch_size.')\n",
        "        sent_final_embedding_lst = torch.stack(sent_final_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "\n",
        "\n",
        "        return sent_final_embedding_lst\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    hàm dưới dùng để lấy ra 1 vector embedding đại diện duy nhất cho 1 entity\n",
        "    đầu tiên, duyệt từng word pice trong danh sách cách word piece của entity\n",
        "\n",
        "    với mỗi word pice, ta sẽ lấy embedding của word piece này ở các layer mà ta muốn sau đó gộp thành 1 vector đại diện cho word pice duy nhất\n",
        "    tức là ví dụ: với mỗi word piece ta sẽ lấy các embedding của word piece này trong 4 layer cuối -> 4 vector từ 4 layer cho 1 word pice,\n",
        "    sau đó ta có thể sum element wise 4 vector này để ra 1 vector duy nhất đại diện cho word piece\n",
        "\n",
        "    cuối cùng ta sẽ có 1 list các embedding (đại diện) của các word piece trong 1 entity\n",
        "    từ các embedding này ta có thể chọn ngẫu nhiên 1 cái hoăc lấy max pooling các embedding này để ra 1 vector duy nhất cho 1 entity\n",
        "    '''\n",
        "    def get_entity_embedding_vector(self, hidden_states, entity_eids, isent):\n",
        "\n",
        "        entity_wpi_embedding_lst = []\n",
        "        for ient_eid, entity_eid in enumerate(entity_eids):                    # từng word piece của entity\n",
        "\n",
        "            if entity_eid < 0:  # nếu gặp padding wpi (-2) thì dừng\n",
        "                assert ient_eid > 0, str('No wpi id')\n",
        "                break\n",
        "                \n",
        "            wpi_final_vector = None\n",
        "            wpi_embedding_lst = []\n",
        "            # thu thập mọi vector trong các layer muốn lấy của 1 word piece\n",
        "            for emb_layer in self.emb_layer_lst:          # từng layer mà ta muốn lấy embedding\n",
        "                wpi_embedding_lst.append(hidden_states[emb_layer-1][isent][entity_eid])\n",
        "                \n",
        "            # xử lý embedding thuộc các layer khác nhau của 1 word piece\n",
        "            if self.emb_layer_handle_type == 'sum':\n",
        "                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "                wpi_final_vector = torch.sum(wpi_embedding_lst, dim=0)\n",
        "\n",
        "            elif self.emb_layer_handle_type == 'concat':\n",
        "                wpi_final_vector = torch.cat(wpi_embedding_lst)\n",
        "\n",
        "            elif self.emb_layer_handle_type == 'max_pooling':\n",
        "                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "                wpi_final_vector = torch.max(wpi_embedding_lst, dim=0).values\n",
        "\n",
        "            elif self.emb_layer_handle_type == 'average_pooling':\n",
        "                wpi_embedding_lst = torch.stack(wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "                wpi_final_vector = torch.mean(wpi_embedding_lst, dim=0)\n",
        "\n",
        "            else:\n",
        "                assert False, \\\n",
        "                str(self.model_type + ': Unknow emb_layer_handle_type: ' + self.emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n",
        "\n",
        "            assert (len(wpi_final_vector.size()) == 1), str('entity_final_vector is not a vector.')\n",
        "            assert (wpi_final_vector.size()[0] == self.wpi_emb_len), str('wpi_emb_len is not: ' + str(self.wpi_emb_len))\n",
        "\n",
        "            entity_wpi_embedding_lst.append(wpi_final_vector)\n",
        "            \n",
        "\n",
        "        assert (len(entity_wpi_embedding_lst) > 0), str('entity_wpi_embedding_lst is empty.')\n",
        "\n",
        "        # xử lý embedding của mọi word piece trong 1 entity\n",
        "        if self.entity_handle_type == 'max_pooling':\n",
        "            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "            entity_final_vector = torch.max(entity_wpi_embedding_lst, dim=0).values\n",
        "\n",
        "        elif self.entity_handle_type == 'average_pooling':\n",
        "            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "            entity_final_vector = torch.mean(entity_wpi_embedding_lst, dim=0)\n",
        "\n",
        "        elif self.entity_handle_type == 'sum':\n",
        "            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "            entity_final_vector = torch.sum(entity_wpi_embedding_lst, dim=0)\n",
        "            \n",
        "        elif self.entity_handle_type == 'random':\n",
        "            rand_index = torch.randint(len(entity_wpi_embedding_lst), (1,))\n",
        "            entity_wpi_embedding_lst = torch.stack(entity_wpi_embedding_lst)  # convert from 'python list of tensors' to 'pytorch tensor of tensers'\n",
        "            entity_final_vector = entity_wpi_embedding_lst[rand_index][0]\n",
        "                \n",
        "        else:\n",
        "            assert False, \\\n",
        "            str(self.model_type + ': Unknow entity_handle_type: ' + self.entity_handle_type + '. Allow: max_pooling, average_pooling, sum, random.')\n",
        "\n",
        "\n",
        "        assert (len(entity_final_vector.size()) == 1), str('entity_final_vector is not a vector.')\n",
        "        \n",
        "        assert (entity_final_vector.size()[0] == self.wpi_emb_len), str('entity_final_vector is not equal wpi_emb_len: ' + str(self.wpi_emb_len))\n",
        "\n",
        "\n",
        "        return entity_final_vector\n",
        "\n",
        "\n",
        "\n",
        "    #  tính len của vector đại diện cho câu\n",
        "    def calculate_len_embedding(self):\n",
        "\n",
        "        if (self.model_type == 'phobert_base') or (self.model_type == 'xlmr_base'):\n",
        "            wpi_emb_len = 768\n",
        "        elif self.model_type == 'phobert_large' or (self.model_type == 'xlmr_large'):\n",
        "            wpi_emb_len = 1024\n",
        "        else:\n",
        "            assert False, str('Unkown model name: ' + self.model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n",
        "\n",
        "        # do entity thì ta chỉ max, average pooling hoặc lấy sum các word piece nên độ dài sẽ bằng luôn độ dài vector đại diện word piece\n",
        "        # nếu không phải concat thì chiều vector đại diện wordpiece sẽ giữ nguyên\n",
        "        if (self.emb_layer_handle_type == 'sum') or (self.emb_layer_handle_type == 'max_pooling') \\\n",
        "        or (self.emb_layer_handle_type == 'average_pooling'):\n",
        "            entity_emb_len = wpi_emb_len\n",
        "\n",
        "        # nếu là concat thì chiều vector đại diện wordpiece sẽ nhân với số layer concat\n",
        "        elif self.emb_layer_handle_type == 'concat':\n",
        "            wpi_emb_len = wpi_emb_len * len(self.emb_layer_lst)\n",
        "            entity_emb_len = wpi_emb_len\n",
        "        else:\n",
        "            assert False, \\\n",
        "            str(self.model_type + ': Unknow emb_layer_handle_type: ' + self.emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n",
        "\n",
        "        \n",
        "\n",
        "        # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n",
        "        # sau này nếu đổi \n",
        "        sent_emb_len = entity_emb_len * 5\n",
        "\n",
        "\n",
        "        return sent_emb_len, wpi_emb_len\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMBOFVoQYLQv"
      },
      "source": [
        "class REClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, flags):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        if flags['use_phobert'] == True:\n",
        "            self.pb_model = BERTModel(flags['phobert_model'], flags['pb_entity_handle_type'], flags['pb_emb_layer_lst'], flags['pb_emb_layer_handle_type'])\n",
        "            pb_sent_emb_len = self.calculate_len_sent_embedding(flags['phobert_model'], flags['pb_emb_layer_lst'], flags['pb_emb_layer_handle_type'])\n",
        "\n",
        "        if flags['use_xlmr'] == True:\n",
        "            self.xlmr_model = BERTModel(flags['xlmr_model'], flags['xlmr_entity_handle_type'], flags['xlmr_emb_layer_lst'], flags['xlmr_emb_layer_handle_type'])\n",
        "            xlmr_sent_emb_len = self.calculate_len_sent_embedding(flags['xlmr_model'], flags['xlmr_emb_layer_lst'], flags['xlmr_emb_layer_handle_type'])\n",
        "\n",
        "        if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "            self.final_sent_emb_len = pb_sent_emb_len + xlmr_sent_emb_len\n",
        "\n",
        "        elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "            self.final_sent_emb_len = pb_sent_emb_len\n",
        "        \n",
        "        elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "            self.final_sent_emb_len = xlmr_sent_emb_len\n",
        "\n",
        "\n",
        "        self.flags = flags\n",
        "\n",
        "        self.dropout1 = nn.Dropout(p=flags['dropout1_rate'])\n",
        "        self.linear1 = nn.Linear(self.final_sent_emb_len, flags['out_linear1'])\n",
        "        self.dropout2 = nn.Dropout(p=flags['dropout2_rate'])\n",
        "        self.linear2 = nn.Linear(flags['out_linear1'], 8)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids):\n",
        "\n",
        "        if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "            \n",
        "\n",
        "            pb_sent_final_embedding = self.pb_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "            xlmr_sent_final_embedding = self.xlmr_model(xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n",
        "            \n",
        "            # concat two embedding\n",
        "            bert_sent_final_embedding = torch.cat((pb_sent_final_embedding, xlmr_sent_final_embedding), dim=1)\n",
        "\n",
        "            assert (len(bert_sent_final_embedding.size()) == 2) and (bert_sent_final_embedding.size()[0] == pb_sent_final_embedding.size()[0]) \\\n",
        "            and (bert_sent_final_embedding.size()[0] == xlmr_sent_final_embedding.size()[0]) \\\n",
        "            and (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n",
        "            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n",
        "\n",
        "        elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "            \n",
        "\n",
        "            bert_sent_final_embedding = self.pb_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids)\n",
        "\n",
        "            assert (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n",
        "            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n",
        "            \n",
        "        \n",
        "        elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "            \n",
        "\n",
        "            bert_sent_final_embedding = self.xlmr_model(xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n",
        "            \n",
        "            assert (bert_sent_final_embedding.size()[1] == self.final_sent_emb_len), \\\n",
        "            str('REClassifier: PROBLEM WITH sent_final_embedding len.')\n",
        "\n",
        "\n",
        "        x = self.dropout1(bert_sent_final_embedding)\n",
        "        x = self.linear1(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    #  tính len của vector đại diện cho câu\n",
        "    def calculate_len_sent_embedding(self, model_type, emb_layer_lst, emb_layer_handle_type):\n",
        "\n",
        "        if (model_type == 'phobert_base') or (model_type == 'xlmr_base'):\n",
        "            wpi_emb_len = 768\n",
        "        elif (model_type == 'phobert_large') or (model_type == 'xlmr_large'):\n",
        "            wpi_emb_len = 1024\n",
        "        else:\n",
        "            assert False, str('Unkown model name: ' + model_type + '. Allow: phobert_base, phobert_large, xlmr_base, xlmr_large')\n",
        "\n",
        "        # do entity thì ta chỉ max, average pooling hoặc lấy sum các word piece nên độ dài sẽ bằng luôn độ dài vector đại diện word piece\n",
        "        # nếu không phải concat thì chiều vector đại diện wordpiece sẽ giữ nguyên\n",
        "        if (emb_layer_handle_type == 'sum') or (emb_layer_handle_type == 'max_pooling') \\\n",
        "        or (emb_layer_handle_type == 'average_pooling'):\n",
        "            entity_emb_len = wpi_emb_len\n",
        "\n",
        "        # nếu là concat thì chiều vector đại diện wordpiece sẽ nhân với số layer concat\n",
        "        elif emb_layer_handle_type == 'concat':\n",
        "            wpi_emb_len = wpi_emb_len * len(emb_layer_lst)\n",
        "            entity_emb_len = wpi_emb_len\n",
        "        else:\n",
        "            assert False, \\\n",
        "            str(model_type + ': Unknow emb_layer_handle_type: ' + emb_layer_handle_type + '. Allow: sum, concat, max_pooling, average_pooling.')\n",
        "\n",
        "        \n",
        "\n",
        "        # [h_s, h_t, h_s*h_t, h_s+h_t, |h_s-h_t|]\n",
        "        # sau này nếu đổi \n",
        "        sent_emb_len = entity_emb_len * 5\n",
        "\n",
        "\n",
        "        return sent_emb_len\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TJjwwBgu32B"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7SbTS2ol2bC"
      },
      "source": [
        "### train_dataset, dev_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDc6lLJGlijU"
      },
      "source": [
        "if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, \\\n",
        "                                  train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, \\\n",
        "                                  train_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "    train_dataset = TensorDataset(train_pb_input_ids, train_pb_attention_masks, train_pb_entity_1_eids, train_pb_entity_2_eids, train_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "    train_dataset = TensorDataset(train_xlmr_input_ids, train_xlmr_attention_masks, train_xlmr_entity_1_eids, train_xlmr_entity_2_eids, train_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJZGAv2AlzHQ"
      },
      "source": [
        "if (flags['use_phobert'] == True) and (flags['use_xlmr'] == True):\n",
        "    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, \\\n",
        "                                  dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids, \\\n",
        "                                  dev_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == True) and (flags['use_xlmr'] == False):\n",
        "    dev_dataset = TensorDataset(dev_pb_input_ids, dev_pb_attention_masks, dev_pb_entity_1_eids, dev_pb_entity_2_eids, dev_labels)\n",
        "\n",
        "elif (flags['use_phobert'] == False) and (flags['use_xlmr'] == True):\n",
        "    dev_dataset = TensorDataset(dev_xlmr_input_ids, dev_xlmr_attention_masks, dev_xlmr_entity_1_eids, dev_xlmr_entity_2_eids, dev_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ulUGZfMIjh"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA7z6epbveDl"
      },
      "source": [
        "del pb_model\n",
        "del xlmr_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwM2q4CifcO7"
      },
      "source": [
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STcmN9RwlFdY"
      },
      "source": [
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XlUBDwkMMy1"
      },
      "source": [
        "def map_fn(flags, train_dataset, dev_dataset, save_path):\n",
        "    ## Setup \n",
        "\n",
        "    # Sets a common random seed - both for initialization and ensuring graph is the same\n",
        "\n",
        "    random.seed(flags['seed'])\n",
        "    np.random.seed(flags['seed'])\n",
        "    torch.manual_seed(flags['seed'])\n",
        "    torch.cuda.manual_seed_all(flags['seed'])\n",
        "\n",
        "    # GPU\n",
        "    # If there's a GPU available...\n",
        "    if torch.cuda.is_available():    \n",
        "        # Tell PyTorch to use the GPU.    \n",
        "        device = torch.device(\"cuda\")\n",
        "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    # If not...\n",
        "    else:\n",
        "        print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    ## Dataloader construction\n",
        "  \n",
        "    \n",
        "  \n",
        "  # Creates dataloaders, which load data in batches\n",
        "  # Note: dev loader is not shuffled or sampled\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        sampler = torch.utils.data.RandomSampler(train_dataset),\n",
        "        batch_size=flags['batch_size'])\n",
        "\n",
        "    dev_loader = torch.utils.data.DataLoader(\n",
        "        dev_dataset,\n",
        "        sampler = torch.utils.data.SequentialSampler(dev_dataset),\n",
        "        batch_size=flags['batch_size'])\n",
        "  \n",
        "\n",
        "    ## Network, optimizer, and loss function creation\n",
        "    print('Loading...')\n",
        "    rec_model = REClassifier(flags)\n",
        "    rec_model.to(device)\n",
        "    print('Finish')\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = AdamW(rec_model.parameters(), lr=flags['linear_lr'], betas=flags['linear_betas'], \\\n",
        "                      eps=flags['linear_eps'], weight_decay=flags['linear_weight_decay'])\n",
        "\n",
        "    lambda2 = lambda epoch: float(flags['linear_lr_schedule_rate']) ** epoch\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda2)\n",
        "\n",
        "\n",
        "    ## Trains\n",
        "    \n",
        "    rec_model.train()\n",
        "\n",
        "    gobal_train_start = time.time()\n",
        "\n",
        "    dev_f1_score_macro_history = []\n",
        "    dev_f1_score_micro_history = []\n",
        "    dev_loss_history = []\n",
        "\n",
        "    for epoch in range(flags['total_epochs']):\n",
        "\n",
        "        print('\\n\\nStart training epoch: ', epoch)\n",
        "\n",
        "        if (epoch == flags['phobert_num_epochs']) and (flags['use_phobert'] == True):\n",
        "            print('freeze phobert')\n",
        "            for param in rec_model.pb_model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if (epoch == flags['xlmr_num_epochs']) and (flags['use_xlmr'] == True):\n",
        "            print('freeze xlmr')\n",
        "            for param in rec_model.xlmr_model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        train_batch_step = 0\n",
        "        train_loss = 0\n",
        "\n",
        "        train_predict_lst = []\n",
        "        train_target_lst = []\n",
        "\n",
        "        for batch_num, batch in enumerate(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "\n",
        "            if flags['use_phobert'] and flags['use_xlmr']:\n",
        "\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids, targets = \\\n",
        "                batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), \\\n",
        "                batch[4].to(device), batch[5].to(device), batch[6].to(device), batch[7].to(device), batch[8].to(device)\n",
        "\n",
        "            elif (flags['use_phobert']) and (not flags['use_xlmr']):\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n",
        "                batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n",
        "\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids = None, None, None, None\n",
        "\n",
        "            elif (not flags['use_phobert']) and (flags['use_xlmr']):\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids, targets = \\\n",
        "                batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device), batch[4].to(device)\n",
        "\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids = None, None, None, None\n",
        "\n",
        "\n",
        "            # Acquires the network's best guesses at each class\n",
        "            output = rec_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n",
        "                               xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n",
        "\n",
        "            # Computes loss\n",
        "            loss = loss_fn(output, targets) \n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to rate.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            nn.utils.clip_grad_norm_(rec_model.parameters(), flags['clip_grad_norm_rate'])\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            if (train_batch_step % flags['log_batch'] == 0):\n",
        "                duration = time.time() - batch_start_time\n",
        "                print(duration, ' - epoch: ', epoch, ' - batch: ', train_batch_step, ' - current_batch_loss: ', loss.item(), ' - current lr: ', str(scheduler.get_last_lr()[0]))\n",
        "\n",
        "            train_batch_step += 1\n",
        "\n",
        "            train_predict_lst.append(torch.argmax(output, 1))\n",
        "            train_target_lst.append(targets)\n",
        "        \n",
        "\n",
        "        print('\\n\\nFinish training epoch: ', epoch, 'after: ', (time.time() - epoch_start_time))\n",
        "        \n",
        "        #print(train_predict_lst)\n",
        "        train_predict_lst = torch.cat(train_predict_lst).to(torch.device(\"cpu\"))\n",
        "        train_target_lst = torch.cat(train_target_lst).to(torch.device(\"cpu\"))\n",
        "\n",
        "        #print(train_predict_lst)\n",
        "\n",
        "        train_f1_macro = sklearn.metrics.f1_score(list(train_target_lst), list(train_predict_lst), average='macro')\n",
        "        train_f1_micro = sklearn.metrics.f1_score(list(train_target_lst), list(train_predict_lst), average='micro')\n",
        "\n",
        "        \n",
        "        print('Current_train_f1_macro: ', train_f1_macro, ' -  current_train_f1_micro: ', train_f1_micro)\n",
        "        print('Avg train_loss per batch: ', train_loss/train_batch_step)\n",
        "\n",
        "        if ((epoch + 1) % int(flags['linear_lr_schedule_epoch'])) == 0:\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "        print('\\nEvaluating on dev set...')\n",
        "        eval_start_time = time.time()\n",
        "\n",
        "        rec_model.eval()\n",
        "\n",
        "        dev_loss = 0\n",
        "        dev_batch_step = 0\n",
        "\n",
        "        dev_predict_lst = []\n",
        "        dev_target_lst = []\n",
        "\n",
        "        \n",
        "        for dev_batch_num, dev_batch in enumerate(dev_loader):\n",
        "            if flags['use_phobert'] and flags['use_xlmr']:\n",
        "\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids, targets = \\\n",
        "                dev_batch[0].to(device), dev_batch[1].to(device), dev_batch[2].to(device), dev_batch[3].to(device), \\\n",
        "                dev_batch[4].to(device), dev_batch[5].to(device), dev_batch[6].to(device), dev_batch[7].to(device), dev_batch[8].to(device)\n",
        "\n",
        "            elif (flags['use_phobert']) and (not flags['use_xlmr']):\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, targets = \\\n",
        "                dev_batch[0].to(device), dev_batch[1].to(device), dev_batch[2].to(device), dev_batch[3].to(device), dev_batch[4].to(device)\n",
        "\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids = None, None, None, None\n",
        "\n",
        "            elif (not flags['use_phobert']) and (flags['use_xlmr']):\n",
        "                xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids, targets = \\\n",
        "                dev_batch[0].to(device), dev_batch[1].to(device), dev_batch[2].to(device), dev_batch[3].to(device), dev_batch[4].to(device)\n",
        "\n",
        "                pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids = None, None, None, None\n",
        "\n",
        "\n",
        "            # Acquires the network's best guesses at each class\n",
        "            output = rec_model(pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, \\\n",
        "                               xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\n",
        "\n",
        "            loss = loss_fn(output, targets)\n",
        "            dev_loss += loss.item()\n",
        "\n",
        "\n",
        "            # Updates running statistics\n",
        "            dev_predict_lst.append(torch.argmax(output, 1))\n",
        "            dev_target_lst.append(targets)\n",
        "\n",
        "            dev_batch_step += 1\n",
        "        \n",
        "        dev_predict_lst = torch.cat(dev_predict_lst).to(torch.device(\"cpu\"))\n",
        "        dev_target_lst = torch.cat(dev_target_lst).to(torch.device(\"cpu\"))\n",
        "\n",
        "        dev_f1_macro = sklearn.metrics.f1_score(list(dev_target_lst), list(dev_predict_lst), average='macro')\n",
        "        dev_f1_micro = sklearn.metrics.f1_score(list(dev_target_lst), list(dev_predict_lst), average='micro')\n",
        "\n",
        "        print('Finish eval epoch: ', epoch, ' after: ', (time.time() - eval_start_time))\n",
        "        print('dev_f1_macro: ', dev_f1_macro, ' -  dev_f1_micro: ', dev_f1_micro)\n",
        "        print('Avg dev_loss per batch: ', dev_loss/dev_batch_step)\n",
        "\n",
        "        # save new better model\n",
        "        root_model_save_path = save_path\n",
        "        if (epoch == 0):\n",
        "            print('SAVING MODEL AT EPOCH 0 ...')\n",
        "            model_save_path = root_model_save_path + '/rec_model.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "\n",
        "            flags_save_path = root_model_save_path + '/flags.txt'\n",
        "            with open(flags_save_path, 'w') as flags_file:\n",
        "                json.dump(flags, flags_file)\n",
        "\n",
        "        elif (dev_f1_micro > max(dev_f1_score_micro_history)):\n",
        "            print('SAVING MODEL with better micro score...')\n",
        "            model_save_path = root_model_save_path + '/rec_model_micro_' + str(epoch) + '.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "        \n",
        "        elif (dev_f1_macro > max(dev_f1_score_macro_history)):\n",
        "            print('SAVING MODEL with better macro score...')\n",
        "            model_save_path = root_model_save_path + '/rec_model_macro_' + str(epoch) + '.bin'\n",
        "            torch.save(rec_model.state_dict(), model_save_path)\n",
        "\n",
        "        dev_f1_score_macro_history.append(dev_f1_macro)\n",
        "        dev_f1_score_micro_history.append(dev_f1_micro)\n",
        "        dev_loss_history.append(dev_loss/dev_batch_step)\n",
        "\n",
        "\n",
        "        dev_f1_score_macro_history_str = [str(itm) for itm in copy.deepcopy(dev_f1_score_macro_history)]\n",
        "        dev_f1_score_micro_history_str = [str(itm) for itm in copy.deepcopy(dev_f1_score_micro_history)]\n",
        "        dev_loss_history_str = [str(itm) for itm in copy.deepcopy(dev_loss_history)]\n",
        "\n",
        "        total_dev_result_save_path = root_model_save_path + '/all_dev_result.txt'\n",
        "\n",
        "        with open(total_dev_result_save_path, 'w') as dev_result_file:\n",
        "            for dev_result in (dev_f1_score_macro_history_str, dev_f1_score_micro_history_str, dev_loss_history_str):\n",
        "                dev_result_file.write('   '.join(dev_result) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    elapsed_train_time = time.time() - gobal_train_start\n",
        "    print(\"Finished training. Train time was:\", elapsed_train_time)\n",
        "\n",
        "    return dev_f1_score_macro_history, dev_f1_score_micro_history, dev_loss_history\n",
        "     \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gilNpxgAol3_"
      },
      "source": [
        "folder_order = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyiTKYD_uuyk"
      },
      "source": [
        "!mkdir rec_model_save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsjlsEwBooSO"
      },
      "source": [
        "import pathlib\n",
        "save_path = 'rec_model_save/' + str(folder_order)\n",
        "pathlib.Path(save_path).mkdir(parents=False, exist_ok=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYnn8iAroW_P",
        "outputId": "5b06efd0-5c6b-41b6-e4bf-14ecd43eabfa"
      },
      "source": [
        "dev_f1_score_macro_history, dev_f1_score_micro_history, dev_loss_history = map_fn(flags,train_dataset, dev_dataset, save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n",
            "Loading...\n",
            "Using  phobert_base .\n",
            "Using  xlmr_large .\n",
            "Finish\n",
            "\n",
            "\n",
            "Start training epoch:  0\n",
            "freeze xlmr\n",
            "1.7315785884857178  - epoch:  0  - batch:  0  - current_batch_loss:  84.40721893310547  - current lr:  1e-05\n",
            "1.5937635898590088  - epoch:  0  - batch:  30  - current_batch_loss:  22.820798873901367  - current lr:  1e-05\n",
            "1.5747010707855225  - epoch:  0  - batch:  60  - current_batch_loss:  25.832979202270508  - current lr:  1e-05\n",
            "1.5902493000030518  - epoch:  0  - batch:  90  - current_batch_loss:  11.978963851928711  - current lr:  1e-05\n",
            "1.5912296772003174  - epoch:  0  - batch:  120  - current_batch_loss:  7.587564468383789  - current lr:  1e-05\n",
            "1.5914125442504883  - epoch:  0  - batch:  150  - current_batch_loss:  4.083885669708252  - current lr:  1e-05\n",
            "1.582141399383545  - epoch:  0  - batch:  180  - current_batch_loss:  11.150200843811035  - current lr:  1e-05\n",
            "1.5967803001403809  - epoch:  0  - batch:  210  - current_batch_loss:  12.235268592834473  - current lr:  1e-05\n",
            "1.5774855613708496  - epoch:  0  - batch:  240  - current_batch_loss:  3.175320863723755  - current lr:  1e-05\n",
            "1.5913660526275635  - epoch:  0  - batch:  270  - current_batch_loss:  6.732058048248291  - current lr:  1e-05\n",
            "1.5719590187072754  - epoch:  0  - batch:  300  - current_batch_loss:  6.102525234222412  - current lr:  1e-05\n",
            "1.5785768032073975  - epoch:  0  - batch:  330  - current_batch_loss:  3.040881633758545  - current lr:  1e-05\n",
            "1.6082220077514648  - epoch:  0  - batch:  360  - current_batch_loss:  2.6037230491638184  - current lr:  1e-05\n",
            "1.599461555480957  - epoch:  0  - batch:  390  - current_batch_loss:  10.813592910766602  - current lr:  1e-05\n",
            "1.5854015350341797  - epoch:  0  - batch:  420  - current_batch_loss:  0.7387757897377014  - current lr:  1e-05\n",
            "1.5816748142242432  - epoch:  0  - batch:  450  - current_batch_loss:  3.6132724285125732  - current lr:  1e-05\n",
            "1.5742602348327637  - epoch:  0  - batch:  480  - current_batch_loss:  2.8083693981170654  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  0 after:  777.2325992584229\n",
            "Current_train_f1_macro:  0.18697125582401114  -  current_train_f1_micro:  0.7299712735397382\n",
            "Avg train_loss per batch:  10.409159307873674\n",
            "\n",
            "Evaluating on dev set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish eval epoch:  0  after:  266.60572504997253\n",
            "dev_f1_macro:  0.20906102389669895  -  dev_f1_micro:  0.8684353004872767\n",
            "Avg dev_loss per batch:  3.982571199100962\n",
            "SAVING MODEL AT EPOCH 0 ...\n",
            "\n",
            "\n",
            "Start training epoch:  1\n",
            "1.5766165256500244  - epoch:  1  - batch:  0  - current_batch_loss:  0.0635533332824707  - current lr:  1e-05\n",
            "1.5484189987182617  - epoch:  1  - batch:  30  - current_batch_loss:  0.6351605653762817  - current lr:  1e-05\n",
            "1.538466215133667  - epoch:  1  - batch:  60  - current_batch_loss:  0.9055660963058472  - current lr:  1e-05\n",
            "1.5438895225524902  - epoch:  1  - batch:  90  - current_batch_loss:  0.25098296999931335  - current lr:  1e-05\n",
            "1.537644863128662  - epoch:  1  - batch:  120  - current_batch_loss:  0.41004976630210876  - current lr:  1e-05\n",
            "1.5410652160644531  - epoch:  1  - batch:  150  - current_batch_loss:  0.2521735727787018  - current lr:  1e-05\n",
            "1.5671412944793701  - epoch:  1  - batch:  180  - current_batch_loss:  0.20408950746059418  - current lr:  1e-05\n",
            "1.5333116054534912  - epoch:  1  - batch:  210  - current_batch_loss:  0.3838523328304291  - current lr:  1e-05\n",
            "1.5538125038146973  - epoch:  1  - batch:  240  - current_batch_loss:  0.17059481143951416  - current lr:  1e-05\n",
            "1.5352730751037598  - epoch:  1  - batch:  270  - current_batch_loss:  0.12128444761037827  - current lr:  1e-05\n",
            "1.5439739227294922  - epoch:  1  - batch:  300  - current_batch_loss:  0.120051808655262  - current lr:  1e-05\n",
            "1.5434527397155762  - epoch:  1  - batch:  330  - current_batch_loss:  0.4137227535247803  - current lr:  1e-05\n",
            "1.5464906692504883  - epoch:  1  - batch:  360  - current_batch_loss:  0.4005066752433777  - current lr:  1e-05\n",
            "1.5522265434265137  - epoch:  1  - batch:  390  - current_batch_loss:  0.04351681098341942  - current lr:  1e-05\n",
            "1.551208257675171  - epoch:  1  - batch:  420  - current_batch_loss:  0.12357452511787415  - current lr:  1e-05\n",
            "1.5470192432403564  - epoch:  1  - batch:  450  - current_batch_loss:  0.19861431419849396  - current lr:  1e-05\n",
            "1.5676145553588867  - epoch:  1  - batch:  480  - current_batch_loss:  0.20082660019397736  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  1 after:  760.6085197925568\n",
            "Current_train_f1_macro:  0.5948712119363238  -  current_train_f1_micro:  0.9127353973827003\n",
            "Avg train_loss per batch:  0.4161533237957605\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  1  after:  266.6166229248047\n",
            "dev_f1_macro:  0.528467524337102  -  dev_f1_micro:  0.9076340010828371\n",
            "Avg dev_loss per batch:  0.33310387487058807\n",
            "SAVING MODEL with better micro score...\n",
            "\n",
            "\n",
            "Start training epoch:  2\n",
            "1.5588486194610596  - epoch:  2  - batch:  0  - current_batch_loss:  0.047659147530794144  - current lr:  1e-05\n",
            "1.5696957111358643  - epoch:  2  - batch:  30  - current_batch_loss:  0.03465805575251579  - current lr:  1e-05\n",
            "1.5596380233764648  - epoch:  2  - batch:  60  - current_batch_loss:  0.1566707193851471  - current lr:  1e-05\n",
            "1.5781002044677734  - epoch:  2  - batch:  90  - current_batch_loss:  0.32810959219932556  - current lr:  1e-05\n",
            "1.5524871349334717  - epoch:  2  - batch:  120  - current_batch_loss:  0.12129409611225128  - current lr:  1e-05\n",
            "1.5444152355194092  - epoch:  2  - batch:  150  - current_batch_loss:  0.06153293699026108  - current lr:  1e-05\n",
            "1.5481772422790527  - epoch:  2  - batch:  180  - current_batch_loss:  0.08780281245708466  - current lr:  1e-05\n",
            "1.5768442153930664  - epoch:  2  - batch:  210  - current_batch_loss:  0.18731075525283813  - current lr:  1e-05\n",
            "1.5619468688964844  - epoch:  2  - batch:  240  - current_batch_loss:  0.15864689648151398  - current lr:  1e-05\n",
            "1.5548830032348633  - epoch:  2  - batch:  270  - current_batch_loss:  0.0980043038725853  - current lr:  1e-05\n",
            "1.5889480113983154  - epoch:  2  - batch:  300  - current_batch_loss:  0.2727600932121277  - current lr:  1e-05\n",
            "1.5685100555419922  - epoch:  2  - batch:  330  - current_batch_loss:  0.03820694237947464  - current lr:  1e-05\n",
            "1.5638551712036133  - epoch:  2  - batch:  360  - current_batch_loss:  0.15377618372440338  - current lr:  1e-05\n",
            "1.5340147018432617  - epoch:  2  - batch:  390  - current_batch_loss:  0.3848307728767395  - current lr:  1e-05\n",
            "1.5678493976593018  - epoch:  2  - batch:  420  - current_batch_loss:  0.01406928151845932  - current lr:  1e-05\n",
            "1.5349111557006836  - epoch:  2  - batch:  450  - current_batch_loss:  0.33174899220466614  - current lr:  1e-05\n",
            "1.5533950328826904  - epoch:  2  - batch:  480  - current_batch_loss:  0.06863636523485184  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  2 after:  760.8299956321716\n",
            "Current_train_f1_macro:  0.7747472526467014  -  current_train_f1_micro:  0.9510373443983402\n",
            "Avg train_loss per batch:  0.1687524457058242\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  2  after:  266.958797454834\n",
            "dev_f1_macro:  0.4409700872911132  -  dev_f1_micro:  0.9173795343800758\n",
            "Avg dev_loss per batch:  0.4505754641222644\n",
            "SAVING MODEL with better micro score...\n",
            "\n",
            "\n",
            "Start training epoch:  3\n",
            "freeze phobert\n",
            "1.1627309322357178  - epoch:  3  - batch:  0  - current_batch_loss:  0.23271235823631287  - current lr:  1e-05\n",
            "1.1142160892486572  - epoch:  3  - batch:  30  - current_batch_loss:  0.04474762827157974  - current lr:  1e-05\n",
            "1.1194756031036377  - epoch:  3  - batch:  60  - current_batch_loss:  0.1984235793352127  - current lr:  1e-05\n",
            "1.1182348728179932  - epoch:  3  - batch:  90  - current_batch_loss:  0.2263583540916443  - current lr:  1e-05\n",
            "1.1190626621246338  - epoch:  3  - batch:  120  - current_batch_loss:  0.3444025218486786  - current lr:  1e-05\n",
            "1.1148993968963623  - epoch:  3  - batch:  150  - current_batch_loss:  0.12305060774087906  - current lr:  1e-05\n",
            "1.1165435314178467  - epoch:  3  - batch:  180  - current_batch_loss:  0.015732385218143463  - current lr:  1e-05\n",
            "1.1256375312805176  - epoch:  3  - batch:  210  - current_batch_loss:  0.013551589101552963  - current lr:  1e-05\n",
            "1.1150031089782715  - epoch:  3  - batch:  240  - current_batch_loss:  0.11820845305919647  - current lr:  1e-05\n",
            "1.1288607120513916  - epoch:  3  - batch:  270  - current_batch_loss:  0.3919181823730469  - current lr:  1e-05\n",
            "1.1239557266235352  - epoch:  3  - batch:  300  - current_batch_loss:  0.056238967925310135  - current lr:  1e-05\n",
            "1.1141018867492676  - epoch:  3  - batch:  330  - current_batch_loss:  0.11968426406383514  - current lr:  1e-05\n",
            "1.1297357082366943  - epoch:  3  - batch:  360  - current_batch_loss:  0.15834076702594757  - current lr:  1e-05\n",
            "1.1189675331115723  - epoch:  3  - batch:  390  - current_batch_loss:  0.14096908271312714  - current lr:  1e-05\n",
            "1.120514154434204  - epoch:  3  - batch:  420  - current_batch_loss:  0.17586924135684967  - current lr:  1e-05\n",
            "1.1105411052703857  - epoch:  3  - batch:  450  - current_batch_loss:  0.17253780364990234  - current lr:  1e-05\n",
            "1.120856761932373  - epoch:  3  - batch:  480  - current_batch_loss:  0.06085256487131119  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  3 after:  548.2519865036011\n",
            "Current_train_f1_macro:  0.8573517821652653  -  current_train_f1_micro:  0.9708905202681136\n",
            "Avg train_loss per batch:  0.09626348195015452\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  3  after:  264.97630286216736\n",
            "dev_f1_macro:  0.5248820441175299  -  dev_f1_micro:  0.9240931239848403\n",
            "Avg dev_loss per batch:  0.3699886091448821\n",
            "SAVING MODEL with better micro score...\n",
            "\n",
            "\n",
            "Start training epoch:  4\n",
            "1.1406059265136719  - epoch:  4  - batch:  0  - current_batch_loss:  0.018041670322418213  - current lr:  1e-05\n",
            "1.1204559803009033  - epoch:  4  - batch:  30  - current_batch_loss:  0.003643890144303441  - current lr:  1e-05\n",
            "1.1209027767181396  - epoch:  4  - batch:  60  - current_batch_loss:  0.01250410545617342  - current lr:  1e-05\n",
            "1.1217191219329834  - epoch:  4  - batch:  90  - current_batch_loss:  0.500708281993866  - current lr:  1e-05\n",
            "1.1157519817352295  - epoch:  4  - batch:  120  - current_batch_loss:  0.006853151135146618  - current lr:  1e-05\n",
            "1.122607946395874  - epoch:  4  - batch:  150  - current_batch_loss:  0.11740782856941223  - current lr:  1e-05\n",
            "1.1237592697143555  - epoch:  4  - batch:  180  - current_batch_loss:  0.22408734261989594  - current lr:  1e-05\n",
            "1.1265244483947754  - epoch:  4  - batch:  210  - current_batch_loss:  0.14159366488456726  - current lr:  1e-05\n",
            "1.130042314529419  - epoch:  4  - batch:  240  - current_batch_loss:  0.026405053213238716  - current lr:  1e-05\n",
            "1.130591869354248  - epoch:  4  - batch:  270  - current_batch_loss:  0.009509638883173466  - current lr:  1e-05\n",
            "1.12736177444458  - epoch:  4  - batch:  300  - current_batch_loss:  0.06529273092746735  - current lr:  1e-05\n",
            "1.1220083236694336  - epoch:  4  - batch:  330  - current_batch_loss:  0.01768816076219082  - current lr:  1e-05\n",
            "1.1187589168548584  - epoch:  4  - batch:  360  - current_batch_loss:  0.046363465487957  - current lr:  1e-05\n",
            "1.112091302871704  - epoch:  4  - batch:  390  - current_batch_loss:  0.026998382061719894  - current lr:  1e-05\n",
            "1.1161010265350342  - epoch:  4  - batch:  420  - current_batch_loss:  0.25493377447128296  - current lr:  1e-05\n",
            "1.1189115047454834  - epoch:  4  - batch:  450  - current_batch_loss:  0.02409600466489792  - current lr:  1e-05\n",
            "1.1084833145141602  - epoch:  4  - batch:  480  - current_batch_loss:  0.04119028151035309  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  4 after:  548.5553193092346\n",
            "Current_train_f1_macro:  0.8836112006990128  -  current_train_f1_micro:  0.9770826683689754\n",
            "Avg train_loss per batch:  0.07564012852211706\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  4  after:  265.1187701225281\n",
            "dev_f1_macro:  0.5399796799170399  -  dev_f1_micro:  0.9230102869518138\n",
            "Avg dev_loss per batch:  0.41638957844859886\n",
            "SAVING MODEL with better macro score...\n",
            "\n",
            "\n",
            "Start training epoch:  5\n",
            "1.1272177696228027  - epoch:  5  - batch:  0  - current_batch_loss:  0.006173594854772091  - current lr:  1e-05\n",
            "1.1163556575775146  - epoch:  5  - batch:  30  - current_batch_loss:  0.007255936041474342  - current lr:  1e-05\n",
            "1.1134483814239502  - epoch:  5  - batch:  60  - current_batch_loss:  0.10222779959440231  - current lr:  1e-05\n",
            "1.1204874515533447  - epoch:  5  - batch:  90  - current_batch_loss:  0.004182808101177216  - current lr:  1e-05\n",
            "1.1214492321014404  - epoch:  5  - batch:  120  - current_batch_loss:  0.07577717304229736  - current lr:  1e-05\n",
            "1.1255760192871094  - epoch:  5  - batch:  150  - current_batch_loss:  0.023304777219891548  - current lr:  1e-05\n",
            "1.1201696395874023  - epoch:  5  - batch:  180  - current_batch_loss:  0.032652463763952255  - current lr:  1e-05\n",
            "1.1276764869689941  - epoch:  5  - batch:  210  - current_batch_loss:  0.16987191140651703  - current lr:  1e-05\n",
            "1.113595724105835  - epoch:  5  - batch:  240  - current_batch_loss:  0.07528606802225113  - current lr:  1e-05\n",
            "1.1240832805633545  - epoch:  5  - batch:  270  - current_batch_loss:  0.13177624344825745  - current lr:  1e-05\n",
            "1.1218070983886719  - epoch:  5  - batch:  300  - current_batch_loss:  0.0015088502550497651  - current lr:  1e-05\n",
            "1.123387098312378  - epoch:  5  - batch:  330  - current_batch_loss:  0.040286529809236526  - current lr:  1e-05\n",
            "1.1209254264831543  - epoch:  5  - batch:  360  - current_batch_loss:  0.03777610510587692  - current lr:  1e-05\n",
            "1.1193759441375732  - epoch:  5  - batch:  390  - current_batch_loss:  0.19750767946243286  - current lr:  1e-05\n",
            "1.1190369129180908  - epoch:  5  - batch:  420  - current_batch_loss:  0.062172189354896545  - current lr:  1e-05\n",
            "1.1389143466949463  - epoch:  5  - batch:  450  - current_batch_loss:  0.04270991310477257  - current lr:  1e-05\n",
            "1.1108424663543701  - epoch:  5  - batch:  480  - current_batch_loss:  0.02746715024113655  - current lr:  1e-05\n",
            "\n",
            "\n",
            "Finish training epoch:  5 after:  548.3528394699097\n",
            "Current_train_f1_macro:  0.9065310480479593  -  current_train_f1_micro:  0.9800829875518672\n",
            "Avg train_loss per batch:  0.06833184919624746\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  5  after:  265.0021758079529\n",
            "dev_f1_macro:  0.5288492364215871  -  dev_f1_micro:  0.9255008121277748\n",
            "Avg dev_loss per batch:  0.4687181377966214\n",
            "SAVING MODEL with better micro score...\n",
            "\n",
            "\n",
            "Start training epoch:  6\n",
            "1.1548981666564941  - epoch:  6  - batch:  0  - current_batch_loss:  0.09109273552894592  - current lr:  9e-06\n",
            "1.11698317527771  - epoch:  6  - batch:  30  - current_batch_loss:  0.0009074814151972532  - current lr:  9e-06\n",
            "1.1206791400909424  - epoch:  6  - batch:  60  - current_batch_loss:  0.006026499904692173  - current lr:  9e-06\n",
            "1.1152896881103516  - epoch:  6  - batch:  90  - current_batch_loss:  0.015337108634412289  - current lr:  9e-06\n",
            "1.117652416229248  - epoch:  6  - batch:  120  - current_batch_loss:  0.004260753747075796  - current lr:  9e-06\n",
            "1.1180953979492188  - epoch:  6  - batch:  150  - current_batch_loss:  0.0017466223798692226  - current lr:  9e-06\n",
            "1.111849308013916  - epoch:  6  - batch:  180  - current_batch_loss:  0.0007673086947761476  - current lr:  9e-06\n",
            "1.1159961223602295  - epoch:  6  - batch:  210  - current_batch_loss:  0.01737128384411335  - current lr:  9e-06\n",
            "1.1092088222503662  - epoch:  6  - batch:  240  - current_batch_loss:  0.08153116703033447  - current lr:  9e-06\n",
            "1.1235477924346924  - epoch:  6  - batch:  270  - current_batch_loss:  0.3815593123435974  - current lr:  9e-06\n",
            "1.1158647537231445  - epoch:  6  - batch:  300  - current_batch_loss:  0.09816136956214905  - current lr:  9e-06\n",
            "1.1138439178466797  - epoch:  6  - batch:  330  - current_batch_loss:  0.12222148478031158  - current lr:  9e-06\n",
            "1.1227149963378906  - epoch:  6  - batch:  360  - current_batch_loss:  0.18885987997055054  - current lr:  9e-06\n",
            "1.1241538524627686  - epoch:  6  - batch:  390  - current_batch_loss:  0.04728245735168457  - current lr:  9e-06\n",
            "1.1159827709197998  - epoch:  6  - batch:  420  - current_batch_loss:  0.0050618755631148815  - current lr:  9e-06\n",
            "1.1111853122711182  - epoch:  6  - batch:  450  - current_batch_loss:  0.021328909322619438  - current lr:  9e-06\n",
            "1.1210038661956787  - epoch:  6  - batch:  480  - current_batch_loss:  0.009372221305966377  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  6 after:  548.234441280365\n",
            "Current_train_f1_macro:  0.9211807385990058  -  current_train_f1_micro:  0.9833386530481966\n",
            "Avg train_loss per batch:  0.056252212452244175\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  6  after:  264.94012093544006\n",
            "dev_f1_macro:  0.5313544409881992  -  dev_f1_micro:  0.9255008121277748\n",
            "Avg dev_loss per batch:  0.4722492589774785\n",
            "\n",
            "\n",
            "Start training epoch:  7\n",
            "1.116060495376587  - epoch:  7  - batch:  0  - current_batch_loss:  0.043142497539520264  - current lr:  9e-06\n",
            "1.109766960144043  - epoch:  7  - batch:  30  - current_batch_loss:  0.0006605424568988383  - current lr:  9e-06\n",
            "1.118377923965454  - epoch:  7  - batch:  60  - current_batch_loss:  0.0034650289453566074  - current lr:  9e-06\n",
            "1.1189918518066406  - epoch:  7  - batch:  90  - current_batch_loss:  0.001826081657782197  - current lr:  9e-06\n",
            "1.1200368404388428  - epoch:  7  - batch:  120  - current_batch_loss:  0.02324751764535904  - current lr:  9e-06\n",
            "1.1254899501800537  - epoch:  7  - batch:  150  - current_batch_loss:  0.02617565169930458  - current lr:  9e-06\n",
            "1.1282777786254883  - epoch:  7  - batch:  180  - current_batch_loss:  0.021265752613544464  - current lr:  9e-06\n",
            "1.1224820613861084  - epoch:  7  - batch:  210  - current_batch_loss:  0.028704235330224037  - current lr:  9e-06\n",
            "1.1219825744628906  - epoch:  7  - batch:  240  - current_batch_loss:  0.07276690751314163  - current lr:  9e-06\n",
            "1.1114215850830078  - epoch:  7  - batch:  270  - current_batch_loss:  0.01730898953974247  - current lr:  9e-06\n",
            "1.113722801208496  - epoch:  7  - batch:  300  - current_batch_loss:  0.005837570875883102  - current lr:  9e-06\n",
            "1.1220884323120117  - epoch:  7  - batch:  330  - current_batch_loss:  0.11248047649860382  - current lr:  9e-06\n",
            "1.1100711822509766  - epoch:  7  - batch:  360  - current_batch_loss:  0.0015105258207768202  - current lr:  9e-06\n",
            "1.1253352165222168  - epoch:  7  - batch:  390  - current_batch_loss:  0.007926873862743378  - current lr:  9e-06\n",
            "1.1118686199188232  - epoch:  7  - batch:  420  - current_batch_loss:  0.0017459489172324538  - current lr:  9e-06\n",
            "1.1174488067626953  - epoch:  7  - batch:  450  - current_batch_loss:  0.10031887888908386  - current lr:  9e-06\n",
            "1.1131742000579834  - epoch:  7  - batch:  480  - current_batch_loss:  0.002660716651007533  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  7 after:  548.1258907318115\n",
            "Current_train_f1_macro:  0.9401904691558474  -  current_train_f1_micro:  0.9862751356527291\n",
            "Avg train_loss per batch:  0.04648683843755565\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  7  after:  264.962908744812\n",
            "dev_f1_macro:  0.5124869494735622  -  dev_f1_micro:  0.926367081754196\n",
            "Avg dev_loss per batch:  0.5129986085785994\n",
            "SAVING MODEL with better micro score...\n",
            "\n",
            "\n",
            "Start training epoch:  8\n",
            "1.1296710968017578  - epoch:  8  - batch:  0  - current_batch_loss:  0.0001990088348975405  - current lr:  9e-06\n",
            "1.1154580116271973  - epoch:  8  - batch:  30  - current_batch_loss:  0.014059603214263916  - current lr:  9e-06\n",
            "1.1136643886566162  - epoch:  8  - batch:  60  - current_batch_loss:  0.0008009178563952446  - current lr:  9e-06\n",
            "1.1158616542816162  - epoch:  8  - batch:  90  - current_batch_loss:  0.0024734672624617815  - current lr:  9e-06\n",
            "1.123802661895752  - epoch:  8  - batch:  120  - current_batch_loss:  0.0030034156516194344  - current lr:  9e-06\n",
            "1.1156022548675537  - epoch:  8  - batch:  150  - current_batch_loss:  0.0009616522584110498  - current lr:  9e-06\n",
            "1.119922161102295  - epoch:  8  - batch:  180  - current_batch_loss:  0.0009834771044552326  - current lr:  9e-06\n",
            "1.123777151107788  - epoch:  8  - batch:  210  - current_batch_loss:  0.05695227161049843  - current lr:  9e-06\n",
            "1.1210482120513916  - epoch:  8  - batch:  240  - current_batch_loss:  0.013619650155305862  - current lr:  9e-06\n",
            "1.1200883388519287  - epoch:  8  - batch:  270  - current_batch_loss:  0.1844744235277176  - current lr:  9e-06\n",
            "1.1170849800109863  - epoch:  8  - batch:  300  - current_batch_loss:  0.014606422744691372  - current lr:  9e-06\n",
            "1.1275253295898438  - epoch:  8  - batch:  330  - current_batch_loss:  0.004401048179715872  - current lr:  9e-06\n",
            "1.1170170307159424  - epoch:  8  - batch:  360  - current_batch_loss:  0.032658886164426804  - current lr:  9e-06\n",
            "1.11501145362854  - epoch:  8  - batch:  390  - current_batch_loss:  0.005435688886791468  - current lr:  9e-06\n",
            "1.1221075057983398  - epoch:  8  - batch:  420  - current_batch_loss:  0.004504371900111437  - current lr:  9e-06\n",
            "1.1102232933044434  - epoch:  8  - batch:  450  - current_batch_loss:  0.006443616934120655  - current lr:  9e-06\n",
            "1.1137745380401611  - epoch:  8  - batch:  480  - current_batch_loss:  0.08715403825044632  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  8 after:  548.0639154911041\n",
            "Current_train_f1_macro:  0.9470225144371485  -  current_train_f1_micro:  0.9872965209064795\n",
            "Avg train_loss per batch:  0.044131580191353756\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  8  after:  264.8289465904236\n",
            "dev_f1_macro:  0.5979221832748252  -  dev_f1_micro:  0.916404981050352\n",
            "Avg dev_loss per batch:  0.460584767151167\n",
            "SAVING MODEL with better macro score...\n",
            "\n",
            "\n",
            "Start training epoch:  9\n",
            "1.1265361309051514  - epoch:  9  - batch:  0  - current_batch_loss:  0.10590141266584396  - current lr:  9e-06\n",
            "1.1177666187286377  - epoch:  9  - batch:  30  - current_batch_loss:  0.014624565839767456  - current lr:  9e-06\n",
            "1.1193912029266357  - epoch:  9  - batch:  60  - current_batch_loss:  0.007771819364279509  - current lr:  9e-06\n",
            "1.1322271823883057  - epoch:  9  - batch:  90  - current_batch_loss:  0.0018976235296577215  - current lr:  9e-06\n",
            "1.1149237155914307  - epoch:  9  - batch:  120  - current_batch_loss:  0.00020980996487196535  - current lr:  9e-06\n",
            "1.1122567653656006  - epoch:  9  - batch:  150  - current_batch_loss:  0.031095588579773903  - current lr:  9e-06\n",
            "1.1211776733398438  - epoch:  9  - batch:  180  - current_batch_loss:  0.009216917678713799  - current lr:  9e-06\n",
            "1.1200594902038574  - epoch:  9  - batch:  210  - current_batch_loss:  0.062288567423820496  - current lr:  9e-06\n",
            "1.1201395988464355  - epoch:  9  - batch:  240  - current_batch_loss:  0.0010801047319546342  - current lr:  9e-06\n",
            "1.1304075717926025  - epoch:  9  - batch:  270  - current_batch_loss:  0.034871816635131836  - current lr:  9e-06\n",
            "1.1120567321777344  - epoch:  9  - batch:  300  - current_batch_loss:  0.02600271999835968  - current lr:  9e-06\n",
            "1.1247367858886719  - epoch:  9  - batch:  330  - current_batch_loss:  0.02494777925312519  - current lr:  9e-06\n",
            "1.126465082168579  - epoch:  9  - batch:  360  - current_batch_loss:  0.040800150483846664  - current lr:  9e-06\n",
            "1.1236045360565186  - epoch:  9  - batch:  390  - current_batch_loss:  0.021040279418230057  - current lr:  9e-06\n",
            "1.1166486740112305  - epoch:  9  - batch:  420  - current_batch_loss:  0.0009522495674900711  - current lr:  9e-06\n",
            "1.1174261569976807  - epoch:  9  - batch:  450  - current_batch_loss:  0.08180917799472809  - current lr:  9e-06\n",
            "1.1207146644592285  - epoch:  9  - batch:  480  - current_batch_loss:  0.0015058590797707438  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  9 after:  547.9114093780518\n",
            "Current_train_f1_macro:  0.9543838605370558  -  current_train_f1_micro:  0.9892754548356208\n",
            "Avg train_loss per batch:  0.03672161044821539\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  9  after:  265.2563650608063\n",
            "dev_f1_macro:  0.5509322179009042  -  dev_f1_micro:  0.9262587980508934\n",
            "Avg dev_loss per batch:  0.5041975786244758\n",
            "\n",
            "\n",
            "Start training epoch:  10\n",
            "1.1175775527954102  - epoch:  10  - batch:  0  - current_batch_loss:  0.007712224032729864  - current lr:  9e-06\n",
            "1.1110754013061523  - epoch:  10  - batch:  30  - current_batch_loss:  0.0004405082145240158  - current lr:  9e-06\n",
            "1.1106293201446533  - epoch:  10  - batch:  60  - current_batch_loss:  0.0019000524189323187  - current lr:  9e-06\n",
            "1.1175475120544434  - epoch:  10  - batch:  90  - current_batch_loss:  0.000594017212279141  - current lr:  9e-06\n",
            "1.1136939525604248  - epoch:  10  - batch:  120  - current_batch_loss:  0.0018254445167258382  - current lr:  9e-06\n",
            "1.122950553894043  - epoch:  10  - batch:  150  - current_batch_loss:  0.00010058026236947626  - current lr:  9e-06\n",
            "1.113145112991333  - epoch:  10  - batch:  180  - current_batch_loss:  4.957205237587914e-05  - current lr:  9e-06\n",
            "1.1185941696166992  - epoch:  10  - batch:  210  - current_batch_loss:  0.00810846034437418  - current lr:  9e-06\n",
            "1.1171746253967285  - epoch:  10  - batch:  240  - current_batch_loss:  0.008576765656471252  - current lr:  9e-06\n",
            "1.1240489482879639  - epoch:  10  - batch:  270  - current_batch_loss:  0.009776948019862175  - current lr:  9e-06\n",
            "1.1193957328796387  - epoch:  10  - batch:  300  - current_batch_loss:  0.0034663130063563585  - current lr:  9e-06\n",
            "1.11962890625  - epoch:  10  - batch:  330  - current_batch_loss:  0.20320715010166168  - current lr:  9e-06\n",
            "1.1215174198150635  - epoch:  10  - batch:  360  - current_batch_loss:  0.026912258937954903  - current lr:  9e-06\n",
            "1.1146838665008545  - epoch:  10  - batch:  390  - current_batch_loss:  0.0007422036724165082  - current lr:  9e-06\n",
            "1.1155016422271729  - epoch:  10  - batch:  420  - current_batch_loss:  3.108086821157485e-05  - current lr:  9e-06\n",
            "1.117182970046997  - epoch:  10  - batch:  450  - current_batch_loss:  0.06951005011796951  - current lr:  9e-06\n",
            "1.1189441680908203  - epoch:  10  - batch:  480  - current_batch_loss:  0.05352208763360977  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  10 after:  547.8664786815643\n",
            "Current_train_f1_macro:  0.9564122839296714  -  current_train_f1_micro:  0.9894031279923396\n",
            "Avg train_loss per batch:  0.03325706750474637\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  10  after:  264.8283898830414\n",
            "dev_f1_macro:  0.573377710239054  -  dev_f1_micro:  0.9248511099079588\n",
            "Avg dev_loss per batch:  0.4838608480265035\n",
            "\n",
            "\n",
            "Start training epoch:  11\n",
            "1.1243205070495605  - epoch:  11  - batch:  0  - current_batch_loss:  0.002381659345701337  - current lr:  9e-06\n",
            "1.1089165210723877  - epoch:  11  - batch:  30  - current_batch_loss:  0.0006082794861868024  - current lr:  9e-06\n",
            "1.1254048347473145  - epoch:  11  - batch:  60  - current_batch_loss:  0.04990284889936447  - current lr:  9e-06\n",
            "1.1202330589294434  - epoch:  11  - batch:  90  - current_batch_loss:  0.2210683822631836  - current lr:  9e-06\n",
            "1.109954595565796  - epoch:  11  - batch:  120  - current_batch_loss:  0.0006228504935279489  - current lr:  9e-06\n",
            "1.1050021648406982  - epoch:  11  - batch:  150  - current_batch_loss:  7.28500381228514e-05  - current lr:  9e-06\n",
            "1.1203758716583252  - epoch:  11  - batch:  180  - current_batch_loss:  0.006831199862062931  - current lr:  9e-06\n",
            "1.126114845275879  - epoch:  11  - batch:  210  - current_batch_loss:  0.0008917978266254067  - current lr:  9e-06\n",
            "1.1151347160339355  - epoch:  11  - batch:  240  - current_batch_loss:  0.0012102373875677586  - current lr:  9e-06\n",
            "1.1177825927734375  - epoch:  11  - batch:  270  - current_batch_loss:  0.0003567842359188944  - current lr:  9e-06\n",
            "1.1230361461639404  - epoch:  11  - batch:  300  - current_batch_loss:  0.00539022171869874  - current lr:  9e-06\n",
            "1.1187398433685303  - epoch:  11  - batch:  330  - current_batch_loss:  0.0025413918774574995  - current lr:  9e-06\n",
            "1.1172730922698975  - epoch:  11  - batch:  360  - current_batch_loss:  0.00059360614977777  - current lr:  9e-06\n",
            "1.107191801071167  - epoch:  11  - batch:  390  - current_batch_loss:  0.0006028247880749404  - current lr:  9e-06\n",
            "1.1099128723144531  - epoch:  11  - batch:  420  - current_batch_loss:  0.0004062540247105062  - current lr:  9e-06\n",
            "1.1233305931091309  - epoch:  11  - batch:  450  - current_batch_loss:  0.0013733734376728535  - current lr:  9e-06\n",
            "1.1113824844360352  - epoch:  11  - batch:  480  - current_batch_loss:  0.0010398513404652476  - current lr:  9e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  11 after:  547.7341828346252\n",
            "Current_train_f1_macro:  0.9583783065480599  -  current_train_f1_micro:  0.9901691669326524\n",
            "Avg train_loss per batch:  0.035913781829807874\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  11  after:  264.9015939235687\n",
            "dev_f1_macro:  0.5346637957053944  -  dev_f1_micro:  0.9251759610178668\n",
            "Avg dev_loss per batch:  0.5732890765903278\n",
            "\n",
            "\n",
            "Start training epoch:  12\n",
            "1.1125187873840332  - epoch:  12  - batch:  0  - current_batch_loss:  0.1531323492527008  - current lr:  8.1e-06\n",
            "1.1211023330688477  - epoch:  12  - batch:  30  - current_batch_loss:  0.004816106986254454  - current lr:  8.1e-06\n",
            "1.1275653839111328  - epoch:  12  - batch:  60  - current_batch_loss:  0.08413130789995193  - current lr:  8.1e-06\n",
            "1.1209931373596191  - epoch:  12  - batch:  90  - current_batch_loss:  0.001614443608559668  - current lr:  8.1e-06\n",
            "1.114863634109497  - epoch:  12  - batch:  120  - current_batch_loss:  0.00017280326574109495  - current lr:  8.1e-06\n",
            "1.1098618507385254  - epoch:  12  - batch:  150  - current_batch_loss:  0.002794776577502489  - current lr:  8.1e-06\n",
            "1.1177401542663574  - epoch:  12  - batch:  180  - current_batch_loss:  0.05936863273382187  - current lr:  8.1e-06\n",
            "1.11983060836792  - epoch:  12  - batch:  210  - current_batch_loss:  0.003782600164413452  - current lr:  8.1e-06\n",
            "1.1185081005096436  - epoch:  12  - batch:  240  - current_batch_loss:  0.1424325555562973  - current lr:  8.1e-06\n",
            "1.1126434803009033  - epoch:  12  - batch:  270  - current_batch_loss:  8.163152961060405e-05  - current lr:  8.1e-06\n",
            "1.1143054962158203  - epoch:  12  - batch:  300  - current_batch_loss:  0.055484894663095474  - current lr:  8.1e-06\n",
            "1.1284472942352295  - epoch:  12  - batch:  330  - current_batch_loss:  0.0029554874636232853  - current lr:  8.1e-06\n",
            "1.120455265045166  - epoch:  12  - batch:  360  - current_batch_loss:  0.008300211280584335  - current lr:  8.1e-06\n",
            "1.1144094467163086  - epoch:  12  - batch:  390  - current_batch_loss:  0.012658621184527874  - current lr:  8.1e-06\n",
            "1.1138598918914795  - epoch:  12  - batch:  420  - current_batch_loss:  0.00012139770842622966  - current lr:  8.1e-06\n",
            "1.1038966178894043  - epoch:  12  - batch:  450  - current_batch_loss:  0.00016200421669054776  - current lr:  8.1e-06\n",
            "1.117650032043457  - epoch:  12  - batch:  480  - current_batch_loss:  0.005849837325513363  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  12 after:  547.4659602642059\n",
            "Current_train_f1_macro:  0.9720660942139057  -  current_train_f1_micro:  0.992339610596872\n",
            "Avg train_loss per batch:  0.025784131782166715\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  12  after:  264.6952905654907\n",
            "dev_f1_macro:  0.5533806362190061  -  dev_f1_micro:  0.926042230644288\n",
            "Avg dev_loss per batch:  0.5414225839786749\n",
            "\n",
            "\n",
            "Start training epoch:  13\n",
            "1.1092684268951416  - epoch:  13  - batch:  0  - current_batch_loss:  0.000732850341591984  - current lr:  8.1e-06\n",
            "1.1131417751312256  - epoch:  13  - batch:  30  - current_batch_loss:  0.0032364416401833296  - current lr:  8.1e-06\n",
            "1.1130411624908447  - epoch:  13  - batch:  60  - current_batch_loss:  0.0027395435608923435  - current lr:  8.1e-06\n",
            "1.1325831413269043  - epoch:  13  - batch:  90  - current_batch_loss:  0.002774316817522049  - current lr:  8.1e-06\n",
            "1.1144683361053467  - epoch:  13  - batch:  120  - current_batch_loss:  0.0018013936933130026  - current lr:  8.1e-06\n",
            "1.119093418121338  - epoch:  13  - batch:  150  - current_batch_loss:  0.05439573526382446  - current lr:  8.1e-06\n",
            "1.1154391765594482  - epoch:  13  - batch:  180  - current_batch_loss:  0.009218533523380756  - current lr:  8.1e-06\n",
            "1.1171164512634277  - epoch:  13  - batch:  210  - current_batch_loss:  0.0011817248305305839  - current lr:  8.1e-06\n",
            "1.1182503700256348  - epoch:  13  - batch:  240  - current_batch_loss:  0.049421295523643494  - current lr:  8.1e-06\n",
            "1.117046594619751  - epoch:  13  - batch:  270  - current_batch_loss:  0.0015342974802479148  - current lr:  8.1e-06\n",
            "1.116079330444336  - epoch:  13  - batch:  300  - current_batch_loss:  7.47867306927219e-05  - current lr:  8.1e-06\n",
            "1.119459629058838  - epoch:  13  - batch:  330  - current_batch_loss:  0.001764926710166037  - current lr:  8.1e-06\n",
            "1.1164350509643555  - epoch:  13  - batch:  360  - current_batch_loss:  0.0009685519617050886  - current lr:  8.1e-06\n",
            "1.1044986248016357  - epoch:  13  - batch:  390  - current_batch_loss:  0.00549516873434186  - current lr:  8.1e-06\n",
            "1.1183547973632812  - epoch:  13  - batch:  420  - current_batch_loss:  0.06238340586423874  - current lr:  8.1e-06\n",
            "1.116405963897705  - epoch:  13  - batch:  450  - current_batch_loss:  0.0036257717292755842  - current lr:  8.1e-06\n",
            "1.1211135387420654  - epoch:  13  - batch:  480  - current_batch_loss:  0.009580027312040329  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  13 after:  547.5048115253448\n",
            "Current_train_f1_macro:  0.9739902125462253  -  current_train_f1_micro:  0.9934886690073412\n",
            "Avg train_loss per batch:  0.022682601967982212\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  13  after:  264.7358160018921\n",
            "dev_f1_macro:  0.5647581360068368  -  dev_f1_micro:  0.9262587980508934\n",
            "Avg dev_loss per batch:  0.5418562481304202\n",
            "\n",
            "\n",
            "Start training epoch:  14\n",
            "1.1197834014892578  - epoch:  14  - batch:  0  - current_batch_loss:  0.004515339620411396  - current lr:  8.1e-06\n",
            "1.1190276145935059  - epoch:  14  - batch:  30  - current_batch_loss:  0.0017714716959744692  - current lr:  8.1e-06\n",
            "1.1166822910308838  - epoch:  14  - batch:  60  - current_batch_loss:  0.00032292306423187256  - current lr:  8.1e-06\n",
            "1.1185812950134277  - epoch:  14  - batch:  90  - current_batch_loss:  0.14485803246498108  - current lr:  8.1e-06\n",
            "1.1149680614471436  - epoch:  14  - batch:  120  - current_batch_loss:  0.016192736104130745  - current lr:  8.1e-06\n",
            "1.1159629821777344  - epoch:  14  - batch:  150  - current_batch_loss:  0.270004540681839  - current lr:  8.1e-06\n",
            "1.1240181922912598  - epoch:  14  - batch:  180  - current_batch_loss:  0.007095749024301767  - current lr:  8.1e-06\n",
            "1.1134412288665771  - epoch:  14  - batch:  210  - current_batch_loss:  0.0036664875224232674  - current lr:  8.1e-06\n",
            "1.1220791339874268  - epoch:  14  - batch:  240  - current_batch_loss:  0.0003504616324789822  - current lr:  8.1e-06\n",
            "1.1186943054199219  - epoch:  14  - batch:  270  - current_batch_loss:  0.03183482587337494  - current lr:  8.1e-06\n",
            "1.1118957996368408  - epoch:  14  - batch:  300  - current_batch_loss:  0.003698962274938822  - current lr:  8.1e-06\n",
            "1.118356466293335  - epoch:  14  - batch:  330  - current_batch_loss:  0.00023318277089856565  - current lr:  8.1e-06\n",
            "1.109689474105835  - epoch:  14  - batch:  360  - current_batch_loss:  0.0055528804659843445  - current lr:  8.1e-06\n",
            "1.1144258975982666  - epoch:  14  - batch:  390  - current_batch_loss:  0.14813412725925446  - current lr:  8.1e-06\n",
            "1.1123781204223633  - epoch:  14  - batch:  420  - current_batch_loss:  0.10319175571203232  - current lr:  8.1e-06\n",
            "1.1206791400909424  - epoch:  14  - batch:  450  - current_batch_loss:  0.0002612664538901299  - current lr:  8.1e-06\n",
            "1.1224610805511475  - epoch:  14  - batch:  480  - current_batch_loss:  0.0027784856501966715  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  14 after:  547.3900165557861\n",
            "Current_train_f1_macro:  0.9714204949092013  -  current_train_f1_micro:  0.993297159272263\n",
            "Avg train_loss per batch:  0.022728904322934795\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  14  after:  265.04338908195496\n",
            "dev_f1_macro:  0.5347230341212671  -  dev_f1_micro:  0.9246345425013536\n",
            "Avg dev_loss per batch:  0.5904954282042028\n",
            "\n",
            "\n",
            "Start training epoch:  15\n",
            "1.118828535079956  - epoch:  15  - batch:  0  - current_batch_loss:  0.016342230141162872  - current lr:  8.1e-06\n",
            "1.1174914836883545  - epoch:  15  - batch:  30  - current_batch_loss:  0.0009544222848489881  - current lr:  8.1e-06\n",
            "1.1168854236602783  - epoch:  15  - batch:  60  - current_batch_loss:  0.0009802100248634815  - current lr:  8.1e-06\n",
            "1.1188464164733887  - epoch:  15  - batch:  90  - current_batch_loss:  0.0003544088685885072  - current lr:  8.1e-06\n",
            "1.1235082149505615  - epoch:  15  - batch:  120  - current_batch_loss:  0.000530325691215694  - current lr:  8.1e-06\n",
            "1.1157348155975342  - epoch:  15  - batch:  150  - current_batch_loss:  0.07645650953054428  - current lr:  8.1e-06\n",
            "1.1044731140136719  - epoch:  15  - batch:  180  - current_batch_loss:  0.0003397251130081713  - current lr:  8.1e-06\n",
            "1.1251814365386963  - epoch:  15  - batch:  210  - current_batch_loss:  0.04018883407115936  - current lr:  8.1e-06\n",
            "1.1174218654632568  - epoch:  15  - batch:  240  - current_batch_loss:  0.0010138902580365539  - current lr:  8.1e-06\n",
            "1.1175246238708496  - epoch:  15  - batch:  270  - current_batch_loss:  0.001215556520037353  - current lr:  8.1e-06\n",
            "1.1241576671600342  - epoch:  15  - batch:  300  - current_batch_loss:  0.004655185155570507  - current lr:  8.1e-06\n",
            "1.1252338886260986  - epoch:  15  - batch:  330  - current_batch_loss:  0.006787933874875307  - current lr:  8.1e-06\n",
            "1.1350734233856201  - epoch:  15  - batch:  360  - current_batch_loss:  0.0009357639937661588  - current lr:  8.1e-06\n",
            "1.1175827980041504  - epoch:  15  - batch:  390  - current_batch_loss:  0.034640949219465256  - current lr:  8.1e-06\n",
            "1.1120924949645996  - epoch:  15  - batch:  420  - current_batch_loss:  0.003108568489551544  - current lr:  8.1e-06\n",
            "1.1155586242675781  - epoch:  15  - batch:  450  - current_batch_loss:  0.0004265432071406394  - current lr:  8.1e-06\n",
            "1.1140377521514893  - epoch:  15  - batch:  480  - current_batch_loss:  0.00019853710546158254  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  15 after:  547.7422916889191\n",
            "Current_train_f1_macro:  0.974459968721545  -  current_train_f1_micro:  0.9943185445260134\n",
            "Avg train_loss per batch:  0.02053959177176378\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  15  after:  265.0125072002411\n",
            "dev_f1_macro:  0.532671293835894  -  dev_f1_micro:  0.9250676773145642\n",
            "Avg dev_loss per batch:  0.6266698949626787\n",
            "\n",
            "\n",
            "Start training epoch:  16\n",
            "1.114593744277954  - epoch:  16  - batch:  0  - current_batch_loss:  0.007803437765687704  - current lr:  8.1e-06\n",
            "1.1224730014801025  - epoch:  16  - batch:  30  - current_batch_loss:  0.0002679275057744235  - current lr:  8.1e-06\n",
            "1.1175580024719238  - epoch:  16  - batch:  60  - current_batch_loss:  0.010605727322399616  - current lr:  8.1e-06\n",
            "1.1241064071655273  - epoch:  16  - batch:  90  - current_batch_loss:  0.008562183938920498  - current lr:  8.1e-06\n",
            "1.1172559261322021  - epoch:  16  - batch:  120  - current_batch_loss:  8.753273141337559e-05  - current lr:  8.1e-06\n",
            "1.1147594451904297  - epoch:  16  - batch:  150  - current_batch_loss:  0.00010531503357924521  - current lr:  8.1e-06\n",
            "1.1176588535308838  - epoch:  16  - batch:  180  - current_batch_loss:  0.00620629359036684  - current lr:  8.1e-06\n",
            "1.120851755142212  - epoch:  16  - batch:  210  - current_batch_loss:  0.0001042928925016895  - current lr:  8.1e-06\n",
            "1.126115322113037  - epoch:  16  - batch:  240  - current_batch_loss:  0.0007221278501674533  - current lr:  8.1e-06\n",
            "1.1203856468200684  - epoch:  16  - batch:  270  - current_batch_loss:  0.0014708919916301966  - current lr:  8.1e-06\n",
            "1.131880760192871  - epoch:  16  - batch:  300  - current_batch_loss:  0.03142585977911949  - current lr:  8.1e-06\n",
            "1.1119928359985352  - epoch:  16  - batch:  330  - current_batch_loss:  0.000354031944880262  - current lr:  8.1e-06\n",
            "1.1234536170959473  - epoch:  16  - batch:  360  - current_batch_loss:  0.06609170883893967  - current lr:  8.1e-06\n",
            "1.1150591373443604  - epoch:  16  - batch:  390  - current_batch_loss:  0.000959648983553052  - current lr:  8.1e-06\n",
            "1.117532730102539  - epoch:  16  - batch:  420  - current_batch_loss:  0.00112174975220114  - current lr:  8.1e-06\n",
            "1.1155781745910645  - epoch:  16  - batch:  450  - current_batch_loss:  0.0002495524240657687  - current lr:  8.1e-06\n",
            "1.1210834980010986  - epoch:  16  - batch:  480  - current_batch_loss:  0.001315370318479836  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  16 after:  548.064825296402\n",
            "Current_train_f1_macro:  0.9778441939254872  -  current_train_f1_micro:  0.994573890839451\n",
            "Avg train_loss per batch:  0.01860992450892716\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  16  after:  265.2844331264496\n",
            "dev_f1_macro:  0.5354732373666423  -  dev_f1_micro:  0.9250676773145642\n",
            "Avg dev_loss per batch:  0.5981104973852515\n",
            "\n",
            "\n",
            "Start training epoch:  17\n",
            "1.1111054420471191  - epoch:  17  - batch:  0  - current_batch_loss:  0.0005895061185583472  - current lr:  8.1e-06\n",
            "1.1196770668029785  - epoch:  17  - batch:  30  - current_batch_loss:  0.0070380656979978085  - current lr:  8.1e-06\n",
            "1.121946096420288  - epoch:  17  - batch:  60  - current_batch_loss:  0.00022466789232566953  - current lr:  8.1e-06\n",
            "1.1121058464050293  - epoch:  17  - batch:  90  - current_batch_loss:  0.00018465673201717436  - current lr:  8.1e-06\n",
            "1.1233525276184082  - epoch:  17  - batch:  120  - current_batch_loss:  0.13669094443321228  - current lr:  8.1e-06\n",
            "1.1173145771026611  - epoch:  17  - batch:  150  - current_batch_loss:  0.0004313113749958575  - current lr:  8.1e-06\n",
            "1.1178898811340332  - epoch:  17  - batch:  180  - current_batch_loss:  0.00043448570067994297  - current lr:  8.1e-06\n",
            "1.1167807579040527  - epoch:  17  - batch:  210  - current_batch_loss:  0.00017848446441348642  - current lr:  8.1e-06\n",
            "1.114816665649414  - epoch:  17  - batch:  240  - current_batch_loss:  0.08888167887926102  - current lr:  8.1e-06\n",
            "1.117023229598999  - epoch:  17  - batch:  270  - current_batch_loss:  0.009726935997605324  - current lr:  8.1e-06\n",
            "1.1199266910552979  - epoch:  17  - batch:  300  - current_batch_loss:  0.017232634127140045  - current lr:  8.1e-06\n",
            "1.1173057556152344  - epoch:  17  - batch:  330  - current_batch_loss:  0.00019632710609585047  - current lr:  8.1e-06\n",
            "1.116246223449707  - epoch:  17  - batch:  360  - current_batch_loss:  0.005927192512899637  - current lr:  8.1e-06\n",
            "1.1114931106567383  - epoch:  17  - batch:  390  - current_batch_loss:  0.00020786092500202358  - current lr:  8.1e-06\n",
            "1.1245877742767334  - epoch:  17  - batch:  420  - current_batch_loss:  0.0008935608202591538  - current lr:  8.1e-06\n",
            "1.1172828674316406  - epoch:  17  - batch:  450  - current_batch_loss:  0.001060214708559215  - current lr:  8.1e-06\n",
            "1.1169443130493164  - epoch:  17  - batch:  480  - current_batch_loss:  0.022269519045948982  - current lr:  8.1e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  17 after:  548.3547582626343\n",
            "Current_train_f1_macro:  0.9832543844875877  -  current_train_f1_micro:  0.9959144589849984\n",
            "Avg train_loss per batch:  0.014160918379646932\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  17  after:  265.30381989479065\n",
            "dev_f1_macro:  0.5295757673615591  -  dev_f1_micro:  0.923876556578235\n",
            "Avg dev_loss per batch:  0.6325052104667699\n",
            "\n",
            "\n",
            "Start training epoch:  18\n",
            "1.12214994430542  - epoch:  18  - batch:  0  - current_batch_loss:  0.0014416341437026858  - current lr:  7.290000000000001e-06\n",
            "1.1181318759918213  - epoch:  18  - batch:  30  - current_batch_loss:  0.11567583680152893  - current lr:  7.290000000000001e-06\n",
            "1.1198561191558838  - epoch:  18  - batch:  60  - current_batch_loss:  0.0003506008069962263  - current lr:  7.290000000000001e-06\n",
            "1.1169459819793701  - epoch:  18  - batch:  90  - current_batch_loss:  0.0024653044529259205  - current lr:  7.290000000000001e-06\n",
            "1.1234993934631348  - epoch:  18  - batch:  120  - current_batch_loss:  0.002238623332232237  - current lr:  7.290000000000001e-06\n",
            "1.1216859817504883  - epoch:  18  - batch:  150  - current_batch_loss:  0.00038905837573111057  - current lr:  7.290000000000001e-06\n",
            "1.113567590713501  - epoch:  18  - batch:  180  - current_batch_loss:  0.0007340671145357192  - current lr:  7.290000000000001e-06\n",
            "1.1277492046356201  - epoch:  18  - batch:  210  - current_batch_loss:  0.0024893786758184433  - current lr:  7.290000000000001e-06\n",
            "1.1409902572631836  - epoch:  18  - batch:  240  - current_batch_loss:  0.013836742378771305  - current lr:  7.290000000000001e-06\n",
            "1.1222567558288574  - epoch:  18  - batch:  270  - current_batch_loss:  0.030827181413769722  - current lr:  7.290000000000001e-06\n",
            "1.1196610927581787  - epoch:  18  - batch:  300  - current_batch_loss:  0.0014671643730252981  - current lr:  7.290000000000001e-06\n",
            "1.1132028102874756  - epoch:  18  - batch:  330  - current_batch_loss:  0.0005452147452160716  - current lr:  7.290000000000001e-06\n",
            "1.1125383377075195  - epoch:  18  - batch:  360  - current_batch_loss:  5.91574571444653e-05  - current lr:  7.290000000000001e-06\n",
            "1.1207153797149658  - epoch:  18  - batch:  390  - current_batch_loss:  0.0002499357215128839  - current lr:  7.290000000000001e-06\n",
            "1.1232953071594238  - epoch:  18  - batch:  420  - current_batch_loss:  0.005237310193479061  - current lr:  7.290000000000001e-06\n",
            "1.1177759170532227  - epoch:  18  - batch:  450  - current_batch_loss:  0.0015602882485836744  - current lr:  7.290000000000001e-06\n",
            "1.1214993000030518  - epoch:  18  - batch:  480  - current_batch_loss:  0.0002069411420961842  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  18 after:  548.3891623020172\n",
            "Current_train_f1_macro:  0.9818673775405959  -  current_train_f1_micro:  0.9957229492499202\n",
            "Avg train_loss per batch:  0.013783168836233723\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  18  after:  265.1180851459503\n",
            "dev_f1_macro:  0.5778400357954852  -  dev_f1_micro:  0.9206280454791553\n",
            "Avg dev_loss per batch:  0.59190255999577\n",
            "\n",
            "\n",
            "Start training epoch:  19\n",
            "1.1194572448730469  - epoch:  19  - batch:  0  - current_batch_loss:  0.033567432314157486  - current lr:  7.290000000000001e-06\n",
            "1.1236889362335205  - epoch:  19  - batch:  30  - current_batch_loss:  0.00029063387773931026  - current lr:  7.290000000000001e-06\n",
            "1.115786075592041  - epoch:  19  - batch:  60  - current_batch_loss:  0.0007813881966285408  - current lr:  7.290000000000001e-06\n",
            "1.1127681732177734  - epoch:  19  - batch:  90  - current_batch_loss:  0.003112120321020484  - current lr:  7.290000000000001e-06\n",
            "1.1098816394805908  - epoch:  19  - batch:  120  - current_batch_loss:  0.00037667356082238257  - current lr:  7.290000000000001e-06\n",
            "1.1143648624420166  - epoch:  19  - batch:  150  - current_batch_loss:  0.0005005736602470279  - current lr:  7.290000000000001e-06\n",
            "1.114426612854004  - epoch:  19  - batch:  180  - current_batch_loss:  2.3629709176020697e-05  - current lr:  7.290000000000001e-06\n",
            "1.1187469959259033  - epoch:  19  - batch:  210  - current_batch_loss:  0.003474343800917268  - current lr:  7.290000000000001e-06\n",
            "1.121061086654663  - epoch:  19  - batch:  240  - current_batch_loss:  0.0001349332887912169  - current lr:  7.290000000000001e-06\n",
            "1.120368242263794  - epoch:  19  - batch:  270  - current_batch_loss:  0.0008728100219741464  - current lr:  7.290000000000001e-06\n",
            "1.1216552257537842  - epoch:  19  - batch:  300  - current_batch_loss:  2.4496175683452748e-05  - current lr:  7.290000000000001e-06\n",
            "1.1238460540771484  - epoch:  19  - batch:  330  - current_batch_loss:  0.002130106557160616  - current lr:  7.290000000000001e-06\n",
            "1.1106517314910889  - epoch:  19  - batch:  360  - current_batch_loss:  0.009356340393424034  - current lr:  7.290000000000001e-06\n",
            "1.1201655864715576  - epoch:  19  - batch:  390  - current_batch_loss:  0.0016562540549784899  - current lr:  7.290000000000001e-06\n",
            "1.121201992034912  - epoch:  19  - batch:  420  - current_batch_loss:  0.00020029004372190684  - current lr:  7.290000000000001e-06\n",
            "1.1225049495697021  - epoch:  19  - batch:  450  - current_batch_loss:  0.0039055836386978626  - current lr:  7.290000000000001e-06\n",
            "1.1209752559661865  - epoch:  19  - batch:  480  - current_batch_loss:  0.0016751679359003901  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  19 after:  548.0027537345886\n",
            "Current_train_f1_macro:  0.9841649234676104  -  current_train_f1_micro:  0.995850622406639\n",
            "Avg train_loss per batch:  0.013048749417169589\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  19  after:  265.2213668823242\n",
            "dev_f1_macro:  0.5357838514224585  -  dev_f1_micro:  0.9251759610178668\n",
            "Avg dev_loss per batch:  0.6161555984156722\n",
            "\n",
            "\n",
            "Start training epoch:  20\n",
            "1.1169514656066895  - epoch:  20  - batch:  0  - current_batch_loss:  0.0007337768329307437  - current lr:  7.290000000000001e-06\n",
            "1.124169111251831  - epoch:  20  - batch:  30  - current_batch_loss:  0.0015573780983686447  - current lr:  7.290000000000001e-06\n",
            "1.1270108222961426  - epoch:  20  - batch:  60  - current_batch_loss:  0.08932984620332718  - current lr:  7.290000000000001e-06\n",
            "1.1165754795074463  - epoch:  20  - batch:  90  - current_batch_loss:  0.0011450566817075014  - current lr:  7.290000000000001e-06\n",
            "1.1317617893218994  - epoch:  20  - batch:  120  - current_batch_loss:  0.013719279319047928  - current lr:  7.290000000000001e-06\n",
            "1.118467092514038  - epoch:  20  - batch:  150  - current_batch_loss:  0.0048207868821918964  - current lr:  7.290000000000001e-06\n",
            "1.1344349384307861  - epoch:  20  - batch:  180  - current_batch_loss:  0.00037264038110151887  - current lr:  7.290000000000001e-06\n",
            "1.1120960712432861  - epoch:  20  - batch:  210  - current_batch_loss:  0.0004425093065947294  - current lr:  7.290000000000001e-06\n",
            "1.1189234256744385  - epoch:  20  - batch:  240  - current_batch_loss:  0.006343028042465448  - current lr:  7.290000000000001e-06\n",
            "1.1221375465393066  - epoch:  20  - batch:  270  - current_batch_loss:  0.09772079437971115  - current lr:  7.290000000000001e-06\n",
            "1.1189768314361572  - epoch:  20  - batch:  300  - current_batch_loss:  0.0012684891698881984  - current lr:  7.290000000000001e-06\n",
            "1.1140222549438477  - epoch:  20  - batch:  330  - current_batch_loss:  0.0007840053294785321  - current lr:  7.290000000000001e-06\n",
            "1.1166908740997314  - epoch:  20  - batch:  360  - current_batch_loss:  0.00012629995762836188  - current lr:  7.290000000000001e-06\n",
            "1.122910499572754  - epoch:  20  - batch:  390  - current_batch_loss:  0.008436781354248524  - current lr:  7.290000000000001e-06\n",
            "1.1232390403747559  - epoch:  20  - batch:  420  - current_batch_loss:  0.0005448387819342315  - current lr:  7.290000000000001e-06\n",
            "1.1201910972595215  - epoch:  20  - batch:  450  - current_batch_loss:  0.0002888983581215143  - current lr:  7.290000000000001e-06\n",
            "1.1193010807037354  - epoch:  20  - batch:  480  - current_batch_loss:  4.030274067190476e-05  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  20 after:  547.950113773346\n",
            "Current_train_f1_macro:  0.9878818498824588  -  current_train_f1_micro:  0.9966166613469518\n",
            "Avg train_loss per batch:  0.01185057000349834\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  20  after:  265.0747308731079\n",
            "dev_f1_macro:  0.5549948817113095  -  dev_f1_micro:  0.9251759610178668\n",
            "Avg dev_loss per batch:  0.6171745922100842\n",
            "\n",
            "\n",
            "Start training epoch:  21\n",
            "1.110959529876709  - epoch:  21  - batch:  0  - current_batch_loss:  9.730501187732443e-05  - current lr:  7.290000000000001e-06\n",
            "1.1214499473571777  - epoch:  21  - batch:  30  - current_batch_loss:  0.024646202102303505  - current lr:  7.290000000000001e-06\n",
            "1.1205368041992188  - epoch:  21  - batch:  60  - current_batch_loss:  0.0007233353680931032  - current lr:  7.290000000000001e-06\n",
            "1.1262149810791016  - epoch:  21  - batch:  90  - current_batch_loss:  0.0005986053729429841  - current lr:  7.290000000000001e-06\n",
            "1.1162314414978027  - epoch:  21  - batch:  120  - current_batch_loss:  0.00015669876302126795  - current lr:  7.290000000000001e-06\n",
            "1.1199052333831787  - epoch:  21  - batch:  150  - current_batch_loss:  0.00028122420189902186  - current lr:  7.290000000000001e-06\n",
            "1.1165268421173096  - epoch:  21  - batch:  180  - current_batch_loss:  0.000379058561520651  - current lr:  7.290000000000001e-06\n",
            "1.1200478076934814  - epoch:  21  - batch:  210  - current_batch_loss:  0.005471557844430208  - current lr:  7.290000000000001e-06\n",
            "1.1261875629425049  - epoch:  21  - batch:  240  - current_batch_loss:  0.0006745465798303485  - current lr:  7.290000000000001e-06\n",
            "1.113175392150879  - epoch:  21  - batch:  270  - current_batch_loss:  0.0023431959562003613  - current lr:  7.290000000000001e-06\n",
            "1.117250919342041  - epoch:  21  - batch:  300  - current_batch_loss:  0.00661030039191246  - current lr:  7.290000000000001e-06\n",
            "1.120586633682251  - epoch:  21  - batch:  330  - current_batch_loss:  0.024694854393601418  - current lr:  7.290000000000001e-06\n",
            "1.1235251426696777  - epoch:  21  - batch:  360  - current_batch_loss:  0.0007657282403670251  - current lr:  7.290000000000001e-06\n",
            "1.1148478984832764  - epoch:  21  - batch:  390  - current_batch_loss:  0.001177858910523355  - current lr:  7.290000000000001e-06\n",
            "1.1215858459472656  - epoch:  21  - batch:  420  - current_batch_loss:  2.7038990083383396e-05  - current lr:  7.290000000000001e-06\n",
            "1.1117641925811768  - epoch:  21  - batch:  450  - current_batch_loss:  7.276904216269031e-05  - current lr:  7.290000000000001e-06\n",
            "1.1227235794067383  - epoch:  21  - batch:  480  - current_batch_loss:  0.008782442659139633  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  21 after:  547.872316122055\n",
            "Current_train_f1_macro:  0.9882942664605363  -  current_train_f1_micro:  0.9970635173954676\n",
            "Avg train_loss per batch:  0.00966107640303318\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  21  after:  265.03567934036255\n",
            "dev_f1_macro:  0.532856497721509  -  dev_f1_micro:  0.9235517054683269\n",
            "Avg dev_loss per batch:  0.6438913876203344\n",
            "\n",
            "\n",
            "Start training epoch:  22\n",
            "1.1071672439575195  - epoch:  22  - batch:  0  - current_batch_loss:  2.923061401816085e-05  - current lr:  7.290000000000001e-06\n",
            "1.1093647480010986  - epoch:  22  - batch:  30  - current_batch_loss:  0.000653541530482471  - current lr:  7.290000000000001e-06\n",
            "1.1210639476776123  - epoch:  22  - batch:  60  - current_batch_loss:  0.0002850080491043627  - current lr:  7.290000000000001e-06\n",
            "1.1178357601165771  - epoch:  22  - batch:  90  - current_batch_loss:  0.002297238213941455  - current lr:  7.290000000000001e-06\n",
            "1.1194884777069092  - epoch:  22  - batch:  120  - current_batch_loss:  0.0001573569024913013  - current lr:  7.290000000000001e-06\n",
            "1.1235706806182861  - epoch:  22  - batch:  150  - current_batch_loss:  0.017444105818867683  - current lr:  7.290000000000001e-06\n",
            "1.1198437213897705  - epoch:  22  - batch:  180  - current_batch_loss:  0.011686346493661404  - current lr:  7.290000000000001e-06\n",
            "1.1139016151428223  - epoch:  22  - batch:  210  - current_batch_loss:  0.0003976284642703831  - current lr:  7.290000000000001e-06\n",
            "1.119072675704956  - epoch:  22  - batch:  240  - current_batch_loss:  0.0004116876807529479  - current lr:  7.290000000000001e-06\n",
            "1.1260030269622803  - epoch:  22  - batch:  270  - current_batch_loss:  0.004007785581052303  - current lr:  7.290000000000001e-06\n",
            "1.1061902046203613  - epoch:  22  - batch:  300  - current_batch_loss:  2.3948110538185574e-05  - current lr:  7.290000000000001e-06\n",
            "1.111814260482788  - epoch:  22  - batch:  330  - current_batch_loss:  9.845304884947836e-05  - current lr:  7.290000000000001e-06\n",
            "1.1098322868347168  - epoch:  22  - batch:  360  - current_batch_loss:  0.0006178722251206636  - current lr:  7.290000000000001e-06\n",
            "1.1141817569732666  - epoch:  22  - batch:  390  - current_batch_loss:  0.1831596940755844  - current lr:  7.290000000000001e-06\n",
            "1.1206045150756836  - epoch:  22  - batch:  420  - current_batch_loss:  0.00010615671635605395  - current lr:  7.290000000000001e-06\n",
            "1.1185693740844727  - epoch:  22  - batch:  450  - current_batch_loss:  0.01008643489331007  - current lr:  7.290000000000001e-06\n",
            "1.1196374893188477  - epoch:  22  - batch:  480  - current_batch_loss:  0.00011254040146013722  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  22 after:  547.5993778705597\n",
            "Current_train_f1_macro:  0.9911430748531389  -  current_train_f1_micro:  0.9975742100223428\n",
            "Avg train_loss per batch:  0.008650445137473348\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  22  after:  265.0123224258423\n",
            "dev_f1_macro:  0.5540562739324391  -  dev_f1_micro:  0.9252842447211694\n",
            "Avg dev_loss per batch:  0.6685017261729106\n",
            "\n",
            "\n",
            "Start training epoch:  23\n",
            "1.1179687976837158  - epoch:  23  - batch:  0  - current_batch_loss:  0.0005487730377353728  - current lr:  7.290000000000001e-06\n",
            "1.1154088973999023  - epoch:  23  - batch:  30  - current_batch_loss:  8.348104529432021e-06  - current lr:  7.290000000000001e-06\n",
            "1.1176047325134277  - epoch:  23  - batch:  60  - current_batch_loss:  2.2910551706445403e-05  - current lr:  7.290000000000001e-06\n",
            "1.108363389968872  - epoch:  23  - batch:  90  - current_batch_loss:  0.00032807019306346774  - current lr:  7.290000000000001e-06\n",
            "1.1102118492126465  - epoch:  23  - batch:  120  - current_batch_loss:  6.405618478311226e-05  - current lr:  7.290000000000001e-06\n",
            "1.1052944660186768  - epoch:  23  - batch:  150  - current_batch_loss:  0.00036355742486193776  - current lr:  7.290000000000001e-06\n",
            "1.121119737625122  - epoch:  23  - batch:  180  - current_batch_loss:  0.0035175420343875885  - current lr:  7.290000000000001e-06\n",
            "1.1202442646026611  - epoch:  23  - batch:  210  - current_batch_loss:  6.037877028575167e-05  - current lr:  7.290000000000001e-06\n",
            "1.1151034832000732  - epoch:  23  - batch:  240  - current_batch_loss:  0.00013967513223178685  - current lr:  7.290000000000001e-06\n",
            "1.1163561344146729  - epoch:  23  - batch:  270  - current_batch_loss:  0.0004975575720891356  - current lr:  7.290000000000001e-06\n",
            "1.125213861465454  - epoch:  23  - batch:  300  - current_batch_loss:  0.00021535322593990713  - current lr:  7.290000000000001e-06\n",
            "1.1281583309173584  - epoch:  23  - batch:  330  - current_batch_loss:  0.00042945879977196455  - current lr:  7.290000000000001e-06\n",
            "1.1111929416656494  - epoch:  23  - batch:  360  - current_batch_loss:  0.0004947574343532324  - current lr:  7.290000000000001e-06\n",
            "1.1204628944396973  - epoch:  23  - batch:  390  - current_batch_loss:  0.0012872136430814862  - current lr:  7.290000000000001e-06\n",
            "1.1164686679840088  - epoch:  23  - batch:  420  - current_batch_loss:  0.0005580061115324497  - current lr:  7.290000000000001e-06\n",
            "1.1363277435302734  - epoch:  23  - batch:  450  - current_batch_loss:  0.001240291865542531  - current lr:  7.290000000000001e-06\n",
            "1.1175899505615234  - epoch:  23  - batch:  480  - current_batch_loss:  0.0022319762501865625  - current lr:  7.290000000000001e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  23 after:  547.7398755550385\n",
            "Current_train_f1_macro:  0.9907204570105275  -  current_train_f1_micro:  0.997765719757421\n",
            "Avg train_loss per batch:  0.008219238408579068\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  23  after:  265.09757900238037\n",
            "dev_f1_macro:  0.5761512755307931  -  dev_f1_micro:  0.9232268543584191\n",
            "Avg dev_loss per batch:  0.6035415786387328\n",
            "\n",
            "\n",
            "Start training epoch:  24\n",
            "1.1155803203582764  - epoch:  24  - batch:  0  - current_batch_loss:  0.05321468412876129  - current lr:  6.561e-06\n",
            "1.1231157779693604  - epoch:  24  - batch:  30  - current_batch_loss:  0.00011877260112669319  - current lr:  6.561e-06\n",
            "1.1187047958374023  - epoch:  24  - batch:  60  - current_batch_loss:  0.07734628766775131  - current lr:  6.561e-06\n",
            "1.1190283298492432  - epoch:  24  - batch:  90  - current_batch_loss:  0.0017308760434389114  - current lr:  6.561e-06\n",
            "1.1114726066589355  - epoch:  24  - batch:  120  - current_batch_loss:  0.00014533191279042512  - current lr:  6.561e-06\n",
            "1.114295482635498  - epoch:  24  - batch:  150  - current_batch_loss:  0.004129321314394474  - current lr:  6.561e-06\n",
            "1.1102259159088135  - epoch:  24  - batch:  180  - current_batch_loss:  0.0032989669125527143  - current lr:  6.561e-06\n",
            "1.1196677684783936  - epoch:  24  - batch:  210  - current_batch_loss:  0.0007763586472719908  - current lr:  6.561e-06\n",
            "1.1304216384887695  - epoch:  24  - batch:  240  - current_batch_loss:  0.0010175403440371156  - current lr:  6.561e-06\n",
            "1.1093635559082031  - epoch:  24  - batch:  270  - current_batch_loss:  0.00016333947132807225  - current lr:  6.561e-06\n",
            "1.109496831893921  - epoch:  24  - batch:  300  - current_batch_loss:  5.3000963816884905e-05  - current lr:  6.561e-06\n",
            "1.1193501949310303  - epoch:  24  - batch:  330  - current_batch_loss:  0.00016649917233735323  - current lr:  6.561e-06\n",
            "1.1183054447174072  - epoch:  24  - batch:  360  - current_batch_loss:  8.330367563758045e-05  - current lr:  6.561e-06\n",
            "1.1319520473480225  - epoch:  24  - batch:  390  - current_batch_loss:  0.0010159274097532034  - current lr:  6.561e-06\n",
            "1.1101562976837158  - epoch:  24  - batch:  420  - current_batch_loss:  0.00031947746174409986  - current lr:  6.561e-06\n",
            "1.1079809665679932  - epoch:  24  - batch:  450  - current_batch_loss:  7.8466662671417e-05  - current lr:  6.561e-06\n",
            "1.1150264739990234  - epoch:  24  - batch:  480  - current_batch_loss:  0.00033043298753909767  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  24 after:  547.6485550403595\n",
            "Current_train_f1_macro:  0.9902802132409616  -  current_train_f1_micro:  0.9977018831790616\n",
            "Avg train_loss per batch:  0.007831907235435656\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  24  after:  265.03942012786865\n",
            "dev_f1_macro:  0.5475199568226835  -  dev_f1_micro:  0.9216025988088793\n",
            "Avg dev_loss per batch:  0.6418380973547783\n",
            "\n",
            "\n",
            "Start training epoch:  25\n",
            "1.1252062320709229  - epoch:  25  - batch:  0  - current_batch_loss:  0.00039381650276482105  - current lr:  6.561e-06\n",
            "1.1315052509307861  - epoch:  25  - batch:  30  - current_batch_loss:  0.001568903331644833  - current lr:  6.561e-06\n",
            "1.1140260696411133  - epoch:  25  - batch:  60  - current_batch_loss:  0.00045081437565386295  - current lr:  6.561e-06\n",
            "1.1150684356689453  - epoch:  25  - batch:  90  - current_batch_loss:  2.17840752156917e-05  - current lr:  6.561e-06\n",
            "1.112849473953247  - epoch:  25  - batch:  120  - current_batch_loss:  0.0006349951727315784  - current lr:  6.561e-06\n",
            "1.119807243347168  - epoch:  25  - batch:  150  - current_batch_loss:  0.0006542677874676883  - current lr:  6.561e-06\n",
            "1.1104824542999268  - epoch:  25  - batch:  180  - current_batch_loss:  0.0001232690119650215  - current lr:  6.561e-06\n",
            "1.1316537857055664  - epoch:  25  - batch:  210  - current_batch_loss:  0.0034694699570536613  - current lr:  6.561e-06\n",
            "1.1169688701629639  - epoch:  25  - batch:  240  - current_batch_loss:  4.207867823424749e-05  - current lr:  6.561e-06\n",
            "1.1276593208312988  - epoch:  25  - batch:  270  - current_batch_loss:  0.0002806843549478799  - current lr:  6.561e-06\n",
            "1.1210682392120361  - epoch:  25  - batch:  300  - current_batch_loss:  0.0020014969632029533  - current lr:  6.561e-06\n",
            "1.1126794815063477  - epoch:  25  - batch:  330  - current_batch_loss:  0.0004491623258218169  - current lr:  6.561e-06\n",
            "1.1141424179077148  - epoch:  25  - batch:  360  - current_batch_loss:  0.00036730762803927064  - current lr:  6.561e-06\n",
            "1.1153500080108643  - epoch:  25  - batch:  390  - current_batch_loss:  0.01463302318006754  - current lr:  6.561e-06\n",
            "1.1181838512420654  - epoch:  25  - batch:  420  - current_batch_loss:  0.000548717740457505  - current lr:  6.561e-06\n",
            "1.1163175106048584  - epoch:  25  - batch:  450  - current_batch_loss:  0.00018605995865073055  - current lr:  6.561e-06\n",
            "1.114246129989624  - epoch:  25  - batch:  480  - current_batch_loss:  4.025876478408463e-05  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  25 after:  547.4977698326111\n",
            "Current_train_f1_macro:  0.9924213130929992  -  current_train_f1_micro:  0.9978933929141398\n",
            "Avg train_loss per batch:  0.0067614428640015425\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  25  after:  264.96675729751587\n",
            "dev_f1_macro:  0.519310869880156  -  dev_f1_micro:  0.9244179750947482\n",
            "Avg dev_loss per batch:  0.6982987546146031\n",
            "\n",
            "\n",
            "Start training epoch:  26\n",
            "1.1193506717681885  - epoch:  26  - batch:  0  - current_batch_loss:  0.0005632557440549135  - current lr:  6.561e-06\n",
            "1.1065673828125  - epoch:  26  - batch:  30  - current_batch_loss:  0.0005440527456812561  - current lr:  6.561e-06\n",
            "1.1122710704803467  - epoch:  26  - batch:  60  - current_batch_loss:  0.00016034484724514186  - current lr:  6.561e-06\n",
            "1.1087346076965332  - epoch:  26  - batch:  90  - current_batch_loss:  0.0003166952228639275  - current lr:  6.561e-06\n",
            "1.1132926940917969  - epoch:  26  - batch:  120  - current_batch_loss:  0.00023722728656139225  - current lr:  6.561e-06\n",
            "1.113645076751709  - epoch:  26  - batch:  150  - current_batch_loss:  0.0003551747358869761  - current lr:  6.561e-06\n",
            "1.1183195114135742  - epoch:  26  - batch:  180  - current_batch_loss:  0.007103643845766783  - current lr:  6.561e-06\n",
            "1.1272404193878174  - epoch:  26  - batch:  210  - current_batch_loss:  0.0027346904389560223  - current lr:  6.561e-06\n",
            "1.12559175491333  - epoch:  26  - batch:  240  - current_batch_loss:  0.1001344621181488  - current lr:  6.561e-06\n",
            "1.1215951442718506  - epoch:  26  - batch:  270  - current_batch_loss:  0.0005842297687195241  - current lr:  6.561e-06\n",
            "1.1208863258361816  - epoch:  26  - batch:  300  - current_batch_loss:  9.442794544156641e-05  - current lr:  6.561e-06\n",
            "1.1165492534637451  - epoch:  26  - batch:  330  - current_batch_loss:  0.024833356961607933  - current lr:  6.561e-06\n",
            "1.1227056980133057  - epoch:  26  - batch:  360  - current_batch_loss:  0.0024802745319902897  - current lr:  6.561e-06\n",
            "1.122255802154541  - epoch:  26  - batch:  390  - current_batch_loss:  9.220100764650851e-05  - current lr:  6.561e-06\n",
            "1.1109559535980225  - epoch:  26  - batch:  420  - current_batch_loss:  0.0003177183971274644  - current lr:  6.561e-06\n",
            "1.1240007877349854  - epoch:  26  - batch:  450  - current_batch_loss:  0.0412491038441658  - current lr:  6.561e-06\n",
            "1.1225056648254395  - epoch:  26  - batch:  480  - current_batch_loss:  0.0019279507687315345  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  26 after:  547.4413065910339\n",
            "Current_train_f1_macro:  0.9909431599110663  -  current_train_f1_micro:  0.9980210660708586\n",
            "Avg train_loss per batch:  0.007236266652084015\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  26  after:  264.8660137653351\n",
            "dev_f1_macro:  0.5417821412053129  -  dev_f1_micro:  0.9244179750947482\n",
            "Avg dev_loss per batch:  0.6695231960326681\n",
            "\n",
            "\n",
            "Start training epoch:  27\n",
            "1.1180140972137451  - epoch:  27  - batch:  0  - current_batch_loss:  0.00035141879925504327  - current lr:  6.561e-06\n",
            "1.1145682334899902  - epoch:  27  - batch:  30  - current_batch_loss:  9.36517390073277e-05  - current lr:  6.561e-06\n",
            "1.1188700199127197  - epoch:  27  - batch:  60  - current_batch_loss:  0.0005081184790469706  - current lr:  6.561e-06\n",
            "1.109964370727539  - epoch:  27  - batch:  90  - current_batch_loss:  0.12239667773246765  - current lr:  6.561e-06\n",
            "1.111687421798706  - epoch:  27  - batch:  120  - current_batch_loss:  0.0002914444194175303  - current lr:  6.561e-06\n",
            "1.1192710399627686  - epoch:  27  - batch:  150  - current_batch_loss:  0.005227326415479183  - current lr:  6.561e-06\n",
            "1.1144168376922607  - epoch:  27  - batch:  180  - current_batch_loss:  0.0003883140452671796  - current lr:  6.561e-06\n",
            "1.1168434619903564  - epoch:  27  - batch:  210  - current_batch_loss:  0.0004366594657767564  - current lr:  6.561e-06\n",
            "1.108314037322998  - epoch:  27  - batch:  240  - current_batch_loss:  0.0002113012596964836  - current lr:  6.561e-06\n",
            "1.11326265335083  - epoch:  27  - batch:  270  - current_batch_loss:  0.00037311899359337986  - current lr:  6.561e-06\n",
            "1.1154780387878418  - epoch:  27  - batch:  300  - current_batch_loss:  0.00018392267520539463  - current lr:  6.561e-06\n",
            "1.1119694709777832  - epoch:  27  - batch:  330  - current_batch_loss:  0.0001729952055029571  - current lr:  6.561e-06\n",
            "1.1093738079071045  - epoch:  27  - batch:  360  - current_batch_loss:  3.912035026587546e-05  - current lr:  6.561e-06\n",
            "1.1172809600830078  - epoch:  27  - batch:  390  - current_batch_loss:  4.4576558138942346e-05  - current lr:  6.561e-06\n",
            "1.1129803657531738  - epoch:  27  - batch:  420  - current_batch_loss:  1.2939120097144041e-05  - current lr:  6.561e-06\n",
            "1.1284081935882568  - epoch:  27  - batch:  450  - current_batch_loss:  0.0007577099022455513  - current lr:  6.561e-06\n",
            "1.1195666790008545  - epoch:  27  - batch:  480  - current_batch_loss:  0.005518341902643442  - current lr:  6.561e-06\n",
            "\n",
            "\n",
            "Finish training epoch:  27 after:  547.2618892192841\n",
            "Current_train_f1_macro:  0.9922917222686518  -  current_train_f1_micro:  0.9982125758059368\n",
            "Avg train_loss per batch:  0.006316736998150079\n",
            "\n",
            "Evaluating on dev set...\n",
            "Finish eval epoch:  27  after:  264.9464247226715\n",
            "dev_f1_macro:  0.5356944634939558  -  dev_f1_micro:  0.9243096913914456\n",
            "Avg dev_loss per batch:  0.6719783182527\n",
            "\n",
            "\n",
            "Start training epoch:  28\n",
            "1.1195964813232422  - epoch:  28  - batch:  0  - current_batch_loss:  0.0019290472846478224  - current lr:  6.561e-06\n",
            "1.105175495147705  - epoch:  28  - batch:  30  - current_batch_loss:  0.00011013424955308437  - current lr:  6.561e-06\n",
            "1.107978105545044  - epoch:  28  - batch:  60  - current_batch_loss:  0.0002790761645883322  - current lr:  6.561e-06\n",
            "1.1183886528015137  - epoch:  28  - batch:  90  - current_batch_loss:  0.00023924560809973627  - current lr:  6.561e-06\n",
            "1.1073589324951172  - epoch:  28  - batch:  120  - current_batch_loss:  0.0005663863266818225  - current lr:  6.561e-06\n",
            "1.1194672584533691  - epoch:  28  - batch:  150  - current_batch_loss:  0.00016532311565242708  - current lr:  6.561e-06\n",
            "1.1170411109924316  - epoch:  28  - batch:  180  - current_batch_loss:  0.0014771786518394947  - current lr:  6.561e-06\n",
            "1.1183066368103027  - epoch:  28  - batch:  210  - current_batch_loss:  7.407870725728571e-05  - current lr:  6.561e-06\n",
            "1.1246914863586426  - epoch:  28  - batch:  240  - current_batch_loss:  0.02427762560546398  - current lr:  6.561e-06\n",
            "1.1143250465393066  - epoch:  28  - batch:  270  - current_batch_loss:  1.0139126061403658e-05  - current lr:  6.561e-06\n",
            "1.1232943534851074  - epoch:  28  - batch:  300  - current_batch_loss:  0.013758309185504913  - current lr:  6.561e-06\n",
            "1.1169276237487793  - epoch:  28  - batch:  330  - current_batch_loss:  0.0002791724109556526  - current lr:  6.561e-06\n",
            "1.1197493076324463  - epoch:  28  - batch:  360  - current_batch_loss:  0.00041600081021897495  - current lr:  6.561e-06\n",
            "1.1165673732757568  - epoch:  28  - batch:  390  - current_batch_loss:  0.00013992881576996297  - current lr:  6.561e-06\n",
            "1.1183154582977295  - epoch:  28  - batch:  420  - current_batch_loss:  0.00014949373144190758  - current lr:  6.561e-06\n",
            "1.1043355464935303  - epoch:  28  - batch:  450  - current_batch_loss:  3.515196658554487e-05  - current lr:  6.561e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-3c19cf9a3b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_f1_score_macro_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_f1_score_micro_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-91-05eb43f07168>\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(flags, train_dataset, dev_dataset, save_path)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Acquires the network's best guesses at each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_entity_1_eids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_entity_2_eids\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mxlmr_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_entity_1_eids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_entity_2_eids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# Computes loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-7bc044a2adad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pb_input_ids, pb_attention_masks, pb_entity_1_eids, pb_entity_2_eids, xlmr_input_ids, xlmr_attention_masks, xlmr_entity_1_eids, xlmr_entity_2_eids)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpb_sent_final_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_entity_1_eids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_entity_2_eids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mxlmr_sent_final_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlmr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlmr_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_entity_1_eids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlmr_entity_2_eids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# concat two embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-410b730c324d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, b_input_ids, b_attention_mask, b_entity_1_eids, b_entity_2_eids)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mb_sent_final_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sent_final_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_entity_1_eids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_entity_2_eids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb_sent_final_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-410b730c324d>\u001b[0m in \u001b[0;36mget_sent_final_vector\u001b[0;34m(self, hidden_states, b_entity_1_eids, b_entity_2_eids)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mentity_1_final_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entity_embedding_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_entity_1_eids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mentity_2_final_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entity_embedding_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_entity_2_eids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-410b730c324d>\u001b[0m in \u001b[0;36mget_entity_embedding_vector\u001b[0;34m(self, hidden_states, entity_eids, isent)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mient_eid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_eid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_eids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                    \u001b[0;31m# từng word piece của entity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mentity_eid\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# nếu gặp padding wpi (-2) thì dừng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mient_eid\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No wpi id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}